<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Aprendizaje Automático 1</title>
  <meta name="description" content="Aprendizaje Automático 1" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Aprendizaje Automático 1" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Aprendizaje Automático 1" />
  
  
  

<meta name="author" content="Juan R González" />


<meta name="date" content="2023-09-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Aprendizaje Automático 1</h1>
<p class="author"><em>Juan R González</em></p>
<p class="date"><em>2023-09-06</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#introducción" id="toc-introducción"><span class="toc-section-number">1</span> Introducción</a></li>
<li><a href="#introducción-a-tidyverse" id="toc-introducción-a-tidyverse"><span class="toc-section-number">2</span> Introducción a Tidyverse</a>
<ul>
<li><a href="#introducción-1" id="toc-introducción-1"><span class="toc-section-number">2.1</span> Introducción</a></li>
<li><a href="#instalación" id="toc-instalación"><span class="toc-section-number">2.2</span> Instalación</a></li>
<li><a href="#librerías-básicas" id="toc-librerías-básicas"><span class="toc-section-number">2.3</span> Librerías básicas</a></li>
<li><a href="#manejo-de-datos" id="toc-manejo-de-datos"><span class="toc-section-number">2.4</span> Manejo de datos</a>
<ul>
<li><a href="#tibbles" id="toc-tibbles"><span class="toc-section-number">2.4.1</span> Tibbles</a></li>
<li><a href="#importar-datos" id="toc-importar-datos"><span class="toc-section-number">2.4.2</span> Importar datos</a></li>
<li><a href="#transformación-de-datos" id="toc-transformación-de-datos"><span class="toc-section-number">2.4.3</span> Transformación de datos</a></li>
<li><a href="#filtrar-filas" id="toc-filtrar-filas"><span class="toc-section-number">2.4.4</span> Filtrar filas</a></li>
<li><a href="#filtrado-lógico" id="toc-filtrado-lógico"><span class="toc-section-number">2.4.5</span> Filtrado lógico</a></li>
<li><a href="#ordenar-filas" id="toc-ordenar-filas"><span class="toc-section-number">2.4.6</span> Ordenar filas</a></li>
<li><a href="#seleccionar-columnas-e.g.-variables" id="toc-seleccionar-columnas-e.g.-variables"><span class="toc-section-number">2.4.7</span> Seleccionar columnas (e.g. variables)</a></li>
<li><a href="#añadir-nuevas-variables" id="toc-añadir-nuevas-variables"><span class="toc-section-number">2.4.8</span> Añadir nuevas variables</a></li>
<li><a href="#grouped-summaries" id="toc-grouped-summaries"><span class="toc-section-number">2.4.9</span> Grouped summaries</a></li>
</ul></li>
<li><a href="#uso-del-pipe" id="toc-uso-del-pipe"><span class="toc-section-number">2.5</span> Uso del pipe <code>%&gt;%</code></a></li>
<li><a href="#ejercicios-manejo-de-datos" id="toc-ejercicios-manejo-de-datos"><span class="toc-section-number">2.6</span> Ejercicios (manejo de datos)</a></li>
<li><a href="#visualización-de-datos" id="toc-visualización-de-datos"><span class="toc-section-number">2.7</span> Visualización de datos</a>
<ul>
<li><a href="#distribución-de-datos-categóricos" id="toc-distribución-de-datos-categóricos"><span class="toc-section-number">2.7.1</span> Distribución de datos categóricos</a></li>
<li><a href="#distribución-de-datos-continuos" id="toc-distribución-de-datos-continuos"><span class="toc-section-number">2.7.2</span> Distribución de datos continuos</a></li>
<li><a href="#distribución-de-datos-continuos-según-una-variable-categórica" id="toc-distribución-de-datos-continuos-según-una-variable-categórica"><span class="toc-section-number">2.7.3</span> Distribución de datos continuos según una variable categórica</a></li>
<li><a href="#dos-variables-categóricas" id="toc-dos-variables-categóricas"><span class="toc-section-number">2.7.4</span> Dos variables categóricas</a></li>
<li><a href="#dos-variables-continuas" id="toc-dos-variables-continuas"><span class="toc-section-number">2.7.5</span> Dos variables continuas</a></li>
<li><a href="#facets" id="toc-facets"><span class="toc-section-number">2.7.6</span> Facets</a></li>
</ul></li>
<li><a href="#ejercicios-visualización-de-datos" id="toc-ejercicios-visualización-de-datos"><span class="toc-section-number">2.8</span> Ejercicios (Visualización de datos)</a></li>
</ul></li>
<li><a href="#introducción-al-aprendizaje-automático" id="toc-introducción-al-aprendizaje-automático"><span class="toc-section-number">3</span> Introducción al Aprendizaje Automático</a></li>
<li><a href="#regresión-lineal" id="toc-regresión-lineal"><span class="toc-section-number">4</span> Regresión lineal</a>
<ul>
<li><a href="#preliminares" id="toc-preliminares"><span class="toc-section-number">4.1</span> Preliminares</a></li>
<li><a href="#conceptos-básicos" id="toc-conceptos-básicos"><span class="toc-section-number">4.2</span> Conceptos básicos</a>
<ul>
<li><a href="#modelo-lineal-simple" id="toc-modelo-lineal-simple"><span class="toc-section-number">4.2.1</span> Modelo lineal simple</a></li>
<li><a href="#regresión-lineal-multivariante" id="toc-regresión-lineal-multivariante"><span class="toc-section-number">4.2.2</span> Regresión lineal multivariante</a></li>
<li><a href="#incertidumbre" id="toc-incertidumbre"><span class="toc-section-number">4.2.3</span> Incertidumbre</a></li>
</ul></li>
<li><a href="#ajuste-de-un-modelo-lineal" id="toc-ajuste-de-un-modelo-lineal"><span class="toc-section-number">4.3</span> Ajuste de un modelo lineal</a>
<ul>
<li><a href="#residuos" id="toc-residuos"><span class="toc-section-number">4.3.1</span> Residuos</a></li>
<li><a href="#interpretación-de-coeficientes" id="toc-interpretación-de-coeficientes"><span class="toc-section-number">4.3.2</span> Interpretación de coeficientes</a></li>
<li><a href="#interacciones" id="toc-interacciones"><span class="toc-section-number">4.3.3</span> Interacciones</a></li>
</ul></li>
<li><a href="#estimación-por-mínimos-cuadrados" id="toc-estimación-por-mínimos-cuadrados"><span class="toc-section-number">4.4</span> Estimación por mínimos cuadrados</a></li>
<li><a href="#medidas-adicionales-de-ajuste-del-modelo" id="toc-medidas-adicionales-de-ajuste-del-modelo"><span class="toc-section-number">4.5</span> Medidas adicionales de ajuste del modelo</a></li>
<li><a href="#sesgo-variación-sobreajuste" id="toc-sesgo-variación-sobreajuste"><span class="toc-section-number">4.6</span> Sesgo, variación, sobreajuste</a></li>
<li><a href="#regresión-como-estimación-de-una-media-condicional" id="toc-regresión-como-estimación-de-una-media-condicional"><span class="toc-section-number">4.7</span> Regresión como estimación de una media condicional</a></li>
<li><a href="#la-función-de-regresión" id="toc-la-función-de-regresión"><span class="toc-section-number">4.8</span> La función de regresión</a></li>
<li><a href="#estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn" id="toc-estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn"><span class="toc-section-number">4.9</span> Estimación no paramétrica de la función de regresión: regresión KNN</a></li>
<li><a href="#estimación-paramétrica-de-la-función-de-regresión-regresión-lineal" id="toc-estimación-paramétrica-de-la-función-de-regresión-regresión-lineal"><span class="toc-section-number">4.10</span> Estimación paramétrica de la función de regresión: regresión lineal</a>
<ul>
<li><a href="#ejercicio" id="toc-ejercicio"><span class="toc-section-number">4.10.1</span> Ejercicio</a></li>
</ul></li>
<li><a href="#predicción" id="toc-predicción"><span class="toc-section-number">4.11</span> Predicción</a></li>
<li><a href="#inferencia-en-el-contexto-de-regresión" id="toc-inferencia-en-el-contexto-de-regresión"><span class="toc-section-number">4.12</span> Inferencia en el contexto de regresión</a></li>
<li><a href="#asunciones-de-un-modelo-de-regresión" id="toc-asunciones-de-un-modelo-de-regresión"><span class="toc-section-number">4.13</span> Asunciones de un modelo de regresión</a></li>
<li><a href="#ejemplos-adicionales-de-interpretación-de-modelos" id="toc-ejemplos-adicionales-de-interpretación-de-modelos"><span class="toc-section-number">4.14</span> Ejemplos adicionales de interpretación de modelos</a>
<ul>
<li><a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos" id="toc-interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos"><span class="toc-section-number">4.14.1</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos</a></li>
<li><a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos" id="toc-interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos"><span class="toc-section-number">4.14.2</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos</a></li>
<li><a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones" id="toc-interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones"><span class="toc-section-number">4.14.3</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos, con interacciones</a></li>
<li><a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones" id="toc-interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones"><span class="toc-section-number">4.14.4</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos, con interacciones</a></li>
</ul></li>
<li><a href="#centrado-y-escalado" id="toc-centrado-y-escalado"><span class="toc-section-number">4.15</span> Centrado y escalado</a></li>
<li><a href="#transformación-de-variables" id="toc-transformación-de-variables"><span class="toc-section-number">4.16</span> Transformación de variables</a></li>
<li><a href="#colinealidad" id="toc-colinealidad"><span class="toc-section-number">4.17</span> Colinealidad</a></li>
<li><a href="#valores-atípicos" id="toc-valores-atípicos"><span class="toc-section-number">4.18</span> Valores atípicos</a></li>
</ul></li>
<li><a href="#ajuste-de-modelos" id="toc-ajuste-de-modelos"><span class="toc-section-number">5</span> Ajuste de modelos</a>
<ul>
<li><a href="#reglas-generales-para-la-selección-de-variables" id="toc-reglas-generales-para-la-selección-de-variables"><span class="toc-section-number">5.1</span> Reglas generales para la selección de variables</a></li>
<li><a href="#selección-paso-a-paso-stepwise" id="toc-selección-paso-a-paso-stepwise"><span class="toc-section-number">5.2</span> Selección paso a paso (stepwise)</a></li>
<li><a href="#comparación-de-modelos" id="toc-comparación-de-modelos"><span class="toc-section-number">5.3</span> Comparación de modelos</a></li>
<li><a href="#métodos-de-selección-automática" id="toc-métodos-de-selección-automática"><span class="toc-section-number">5.4</span> Métodos de selección automática</a></li>
<li><a href="#validación-cruzada" id="toc-validación-cruzada"><span class="toc-section-number">5.5</span> Validación cruzada</a>
<ul>
<li><a href="#validación-en-un-conjunto-de-datos-externo" id="toc-validación-en-un-conjunto-de-datos-externo"><span class="toc-section-number">5.5.1</span> Validación en un conjunto de datos externo</a></li>
<li><a href="#leave-one-out-cross-validation-loocv" id="toc-leave-one-out-cross-validation-loocv"><span class="toc-section-number">5.5.2</span> Leave-one-out cross validation (LOOCV)</a></li>
<li><a href="#k-fold-cross-validation-k-fold-cv" id="toc-k-fold-cross-validation-k-fold-cv"><span class="toc-section-number">5.5.3</span> K-fold cross validation (K-fold CV)</a></li>
<li><a href="#uso-de-cv-para-estimar-el-hiper-parámetro" id="toc-uso-de-cv-para-estimar-el-hiper-parámetro"><span class="toc-section-number">5.5.4</span> Uso de CV para estimar el hiper-parámetro</a></li>
<li><a href="#uso-de-bootstrap" id="toc-uso-de-bootstrap"><span class="toc-section-number">5.5.5</span> Uso de bootstrap</a></li>
</ul></li>
<li><a href="#imputación-de-datos-faltantes" id="toc-imputación-de-datos-faltantes"><span class="toc-section-number">5.6</span> Imputación de datos faltantes</a></li>
</ul></li>
<li><a href="#regresión-logística" id="toc-regresión-logística"><span class="toc-section-number">6</span> Regresión logística</a>
<ul>
<li><a href="#la-función-logit-inversa" id="toc-la-función-logit-inversa"><span class="toc-section-number">6.1</span> La función logit inversa</a></li>
<li><a href="#ejemplo-de-regresión-logística" id="toc-ejemplo-de-regresión-logística"><span class="toc-section-number">6.2</span> Ejemplo de regresión logística</a></li>
<li><a href="#coeficientes-de-regresión-logística-como-probabilidades" id="toc-coeficientes-de-regresión-logística-como-probabilidades"><span class="toc-section-number">6.3</span> Coeficientes de regresión logística como probabilidades</a></li>
<li><a href="#coeficientes-de-regresión-logística-como-razones-de-odds" id="toc-coeficientes-de-regresión-logística-como-razones-de-odds"><span class="toc-section-number">6.4</span> Coeficientes de regresión logística como razones de odds</a></li>
<li><a href="#capacidad-predictiva-de-un-modelo-de-clasificación" id="toc-capacidad-predictiva-de-un-modelo-de-clasificación"><span class="toc-section-number">6.5</span> Capacidad predictiva de un modelo de clasificación</a></li>
<li><a href="#ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes" id="toc-ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes"><span class="toc-section-number">6.6</span> Ejemplo de regresión logística: modelización de riesgo diabetes</a>
<ul>
<li><a href="#modelo-simple" id="toc-modelo-simple"><span class="toc-section-number">6.6.1</span> Modelo simple</a></li>
<li><a href="#agregar-predictores-y-evaluar-el-ajuste" id="toc-agregar-predictores-y-evaluar-el-ajuste"><span class="toc-section-number">6.6.2</span> Agregar predictores y evaluar el ajuste</a></li>
<li><a href="#análisis-de-interacciones" id="toc-análisis-de-interacciones"><span class="toc-section-number">6.6.3</span> Análisis de interacciones</a></li>
<li><a href="#gráfico-de-la-interacción" id="toc-gráfico-de-la-interacción"><span class="toc-section-number">6.6.4</span> Gráfico de la interacción</a></li>
<li><a href="#uso-del-modelo-para-predecir-probabilidades" id="toc-uso-del-modelo-para-predecir-probabilidades"><span class="toc-section-number">6.6.5</span> Uso del modelo para predecir probabilidades</a></li>
</ul></li>
<li><a href="#creación-de-un-modelo-y-validación" id="toc-creación-de-un-modelo-y-validación"><span class="toc-section-number">6.7</span> Creación de un modelo y validación</a></li>
<li><a href="#nomogramas" id="toc-nomogramas"><span class="toc-section-number">6.8</span> Nomogramas</a></li>
</ul></li>
<li><a href="#modelos-de-regularización" id="toc-modelos-de-regularización"><span class="toc-section-number">7</span> Modelos de regularización</a>
<ul>
<li><a href="#introducción-2" id="toc-introducción-2"><span class="toc-section-number">7.1</span> Introducción</a></li>
<li><a href="#cómo-regularizar" id="toc-cómo-regularizar"><span class="toc-section-number">7.2</span> Cómo regularizar</a></li>
<li><a href="#implementación-en-r" id="toc-implementación-en-r"><span class="toc-section-number">7.3</span> Implementación en R</a>
<ul>
<li><a href="#ejemplo-ridge-regression" id="toc-ejemplo-ridge-regression"><span class="toc-section-number">7.3.1</span> Ejemplo: Ridge Regression</a></li>
<li><a href="#ejemplo-lasso" id="toc-ejemplo-lasso"><span class="toc-section-number">7.3.2</span> Ejemplo: Lasso</a></li>
<li><a href="#ejemplo-elastic-net" id="toc-ejemplo-elastic-net"><span class="toc-section-number">7.3.3</span> Ejemplo: Elastic Net</a></li>
</ul></li>
</ul></li>
<li><a href="#dealing-with-big-data-in-r" id="toc-dealing-with-big-data-in-r"><span class="toc-section-number">8</span> Dealing with Big Data in R</a>
<ul>
<li><a href="#nodes-cores-processes-and-threads" id="toc-nodes-cores-processes-and-threads"><span class="toc-section-number">8.1</span> Nodes, cores, processes and threads</a></li>
<li><a href="#paralelización" id="toc-paralelización"><span class="toc-section-number">8.2</span> Paralelización</a>
<ul>
<li><a href="#shared-memory-programming" id="toc-shared-memory-programming"><span class="toc-section-number">8.2.1</span> Shared Memory Programming</a></li>
<li><a href="#distributed-memory-programming" id="toc-distributed-memory-programming"><span class="toc-section-number">8.2.2</span> Distributed Memory Programming</a></li>
</ul></li>
<li><a href="#mapreduce" id="toc-mapreduce"><span class="toc-section-number">8.3</span> MapReduce</a>
<ul>
<li><a href="#map" id="toc-map"><span class="toc-section-number">8.3.1</span> Map</a></li>
<li><a href="#reduce" id="toc-reduce"><span class="toc-section-number">8.3.2</span> Reduce</a></li>
</ul></li>
<li><a href="#example-linear-regression-for-big-data" id="toc-example-linear-regression-for-big-data"><span class="toc-section-number">8.4</span> Example: Linear regression for Big Data</a></li>
</ul></li>
<li><a href="#caret" id="toc-caret"><span class="toc-section-number">9</span> La librería <code>caret</code></a>
<ul>
<li><a href="#pre-procesado" id="toc-pre-procesado"><span class="toc-section-number">9.1</span> Pre-procesado</a>
<ul>
<li><a href="#creación-de-variables" id="toc-creación-de-variables"><span class="toc-section-number">9.1.1</span> Creación de variables</a></li>
<li><a href="#predictores-con-poca-variabilidad" id="toc-predictores-con-poca-variabilidad"><span class="toc-section-number">9.1.2</span> Predictores con poca variabilidad</a></li>
<li><a href="#identificación-de-predictores-correlacionados" id="toc-identificación-de-predictores-correlacionados"><span class="toc-section-number">9.1.3</span> Identificación de predictores correlacionados</a></li>
<li><a href="#centrado-y-escalado-1" id="toc-centrado-y-escalado-1"><span class="toc-section-number">9.1.4</span> Centrado y escalado</a></li>
<li><a href="#imputación" id="toc-imputación"><span class="toc-section-number">9.1.5</span> Imputación</a></li>
<li><a href="#pre-procesado-con-la-librería-recipes" id="toc-pre-procesado-con-la-librería-recipes"><span class="toc-section-number">9.1.6</span> Pre-procesado con la librería <code>recipes</code></a></li>
</ul></li>
<li><a href="#visualización" id="toc-visualización"><span class="toc-section-number">9.2</span> Visualización</a></li>
<li><a href="#ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama" id="toc-ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama"><span class="toc-section-number">9.3</span> Ejemplo completo: creación de modelo diagnóstico para cáncer de mama</a></li>
<li><a href="#creación-de-un-modelo-predictivo" id="toc-creación-de-un-modelo-predictivo"><span class="toc-section-number">9.4</span> Creación de un modelo predictivo</a></li>
</ul></li>
<li><a href="#KNN" id="toc-KNN"><span class="toc-section-number">10</span> K vecinos más próximos (KNN)</a></li>
<li><a href="#análisis-discriminante-lineal-lda" id="toc-análisis-discriminante-lineal-lda"><span class="toc-section-number">11</span> Análisis discriminante lineal (LDA)</a>
<ul>
<li><a href="#concurso-predicción-de-actividad-física-con-sensores" id="toc-concurso-predicción-de-actividad-física-con-sensores"><span class="toc-section-number">11.1</span> Concurso predicción de actividad física con sensores</a></li>
</ul></li>
<li><a href="#máquinas-de-soporte-vectorial" id="toc-máquinas-de-soporte-vectorial"><span class="toc-section-number">12</span> Máquinas de soporte vectorial</a>
<ul>
<li><a href="#clasificador-de-margen-máximo" id="toc-clasificador-de-margen-máximo"><span class="toc-section-number">12.1</span> Clasificador de margen máximo</a></li>
<li><a href="#clasificador-de-soporte-vectorial" id="toc-clasificador-de-soporte-vectorial"><span class="toc-section-number">12.2</span> Clasificador de soporte vectorial</a></li>
<li><a href="#máquinas-de-soporte-vectorial-1" id="toc-máquinas-de-soporte-vectorial-1"><span class="toc-section-number">12.3</span> Máquinas de soporte vectorial</a></li>
<li><a href="#svm-con-e1071" id="toc-svm-con-e1071"><span class="toc-section-number">12.4</span> SVM con <code>e1071</code></a></li>
<li><a href="#svm-con-caret" id="toc-svm-con-caret"><span class="toc-section-number">12.5</span> SVM con <code>caret</code></a></li>
</ul></li>
<li><a href="#respuesta-no-balanceada" id="toc-respuesta-no-balanceada"><span class="toc-section-number">13</span> Respuesta no balanceada</a></li>
<li><a href="#árboles-de-decisión" id="toc-árboles-de-decisión"><span class="toc-section-number">14</span> Árboles de decisión</a>
<ul>
<li><a href="#árboles-de-clasificación" id="toc-árboles-de-clasificación"><span class="toc-section-number">14.1</span> Árboles de clasificación</a></li>
<li><a href="#área-bajo-la-curva-roc" id="toc-área-bajo-la-curva-roc"><span class="toc-section-number">14.2</span> Área bajo la curva ROC</a>
<ul>
<li><a href="#entrenamiento-con-caret" id="toc-entrenamiento-con-caret"><span class="toc-section-number">14.2.1</span> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li><a href="#árboles-de-regresión" id="toc-árboles-de-regresión"><span class="toc-section-number">14.3</span> Árboles de regresión</a>
<ul>
<li><a href="#entrenamiento-con-caret-1" id="toc-entrenamiento-con-caret-1"><span class="toc-section-number">14.3.1</span> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li><a href="#bagged-trees" id="toc-bagged-trees"><span class="toc-section-number">14.4</span> Bagged trees</a>
<ul>
<li><a href="#bagging-árboles-de-clasificación" id="toc-bagging-árboles-de-clasificación"><span class="toc-section-number">14.4.1</span> Bagging árboles de clasificación</a></li>
<li><a href="#bagging-árboles-de-regresión" id="toc-bagging-árboles-de-regresión"><span class="toc-section-number">14.4.2</span> Bagging árboles de regresión</a></li>
</ul></li>
<li><a href="#random-forest" id="toc-random-forest"><span class="toc-section-number">14.5</span> Random Forest</a></li>
<li><a href="#random-forest-pn" id="toc-random-forest-pn"><span class="toc-section-number">14.6</span> Random Forest p&gt;&gt;n</a></li>
</ul></li>
<li><a href="#boosting" id="toc-boosting"><span class="toc-section-number">15</span> Boosting</a>
<ul>
<li><a href="#cómo-funciona-el-boosting" id="toc-cómo-funciona-el-boosting"><span class="toc-section-number">15.1</span> Cómo funciona el <em>boosting</em></a></li>
<li><a href="#adaboost" id="toc-adaboost"><span class="toc-section-number">15.2</span> AdaBoost</a></li>
<li><a href="#gbm-básico" id="toc-gbm-básico"><span class="toc-section-number">15.3</span> GBM básico</a>
<ul>
<li><a href="#boostingHiperparam" id="toc-boostingHiperparam"><span class="toc-section-number">15.3.1</span> Hiperparámetros</a></li>
<li><a href="#implementación" id="toc-implementación"><span class="toc-section-number">15.3.2</span> Implementación</a></li>
<li><a href="#estrategia-general-de-tuning" id="toc-estrategia-general-de-tuning"><span class="toc-section-number">15.3.3</span> Estrategia general de <em>tuning</em></a></li>
</ul></li>
<li><a href="#gbms-estocásticos" id="toc-gbms-estocásticos"><span class="toc-section-number">15.4</span> GBMs estocásticos</a>
<ul>
<li><a href="#hiperparámetros-estocásticos" id="toc-hiperparámetros-estocásticos"><span class="toc-section-number">15.4.1</span> Hiperparámetros estocásticos</a></li>
</ul></li>
<li><a href="#xgboost" id="toc-xgboost"><span class="toc-section-number">15.5</span> XGBoost</a>
<ul>
<li><a href="#reguralización" id="toc-reguralización"><span class="toc-section-number">15.5.1</span> Reguralización</a></li>
<li><a href="#estrategia-de-tuning" id="toc-estrategia-de-tuning"><span class="toc-section-number">15.5.2</span> Estrategia de <em>tuning</em></a></li>
</ul></li>
<li><a href="#otros-algoritmos-gbm" id="toc-otros-algoritmos-gbm"><span class="toc-section-number">15.6</span> Otros algoritmos GBM</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje Automático 1</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="introducción" class="section level1 hasAnchor" number="1">
<h1 class="hasAnchor"><span class="header-section-number">1</span> Introducción<a href="#introducción" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Este bookdown sirven como notas para el curso <a href="https://guies.uab.cat/guies_docents/public/portal/html/2020/assignatura/104870/es">Aprendizaje Automático 1</a> impartido en el <a href="https://www.uab.cat/web/estudiar/listado-de-grados/informacion-general-1216708258897.html?param1=1264404714557">Grado de Estadística</a> de la UAB</p>
<p>El objetivo de este material es familiarizar al alumno con diferentes métodos de aprendizaje automático (machine learning en inglés) desde un punto de vista aplicado haciendo énfasis a situaciones donde se dispone de grandes cantidades de datos.</p>
<p>Los contenidos incluyen los siguientes temas:</p>
<ul>
<li>Breve introducción a Tidyverse</li>
<li>Introducción al aprendizaje automático</li>
<li>Regresión lineal y logística</li>
<li>Pasos previos a la creación de un modelo predictivo y medidas de validación</li>
<li>Datos no balanceados</li>
<li>Métodos de aprendizaje automático
<ul>
<li>Arboles de clasificación</li>
<li>K-vecinos más cercanos</li>
<li>Árboles: clasificación, regresión, bagged
- Random Forest
- Boosting
- XGBoost</li>
</ul></li>
<li>La librería ‘caret’</li>
<li>La librería ‘H20’</li>
<li>Modelos no lineales
<ul>
<li>Splines</li>
<li>MARS</li>
<li>GAM</li>
</ul></li>
</ul>
<p>En el aula virtual de la asignatura (Moodle) se dispondrán de numerosas preguntas de autoevaluación para que el alumno pueda ver si adquiere los conocimientos descritos en cada sesión teórica, así como varias prácticas que permitirán formar al alumno en el análisis de datos mediante las principales técnicas de aprendizaje automático utilizando datos reales usando el software R.</p>
<p>Algunas partes de este material está inspirados en vignettes que se referencian en cada capítulo. Los ejemplos de regresión lineal se basan en el trabajo de <a href="https://github.com/jefftwebb">Jeff Webb</a>. Este material está licenciado bajo una <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFgAAAAfCAMAAABUFvrSAAAAIGNIUk0AAHolAACAgwAA+f8AAIDpAAB1MAAA6mAAADqYAAAXb5JfxUYAAAAEZ0FNQQAAsY58+1GTAAAAAXNSR0IB2cksfwAAAW5QTFRF////////////////7+/v39/f1tXV09bS0tXS0tXR0dTR0dTQ0NTQ0NPPz9PPztLOztHNzdHNzdHMz8/PzdDMzNDMzNDLzM/Ly8/Ly8/Ky87Kys3Jyc3Jyc3IyMzIyMzHx8vHxsrGxsrFxcnFxcnExMnExMjDw8jDxMfDw8fCwsfCwcXAwMXAwMW/wMS/v8S+v8O+vsO+vsK9vcK9vcK8v7+/vMG8vMG7vMC8u8C7u8C6ur+6ur+5ub65ub64uL23t7y2tru1tbq0tLqztLmzs7iysrixsrexsbewsbawsLavsLWvr7Wur7SusLOvrrStrrOtr7KvrbOsrLKrr6+vq7Gqn6OenqCdn5+flpmWk5iTkZSRkZORj4+PiYyJhIaEhIWEgoWCgICAfX98fH98eXx5cHJvcHBwYGBgXV5dUFFQUFBQQ0RDQEBAPj8+NTY1MjMxMDAwKSkpKCkoICAgGxsbEBAQDg4ODQ4NAAAAlzoSDQAAAAN0Uk5TAAoO5yEBUwAAAvhJREFUeNq1lutX2kAQxWmXFDVGYy1EIjQ2VZDiu1CsRQQURYvV+qSKj6II8rANYOT+9z0JqIASo9Y5ydkP2f2d2Ts7d2N4jRcJgwEIBwO+SbdTFGw8ZzZz1n5BdLgnfLPBcCT6fW1jY3P78QEYEA76PWMu0W5lGbrNZGrrYNg+u+ga9fgVcmxtY/NJZAOCfs+IY4Bn6eN8RdlEJX9Ed1uFIfdnfzC8uBJbv5tyqqhMLKa0wQHPiEOwMInLW4Eu9xmzfdDtmQ0uLK3cSXmvBBTS6QJQ2tMC+8YcgpnOApAzSa83mZEBZIff2odGfYFQJNqc8s4VchQhhFA5XO1pgCddAxaFKyeNpBpxGSgNmwXXxMxcWE25fkkJGUIIoExESQPsFnkmC0gUuQmjBGQZq+j2BEKR5dUGLVLIvbkGkxxSrcHO92wCkIyENJL3u+2O8Zng/FJsvR5cRF0GFIqtwaKVvoTcSxrCKOOS7hPdXwLhxUYtUFC+Z6AKQgpoDRZ6joEkaYo4cMQKril/KLLcCE4TVYmqFmkNsK0rD9lIiDdXKCSrwwEhREae6Ve0WIiuPg3M0xVlW171BBe21CGjbLbSYR0c/To3H409TQquHTggREKZ8pbjEiRqqxxXtWjjRLdvLrzUAK4Vr5qwZvEsJsCrzExWF9Tk9gIm84e74BRyRN9xeyS4vkHSmg1yK4Wxt5yUIClDayn0t3SteLWq3RQvjQrN31O87e2dEiBl0tJDJmTrykImN8dtq6AOpIw8Y3OMf2s+bvptU+hJqFrc1yCfpmZDkWYX0mv0H9WWpvS2tH6w8z27e58JJVi7c2ImuNBkQvrBOOWZc0CqsyFKtU3+97OuaQBnXGe90RuTMvCHtpziuWCcmDvPm64m+t2vlmuq/YHqqwnGCcfs1l+mCcbSmgtSe8iDGQNnPEsnrq//fZrltXS4tk3oAOPvT2tPF91uMrXTDNv340JrjQ4hbsHAxeE0z1ksHD99eKFdl0dl/P//Cl+9EPcfS+yBAoqk3eUAAAAASUVORK5CYII=" /></p>
<!--chapter:end:index.Rmd-->
</div>
<div id="introducción-a-tidyverse" class="section level1 hasAnchor" number="2">
<h1 class="hasAnchor"><span class="header-section-number">2</span> Introducción a Tidyverse<a href="#introducción-a-tidyverse" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introducción-1" class="section level2 hasAnchor" number="2.1">
<h2 class="hasAnchor"><span class="header-section-number">2.1</span> Introducción<a href="#introducción-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<center>
<div class="figure">
<img src="figures/tidiverse.png" width="450" alt="" />
<p class="caption">Tidyverse</p>
</div>
</center>
<p><a href="https://www.tidyverse.org/">tidyverse</a> es una forma elegante de usar R y hacer de este software una herramienta mejorada. Ha sido diseñado por <a href="http://hadley.nz/">Hadley / Rstudio</a> e incluye distintas librería que siguen las reglas principales del manifiesto de <a href="https://mran.microsoft.com/web/packages/tidyverse/vignettes/manifesto.html">The tidy tools</a>. Los autores describen esta nueva implementación como:</p>
<p><code>tidyverse es un conjunto de librerías que funcionan en armonía porque comparten representaciones de datos comunes y diseño de API. El paquete tidyverse está diseñado para facilitar la instalación y carga de los paquetes principales desde el tidyverse en un solo comando.</code></p>
<p>Existen numeros ayudas, cursos y material en general para aprender todo sobre las librerías de tidyverse, pero el autor ha usado el libro <a href="https://r4ds.had.co.nz/">R for Data Science</a> como base para ilustrar cómo usar este conjunto de herramientas para el análisis de datos en ciencias. Este libro (del que os he puesto el link) es una excelente fuente para aprender todo sobre <code>tidyverse</code>. En este capítulo os referenciaré otro material que puede ser de ayuda.</p>
<p>El libro de <a href="https://r4ds.had.co.nz/">R for Data Science</a> se organiza siguiendo este esquema:</p>
<div class="figure">
<img src="figures/flujoTrabajoAnalsisiDatos.gif" alt="Esquema R for Data Science" width="100%" />
<p class="caption">
(#fig:flujo)Esquema R for Data Science
</p>
</div>
<p>De forma que las librerías incluidas en <code>tidyverse</code> cubren todos estos aspectos. Está pensado para facilitar tareas de gestión de datos, y en su caso, el manejo de grandes volúmenes de información de forma eficiente. Se describen técnicas que ayudan a la visualización de datos que es el primer paso que se debe llevar a cabo en cualquier análisis estadístico que se precie. Esta visualización y posterior análisis no sólo deber llevarse a cabo en toda la base de datos, puede requerirse analizar subconjuntos de datos obtenidos mediante algún filtro o inlcuso puede necesitarse recodificar o restructurar la información disponible . Quizás estos sean los procedimientos para los que <code>tidiverse</code> mejore de forma sustancial el uso de R tradicional (junto con la forma compacta y clara de escribir código), ya que la posterior modelización puede llevarse a cabo con decenas de librerías diseñadas para tal efecto.</p>
</div>
<div id="instalación" class="section level2 hasAnchor" number="2.2">
<h2 class="hasAnchor"><span class="header-section-number">2.2</span> Instalación<a href="#instalación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para instalar el conjunto básico de liberías relacionadas con <code>tidyverse</code> basta con ejecutar_</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)</span></code></pre></div>
<p>Las librerías básicas relacionadas con <code>tidyverse</code> se cargan de la forma usual, con una única llamada</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</span></code></pre></div>
<p>La diferencia con el hecho de cargar cualquier otra librería, es que en un sólo comando se instalan/cargan un par de docenas de paquetes. Como beneficio adicional, uno puede estar seguro de que todos los paquetes instalados / cargados son de versiones compatibles.</p>
</div>
<div id="librerías-básicas" class="section level2 hasAnchor" number="2.3">
<h2 class="hasAnchor"><span class="header-section-number">2.3</span> Librerías básicas<a href="#librerías-básicas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Las librerías que son más conocidas y ampliamente utilizadas en <code>tidyverse</code> son:</p>
<ul>
<li><strong>ggplot2</strong>: visualización avanzada de datos</li>
<li><strong>dplyr</strong>: manipulación de datos de forma eficiente y escalable (usa Rcpp)</li>
<li><strong>tidyr</strong>: funciones para ordenar datos</li>
<li><strong>readr</strong>: importa datos.</li>
<li><strong>purrr</strong>: desarrolla una especie de “dialecto” de R que facilita muchas operaciones (map, Reduce, …)</li>
<li><strong>tibble</strong>: forma moderna para conceptualizar los datos.</li>
<li><strong>magrittr</strong>: canalización para hacer el código más legible (uso del “pipe” %&gt;%)</li>
</ul></li>
<li><p>Paquetes para manipular formatos de datos específicos:</p>
<ul>
<li><strong>hms</strong>: leer fácilmente fechas y tiempos</li>
<li><strong>stringr</strong>: funciones para trabajar de forma sencilla con cadenas de carácteres</li>
<li><strong>Lubridate</strong>: Manipulación avanzada de fechas</li>
<li><strong>Forcats</strong>: funciones avanzadas con factores</li>
</ul></li>
<li><p>Importar datos:</p>
<ul>
<li><strong>DBI</strong>: define una interfaz común entre R y los sistemas de administración de bases de datos (DBMS)</li>
<li><strong>haven</strong>: importar archivos SPSS, SAS y Stata de forma sencilla</li>
<li><strong>httr</strong>: facilitar el uso del paquete curl personalizado las necesidades de las API web modernas</li>
<li><strong>jsonlite</strong>: análisis y generación de JSON rápido y optimizado para obtener estadísticas en la web</li>
<li><strong>readxl</strong>: leer archivos read.xls y .xlsx de forma sencilla y sin necesitar otras dependencias</li>
<li><strong>rvest</strong>: obtener información de páginas web</li>
<li><strong>xml2</strong>: trabajar con XML</li>
</ul></li>
<li><p>Modelización: Existen varias librerías, pero yo prefiero usar las de R y/o Bioconductor</p></li>
</ul>
</div>
<div id="manejo-de-datos" class="section level2 hasAnchor" number="2.4">
<h2 class="hasAnchor"><span class="header-section-number">2.4</span> Manejo de datos<a href="#manejo-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En tidyverse, los data.frames se trabajan como <strong>tibbles</strong>. Esto permite disponer de una forma consistente y eficiente de guardar nuestros datos permitiendo una forma sencilla de hacer transformaciones, visualización y modelización. Esta sección pretende ser una introducción básica a <code>tidyverse</code> por lo que sólo veremos cómo llevar a cabo los principales tipos de manipulación de datos. No obstante, también existen funciones específicas para:</p>
<ul>
<li>Relacionar múltiples tablas <a href="https://rpubs.com/williamsurles/293454">ver ejemplos</a>.</li>
<li>Trabajar con variables carácter</li>
<li>Usar factores para variables categóricas de forma sencilla (sin los problemas de orden de categorías)</li>
<li>Realizar operaciones con variables de tipo fecha <a href="https://rpubs.com/carloslesmes/474297">ver ejemplos</a>.</li>
</ul>
<div id="tibbles" class="section level3 hasAnchor" number="2.4.1">
<h3 class="hasAnchor"><span class="header-section-number">2.4.1</span> Tibbles<a href="#tibbles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Empecemos introduciendo lo que es un <em>tibble</em> (pronunciado “tibel”). Se puede aprender más cosas ejecutando <code>vignette("tibble")</code> en la consola de RStudio. Tras cargar la librería <code>tidyverse</code> podemos crear un tibble a partir de un data.frame de la siguiente forma. Usaremos la base de datos iris a modo de ejemplo</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>iris.tib <span class="ot">&lt;-</span> <span class="fu">tibble</span>(iris)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>iris.tib</span></code></pre></div>
<pre><code># A tibble: 150 × 5
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
 1          5.1         3.5          1.4         0.2 setosa 
 2          4.9         3            1.4         0.2 setosa 
 3          4.7         3.2          1.3         0.2 setosa 
 4          4.6         3.1          1.5         0.2 setosa 
 5          5           3.6          1.4         0.2 setosa 
 6          5.4         3.9          1.7         0.4 setosa 
 7          4.6         3.4          1.4         0.3 setosa 
 8          5           3.4          1.5         0.2 setosa 
 9          4.4         2.9          1.4         0.2 setosa 
10          4.9         3.1          1.5         0.1 setosa 
# ℹ 140 more rows</code></pre>
<p>También podemos crear un nuevo <em>tibble</em> mediante (los datos se reciclan):</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">1</span>, </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">z =</span> x <span class="sc">^</span> <span class="dv">2</span> <span class="sc">+</span> y</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code># A tibble: 5 × 3
      x     y     z
  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
1     1     1     2
2     2     1     5
3     3     1    10
4     4     1    17
5     5     1    26</code></pre>
<p>NOTA 1: Nunca cambia los tipos de datos! (i.e. caracter a factor)
NOTA 2: El <code>rownames</code> desaparece</p>
<p>Quizás uno de los aspectos más novedosos de las <em>tibble</em> sea que se ha re-definido el método <code>print()</code> que permite, por defecto, ver las 10 primeras filas y todas las columnas que quepan en la pantalla. Esto puede cambiarse con</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(iris.tib, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">width =</span> <span class="cn">Inf</span>)</span></code></pre></div>
<pre><code># A tibble: 150 × 5
   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
 1          5.1         3.5          1.4         0.2 setosa 
 2          4.9         3            1.4         0.2 setosa 
 3          4.7         3.2          1.3         0.2 setosa 
 4          4.6         3.1          1.5         0.2 setosa 
 5          5           3.6          1.4         0.2 setosa 
 6          5.4         3.9          1.7         0.4 setosa 
 7          4.6         3.4          1.4         0.3 setosa 
 8          5           3.4          1.5         0.2 setosa 
 9          4.4         2.9          1.4         0.2 setosa 
10          4.9         3.1          1.5         0.1 setosa 
# ℹ 140 more rows</code></pre>
<p>ó</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(iris.tib, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">width =</span> <span class="dv">25</span>)</span></code></pre></div>
<pre><code># A tibble: 150 × 5
   Sepal.Length
          &lt;dbl&gt;
 1          5.1
 2          4.9
 3          4.7
 4          4.6
 5          5  
 6          5.4
 7          4.6
 8          5  
 9          4.4
10          4.9
# ℹ 140 more rows
# ℹ 4 more variables:
#   Sepal.Width &lt;dbl&gt;,
#   Petal.Length &lt;dbl&gt;,
#   Petal.Width &lt;dbl&gt;,
#   Species &lt;fct&gt;</code></pre>
<p>Podemos acceder a una columna (e.g. variable) de la misma forma que con un data.frame</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">5</span>),</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">rnorm</span>(<span class="dv">5</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract by name</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x</span></code></pre></div>
<pre><code>[1] 0.797226377 0.003549761 0.275309645 0.802863378 0.733837659</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">&quot;x&quot;</span>]]</span></code></pre></div>
<pre><code>[1] 0.797226377 0.003549761 0.275309645 0.802863378 0.733837659</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract by position</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df[[<span class="dv">1</span>]]</span></code></pre></div>
<pre><code>[1] 0.797226377 0.003549761 0.275309645 0.802863378 0.733837659</code></pre>
</div>
<div id="importar-datos" class="section level3 hasAnchor" number="2.4.2">
<h3 class="hasAnchor"><span class="header-section-number">2.4.2</span> Importar datos<a href="#importar-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El paquete clave para leer datos es <em>readr</em></p>
<ul>
<li><p><em>read_csv ()</em> lee archivos delimitados por comas, <em>read_csv2 () </em> lee archivos separados por punto y coma (común en países donde, se usa como el lugar decimal), <em>read_tsv () </em> lee archivos delimitados por tabulaciones y <em>read_delim () </em> lee archivos con cualquier delimitador.</p></li>
<li><p><em>read_fwf ()</em> lee archivos de ancho fijo. Se puede especificar campos por sus anchos con <em>fwf_widths ()</em> o su posición con <em>fwf_positions ()</em>. <em>read_table ()</em> lee archivos de ancho fijo donde las columnas están separadas por espacios en blanco.</p></li>
<li><p><em>read_log ()</em> lee archivos de registro de estilo Apache (servidor web de código abierto). Pero también es muy útil <em>webreadr</em>, que está construido sobre <em>read_log ()</em> y proporciona muchas más herramientas útiles.</p></li>
</ul>
<p>Estas funciones suelen ser mucho más rápidas (~ 10x) que sus equivalentes en R básico. Además, la importación de datos de ejecución prolongada tienen una barra de progreso para que se pueda ver lo que está sucediendo. Si se está buscando velocidad bruta, también podemos usar <em>data.table::fread()</em> que aunque no encaja tan bien en <code>tidyverse</code> puede usarse en ocasiones donde precie la velocidad (pero no es mucho más rápido). Los datos se importan como objetos que:</p>
<ul>
<li>son <em>tibbles</em></li>
<li>no convierten vectores de caracteres en factores</li>
<li>no usan nombres de filas ni modifican los nombres de columnas. Éstas son fuentes comunes de frustración con las funciones base R [¡declaración de Hadley!].</li>
<li>Son más reproducibles. Las funciones de Base R heredan algún comportamiento de su sistema operativo y variables de entorno, por lo que el código para importar datos que funciona en un ordenador, podría no funcionar en el de otra persona.</li>
</ul>
<p>Hagamos una comparación con un archivo grande</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(dd1 <span class="ot">&lt;-</span> <span class="fu">read.delim</span>(<span class="st">&quot;data/genome.txt&quot;</span>))</span></code></pre></div>
<pre><code>   user  system elapsed 
   5.68    0.03    5.72 </code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(dd2 <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">&quot;data/genome.txt&quot;</span>, <span class="at">delim=</span><span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>))</span></code></pre></div>
<pre><code>   user  system elapsed 
   1.14    0.12    3.08 </code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(dd2)</span></code></pre></div>
<pre><code>[1] 733202      5</code></pre>
<p>Efectivamente ambos objetos contienen la misma información</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dd1)</span></code></pre></div>
<pre><code>        Name Chr  Position  Log.R.Ratio B.Allele.Freq
1  rs1000000  12 125456933 -0.002501764   1.000000000
2  rs1000002   3 185118461 -0.029741180   0.000336171
3 rs10000023   4  95952928  0.004015533   0.460671800
4  rs1000003   3  99825597 -0.142527700   0.541123600
5 rs10000030   4 103593179  0.365104000   1.000000000
6 rs10000037   4  38600725 -0.005177616   0.504625300</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>dd2</span></code></pre></div>
<pre><code># A tibble: 733,202 × 5
   Name       Chr    Position Log.R.Ratio B.Allele.Freq
   &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;
 1 rs1000000  12    125456933    -0.00250      1       
 2 rs1000002  3     185118461    -0.0297       0.000336
 3 rs10000023 4      95952928     0.00402      0.461   
 4 rs1000003  3      99825597    -0.143        0.541   
 5 rs10000030 4     103593179     0.365        1       
 6 rs10000037 4      38600725    -0.00518      0.505   
 7 rs10000041 4     165841405    -0.179        0       
 8 rs10000042 4       5288053     0.168        0.998   
 9 rs10000049 4     119167668    -0.00238      0       
10 rs1000007  2     237416793    -0.00411      0       
# ℹ 733,192 more rows</code></pre>
</div>
<div id="transformación-de-datos" class="section level3 hasAnchor" number="2.4.3">
<h3 class="hasAnchor"><span class="header-section-number">2.4.3</span> Transformación de datos<a href="#transformación-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Antes de empezar a analizar los datos suele ser necesario realizar algunas transformaciones o crear nuevas variables ya que:</p>
<ul>
<li>Es raro que obtengamos los datos exactamente en la forma correcta que necesitamos.</li>
<li>A menudo, se deberán crear algunas variables o resúmenes nuevos.</li>
<li>A veces se necesita cambiar el nombre de las variables o reordenar las observaciones para que sea un poco más fácil trabajar con los datos.</li>
</ul>
<p>Ilustremos cómo realizar estas tareas utilizando los datos disponibles en una base de datos de vuelos de NYC. El objeto <code>nycflights13::fligths</code> contiene los 336,776 vuelos que partieron de la ciudad de Nueva York en 2013. Los datos provienen de la Oficina de Estadísticas de Transporte de EE. UU. y están documentados en <code>?flights</code>.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nycflights13)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>flights</span></code></pre></div>
<pre><code># A tibble: 336,776 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013     1     1      517            515         2      830            819        11 UA        1545
 2  2013     1     1      533            529         4      850            830        20 UA        1714
 3  2013     1     1      542            540         2      923            850        33 AA        1141
 4  2013     1     1      544            545        -1     1004           1022       -18 B6         725
 5  2013     1     1      554            600        -6      812            837       -25 DL         461
 6  2013     1     1      554            558        -4      740            728        12 UA        1696
 7  2013     1     1      555            600        -5      913            854        19 B6         507
 8  2013     1     1      557            600        -3      709            723       -14 EV        5708
 9  2013     1     1      557            600        -3      838            846        -8 B6          79
10  2013     1     1      558            600        -2      753            745         8 AA         301
# ℹ 336,766 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
<p>Las funciones básicas que usaremos están disponibles en la librería <code>dlpyr</code> y son las siguientes:</p>
<ul>
<li>Elegir observaciones por sus valores: <code>filter()</code>.</li>
<li>Reordenar las filas: <code>arrange()</code>.</li>
<li>Elegir las variables por sus nombres: <code>select()</code>.</li>
<li>Crear nuevas variables a partir de variables existentes: <code>mutate()</code>.</li>
<li>Colapsar valores en un sólo resumen: <code>summarise()</code>.</li>
</ul>
<p>Todos los <strong>verbos</strong> (e.g funciones) se usan de la misma forma:</p>
<ul>
<li><p>El primer argumento es un <em>tibble</em> o un <em>data.frame</em>.</p></li>
<li><p>Los argumentos siguientes describen qué hacer con los datos, utilizando los nombres de las variables (sin comillas).</p></li>
<li><p>El resultado es un nuevo <em>tibble</em>.</p></li>
</ul>
</div>
<div id="filtrar-filas" class="section level3 hasAnchor" number="2.4.4">
<h3 class="hasAnchor"><span class="header-section-number">2.4.4</span> Filtrar filas<a href="#filtrar-filas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>jan1 <span class="ot">&lt;-</span> <span class="fu">filter</span>(flights, month <span class="sc">==</span> <span class="dv">1</span>, day <span class="sc">==</span> <span class="dv">1</span>)</span></code></pre></div>
<p>R imprime los resultados o los guarda en una variable. Si desea hacer ambas cosas, podemos envolver la sintaxis entre paréntesis:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>(jan1 <span class="ot">&lt;-</span> <span class="fu">filter</span>(flights, month <span class="sc">==</span> <span class="dv">1</span>, day <span class="sc">==</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code># A tibble: 842 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013     1     1      517            515         2      830            819        11 UA        1545
 2  2013     1     1      533            529         4      850            830        20 UA        1714
 3  2013     1     1      542            540         2      923            850        33 AA        1141
 4  2013     1     1      544            545        -1     1004           1022       -18 B6         725
 5  2013     1     1      554            600        -6      812            837       -25 DL         461
 6  2013     1     1      554            558        -4      740            728        12 UA        1696
 7  2013     1     1      555            600        -5      913            854        19 B6         507
 8  2013     1     1      557            600        -3      709            723       -14 EV        5708
 9  2013     1     1      557            600        -3      838            846        -8 B6          79
10  2013     1     1      558            600        -2      753            745         8 AA         301
# ℹ 832 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
</div>
<div id="filtrado-lógico" class="section level3 hasAnchor" number="2.4.5">
<h3 class="hasAnchor"><span class="header-section-number">2.4.5</span> Filtrado lógico<a href="#filtrado-lógico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estos son los operadoles lógicos que podemos aplicar</p>
<div class="figure">
<img src="figures/transform-logical.png" alt="" />
<p class="caption">boolean operations</p>
</div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">filter</span>(flights, month <span class="sc">==</span> <span class="dv">11</span> <span class="sc">|</span> month <span class="sc">==</span> <span class="dv">12</span>)</span></code></pre></div>
<pre><code># A tibble: 55,403 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013    11     1        5           2359         6      352            345         7 B6         745
 2  2013    11     1       35           2250       105      123           2356        87 B6        1816
 3  2013    11     1      455            500        -5      641            651       -10 US        1895
 4  2013    11     1      539            545        -6      856            827        29 UA        1714
 5  2013    11     1      542            545        -3      831            855       -24 AA        2243
 6  2013    11     1      549            600       -11      912            923       -11 UA         303
 7  2013    11     1      550            600       -10      705            659         6 US        2167
 8  2013    11     1      554            600        -6      659            701        -2 US        2134
 9  2013    11     1      554            600        -6      826            827        -1 DL         563
10  2013    11     1      554            600        -6      749            751        -2 DL         731
# ℹ 55,393 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">filter</span>(flights, <span class="sc">!</span>(arr_delay <span class="sc">&gt;</span> <span class="dv">120</span> <span class="sc">|</span> dep_delay <span class="sc">&gt;</span> <span class="dv">120</span>))</span></code></pre></div>
<pre><code># A tibble: 316,050 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013     1     1      517            515         2      830            819        11 UA        1545
 2  2013     1     1      533            529         4      850            830        20 UA        1714
 3  2013     1     1      542            540         2      923            850        33 AA        1141
 4  2013     1     1      544            545        -1     1004           1022       -18 B6         725
 5  2013     1     1      554            600        -6      812            837       -25 DL         461
 6  2013     1     1      554            558        -4      740            728        12 UA        1696
 7  2013     1     1      555            600        -5      913            854        19 B6         507
 8  2013     1     1      557            600        -3      709            723       -14 EV        5708
 9  2013     1     1      557            600        -3      838            846        -8 B6          79
10  2013     1     1      558            600        -2      753            745         8 AA         301
# ℹ 316,040 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
</div>
<div id="ordenar-filas" class="section level3 hasAnchor" number="2.4.6">
<h3 class="hasAnchor"><span class="header-section-number">2.4.6</span> Ordenar filas<a href="#ordenar-filas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En orden ascendente</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">arrange</span>(flights, year, month, day)</span></code></pre></div>
<pre><code># A tibble: 336,776 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013     1     1      517            515         2      830            819        11 UA        1545
 2  2013     1     1      533            529         4      850            830        20 UA        1714
 3  2013     1     1      542            540         2      923            850        33 AA        1141
 4  2013     1     1      544            545        -1     1004           1022       -18 B6         725
 5  2013     1     1      554            600        -6      812            837       -25 DL         461
 6  2013     1     1      554            558        -4      740            728        12 UA        1696
 7  2013     1     1      555            600        -5      913            854        19 B6         507
 8  2013     1     1      557            600        -3      709            723       -14 EV        5708
 9  2013     1     1      557            600        -3      838            846        -8 B6          79
10  2013     1     1      558            600        -2      753            745         8 AA         301
# ℹ 336,766 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
<p>y descendente</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">arrange</span>(flights, <span class="fu">desc</span>(dep_delay))</span></code></pre></div>
<pre><code># A tibble: 336,776 × 19
    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight
   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
 1  2013     1     9      641            900      1301     1242           1530      1272 HA          51
 2  2013     6    15     1432           1935      1137     1607           2120      1127 MQ        3535
 3  2013     1    10     1121           1635      1126     1239           1810      1109 MQ        3695
 4  2013     9    20     1139           1845      1014     1457           2210      1007 AA         177
 5  2013     7    22      845           1600      1005     1044           1815       989 MQ        3075
 6  2013     4    10     1100           1900       960     1342           2211       931 DL        2391
 7  2013     3    17     2321            810       911      135           1020       915 DL        2119
 8  2013     6    27      959           1900       899     1236           2226       850 DL        2007
 9  2013     7    22     2257            759       898      121           1026       895 DL        2047
10  2013    12     5      756           1700       896     1058           2020       878 AA         172
# ℹ 336,766 more rows
# ℹ 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;</code></pre>
<p>NOTA: los valores missing están situados al final</p>
</div>
<div id="seleccionar-columnas-e.g.-variables" class="section level3 hasAnchor" number="2.4.7">
<h3 class="hasAnchor"><span class="header-section-number">2.4.7</span> Seleccionar columnas (e.g. variables)<a href="#seleccionar-columnas-e.g.-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Seleccionamos las columnas que queremos</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">select</span>(flights, year, month, day)</span></code></pre></div>
<pre><code># A tibble: 336,776 × 3
    year month   day
   &lt;int&gt; &lt;int&gt; &lt;int&gt;
 1  2013     1     1
 2  2013     1     1
 3  2013     1     1
 4  2013     1     1
 5  2013     1     1
 6  2013     1     1
 7  2013     1     1
 8  2013     1     1
 9  2013     1     1
10  2013     1     1
# ℹ 336,766 more rows</code></pre>
<p>o las que están entre dos columnas</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">select</span>(flights, year<span class="sc">:</span>day)</span></code></pre></div>
<pre><code># A tibble: 336,776 × 3
    year month   day
   &lt;int&gt; &lt;int&gt; &lt;int&gt;
 1  2013     1     1
 2  2013     1     1
 3  2013     1     1
 4  2013     1     1
 5  2013     1     1
 6  2013     1     1
 7  2013     1     1
 8  2013     1     1
 9  2013     1     1
10  2013     1     1
# ℹ 336,766 more rows</code></pre>
<p>también podemos seleccionar todas las columnas menos algunas</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">select</span>(flights, <span class="sc">-</span>(year<span class="sc">:</span>day))</span></code></pre></div>
<pre><code># A tibble: 336,776 × 16
   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier flight tailnum origin
      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; 
 1      517            515         2      830            819        11 UA        1545 N14228  EWR   
 2      533            529         4      850            830        20 UA        1714 N24211  LGA   
 3      542            540         2      923            850        33 AA        1141 N619AA  JFK   
 4      544            545        -1     1004           1022       -18 B6         725 N804JB  JFK   
 5      554            600        -6      812            837       -25 DL         461 N668DN  LGA   
 6      554            558        -4      740            728        12 UA        1696 N39463  EWR   
 7      555            600        -5      913            854        19 B6         507 N516JB  EWR   
 8      557            600        -3      709            723       -14 EV        5708 N829AS  LGA   
 9      557            600        -3      838            846        -8 B6          79 N593JB  JFK   
10      558            600        -2      753            745         8 AA         301 N3ALAA  LGA   
# ℹ 336,766 more rows
# ℹ 6 more variables: dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
#   time_hour &lt;dttm&gt;</code></pre>
<p>Existen numerosas funciones que pueden ser de mucha utilidad para hacer selecciones más complejas y rápidas dentro de la función <code>select()</code></p>
<ul>
<li><p><code>starts_with("abc")</code>: nombres que empiezan con “abc”.</p></li>
<li><p><code>ends_with("xyz")</code>: nombres que acaban con “xyz”.</p></li>
<li><p><code>contains("ijk")</code>: nombres que contienen “ijk”.</p></li>
<li><p><code>matches("(.)\\1")</code>: selecciona variables que coinciden con una expresión regular. Se puede aprender más con <code>strings</code>.</p></li>
<li><p><code>num_range("x", 1:3)</code>: coincide con x1, x2 y x3.</p></li>
</ul>
</div>
<div id="añadir-nuevas-variables" class="section level3 hasAnchor" number="2.4.8">
<h3 class="hasAnchor"><span class="header-section-number">2.4.8</span> Añadir nuevas variables<a href="#añadir-nuevas-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Debemos usar la función <code>mutate()</code></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>flights_sml <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(flights, </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  year<span class="sc">:</span>day, </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ends_with</span>(<span class="st">&quot;delay&quot;</span>), </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>  distance, </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>  air_time</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(flights_sml,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">gain =</span> dep_delay <span class="sc">-</span> arr_delay,</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">speed =</span> distance <span class="sc">/</span> air_time <span class="sc">*</span> <span class="dv">60</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code># A tibble: 336,776 × 9
    year month   day dep_delay arr_delay distance air_time  gain speed
   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1  2013     1     1         2        11     1400      227    -9  370.
 2  2013     1     1         4        20     1416      227   -16  374.
 3  2013     1     1         2        33     1089      160   -31  408.
 4  2013     1     1        -1       -18     1576      183    17  517.
 5  2013     1     1        -6       -25      762      116    19  394.
 6  2013     1     1        -4        12      719      150   -16  288.
 7  2013     1     1        -5        19     1065      158   -24  404.
 8  2013     1     1        -3       -14      229       53    11  259.
 9  2013     1     1        -3        -8      944      140     5  405.
10  2013     1     1        -2         8      733      138   -10  319.
# ℹ 336,766 more rows</code></pre>
<p>Si sólo queremos mantener las nuevas variables en nuestra tabla de datos, debemos usar <code>transmute()</code>:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">transmute</span>(flights,</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">gain =</span> dep_delay <span class="sc">-</span> arr_delay,</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">hours =</span> air_time <span class="sc">/</span> <span class="dv">60</span>,</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">gain_per_hour =</span> gain <span class="sc">/</span> hours</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code># A tibble: 336,776 × 3
    gain hours gain_per_hour
   &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;
 1    -9 3.78          -2.38
 2   -16 3.78          -4.23
 3   -31 2.67         -11.6 
 4    17 3.05           5.57
 5    19 1.93           9.83
 6   -16 2.5           -6.4 
 7   -24 2.63          -9.11
 8    11 0.883         12.5 
 9     5 2.33           2.14
10   -10 2.3           -4.35
# ℹ 336,766 more rows</code></pre>
</div>
<div id="grouped-summaries" class="section level3 hasAnchor" number="2.4.9">
<h3 class="hasAnchor"><span class="header-section-number">2.4.9</span> Grouped summaries<a href="#grouped-summaries" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos agrupar variables de la siguiente forma:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summarise</span>(flights, <span class="at">delay =</span> <span class="fu">mean</span>(dep_delay, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  delay
  &lt;dbl&gt;
1  12.6</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>by_day <span class="ot">&lt;-</span> <span class="fu">group_by</span>(flights, year, month, day)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summarise</span>(by_day, <span class="at">delay =</span> <span class="fu">mean</span>(dep_delay, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code># A tibble: 365 × 4
# Groups:   year, month [12]
    year month   day delay
   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
 1  2013     1     1 11.5 
 2  2013     1     2 13.9 
 3  2013     1     3 11.0 
 4  2013     1     4  8.95
 5  2013     1     5  5.73
 6  2013     1     6  7.15
 7  2013     1     7  5.42
 8  2013     1     8  2.55
 9  2013     1     9  2.28
10  2013     1    10  2.84
# ℹ 355 more rows</code></pre>
<p>También podemos agrupar según varios criterios</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>flights <span class="sc">%&gt;%</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(year, month, day) <span class="sc">%&gt;%</span> </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">avg_delay1 =</span> <span class="fu">mean</span>(arr_delay, <span class="at">na.rm=</span><span class="cn">TRUE</span>),</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">avg_delay2 =</span> <span class="fu">mean</span>(arr_delay[arr_delay <span class="sc">&gt;</span> <span class="dv">0</span>], <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<pre><code># A tibble: 365 × 5
# Groups:   year, month [12]
    year month   day avg_delay1 avg_delay2
   &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;
 1  2013     1     1     12.7         32.5
 2  2013     1     2     12.7         32.0
 3  2013     1     3      5.73        27.7
 4  2013     1     4     -1.93        28.3
 5  2013     1     5     -1.53        22.6
 6  2013     1     6      4.24        24.4
 7  2013     1     7     -4.95        27.8
 8  2013     1     8     -3.23        20.8
 9  2013     1     9     -0.264       25.6
10  2013     1    10     -5.90        27.3
# ℹ 355 more rows</code></pre>
<p>Existen otras funciones útiles por las que nos podría interesar agrupar</p>
<ul>
<li><code>count()</code></li>
<li><code>mean()</code></li>
<li><code>median()</code></li>
<li><code>min()</code></li>
<li><code>max()</code></li>
<li><code>quantile(x, 0.25)</code></li>
<li><code>IQR()</code></li>
<li><code>mad()</code></li>
</ul>
</div>
</div>
<div id="uso-del-pipe" class="section level2 hasAnchor" number="2.5">
<h2 class="hasAnchor"><span class="header-section-number">2.5</span> Uso del pipe <code>%&gt;%</code><a href="#uso-del-pipe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imaginemos que queremos explorar la relación entre la distancia y el retraso promedio para cada ubicación. Los pasos para obtener esta información serían:</p>
<ul>
<li><p>Agrupar los vuelos por destino.</p></li>
<li><p>Resumir la información calculando la distancia, el retraso promedio y el número de vuelos.</p></li>
<li><p>Filtrar algunos valores que introducen ruido (producen sesgo) como el aeropuerto de Honolulu, que está casi el doble de lejos que el siguiente aeropuerto más cercano.</p></li>
</ul>
<p>Utilizando <code>dplyr</code> escribiríamos algo como esto (aún más largo en R tradicional y menos legible):</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>by_dest <span class="ot">&lt;-</span> <span class="fu">group_by</span>(flights, dest)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>delay <span class="ot">&lt;-</span> <span class="fu">summarise</span>(by_dest,</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">count =</span> <span class="fu">n</span>(),</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">dist =</span> <span class="fu">mean</span>(distance, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">delay =</span> <span class="fu">mean</span>(arr_delay, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>delay <span class="ot">&lt;-</span> <span class="fu">filter</span>(delay, count <span class="sc">&gt;</span> <span class="dv">20</span>, dest <span class="sc">!=</span> <span class="st">&quot;HNL&quot;</span>)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>delay</span></code></pre></div>
<pre><code># A tibble: 96 × 4
   dest  count  dist delay
   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 ABQ     254 1826   4.38
 2 ACK     265  199   4.85
 3 ALB     439  143  14.4 
 4 ATL   17215  757. 11.3 
 5 AUS    2439 1514.  6.02
 6 AVL     275  584.  8.00
 7 BDL     443  116   7.05
 8 BGR     375  378   8.03
 9 BHM     297  866. 16.9 
10 BNA    6333  758. 11.8 
# ℹ 86 more rows</code></pre>
<p>Y podríamos tener un gráfico de la siguiente forma (veremos cómo hacer esto en la siguiente sesión)</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> delay, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> dist, <span class="at">y =</span> delay)) <span class="sc">+</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> count), <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="fig/plot_pipe-1.png" width="672" /></p>
<p>Utilizando <em>pipe</em>s el código quedaría mucho más compacto y legible</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>delays <span class="ot">&lt;-</span> flights <span class="sc">%&gt;%</span> </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(dest) <span class="sc">%&gt;%</span> </span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">count =</span> <span class="fu">n</span>(),</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">dist =</span> <span class="fu">mean</span>(distance, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">delay =</span> <span class="fu">mean</span>(arr_delay, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(count <span class="sc">&gt;</span> <span class="dv">20</span>, dest <span class="sc">!=</span> <span class="st">&quot;HNL&quot;</span>)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>delays</span></code></pre></div>
<pre><code># A tibble: 96 × 4
   dest  count  dist delay
   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 ABQ     254 1826   4.38
 2 ACK     265  199   4.85
 3 ALB     439  143  14.4 
 4 ATL   17215  757. 11.3 
 5 AUS    2439 1514.  6.02
 6 AVL     275  584.  8.00
 7 BDL     443  116   7.05
 8 BGR     375  378   8.03
 9 BHM     297  866. 16.9 
10 BNA    6333  758. 11.8 
# ℹ 86 more rows</code></pre>
</div>
<div id="ejercicios-manejo-de-datos" class="section level2 hasAnchor" number="2.6">
<h2 class="hasAnchor"><span class="header-section-number">2.6</span> Ejercicios (manejo de datos)<a href="#ejercicios-manejo-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los siguientes ejercicios os ayudarán a trabajar con las tareas más básicas de <code>dplyr</code>. <strong>Debéis realizarlos usando las funciones que hemos visto en esta presentación - no vale usar código R básico</strong>. Usaremos los datos <code>mtcars</code> vistos en clase. Recordad que podemos obtener más información sobre las variables con <code>?mtcars</code>. También podemos usar <code>glimpse()</code> para ver qué tipo de variables tenemos, y en caso de ser variables categóricas, qué categorías hay (Siempre es muy recomendable hacer este tipo de visualización de datos para ver que no hayan valores raros ni categorías no definidas o errores en la definición de categorías - por ejemplo tener la variable sexo como: H, M, h, m, hombre).</p>
<ul>
<li><p>Visualiza la variable ‘hp’ usando la función <code>select()</code>. Intenta usar la función <code>pull()</code> para hacer lo mismo y ver cuál es la diferencia.</p></li>
<li><p>Visualiza todos los datos excepto la columna ‘hp’.</p></li>
<li><p>Visualiza las columnas mpg, hp, vs, am y gear escribiendo el código más corto posible.</p></li>
<li><p>Crea un objeto que se llame ‘mycars’ que contenga las columnas mpg y hp pero que el nombre de la variable sea ‘miles_per_gallon’ y ‘horse_power’ respectivamente. Pon los rownames del data.frame en una variable que se llame ‘model’ [PISTA: debes buscar qué función hay para poner los rownames en una columna].</p></li>
<li><p>Crea una nueva variable en ‘mycars’ que sea ‘km_per_litre’ que describa el consumo del coche (variable ‘mpg’). NOTA: 1 mpg es 0.425 km / l.</p></li>
<li><p>Selecciona al azar (y visualiza) la mitad de las observaciones de ‘mycars’ [PISTA: busca una función de <code>dplyr</code> que haga esto de forma sencilla (similar a <code>sample</code> en R tradicional).</p></li>
<li><p>Crea un objeto ‘mycars_s’ que contenga de la 10ª a la 32ª fila de mycars [PISTA: considera usar la función <code>slice()</code> o alguna similar].</p></li>
<li><p>Visualiza el objeto ‘mycars_s’ sin duplicados [PISTA: considera usar la función <code>distinct()</code>].</p></li>
<li><p>Visualiza del objeto ‘mycars_s’ todas las observaciones que tengan mpg&gt; 20 y hp&gt; 100.</p></li>
<li><p>Visualiza la la fila correspondiente al coche Lotus Europa.</p></li>
</ul>
</div>
<div id="visualización-de-datos" class="section level2 hasAnchor" number="2.7">
<h2 class="hasAnchor"><span class="header-section-number">2.7</span> Visualización de datos<a href="#visualización-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R es una herramienta muy potente para realizar gráficos, mucho más que otros software de análisis estadístico como SPSS, SAS o Stata. Aún así, <code>ggplot</code> fue desarrollado con los siguientes objetivos:</p>
<p><code>The aim of the grammar is to “bring together in a coherent way things that previously appeared unrelated and which also will provide a basis for dealing systematically with new situations” (Cox 1978). How well have we succeeded? (Wickham, 2012)</code></p>
<p>``The emphasis in ggplot2 is reducing the amount of thinking time by making it easier to go from the plot in your brain to the plot on the page.” (Wickham, 2012)```</p>
<p><code>Base graphics are good for drawing pictures; ggplot2 graphics are good for understanding the data." (Wickham, 2012)</code></p>
<p>En definitiva, deberíamos usar <code>ggplot</code> porque:</p>
<ul>
<li>Es flexible</li>
<li>Tenemos gran control de lo que estamos haciendo</li>
<li>Crea gráficos muy bonitos (y se usan en la mayoría de revistas científicas)</li>
<li>De forma más importante, hay mucha documentación sobre cómo hacer gráficos muy complicados de forma sencilla (libros, páginas web, infografrías, etc.</li>
</ul>
<p><a href="https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf">Aquí</a> podéis encontrar una chuleta con las principales funciones</p>
<p>Cada visualización en ggplot se compone de:</p>
<p><strong>plot = data + Aesthetics + geometry</strong></p>
<ul>
<li><strong>Datos</strong> (<em>Data</em>) que queremos representar (que serán un data frame).</li>
<li><strong>Características estéticas</strong> (<em>aesthetic mappings</em>) que describen cómo queremos que los datos se vean en el gráfico. Para más información podemos consultar la vignette (vignette(“ggplot2-specs”)). Como luego veremos, se introducen con la función aes() y se refieren a:
<ul>
<li>posición (en los ejes)</li>
<li>color exterior (color) y de relleno (fill)</li>
<li>forma de puntos (shape)</li>
<li>tipo de línea (linetype)</li>
<li>tamaño (size)</li>
</ul></li>
<li><strong>Objetos geométricos</strong> (<em>Geom</em>) representan lo que vemos en un gráficos (puntos, líneas, etc.). Todo gráfico tiene, como mínimo, una geometría. La geometría determina el tipo de gráfico:
<ul>
<li>geom_point (para puntos)</li>
<li>geom_lines (para lineas)</li>
<li>geom_histogram (para histograma)</li>
<li>geom_boxplot (para boxplot)</li>
<li>geom_bar (para barras)</li>
<li>geom_smooth (líneas suavizadas)</li>
<li>geom_polygons (para polígonos en un mapa)</li>
<li>etc. (si ejecutáis el comando help.search(“geom_”, package = “ggplot2”) podéis ver el listado de objetos geométricos)</li>
</ul></li>
</ul>
<p>Por tanto, para construir un gráfico con ggplot2 comenzamos con la siguiente estructura de código:</p>
<p><strong>ggplot(datos, aes()) + geom_tipo()</strong></p>
<p>Por ejemplo para hacer una gráfica que represente las millas por galón (mpg) en función del peso del coche, podemos hacer los siguiente:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>mtcars[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>]</span></code></pre></div>
<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars) <span class="sc">+</span>         <span class="co"># data</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> mpg, <span class="at">y=</span>wt) <span class="sc">+</span>   <span class="co"># Aesthetics</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()           <span class="co"># geometry (layer)  </span></span></code></pre></div>
<p><img src="fig/plot_mtcars-1.png" width="672" /></p>
<p>Podemos cambiar a una de estas estéticas</p>
<ul>
<li><code>theme_dark()</code></li>
<li><code>theme_minimal()</code></li>
<li><code>theme_classic()</code></li>
<li><code>theme_void()</code></li>
<li><code>theme_test()</code></li>
</ul>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars) <span class="sc">+</span>         <span class="co"># data</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> mpg, <span class="at">y=</span>wt) <span class="sc">+</span>   <span class="co"># Aesthetics</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span>         <span class="co"># geometry (layer)  </span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()        <span class="co"># theme </span></span></code></pre></div>
<p><img src="fig/plot_mtcars2-1.png" width="672" /></p>
<p>o alguna geometría</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars) <span class="sc">+</span>        </span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">sample =</span> mpg) <span class="sc">+</span> <span class="fu">stat_qq</span>()</span></code></pre></div>
<p><img src="fig/area-1.png" width="672" /></p>
<p>A continuación ilustratemos cómo hacer los principales tipos de gráficos que necesitamos en estadística</p>
<div id="distribución-de-datos-categóricos" class="section level3 hasAnchor" number="2.7.1">
<h3 class="hasAnchor"><span class="header-section-number">2.7.1</span> Distribución de datos categóricos<a href="#distribución-de-datos-categóricos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>diamonds</span></code></pre></div>
<pre><code># A tibble: 53,940 × 10
   carat cut       color clarity depth table price     x     y     z
   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43
 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31
 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31
 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63
 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75
 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48
 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47
 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53
 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49
10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39
# ℹ 53,930 more rows</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">count</span>(diamonds, cut)</span></code></pre></div>
<pre><code># A tibble: 5 × 2
  cut           n
  &lt;ord&gt;     &lt;int&gt;
1 Fair       1610
2 Good       4906
3 Very Good 12082
4 Premium   13791
5 Ideal     21551</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds)</span></code></pre></div>
<p><img src="fig/empty-1.png" width="672" /></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds) <span class="sc">+</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> cut))</span></code></pre></div>
<p><img src="fig/dist_cat-1.png" width="672" /></p>
</div>
<div id="distribución-de-datos-continuos" class="section level3 hasAnchor" number="2.7.2">
<h3 class="hasAnchor"><span class="header-section-number">2.7.2</span> Distribución de datos continuos<a href="#distribución-de-datos-continuos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds) <span class="sc">+</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> carat), <span class="at">binwidth =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="fig/dist_cont-1.png" width="672" /></p>
</div>
<div id="distribución-de-datos-continuos-según-una-variable-categórica" class="section level3 hasAnchor" number="2.7.3">
<h3 class="hasAnchor"><span class="header-section-number">2.7.3</span> Distribución de datos continuos según una variable categórica<a href="#distribución-de-datos-continuos-según-una-variable-categórica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> price)) <span class="sc">+</span> </span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_freqpoly</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">colour =</span> cut), <span class="at">binwidth =</span> <span class="dv">500</span>)</span></code></pre></div>
<p><img src="fig/dist_2-1.png" width="672" /></p>
<p>Idealmente esta descriptiva debemos hacerla con un boxplot</p>
<div class="figure">
<img src="figures/EDA-boxplot.png" alt="" />
<p class="caption">Box-plot</p>
</div>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mpg, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> class, <span class="at">y =</span> hwy)) <span class="sc">+</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()</span></code></pre></div>
<p><img src="fig/boxplot-1.png" width="672" /></p>
<p>Podemos reordenar el boxplot para facilitar la interpretación de la siguiente manera (notamos que el código es mucho más compacto y legible que en R tradicional)</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mpg) <span class="sc">+</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(class, hwy, </span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">FUN =</span> median), </span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">y =</span> hwy))</span></code></pre></div>
<p><img src="fig/boxplot2-1.png" width="672" /></p>
<p>Podemos cambiar las coordenadas añadiendo otra función</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mpg) <span class="sc">+</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(class, hwy, </span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">FUN =</span> median), </span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">y =</span> hwy)) <span class="sc">+</span>  <span class="fu">coord_flip</span>()</span></code></pre></div>
<p><img src="fig/boxplot_flipped-1.png" width="672" /></p>
<p>Los gráficos se pueden reciclar y aprovechar el código ya escrito</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>plt <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> mpg) <span class="sc">+</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(class, hwy, </span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">FUN =</span> median), </span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">y =</span> hwy))</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>plt <span class="sc">+</span> <span class="fu">coord_flip</span>()</span></code></pre></div>
<p>Podemos mejorar un boxplot añadiendo más información tras ’ + ’</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(iris, <span class="fu">aes</span>(<span class="at">x=</span>Species, <span class="at">y=</span>Sepal.Width) ) <span class="sc">+</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">alpha=</span><span class="fl">0.3</span>, <span class="at">outlier.colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">stat=</span> <span class="st">&quot;summary&quot;</span>, <span class="at">fun.y=</span>mean, </span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">shape=</span><span class="dv">16</span>, <span class="at">size=</span><span class="fl">1.5</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<p><img src="fig/improved_boxplot-1.png" width="672" /></p>
</div>
<div id="dos-variables-categóricas" class="section level3 hasAnchor" number="2.7.4">
<h3 class="hasAnchor"><span class="header-section-number">2.7.4</span> Dos variables categóricas<a href="#dos-variables-categóricas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos resumir dos variables categóricas de esta forma</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds) <span class="sc">+</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_count</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> cut, <span class="at">y =</span> color))</span></code></pre></div>
<p><img src="fig/two_cat-1.png" width="432" /></p>
<p>Otra aproximación sería contar cuántos hay en una categoría con <code>dplyr</code>:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%&gt;%</span> </span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(color, cut)</span></code></pre></div>
<pre><code># A tibble: 35 × 3
   color cut           n
   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;
 1 D     Fair        163
 2 D     Good        662
 3 D     Very Good  1513
 4 D     Premium    1603
 5 D     Ideal      2834
 6 E     Fair        224
 7 E     Good        933
 8 E     Very Good  2400
 9 E     Premium    2337
10 E     Ideal      3903
# ℹ 25 more rows</code></pre>
<p>y luego visualizarlo con <code>geom_tile()</code> que nos daría un gráfico tipo heatmap</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>diamonds <span class="sc">%&gt;%</span> </span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(color, cut) <span class="sc">%&gt;%</span>  </span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> color, <span class="at">y =</span> cut)) <span class="sc">+</span></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_tile</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">fill =</span> n))</span></code></pre></div>
<p><img src="fig/visualize-1.png" width="384" /></p>
</div>
<div id="dos-variables-continuas" class="section level3 hasAnchor" number="2.7.5">
<h3 class="hasAnchor"><span class="header-section-number">2.7.5</span> Dos variables continuas<a href="#dos-variables-continuas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds) <span class="sc">+</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price))</span></code></pre></div>
<p><img src="fig/2cont%20-1.png" width="336" /></p>
<p>Scatterplots se vuelven menos útiles cuando el tamaño del conjunto de datos aumenta porque los puntos coinciden. En ese caso podemos usar la estética <code>alpha</code>:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds) <span class="sc">+</span> </span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price), </span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="dv">1</span> <span class="sc">/</span> <span class="dv">100</span>)</span></code></pre></div>
<p><img src="fig/plot_alpha-1.png" width="672" /></p>
<p>Otra opción es discretizar una de las variables continuas y usar <code>boxplot()</code></p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> diamonds, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> carat, <span class="at">y =</span> price)) <span class="sc">+</span> </span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">group =</span> <span class="fu">cut_width</span>(carat, <span class="fl">0.1</span>)))</span></code></pre></div>
<p><img src="fig/bin_2cont-1.png" width="672" /></p>
<p>A veces nos interesa añadir una línea de regresión al gráfico. Exsiten numerosas librerías que extienden las facilidades de <code>ggplot</code> com esta:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggpmisc)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>iris <span class="ot">&lt;-</span> <span class="fu">mutate</span>(iris,</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">Y =</span> <span class="fl">1.5</span> <span class="sc">+</span> <span class="fl">3.2</span><span class="sc">*</span>Sepal.Width <span class="sc">+</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">rnorm</span>(<span class="fu">nrow</span>(iris)))</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(iris, <span class="fu">aes</span>(<span class="at">x =</span> Sepal.Width, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>, <span class="at">color=</span><span class="st">&quot;black&quot;</span>,</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_poly_eq</span>(<span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">paste</span>(..eq.label.., ..rr.label.., </span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sep =</span> <span class="st">&quot;~~~&quot;</span>)),</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">parse =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="fig/lm_info-1.png" width="672" /></p>
<p>R tiene unas capacidades gráficas excelentes, pero el uso de <code>ggplot</code> hace que éstas sean aún más espectaculares. Imaginemos que queremos comparar la expresión génica según la tasa de crecimiento en 20 genes y seis condiciones<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;data/genes.Rdata&quot;</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>genes</span></code></pre></div>
<pre><code># A tibble: 711 × 7
   name    BP                              MF                 systematic_name nutrient  rate expression
   &lt;chr&gt;   &lt;chr&gt;                           &lt;chr&gt;              &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;
 1 &quot;SUL1&quot;  sulfate transport               sulfate transport… YBR294W         Glucose   0.05      -0.32
 2 &quot;&quot;      biological process unknown      molecular functio… YKL187C         Glucose   0.05       4.13
 3 &quot;QDR2&quot;  multidrug transport             multidrug efflux … YIL121W         Glucose   0.05       1.07
 4 &quot;LEU1&quot;  leucine biosynthesis            3-isopropylmalate… YGL009C         Glucose   0.05      -1.12
 5 &quot;PHO5&quot;  phosphate metabolism*           acid phosphatase … YBR093C         Glucose   0.05       2.39
 6 &quot;PHO12&quot; biological process unknown      acid phosphatase … YHR215W         Glucose   0.05       0.9 
 7 &quot;PHO11&quot; phosphate metabolism            acid phosphatase … YAR071W         Glucose   0.05       1.14
 8 &quot;GIT1&quot;  glycerophosphodiester transport glycerophosphodie… YCR098C         Glucose   0.05       0.77
 9 &quot;AGP3&quot;  amino acid transport            amino acid transp… YFL055W         Glucose   0.05       0.57
10 &quot;&quot;      biological process unknown      molecular functio… YOL164W         Glucose   0.05       0.53
# ℹ 701 more rows</code></pre>
<p>Este tendría que ser el (largo) código para hacer este gráfico usando funciones básicas de R (el aspecto del gráfico es mejorable y la sintaxis de R ilegible)</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">1.5</span>, <span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(colors) <span class="ot">&lt;-</span> <span class="fu">unique</span>(genes<span class="sc">$</span>nutrient)</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="dv">21</span>, <span class="dv">21</span>, <span class="dv">21</span>, <span class="dv">21</span>), <span class="at">nrow =</span> <span class="dv">6</span>, </span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">ncol =</span> <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="at">mat =</span> m, <span class="at">heights =</span> <span class="fu">c</span>(.<span class="dv">18</span>, .<span class="dv">18</span>, .<span class="dv">18</span>, .<span class="dv">18</span>, .<span class="dv">18</span>, .<span class="dv">1</span>))</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>genes<span class="sc">$</span>combined <span class="ot">&lt;-</span> <span class="fu">paste</span>(genes<span class="sc">$</span>name, genes<span class="sc">$</span>systematic_name)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (gene <span class="cf">in</span> <span class="fu">unique</span>(genes<span class="sc">$</span>combined)) {</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>    sub_data <span class="ot">&lt;-</span> <span class="fu">filter</span>(genes, combined <span class="sc">==</span> gene)</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(expression <span class="sc">~</span> rate, sub_data, </span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">col =</span> colors[sub_data<span class="sc">$</span>nutrient], <span class="at">main =</span> gene)</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (n <span class="cf">in</span> <span class="fu">unique</span>(sub_data<span class="sc">$</span>nutrient)) {</span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>        m <span class="ot">&lt;-</span> <span class="fu">lm</span>(expression <span class="sc">~</span> rate, </span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a>                <span class="fu">filter</span>(sub_data, nutrient <span class="sc">==</span> n))</span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.na</span>(m<span class="sc">$</span>coefficients[<span class="dv">2</span>])) {</span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a>            <span class="fu">abline</span>(m, <span class="at">col =</span> colors[n])</span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb92-21"><a href="#cb92-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb92-22"><a href="#cb92-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb92-23"><a href="#cb92-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-24"><a href="#cb92-24" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new plot for legend</span></span>
<span id="cb92-25"><a href="#cb92-25" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span>, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb92-26"><a href="#cb92-26" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="fu">names</span>(colors), <span class="at">col =</span> colors, <span class="at">horiz =</span> <span class="cn">TRUE</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="fig/plot_with_r-1.png" width="672" /></p>
<p>Sin embargo con <code>ggplot2</code> bastaría con</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(genes, <span class="fu">aes</span>(rate, expression, <span class="at">color =</span> nutrient)) <span class="sc">+</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span>name <span class="sc">+</span> systematic_name, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>)</span></code></pre></div>
<p><img src="fig/plot_genes-1.png" width="672" /></p>
</div>
<div id="facets" class="section level3 hasAnchor" number="2.7.6">
<h3 class="hasAnchor"><span class="header-section-number">2.7.6</span> Facets<a href="#facets" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Faceting</em> es el proceso que en el dividimos la ventana del gráfico en varias partes pequeñas (una cuadrícula) y muestra un gráfico similar en cada sección. Cada sección generalmente muestra el mismo gráfico para un grupo específico del conjunto de datos. Aquí podemos ver cómo llevar a cabo este tipo de gráficos. Utilizaremos una base de datos sobre propinas</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(tips, <span class="at">package=</span><span class="st">&quot;reshape2&quot;</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(tips)</span></code></pre></div>
<pre><code>  total_bill  tip    sex smoker day   time size
1      16.99 1.01 Female     No Sun Dinner    2
2      10.34 1.66   Male     No Sun Dinner    3
3      21.01 3.50   Male     No Sun Dinner    3
4      23.68 3.31   Male     No Sun Dinner    2
5      24.59 3.61 Female     No Sun Dinner    4
6      25.29 4.71   Male     No Sun Dinner    4</code></pre>
<p>Imaginemos que queremos representar qué propinas se dan en función del total de la cuenta</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>sp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(tips, <span class="fu">aes</span>(<span class="at">x=</span>total_bill, <span class="at">y=</span>tip<span class="sc">/</span>total_bill)) <span class="sc">+</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>sp</span></code></pre></div>
<p><img src="fig/facet-1.png" width="672" /></p>
<p>Ahora nos puede interesar obtener el mismo gráfico para hombres y mujeres. Para ello, podemos hacer el <em>faceting</em> de forma vertical</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># vertical direction</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>sp <span class="sc">+</span> <span class="fu">facet_grid</span>(sex <span class="sc">~</span> .)</span></code></pre></div>
<p><img src="fig/grid_vertical-1.png" width="672" /></p>
<p>u horizontal</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># horizontal direction</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>sp <span class="sc">+</span> <span class="fu">facet_grid</span>(. <span class="sc">~</span> sex)</span></code></pre></div>
<p><img src="fig/grid_horiz-1.png" width="672" /></p>
<p>también según dos variables</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide with &quot;sex&quot; vertical, &quot;day&quot; horizontal</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>sp <span class="sc">+</span> <span class="fu">facet_grid</span>(sex <span class="sc">~</span> day)</span></code></pre></div>
<p><img src="fig/grid_two-1.png" width="672" /></p>
<p>En lugar de crear los paneles con una variable en la dirección horizontal o vertical, las gráficas se pueden colocar una al lado de la otra, envolviéndose con un cierto número de columnas o filas. La etiqueta de cada figura estará en la parte superior.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide by day, going horizontally and wrapping with 2 columns</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>sp <span class="sc">+</span> <span class="fu">facet_wrap</span>( <span class="sc">~</span> day, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="fig/wrap-1.png" width="672" /></p>
<p>Podemos cambiar todo lo que queramos. Este es sólo un ejemplo</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>sp <span class="sc">+</span> <span class="fu">facet_grid</span>(sex <span class="sc">~</span> day) <span class="sc">+</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">strip.text.x =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">8</span>, <span class="at">angle=</span><span class="dv">75</span>),</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">strip.text.y =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">12</span>, <span class="at">face=</span><span class="st">&quot;bold&quot;</span>),</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">colour=</span><span class="st">&quot;brown&quot;</span>,</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">fill=</span><span class="st">&quot;tomato&quot;</span>))</span></code></pre></div>
<p><img src="fig/modifying-1.png" width="672" /></p>
<p>En este <a href="https://ggplot2.tidyverse.org/reference/">link</a> tenéis la referencia de ggplot2.</p>
</div>
</div>
<div id="ejercicios-visualización-de-datos" class="section level2 hasAnchor" number="2.8">
<h2 class="hasAnchor"><span class="header-section-number">2.8</span> Ejercicios (Visualización de datos)<a href="#ejercicios-visualización-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Visualiza el número de vuelos para cada aerolínia por mes.</p></li>
<li><p>Visualiza la distribución de la variabla carat según el precio en el dataset <code>diamonds</code>.</p></li>
<li><p>Carga los datos qe están en <a href="https://raw.githubusercontent.com/isglobal-brge/Master_Modelling/main/data/genome.txt" class="uri">https://raw.githubusercontent.com/isglobal-brge/Master_Modelling/main/data/genome.txt</a> en tu sesión de RStudio utilizando la función <code>read_delim</code> (NOTA: los datos están delimitados por tabulaciones - no hace falta bajarlos al ordenador se cargan desde la URL).</p></li>
</ol>
<p>El archivo contiene información sobre ~730K variantes genéticas en todo el genoma:</p>
<ul>
<li><p>Name: variante genómica (single nucleotide polymorphism)</p></li>
<li><p>Chr: cromosoma</p></li>
<li><p>Position: posición en el cromosoma</p></li>
<li><p>Log.R.Ratio: log-ratio de la intensidad de los dos alelos</p></li>
<li><p>B.Allele.Freq: frecuencia del alelo alternativo</p>
<ul>
<li>¿Cuál es el valor esperado (media) de <code>Log.R.Ratio</code> y <code>B.Allel.Freq</code> para cada cromosoma? (muestra el código de R que usas para obtener dicha información)</li>
<li>Crea un “facet plot” que represente el <code>Log.R.Ratio</code> para cada cromosoma</li>
<li>Crea un “facet plot” que represente el <code>B.Allele.Freq</code> para los cromosomas 1, 2, 3, …, 6 y pinta la etiqueta <code>B.Allele.Freq</code> en rojo.</li>
</ul></li>
</ul>
<!--chapter:end:01-tidyverse.Rmd-->
</div>
</div>
<div id="introducción-al-aprendizaje-automático" class="section level1 hasAnchor" number="3">
<h1 class="hasAnchor"><span class="header-section-number">3</span> Introducción al Aprendizaje Automático<a href="#introducción-al-aprendizaje-automático" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>El aprendizaje automático (AA) (Machine Learning en inglés) es una disciplina científica que suele incluirse en el ámbito de la Inteligencia Artificial (IA) que crea sistemas que aprenden automáticamente. Aprender en este contexto quiere decir identificar patrones complejos en millones de datos. La máquina/ordenador que realmente aprende es un algoritmo que usando datos existentes es capaz de predecir comportamientos futuros. Automáticamente, también en este contexto, implica que estos sistemas se mejoran de forma autónoma con el tiempo, sin intervención humana. En esta figura podemos observar la conexión que hay entre estas áreas y una más reciente conocida como aprendizaje profundo (AP) (Deep Learning en inglés) que veréis en el curso de Aprendizaje Automático 2.</p>
<div class="figure">
<img src="figures/intro_AA.png" alt="" />
<p class="caption">Relación entre AA, AI y AP</p>
</div>
<p>La principal diferencia entre estas áreas radica en el objetivo (e.g pregunta científica) que queremos tratar. Así, la IA vendría a representar a un sistema no biológico que es inteligente basándose en reglas. El AA se basa en algoritmos que entrenan modelos usando datos existentes, y el AP se basa en algoritmos que parametriza redes neuronales de múltiples capas que representan los datos mediante diferentes niveles de abstracción.</p>
<p>En la siguiente figura podemos ver la clasificación (de manera muy genérica) de los tipos de AA a los que podemos enfrentarnos</p>
<div class="figure">
<img src="figures/aa_tipos.png" alt="" />
<p class="caption">Tipos de Aprendizaje Automático</p>
</div>
<p>En estadística, el AA se ha considerado como una ciencia independiente en la que se dispone de un conjunto de herramientas basadas en diferentes métodos y algoritmos que permiten clasificar individuos según una serie de variables. Concer estas técnicas estadísticas es de gran ayuda para la IA y el AP. En este curso estudiaremos estas metodologías en detalle que incluirán:</p>
<ul>
<li>Regresión lineal</li>
<li>Regresión logística</li>
<li>Regresión lasso (ridge, elastic net)</li>
<li>Análisis lineal discriminante</li>
<li>Árboles de clasificación</li>
<li>KNN</li>
<li>Random Forest</li>
<li>Boosting</li>
<li>XGBoost</li>
</ul>
<p>y cómo implementar estos algoritmos con funciones eficientes (<a href="https://www.jstatsoft.org/article/view/v028i05">caret</a>) y escalables (<a href="http://docs.h2o.ai/">H2O</a>).</p>
<!--chapter:end:02-intro_ML.Rmd-->
</div>
<div id="regresión-lineal" class="section level1 hasAnchor" number="4">
<h1 class="hasAnchor"><span class="header-section-number">4</span> Regresión lineal<a href="#regresión-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Este capítulo presenta la regresión lineal, el método de regresión paramétrica que usamos cuando la variable de resultado o respuesta es continua. Cuando el resultado es binario, utilizamos la regresión logística, tema de un capítulo posterior.</p>
<p>El contenido de este capítulo ya se introdujo en la asignatura <a href="https://guies.uab.cat/guies_docents/public/portal/html/2020/assignatura/104855/es">Inferencia Estadística 1</a>, y se vió de forma exhaustiva en la asignatura de <a href="https://guies.uab.cat/guies_docents/public/portal/html/2020/assignatura/104860/es">Modelos lineales 1</a> y aquí se hará un breve repaso de los conceptos más importantes y se hará énfasis en la interpretación práctica de los conceptos aprendidos.</p>
<p>Qué pretendemos aprender en este capítulo:</p>
<ul>
<li>Entender qué pretende y cuándo se usa la regresión lineal</li>
<li>Cómo estimar los parámetros de un modelo de regresión</li>
<li>Familiarizarnos con algunas medidas usadas en la regresión lineal para valorar la utilidad del modelo</li>
<li>Tener una idea de otros aspectos a tener encuenta para estos modelos (suposiciones del modelo, colinealidad, valores atípicos, …)</li>
</ul>
<p>Existen numerosos recursos en la red para complementar este curso. Aquí tenéis algunos tutoriales/cursos en Datacamp:</p>
<p>– [DataCamp: Correlación y regresión] (<a href="https://www.datacamp.com/courses/correlation-and-regression" class="uri">https://www.datacamp.com/courses/correlation-and-regression</a>)</p>
<p>– [DataCamp: Intro to Statistics with R: Correlation and Linear Regression] (<a href="https://www.datacamp.com/courses/intro-to-statistics-with-r-correlation-and-linear-regression" class="uri">https://www.datacamp.com/courses/intro-to-statistics-with-r-correlation-and-linear-regression</a>)</p>
<p>– [Intro to Statistics with R: Multiple Regression] (<a href="https://www.datacamp.com/courses/intro-to-statistics-with-r-multiple-regression" class="uri">https://www.datacamp.com/courses/intro-to-statistics-with-r-multiple-regression</a>)</p>
<div id="preliminares" class="section level2 hasAnchor" number="4.1">
<h2 class="hasAnchor"><span class="header-section-number">4.1</span> Preliminares<a href="#preliminares" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>¿Qué son los modelos? Los modelos simplifican la realidad con fines de comprensión o predicción. Si bien pueden ser herramientas poderosas, debemos tener en cuenta que, después de todo, no son la realidad. En consecuencia, como se dice que dijo el estadístico George Box, “Todos los modelos son incorrectos, pero algunos son útiles”.</p>
<p>En términos generales, el modelado estadístico tiene estos dos objetivos a veces divergentes:</p>
<ol style="list-style-type: decimal">
<li><p><em>Descripción</em>: usar un modelo para describir la relación entre una variable de resultado de interés y una o más variables predictoras.</p></li>
<li><p><em>Predicción</em>: uso de un modelo para predecir instancias desconocidas de la variable de resultado de manera que se minimice el error predictivo fuera de la muestra.</p></li>
</ol>
<p>En el modelado, es posible centrarse en la descripción e ignorar la predicción, y viceversa. Por ejemplo, muchos algoritmos de aprendizaje automático son cajas negras: crean modelos que hacen un buen trabajo de predicción, pero son difíciles, si no imposibles, de interpretar y, en consecuencia, a menudo no nos ayudan a comprender las relaciones entre variables. La regresión lineal puede no ser la técnica más sofisticada, pero si se usa correctamente, su precisión predictiva compara bien con otros algoritmos más avanzados que veremos en este curso. Además, ofrece información descriptiva, en forma de coeficientes para cada variable, que son de gran utilida. La regresión lineal hace un buen trabajo con <em>tanto</em> descripción como predicción. En este capítulo aprenderemos estos usos de la regresión lineal.</p>
</div>
<div id="conceptos-básicos" class="section level2 hasAnchor" number="4.2">
<h2 class="hasAnchor"><span class="header-section-number">4.2</span> Conceptos básicos<a href="#conceptos-básicos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Comencemos por presentar brevemente el modelo lineal junto con algunos de los conceptos y terminología que usaremos a lo largo del curso.</p>
<p>Un modelo lineal es <em>paramétrico</em> porque asumimos que la relación entre dos variables es lineal y puede ser definida por los <em>parámetros</em> de una recta (el <em>intercept</em> y la pendiente). Comenzaremos considerando un modelo lineal simple. En la siguiente figura podemos observar cómo existe una relación lineal entre la dosis de chocolate consumida y el nivel de felicidad reportado por una muestra de individuos seleccionados al azar en una población de Barcelona. Los puntos negros muestran los datos observados para cada individuo y los blancos representan a la felicidad que tendría cada individuo según la dosis de chocolate que reporta tomar.</p>
<div class="figure">
<img src="figures/reg_lin.png" alt="" />
<p class="caption">Regresión lineal simple</p>
</div>
<div id="modelo-lineal-simple" class="section level3 hasAnchor" number="4.2.1">
<h3 class="hasAnchor"><span class="header-section-number">4.2.1</span> Modelo lineal simple<a href="#modelo-lineal-simple" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un modelo lineal simple tiene un resultado (outcome, variable predictiva - en nuestro ejemplo la felicidad), <span class="math inline">\(y\)</span>, y un predictor, <span class="math inline">\(x\)</span> (el consumo de chocolate en nuestro ejemplo). Está definido por la siguiente ecuación.</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1x_i + \epsilon_i,
\]</span></p>
<p>donde <span class="math inline">\(i = 1, \ldots, n.\)</span></p>
<p>El subíndice en esta ecuación, <span class="math inline">\(i\)</span>, indexa las observaciones <span class="math inline">\(n\)</span> en el conjunto de datos. (Pensemos en <span class="math inline">\(i\)</span> como un número de fila que corresponde a los datos de un individuo). La ecuación se puede leer de la siguiente manera: el valor de la <span class="math inline">\(i\)</span>-ésima variable resultado, <span class="math inline">\(y_i\)</span>, está definido por una <em>intercept</em>, <span class="math inline">\(\beta_0\)</span>, más una pendiente, <span class="math inline">\(\beta_1\)</span>, multiplicada por la variable predictora <span class="math inline">\(i\)</span>-ésima, <span class="math inline">\(x_i\)</span>. Estos elementos definen la parte <em>sistemática</em> o <em>determinista</em> del modelo. Sin embargo, debido a que el mundo es incierto y contiene aleatoriedad, sabemos que el modelo será incorrecto (estará sujeto a error). Para describir completamente los datos, necesitamos un término de error, <span class="math inline">\(\epsilon_i\)</span>, que también está indexado por fila. El término de error es la parte <em>estocástica</em> o <em>aleatoria</em> del modelo. <span class="math inline">\(\epsilon_i\)</span> mide la distancia entre los valores ajustados o esperados del modelo — calculados a partir de la parte determinista del modelo — y los valores reales. Los errores en un modelo lineal, también conocidos como residuales del modelo, son la parte de los datos que permanece sin explicar por la parte determinista del modelo. Uno de los supuestos clave de un modelo lineal es que los residuos se distribuyen normalmente con media = 0 y varianza = <span class="math inline">\(\sigma^2\)</span>, que denotamos, en notación matricial, como <span class="math inline">\(N (0, \sigma ^ 2)\)</span>.</p>
</div>
<div id="regresión-lineal-multivariante" class="section level3 hasAnchor" number="4.2.2">
<h3 class="hasAnchor"><span class="header-section-number">4.2.2</span> Regresión lineal multivariante<a href="#regresión-lineal-multivariante" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos agregar predictores adicionales, <span class="math inline">\(p\)</span>, a un modelo lineal simple, convirtiéndolo en un modelo lineal multivariante, que definimos de la siguiente manera:</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_ {i1} + \cdots + \beta_p x_ {ip} + \varepsilon_i,
\]</span></p>
<p>donde <span class="math inline">\(i = 1, \ldots, n\)</span> y <span class="math inline">\(p = 1, \ldots, p.\)</span> En esta ecuación <span class="math inline">\(y_i\)</span> es nuevamente la variable resultado <span class="math inline">\(i\)</span>-ésima, <span class="math inline">\(\beta_0\)</span> es la <em>intercept</em>, <span class="math inline">\(\beta_1\)</span> es el coeficiente de la primera variable predictora, <span class="math inline">\(x_{1}\)</span>, <span class="math inline">\(\beta_p\)</span> es el coeficiente de la variable predictora <span class="math inline">\(p\)</span>-ésima, <span class="math inline">\(x_{p}\)</span>, y <span class="math inline">\(\epsilon_i\)</span> representa la parte estocástica del modelo, los residuos, indexados por fila. La parte determinista del modelo se puede resumir como <span class="math inline">\(X \beta\)</span>, una matriz <span class="math inline">\(p\)</span> x <span class="math inline">\(n\)</span>, que llamaremos el “predictor lineal”.</p>
</div>
<div id="incertidumbre" class="section level3 hasAnchor" number="4.2.3">
<h3 class="hasAnchor"><span class="header-section-number">4.2.3</span> Incertidumbre<a href="#incertidumbre" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La incertidumbre es intrínseca al modelado estadístico. Distinguimos entre <em>Incertidumbre de estimación</em> e <em>Incertidumbre fundamental </em>:</p>
<ul>
<li><p>La incertidumbre de la estimación se deriva del desconocimiento de los parámetros <span class="math inline">\(\beta\)</span>. Disminuye a medida que <span class="math inline">\(n\)</span> aumenta y los <span class="math inline">\(SE\)</span>s se reducen.</p></li>
<li><p>La incertidumbre fundamental se deriva del componente estocástico del modelo, <span class="math inline">\(\epsilon\)</span>. Existe sin importar lo que haga el investigador, sin importar como de grande sea el tamaño muestral <span class="math inline">\(n\)</span>. Podemos reducir la incertidumbre fundamental con predictores elegidos inteligentemente, pero nunca podremos eliminarla.</p></li>
</ul>
</div>
</div>
<div id="ajuste-de-un-modelo-lineal" class="section level2 hasAnchor" number="4.3">
<h2 class="hasAnchor"><span class="header-section-number">4.3</span> Ajuste de un modelo lineal<a href="#ajuste-de-un-modelo-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para ajustar un modelo lineal usamos la función <code>lm()</code>. (La función <code>glm()</code> también se ajusta a un modelo lineal por defecto, definido por <code>family = gaussian</code>. También usaremos<code>glm()</code> para ajustar una regresión logística, con<code>family = binomial</code>). Por ejemplo, usemos el conjunto de dataos mtcars para averiguar si el consumo de combustible (mpg) está correlacionado con el peso del coche (wt). En R deberíamos ejecutar:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>(simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars))</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt, data = mtcars)

Coefficients:
(Intercept)           wt  
     37.285       -5.344  </code></pre>
<p>La ecuación del modelo es: <span class="math inline">\(\widehat {mpg} = 37.285 - 5.344wt\)</span>. (La notación del sombrero, <span class="math inline">\(\widehat {mpg}\)</span>, significa “estimación de”). Sin embargo, con el término de error incluido, ya no estamos <em>estimando</em> mpg sino describiéndolo exactamente: <span class="math inline">\(mpg = 37.285 - 5.344wt + error\)</span> (Por lo tanto, no hay notación de sombrero). Los componentes del modelo se pueden extraer del objeto del modelo usando <code>adjust()</code>, o, de manera equivalente en este caso, <code>predict()</code> y <code>residuals()</code>:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>mtcars_new <span class="ot">&lt;-</span> mtcars <span class="sc">%&gt;%</span> </span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cars =</span> <span class="fu">rownames</span>(mtcars),</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">fitted =</span> <span class="fu">fitted</span>(simple_model),</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="fu">residuals</span>(simple_model)) <span class="sc">%&gt;%</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(cars, mpg, wt, fitted, residuals)</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mtcars_new)</span></code></pre></div>
<pre><code>                               cars  mpg    wt   fitted  residuals
Mazda RX4                 Mazda RX4 21.0 2.620 23.28261 -2.2826106
Mazda RX4 Wag         Mazda RX4 Wag 21.0 2.875 21.91977 -0.9197704
Datsun 710               Datsun 710 22.8 2.320 24.88595 -2.0859521
Hornet 4 Drive       Hornet 4 Drive 21.4 3.215 20.10265  1.2973499
Hornet Sportabout Hornet Sportabout 18.7 3.440 18.90014 -0.2001440
Valiant                     Valiant 18.1 3.460 18.79325 -0.6932545</code></pre>
<p>El modelo se puede utilizar para calcular valores ajustados para coches individuales en el conjunto de datos. Por ejemplo, el valor ajustado para el Mazda RX4, <span class="math inline">\(\widehat {mpg_1}\)</span>, se puede derivar de la ecuación del modelo, <span class="math inline">\(\beta_0 + \beta_1 x_ {i1}\)</span>: 37.29 - 5.34 x 2.62 = 23.28. (El valor <em>real</em> del Mazda RX4, calculado a partir del modelo, sería: 37.29 - 5.34 x 2.62 + 2.28 = 21). El modelo también se puede utilizar para la predicción. ¿Cuál sería el mpg para un coche que pesa 5000 libras? Según el modelo: 37,29 - 5,34 x 5 = 10.56.</p>
<div id="residuos" class="section level3 hasAnchor" number="4.3.1">
<h3 class="hasAnchor"><span class="header-section-number">4.3.1</span> Residuos<a href="#residuos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los residuales del modelo — representados por los segmentos de línea vertical en el gráfico siguiente — son las diferencias entre los valores ajustados y reales de mpg.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars_new, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">&quot;lightgrey&quot;</span>) <span class="sc">+</span>   </span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend =</span> wt, <span class="at">yend =</span> fitted), <span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> fitted), <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Residuales del modelo para mpg ~ wt&quot;</span>)</span></code></pre></div>
<p><img src="fig/plotResid-1.png" width="672" /></p>
<p>Podemos resumir los residuos con una medida llamada suma de cuadrados residual (RSS), que se calcula restando los resultados reales, <span class="math inline">\(y_i\)</span>, de los valores ajustados, <span class="math inline">\(\hat {y} _i\)</span>, elevando al cuadrado esas diferencias, luego sumando los cuadrados.</p>
<p><span class="math display">\[
\operatorname {RSS} = \sum_ {i = 1} ^ n ((\beta_0 + \beta_1x_i) - y_i) ^ 2 = \sum_{i = 1}^n(\hat {y} _i - y_i) ^ 2
\]</span></p>
<p>Al resumir los errores del modelo, RSS nos permite cuantificar el rendimiento del modelo con un solo número:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>rss <span class="ot">&lt;-</span> <span class="cf">function</span>(fitted, actual){</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>((fitted <span class="sc">-</span> actual)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rss</span>(<span class="fu">fitted</span>(simple_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 278.3219</code></pre>
</div>
<div id="interpretación-de-coeficientes" class="section level3 hasAnchor" number="4.3.2">
<h3 class="hasAnchor"><span class="header-section-number">4.3.2</span> Interpretación de coeficientes<a href="#interpretación-de-coeficientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>¿Cómo interpretamos la salida de la función <code>lm()</code>? Comencemos con el modelo simple de mpg.</p>
<ul>
<li><strong>intercept</strong>: 37.29 representa el valor predicho de mpg cuando wt es 0. Dado que wt no puede ser igual a 0. El <em>intercept</em> no es interpretable en este modelo. Para hacerlo interpretable, necesitamos centrar la variable wt en 0, lo que podemos hacer fácilmente restando la media de wt de cada observación (<span class="math inline">\(x_ {centrado} = x - \ bar {x}\)</span>). Esta es una transformación lineal que cambiará la escala del predictor y, por lo tanto, <span class="math inline">\(\beta_0\)</span> también, pero no el ajuste del modelo: <span class="math inline">\(\beta_1\)</span> permanecerá igual (-5,34) al igual que RSS (278,32). Después de la transformación, el peso promedio del coche es 0 y el <em>intercept</em> representa las millas por galón pronosticadas para coches de peso promedio.</li>
</ul>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>mtcars<span class="sc">$</span>wt_centered <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>wt <span class="sc">-</span> <span class="fu">mean</span>(mtcars<span class="sc">$</span>wt)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>(simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt_centered, <span class="at">data =</span> mtcars))</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt_centered, data = mtcars)

Coefficients:
(Intercept)  wt_centered  
     20.091       -5.344  </code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rss</span>(<span class="fu">fitted</span>(simple_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 278.3219</code></pre>
<p>Ahora el <em>intercept</em>, 20.09, es significativa y representa el valor predicho de mpg cuando wt_centered es 0 — es decir, cuando wt es promedio.</p>
<p>Hay dos formas de interpretar los coeficientes de las variables en un modelo lineal:</p>
<ol style="list-style-type: decimal">
<li><p><em>Contrafactual</em>: el coeficiente representa el cambio predicho en el resultado asociado con un aumento de 1 unidad en el predictor, mientras se mantienen constantes los demás predictores (en el caso multivariable).</p></li>
<li><p><em>Predictivo</em>: el coeficiente representa la diferencia pronosticada en el resultado entre dos grupos que difieren en 1 unidad en el predictor, mientras se mantienen constantes los otros predictores.</p></li>
</ol>
<p>Normalmente los coeficientes del modelo se suelen interpretar de acuerdo con el paradigma contrafáctico. Por lo tanto,</p>
<ul>
<li><em>wt_centered</em>: -5.34 representa el cambio previsto en el resultado, mpg, asociado con un aumento de 1 unidad en wt_centered.</li>
</ul>
<p>Agreguemos un segundo predictor al modelo, una versión binaria de caballos de fuerza (hp_bin), que definiremos como 0 para valores de hp que están por debajo del promedio y 1 para valores mayores o iguales que el promedio.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>mtcars<span class="sc">$</span>hp_bin <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(mtcars<span class="sc">$</span>hp <span class="sc">&lt;</span> <span class="fu">mean</span>(mtcars<span class="sc">$</span>hp), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>(multivariable_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt_centered <span class="sc">+</span> hp_bin , <span class="at">data =</span> mtcars))</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt_centered + hp_bin, data = mtcars)

Coefficients:
(Intercept)  wt_centered       hp_bin  
     21.649       -4.168       -3.324  </code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rss</span>(<span class="fu">fitted</span>(multivariable_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 231.3121</code></pre>
<p>Este modelo multivariante es una mejora con respecto al modelo simple ya que tiene un RSS menor.</p>
<ul>
<li><p><strong>intercept</strong>: 21,65 representa el mpg predicho cuando los predictores continuos o binarios son iguales a 0 o (no aplicable en este caso) cuando las variables de los factores están en su nivel de referencia. El <em>intercept</em> es el mpg pronosticado por el modelo para autos de peso promedio que tienen caballos de fuerza por debajo del promedio.</p></li>
<li><p><em>wt_centered</em>: -4,17 representa el cambio previsto en mpg asociado con un aumento de 1 unidad en wt_centered (digamos, de 1 a 2) mientras se mantiene constante el otro predictor, hp_bin. <em>Los coeficientes de regresión multivariable capturan cómo el resultado varía de manera única con un predictor dado, después de tener en cuenta los efectos de todos los demás predictores.</em> En la práctica, esto significa que el coeficiente que describe la relación entre mpg y wt_centrado se ha promediado en los niveles hp_bin, por lo que es igual en cada nivel de hp_bin.</p></li>
<li><p><em>hp_bin</em>: -3.32 representa el cambio previsto en mpg asociado con un aumento de 1 unidad en hp_bin (de 0 a 1) mientras se mantiene constante el otro predictor, wt_centered.</p></li>
</ul>
</div>
<div id="interacciones" class="section level3 hasAnchor" number="4.3.3">
<h3 class="hasAnchor"><span class="header-section-number">4.3.3</span> Interacciones<a href="#interacciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos agregar una interacción a este modelo. A menudo, la relación entre un predictor y un resultado puede depender del nivel de otra variable predictiva. Por ejemplo, la pendiente de la recta de regresión que define la relación entre wt_centrado y mpg puede variar con los niveles de hp_bin. Si es así, decimos que existe una interacción entre wt_centered y hp_bin al predecir mpg. Para incluir una interacción entre dos variables en la fórmula del modelo, simplemente reemplazamos “+” por “*” en la fórmula del modelo. Esta fórmula, <code>mpg ~ wt_centered * hp_bin</code>, es exactamente equivalente a <code>mpg ~ wt_centered + wt_centered * hp_bin</code>, o a <code>mpg ~ wt_centered + hp_bin + wt_centered*hp_bin</code> ya que <code>lm ()</code> agrega automáticamente el efecto principal junto con la interacción. También se puede usar “:” para el término exacto de la interacción `<code>mpg ~ wt_centered + hp_bin + wt_centered:hp_bin</code>. Por “efecto principal” nos referimos a los términos que interactúan entre si. En este modelo, el efecto de interacción es wt_centered:hp_bin, mientras que wt_centered y hp_bin por sí mismos son los efectos principales.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>(multivariable_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt_centered  <span class="sc">*</span> hp_bin, <span class="at">data =</span> mtcars))</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt_centered * hp_bin, data = mtcars)

Coefficients:
       (Intercept)         wt_centered              hp_bin  wt_centered:hp_bin  
            20.276              -6.391              -3.163               3.953  </code></pre>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rss</span>(<span class="fu">fitted</span>(multivariable_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 170.3792</code></pre>
<p>RSS mejora una vez más.</p>
<p>Las interacciones pueden ser difíciles de interpretar es por ello que la visualización ayuda a comprender qué está sucediendo.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(wt_centered, mpg, <span class="at">col =</span> <span class="fu">factor</span>(hp_bin), <span class="at">group =</span> <span class="fu">factor</span>(hp_bin))) <span class="sc">+</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;mpg ~ wt_centered * hp_bin&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-9-1.png" width="672" /></p>
<p>Podemos ver que la relación entre wt y mpg depende de los niveles de hp_bin: las pendientes de las rectas de regresión difieren. <em>Las rectas de regresión no paralelas indican la presencia de una interacción</em>. Observamos una relación más fuerte entre el peso y las millas por galón entre los autos con caballos de fuerza por debajo del promedio (una relación <em>negativa</em> más fuerte) que entre los autos con más caballos de fuerza. Las rectas de regresión para hp_bin se vuelven más planas a medida que aumenta wt_centrado.</p>
<p><em>NOTA: la presencia de una interacción cambia la interpretación de los efectos principales</em>. En un modelo sin interacción, los efectos principales son independientes de los valores particulares de los otros predictores. Por el contrario, una interacción hace que los efectos principales dependan de valores particulares de los otros predictores.</p>
<ul>
<li><p><em>wt_centered:hp_bin</em>: 3.95 representa la diferencia en la pendiente de wt_centered para hp_bin = 1 en comparación con hp_bin = 0. En otras palabras, cuando aumentamos hp_bin de 0 a 1, se predice que la pendiente de la rectas de regresión para wt_centered aumentar en 3,95. O, cuando aumentamos wt_centrado en 1, se predice que la rectas de regresión para hp_bin aumentará en 3,95.</p></li>
<li><p><em>wt_centered</em>: -6.39 representa el cambio predicho en mpg asociado con un aumento de 1 unidad en wt <em>entre aquellos coches donde hp_bin = 0.</em></p></li>
<li><p><em>hp_bin</em>: -3.16 representa el cambio previsto en mpg asociado con un aumento de 1 unidad en hp_bin de 0 a 1 <em>entre los coches con wt_centered = 0</em> (promedio).</p></li>
</ul>
<p>Puede resultar instructivo ver qué está haciendo <code>lm ()</code> en segundo plano para ajustarse a este modelo. El comando <code>model.matrix ()</code> muestra cómo se ha reformateado la matriz del predictor para la regresión:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(multivariable_model))</span></code></pre></div>
<pre><code>                  (Intercept) wt_centered hp_bin wt_centered:hp_bin
Mazda RX4                   1    -0.59725      0            0.00000
Mazda RX4 Wag               1    -0.34225      0            0.00000
Datsun 710                  1    -0.89725      0            0.00000
Hornet 4 Drive              1    -0.00225      0            0.00000
Hornet Sportabout           1     0.22275      1            0.22275
Valiant                     1     0.24275      0            0.00000</code></pre>
<p>El <em>intercept</em> es un vector de 1s. El vector para el término de interacción, wt_centered: hp_bin, consiste simplemente en el producto de los dos vectores con las componentes de cada variable</p>
</div>
</div>
<div id="estimación-por-mínimos-cuadrados" class="section level2 hasAnchor" number="4.4">
<h2 class="hasAnchor"><span class="header-section-number">4.4</span> Estimación por mínimos cuadrados<a href="#estimación-por-mínimos-cuadrados" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para el modelo <span class="math inline">\(y = X \beta + \epsilon\)</span>, donde <span class="math inline">\(\beta\)</span> es el vector de coeficientes ajustados y $$ es el vector de residuos del modelo, la estimación de mínimos cuadrados es <span class="math inline">\(\hat {\beta}\)</span> que minimiza RSS para los datos dados <span class="math inline">\(X, y\)</span>. Podemos expresar la estimación de mínimos cuadrados como <span class="math inline">\(\ hat {\beta} = (X&#39;X) ^ {- 1} X&#39;y\)</span>, donde <span class="math inline">\(X&#39;\)</span> es la transposición de la matriz de <span class="math inline">\(X\)</span>. A continuación podemos ver cómo se deriva esta fórmula<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p><span class="math display">\[
RSS = \epsilon ^ 2 = (y - X \beta) &#39;(y - X \beta)
\]</span></p>
<p><span class="math display">\[
RSS = y&#39;y - y&#39;X \beta - \beta&#39;X&#39;y + \beta&#39;X&#39;X \beta
\]</span></p>
<p><span class="math display">\[
RSS = y&#39;y - (2y&#39;X) \beta + \beta &#39;(X&#39;X) \beta
\]</span></p>
<p>Según apunta el autor: “Aunque la multiplicación de matrices generalmente no es conmutativa, cada producto [arriba] es 1 x 1, por lo que <span class="math inline">\(y&#39;X \beta = \beta&#39;X&#39;y\)</span>”.</p>
<p>Para minimizar RSS encontramos la derivada parcial con respecto a <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\frac{\partial RSS}{\partial\beta}= 0  - 2X&#39;y + 2X&#39;X\beta
\]</span></p>
<p>Establecemos esta derivada igual a 0 y resolvemos $$:</p>
<p><span class="math display">\[
X&#39;X \beta = X&#39;y
\]</span></p>
<p><span class="math display">\[
\beta = (X&#39;X) ^ {- 1} X&#39;y
\]</span></p>
<p>Podemos usar esta ecuación y la matriz del modelo para el modelo multivariable para estimar <span class="math inline">\(\hat{\beta}\)</span> para <code>mpg ~ wt_centered * hp_bin + hp_centered</code>:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(multivariable_model)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>mpg</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y</span></code></pre></div>
<pre><code>                        [,1]
(Intercept)        20.276155
wt_centered        -6.390834
hp_bin             -3.162983
wt_centered:hp_bin  3.953027</code></pre>
<p>Este método devuelve las mismas estimaciones de coeficientes que <code>lm ()</code>.</p>
</div>
<div id="medidas-adicionales-de-ajuste-del-modelo" class="section level2 hasAnchor" number="4.5">
<h2 class="hasAnchor"><span class="header-section-number">4.5</span> Medidas adicionales de ajuste del modelo<a href="#medidas-adicionales-de-ajuste-del-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como hemos visto, RSS nos permite comparar qué tan bien se ajustan los modelos a los datos. Una medida relacionada es la raíz del error cuadrático medio (RMSE por sus siglas en inglés), la raíz cuadrada del promedio de los errores cuadráticos:</p>
<p><span class="math display">\[
\operatorname{RMSE}= \sqrt{\frac{\sum_{i=1}^n ((\beta_0 + \beta_1x_i) - y_i)^2}{n}}
\]</span></p>
<p><span class="math display">\[
= \sqrt{\frac{\sum_{i=1}^n (\hat{y}_i - y_i)^2}{n}}
\]</span></p>
<p>Lo bueno de RMSE es que, a diferencia de RSS, devuelve un valor que está en la escala del variable resultado.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rss</span>(<span class="fu">fitted</span>(multivariable_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 170.3792</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="cf">function</span>(fitted, actual){</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">mean</span>((fitted <span class="sc">-</span> actual)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">fitted</span>(multivariable_model), mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<pre><code>[1] 2.307455</code></pre>
<p>En promedio, entonces, este modelo tiene una diferencia de aproximadamente 2.31 mpg por cada coche.</p>
<p><span class="math inline">\(R^2\)</span> es otra medida de ajuste del modelo que es conveniente porque es una medida estandarizada — escalada entre 0 y 1 — y, por lo tanto, es comparable en todos los contextos.</p>
<p><span class="math display">\[
R^2 = 1 - \frac{SS_\text{resid}}{SS_\text{tot}},
\]</span></p>
<p>donde <span class="math inline">\(SS_\text{tot} = \sum_i (y_i- \bar{y}) ^ 2\)</span> y <span class="math inline">\(SS_\text{res} = \sum_i (y_i - \hat {y} _i) ^ 2\)</span>. En resumen: <span class="math inline">\(R^2\)</span> representa la variación en la variable de resultado explicada por el modelo como una proporción de la variación total. En la gráfica de abajo, el panel de la izquierda, TSS, sirve como denominador para calcular <span class="math inline">\(R^2\)</span>, y el panel de la derecha, RSS, es el numerador.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(gridExtra)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>mtcars<span class="sc">$</span>mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(mtcars<span class="sc">$</span>mpg) </span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>plot1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(wt, mpg)) <span class="sc">+</span></span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">mean</span>(mtcars<span class="sc">$</span>mpg), <span class="at">col =</span> <span class="dv">2</span>) <span class="sc">+</span>  </span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend =</span> wt, <span class="at">yend =</span> mean), <span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb130-7"><a href="#cb130-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">&quot;Total Sum of Squares (TSS) </span><span class="sc">\n</span><span class="st">&quot;</span>,tss))</span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a>plot2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(wt, mpg)) <span class="sc">+</span></span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">col=</span><span class="dv">2</span>) <span class="sc">+</span>  </span>
<span id="cb130-11"><a href="#cb130-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend =</span> wt, <span class="at">yend =</span> <span class="fu">fitted</span>(<span class="fu">lm</span>(mpg<span class="sc">~</span>wt, <span class="at">data=</span>mtcars))), <span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span>  </span>
<span id="cb130-12"><a href="#cb130-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb130-13"><a href="#cb130-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">paste</span>(<span class="st">&quot;Residual Sum of Squares (RSS) </span><span class="sc">\n</span><span class="st">&quot;</span>,rss))</span>
<span id="cb130-14"><a href="#cb130-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-15"><a href="#cb130-15" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(plot1, plot2, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-14-1.png" width="672" /></p>
<p>Para nuestro modelo lineal simple, mpg ~ wt, <span class="math inline">\(R^2\)</span> era de .75, que coincide con nuestro cálculo aquí: 1 - 278/1126 = .75. Esto significa que wt explica el 75% de la variación total en mpg. Cuanto mejor se ajusta la regresión lineal a los datos en comparación con el promedio simple, más se acerca el valor de <span class="math inline">\(R^2\)</span> a 1. Para la regresión lineal simple, <span class="math inline">\(R^2\)</span> es como la correlación al cuadrado entre el resultado y el predictor.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(mtcars<span class="sc">$</span>mpg, mtcars<span class="sc">$</span>wt)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>[1] 0.7528328</code></pre>
<p>Un problema con el <span class="math inline">\(R^2\)</span> es que agregar variables al modelo tiende a mejorarlo aunque las nuevas variables no sean relevantes. Añadir más variables puede conducir a un sobreajuste. Se ha desarrollado una variante de <span class="math inline">\(R^2\)</span> que penaliza la medida para predictores adicionales: <span class="math inline">\(R^2\)</span>ajustados.</p>
<p><span class="math display">\[
\bar R^2 = {1-(1-R^2){n-1 \over n-p-1}}
\bar R^2 = {R^2-(1-R^2){p \over n-p-1}},
\]</span></p>
<p>donde <span class="math inline">\(n\)</span> es el número de observaciones en el conjunto de datos y <span class="math inline">\(p\)</span> es el número de predictores en el modelo. Es fácil calcular este resultado utilizando la función <code>summary()</code></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multivariable_model)</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt_centered * hp_bin, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.5837 -1.4371 -0.8214  1.4517  5.6228 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         20.2762     0.8323  24.363  &lt; 2e-16 ***
wt_centered         -6.3908     0.9367  -6.823 2.06e-07 ***
hp_bin              -3.1630     1.1971  -2.642  0.01333 *  
wt_centered:hp_bin   3.9530     1.2492   3.164  0.00373 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.467 on 28 degrees of freedom
Multiple R-squared:  0.8487,    Adjusted R-squared:  0.8325 
F-statistic: 52.35 on 3 and 28 DF,  p-value: 1.324e-11</code></pre>
<p>En este caso <span class="math inline">\(\bar R^2=0.8325\)</span> lo que indica que nuestro modelo explica un 83.25% de la variabilidad observada de la variable ‘mpg’.</p>
</div>
<div id="sesgo-variación-sobreajuste" class="section level2 hasAnchor" number="4.6">
<h2 class="hasAnchor"><span class="header-section-number">4.6</span> Sesgo, variación, sobreajuste<a href="#sesgo-variación-sobreajuste" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>¿Qué entendemos por “sobreajuste”? Los siguientes son conceptos clave para pensar en el rendimiento del modelo, a los que volveremos a lo largo del curso:</p>
<ul>
<li><p><em>Rendimiento en la muestra</em>: cómo se comporta el modelo en los datos que se utilizaron para construirlo.</p></li>
<li><p><em>Rendimiento fuera de la muestra</em>: cómo se comporta el modelo cuando encuentra nuevos datos.</p></li>
<li><p>Si el modelo funciona mejor dentro de la muestra que fuera de la muestra, entonces decimos que el modelo <em>sobreajusta</em> los datos de la muestra o de entrenamiento.</p></li>
<li><p>El sobreajuste ocurre cuando un modelo se ajusta a la muestra <em>demasiado bien</em>: el modelo ha sido optimizado para capturar las idiosincrasias — el ruido aleatorio — de la muestra.</p></li>
<li><p><em>Sesgo</em> se refiere a una alta precisión predictiva en la muestra. El sesgo bajo es bueno.</p></li>
<li><p><em>Varianza</em> se refiere a una mayor precisión predictiva dentro de la muestra que fuera de la muestra. La varianza baja es buena.</p></li>
<li><p>Un modelo que sobreajusta tiene un sesgo bajo y una gran varianza.</p></li>
<li><p><em>La compensación de sesgo-varianza</em> se refiere a la idea de que no se puede tener un sesgo bajo y una varianza baja a la vez.</p></li>
</ul>
<p>Nos protegeremos contra — o evaluaremos la cantidad de — sobreajuste usando una técnica llamada validación cruzada que veremos más adelante.</p>
</div>
<div id="regresión-como-estimación-de-una-media-condicional" class="section level2 hasAnchor" number="4.7">
<h2 class="hasAnchor"><span class="header-section-number">4.7</span> Regresión como estimación de una media condicional<a href="#regresión-como-estimación-de-una-media-condicional" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dadas las complejidades anteriores, se podría pensar que el uso de la regresión lineal sólo es útil para nada más (¡y nada menos!) estimar una media condicional. Pero, ¿qué es una media condicional?</p>
<p>Consideremos el siguiente ejemplo. En 2011 se inició un programa de uso compartido de bicicletas en USA y se recopilaron datos durante 2011 y 2012 sobre el uso estacional de bicicletas y las condiciones climáticas. Estos datos se encuentran recogidos en el fichero <a href="https://raw.githubusercontent.com/isglobal-brge/TeachingMaterials/master/Aprendizaje_Automatico_1/data/day.csv">day.csv</a>. La variable de resultado que nos interesa es “count”— el número total de ciclistas que alquilan bicicletas en un día determinado. El conjunto de datos tiene una fila para cada día, con variables para (entre otras) estación, año, mes, feriado, día de la semana, temperatura, temperatura percibida, humedad y velocidad del viento (nombradas en inglés).</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>day <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/day.csv&quot;</span>)</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>day <span class="ot">&lt;-</span> day <span class="sc">%&gt;%</span></span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="at">count =</span> cnt,</span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>         season,</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">year=</span> yr,</span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">month =</span> mnth,</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>         holiday,</span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>         weekday,</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">temperature =</span> temp,</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>         atemp,</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">humidity =</span> hum,</span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a>         windspeed)</span></code></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(day)</span></code></pre></div>
<pre><code>Rows: 731
Columns: 10
$ count       &lt;int&gt; 985, 801, 1349, 1562, 1600, 1606, 1510, 959, 822, 1321, 1263, 1162, 1406, 1421, 1…
$ season      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
$ year        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
$ month       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
$ holiday     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
$ weekday     &lt;int&gt; 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, …
$ temperature &lt;dbl&gt; 0.3441670, 0.3634780, 0.1963640, 0.2000000, 0.2269570, 0.2043480, 0.1965220, 0.16…
$ atemp       &lt;dbl&gt; 0.3636250, 0.3537390, 0.1894050, 0.2121220, 0.2292700, 0.2332090, 0.2088390, 0.16…
$ humidity    &lt;dbl&gt; 0.805833, 0.696087, 0.437273, 0.590435, 0.436957, 0.518261, 0.498696, 0.535833, 0…
$ windspeed   &lt;dbl&gt; 0.1604460, 0.2485390, 0.2483090, 0.1602960, 0.1869000, 0.0895652, 0.1687260, 0.26…</code></pre>
<p>Una pregunta exploratoria inicial es: ¿cómo varía el uso de la bicicleta por año? Podemos responder a esta pregunta simplemente calculando un promedio para cada año:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>day <span class="sc">%&gt;%</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">year =</span> <span class="fu">ifelse</span>(year <span class="sc">==</span> <span class="dv">0</span>, <span class="dv">2011</span>, <span class="dv">2012</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(year) <span class="sc">%&gt;%</span></span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="st">`</span><span class="at">average ridership</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">mean</span>(count)))</span></code></pre></div>
<pre><code># A tibble: 2 × 2
   year `average ridership`
  &lt;dbl&gt;               &lt;dbl&gt;
1  2011                3406
2  2012                5600</code></pre>
<p>El número de pasajeros promedio en este resumen representa una media condicional: la media de la variable de recuento, condicional al año. ¿Qué nos dice la regresión lineal sobre el promedio de pasajeros (riders) por año?</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(count <span class="sc">~</span> year, <span class="at">data =</span> day)</span></code></pre></div>
<pre><code>
Call:
lm(formula = count ~ year, data = day)

Coefficients:
(Intercept)         year  
       3406         2194  </code></pre>
<p>La salida del modelo incluye un <em>intercept</em> y un coeficiente para el año. El <em>intercept</em> es el promedio de la variable de resultado cuando los predictores numéricos son iguales a cero. Por lo tanto, 3406 es el número de pasajeros promedio cuando año = 0 (es decir, 2011), y el coeficiente para el año, 2194, es el aumento esperado en el número de pasajeros asociado con un aumento de 1 unidad en el año (es decir, cuando el año pasa de 0 a 1 ). Por lo tanto, el número promedio de pasajeros en el año 1 (2012) es solo la suma de los dos coeficientes — 3406 + 2194 = 5600 — que es idéntica a la media condicional para 2012 que calculamos anteriormente usando<code>dplyr</code> .</p>
<p>En general, dadas dos variables aleatorias, X e Y (piense: año y número de pasajeros), podemos definir la media condicional como el valor esperado o promedio de Y dado que X está restringido a tener un valor específico, <span class="math inline">\(x\)</span>, a partir de su rango: <span class="math inline">\(\mathbf {E} [Y \mid X = x]\)</span>. Ejemplo: <span class="math inline">\(\mathbf{E} [Ridership \mid Year = 2012]\)</span> es el número promedio de pasajeros dado ese año = 2012. Una media condicional tiene un valor descriptivo — sabemos que el coeficiente <span class="math inline">\(\beta\)</span> para el año de nuestro modelo, 2194, representa la relación entre el número de pasajeros y el año, con la magnitud o el valor absoluto del coeficiente que indica la fuerza de la relación, positiva o negativa. Los coeficientes también se pueden utilizar para la predicción. ¿Cuántos ciclistas más deberíamos esperar en 2013? Utilice el modelo: <span class="math inline">\(\mathbf {E} [riders \mid year = 2013]\)</span> es igual al número en 2012, 5600, más el coeficiente del año: 5600 + 2194 = 7794.</p>
<p>El modelo nos permite predecir, pero debemos recordar que no hay nada mágico en la predicción. Deberíamos pensar críticamente al respecto. Por un lado, asume una tendencia constante año tras año. ¿Es esta una suposición razonable?</p>
</div>
<div id="la-función-de-regresión" class="section level2 hasAnchor" number="4.8">
<h2 class="hasAnchor"><span class="header-section-number">4.8</span> La función de regresión<a href="#la-función-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consideremos la cantidad media de pasajeros condicionada a la temperatura (que en este conjunto de datos se ha normalizado y convertido a grados Celsius). Podemos definir una función que devolverá la media condicional. Para cualquier temperatura, <span class="math inline">\(t\)</span>, defina <span class="math inline">\(\mu (t) = \mathbf {E} [Riders \mid Temperature = t]\)</span>, que es el número medio de pasajeros cuando temperatura = <span class="math inline">\(t\)</span>. Dado que podemos variar <span class="math inline">\(t\)</span>, esto es de hecho una función, y se conoce como la <em>función de regresión</em> que relaciona a los pasajeros con la temperatura. Por ejemplo, <span class="math inline">\(\mu\)</span> (.68) es el número medio de pasajeros cuando <span class="math inline">\(t\)</span>= .68 y <span class="math inline">\(\mu\)</span> (.05)es el número medio de pasajeros cuando <span class="math inline">\(t\)</span>= .05, etc.</p>
<p>Debemos tener en cuenta que el valor real de <span class="math inline">\(\mu\)</span> (.68) se desconoce porque es un valor de población. Existe, pero no en nuestra muestra. Entonces, nuestra estimación, <span class="math inline">\(\hat {\ mu}\)</span> (. 68), debe basarse en los pares de Riders-Temperature que tenemos en nuestros datos: <span class="math inline">\((r_ {1}, t_ {1}), ..., ( r_ {731}, t_ {731})\)</span>. ¿Cómo podemos hacer esto exactamente? Un enfoque sería simplemente calcular las medias condicionales relevantes a partir de nuestros datos. Para encontrar <span class="math inline">\(\hat {\mu} (t)\)</span> usando este método, simplificaremos los datos redondeando la temperatura a dos lugares decimales.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>day <span class="sc">%&gt;%</span> </span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(<span class="at">temperature =</span> <span class="fu">round</span>(temperature, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">mean =</span> <span class="fu">round</span>(<span class="fu">mean</span>(count))) </span></code></pre></div>
<pre><code># A tibble: 77 × 2
   temperature  mean
         &lt;dbl&gt; &lt;dbl&gt;
 1        0.06   981
 2        0.1   1201
 3        0.11  2368
 4        0.13  1567
 5        0.14  1180
 6        0.15  1778
 7        0.16  1441
 8        0.17  1509
 9        0.18  1597
10        0.19  2049
# ℹ 67 more rows</code></pre>
<p>Sin embargo, se puede observar que faltan valores en la secuencia. Aquí hay un gráfico que muestra las brechas en los datos.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>day <span class="sc">%&gt;%</span> </span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(<span class="at">temperature =</span> <span class="fu">round</span>(temperature, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">mean =</span> <span class="fu">round</span>(<span class="fu">mean</span>(count))) <span class="sc">%&gt;%</span></span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">right_join</span>(<span class="fu">data.frame</span>(<span class="at">temperature=</span><span class="fu">seq</span>(.<span class="dv">01</span>, .<span class="dv">9</span>, .<span class="dv">01</span>)), <span class="at">by =</span> <span class="st">&quot;temperature&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(temperature, mean)) <span class="sc">+</span></span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb144-7"><a href="#cb144-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Estimated mean daily riders (with missing observations)&quot;</span>) <span class="sc">+</span></span>
<span id="cb144-8"><a href="#cb144-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;temperature&quot;</span>, <span class="at">y =</span> <span class="st">&quot;mean riders&quot;</span>)</span></code></pre></div>
<p><img src="fig/temp2-1.png" width="672" /></p>
<p>Este enfoque para estimar la función de regresión, <span class="math inline">\(\hat{\mu} (t)\)</span> tendrá problemas cuando, por ejemplo, queremos predecir el número de pasajeros a una temperatura para la que no tenemos datos.</p>
<p>Usar medias condicionales para estimar <span class="math inline">\(\hat {\mu} (t)\)</span> es un enfoque <em>no paramétrico</em>. Es decir, no asumimos nada sobre la forma de la función desconocida <span class="math inline">\(\mu(t)\)</span> si se trazara en un gráfico, sino que simplemente la estimamos directamente a partir de nuestros datos. La regresión de K-vecinos más cercanos (KNN) es una generalización de este enfoque no paramétrico. Este tipo de regresión es muy útil cuando queremos describir cuál es la relación entre nuestros datos sin asumir que dicha relación es lineal (que puede que sea el caso).</p>
<p>Debemos tener en cuenta que podríamos hacer algunas suposiciones sobre esa forma, posiblemente mejorando nuestras estimaciones, lo que haría que nuestro enfoque sea <em>paramétrico</em>, como en el caso de la regresión lineal.</p>
</div>
<div id="estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn" class="section level2 hasAnchor" number="4.9">
<h2 class="hasAnchor"><span class="header-section-number">4.9</span> Estimación no paramétrica de la función de regresión: regresión KNN<a href="#estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A veces no es posible calcular buenas medias condicionales para el resultado debido a la falta de valores de predicción. Supongamos que queremos encontrar <span class="math inline">\(\hat{\mu} (. 12)\)</span>. Resulta que no hubo días en nuestro conjunto de datos en los que la temperatura fuera de .12. El algoritmo KNN resuelve este problema usando las <span class="math inline">\(k\)</span> observaciones más cercanas a <span class="math inline">\(t\)</span>= .12 para calcular la media condicional, <span class="math inline">\(\hat {\mu} (. 12)\)</span>. Si definimos <span class="math inline">\(k\)</span>= 4, entonces tomaríamos los <em>cuatro</em> valores más cercanos a .12 en el conjunto de datos — .1275, .134783, .138333, .1075. (“Más cercano” en este caso se define como la distancia euclidiana, que en un espacio unidimensional, una recta numérica, es simplemente: <span class="math inline">\(\sqrt {(xy) ^ 2}\)</span>.) Estos <span class="math inline">\(k\)</span>= 4 valores más cercanos se usarían para calcular <span class="math inline">\(\hat{\mu} (. 12)\)</span> calculando el promedio.</p>
<p>Establecer el valor de <span class="math inline">\(k\)</span> es obviamente una decisión crítica. Si usamos <span class="math inline">\(k\)</span>= 100, por ejemplo, nuestras estimaciones podrían no ser muy buenas. Y quizás <span class="math inline">\(k\)</span>= 4 sea demasiado bajo — podría llevar a un sobreajuste. En el caso de <span class="math inline">\(k\)</span>= 4, el error dentro de la muestra (sesgo) puede ser bajo, pero el error al predecir nuevas observaciones (varianza) puede ser alto.</p>
<p>Aquí, por ejemplo, hay una gráfica de los valores ajustados de un modelo KNN de la temperatura de los pasajeros cuando <span class="math inline">\(k\)</span>= 4.</p>
<p><img src="fig/unnamed-chunk-18-1.png" width="672" /></p>
<p>El sesgo en este modelo es presumiblemente bajo porque el ajuste es muy flexible: los valores ajustados están muy cerca de los valores reales. El problema es que la función de regresión KNN en <span class="math inline">\(k\)</span>= 4 podría estar haciendo <em>demasiado</em> buen trabajo al describir la muestra. Cuando este modelo encuentra nuevos datos, sin las mismas idiosincrasias, su rendimiento puede ser muy pobre, con una gran variación. Es posible que el modelo esté sobre-ajustado a la muestra. La compensación de sesgo-varianza expresa esta idea: cuando el sesgo es bajo, es probable que la varianza sea alta, y viceversa.</p>
<p>A continuación se muestra un ejemplo de un sesgo más alto, posiblemente un caso de varianza menor cuando <span class="math inline">\(k\)</span>= 40.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> day</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>r<span class="sc">$</span>temp_rounded <span class="ot">&lt;-</span> <span class="fu">round</span>(r<span class="sc">$</span>temp,<span class="dv">2</span>)</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">knn.reg</span>(<span class="at">train=</span>r<span class="sc">$</span>temperature, <span class="at">y=</span>r<span class="sc">$</span>count, <span class="at">k=</span><span class="dv">40</span>,</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">algorithm=</span><span class="st">&quot;brute&quot;</span>)</span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>r<span class="sc">$</span>knn <span class="ot">&lt;-</span> knn<span class="sc">$</span>pred</span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a>est <span class="ot">&lt;-</span>  r <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(temp_rounded) <span class="sc">%&gt;%</span>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">count=</span><span class="fu">mean</span>(count), <span class="at">knn=</span><span class="fu">mean</span>(knn))</span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span>est<span class="sc">$</span>temp_rounded, <span class="at">y=</span>est<span class="sc">$</span>count, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">ylab=</span><span class="st">&quot;mean riders&quot;</span>,</span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;temperature&quot;</span>, <span class="at">main =</span><span class="st">&quot;KNN fit for riders ~ temperature, k = 40&quot;</span>)</span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x=</span>est<span class="sc">$</span>temp_rounded, <span class="at">y=</span>est<span class="sc">$</span>knn, <span class="at">col=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-19-1.png" width="672" /></p>
<p>El sesgo es mayor aquí porque el error del modelo en la muestra es visiblemente mayor que en el caso de <span class="math inline">\(k\)</span>= 4, pero por esa misma razón es probable que la varianza sea menor. <em>No hay forma de lograr un sesgo bajo y una varianza baja simultáneamente.</em> Todo lo que puede hacer es tratar de equilibrar los dos, aceptando un sesgo moderado para lograr un mejor rendimiento fuera de la muestra. La técnica que usamos para lograr este equilibrio es la validación cruzada, que cubriremos más adelante en el curso. Por ahora podemos notar que el mejor valor para <span class="math inline">\(k\)</span> en la regresión KNN es el que minimiza la varianza, no el sesgo.</p>
<p>Como referencia, aquí hay un código para ajustar una regresión KNN usando el paquete <code>caret</code> en R. Usaremos<code>caret</code> frecuentemente en el curso porque proporciona una sintaxis consistente para ajustar una amplia gama de modelos (incluyendo, si quisiéramos, regresión lineal) y porque, muy convenientemente, ejecuta una validación cruzada en segundo plano para elegir parámetros de modelo óptimos como <span class="math inline">\(k\)</span>. Pero esto lo veremos más adelante.</p>
</div>
<div id="estimación-paramétrica-de-la-función-de-regresión-regresión-lineal" class="section level2 hasAnchor" number="4.10">
<h2 class="hasAnchor"><span class="header-section-number">4.10</span> Estimación paramétrica de la función de regresión: regresión lineal<a href="#estimación-paramétrica-de-la-función-de-regresión-regresión-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Con la regresión KNN no asumimos nada sobre la forma de la función de regresión, sino que la estimamos directamente a partir de los datos. Supongamos ahora que <span class="math inline">\(\mu(t)\)</span> es lineal y se puede describir con los parámetros de una recta: <span class="math inline">\(\mu (t) = \beta_0 + \beta_1t\)</span>, donde <span class="math inline">\(\beta_0\)</span> es el <em>intercept</em> de la recta y <span class="math inline">\(\beta_1\)</span> es la pendiente. En este caso, entonces, <span class="math inline">\(\widehat{riders} = \beta_0 + \beta_1temperature\)</span>. Dado que <span class="math inline">\(\mu(t)\)</span> es una función poblacional (es decir, promedio), los parámetros <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> son valores de población y son desconocidos, pero podemos estimarlos (también) con versosimilitud. Hagamos un breve repaso de este concepto tan importante en estadística.</p>
<p>La <strong>función de verosimilitud</strong> para un vector de parámetros <span class="math inline">\(\boldsymbol{\Theta}\)</span> dada una muestra aleatoria <span class="math inline">\(\boldsymbol{x}\)</span> con una distribución asumida se define como:</p>
<p><span class="math display">\[
L(\boldsymbol{\Theta} | \boldsymbol{x}) = \prod_{i=1}^{n}  f(x_i | \boldsymbol{\Theta}),
\]</span></p>
<p>donde <span class="math inline">\(x_i\)</span> representa uno de los elementos de la muestra aleatoria y <span class="math inline">\(f\)</span> es la función de masa/densidad de la distribución de la cual se obtuvo <span class="math inline">\(\boldsymbol{x}\)</span>. Por otro lado, la función de log-verosimilitud <span class="math inline">\(l\)</span> se define como el logaritmo de la función de verosimilitud <span class="math inline">\(L\)</span>, es decir</p>
<p><span class="math display">\[
l(\boldsymbol{\Theta} | \boldsymbol{x}) = \log L(\boldsymbol{\Theta} | \boldsymbol{x}) = \sum_{i=1}^{n} \log f(x_i | \boldsymbol{\Theta})
\]</span></p>
<p>Los parámetros de esta distribución se pueden estimar mediante el método de máxima verosimilitud. El objetivo de este método es encontrar los valores de <span class="math inline">\(\boldsymbol{\Theta}\)</span> que maximizan <span class="math inline">\(L\)</span> o <span class="math inline">\(l\)</span> y valores encontrados se representan por <span class="math inline">\(\hat{\boldsymbol{\Theta}}\)</span>. Veamos como estimar los parámetros para unos datos que pensamos que siguen una distribución de <a href="https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_Poisson">Poisson</a>. Hemos recogido el número de veces que 20 alumnos escogidos al azar no han asistido a una clase durante un semestre del total de alumnos del Grado de Estadística. Queremos estimar cuál es el parámetro <span class="math inline">\(\lambda\)</span> que nos cuantificaría cual es el promedio de no asistencia semetral de los alumnos de nuestra clase</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>alumnos <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span></code></pre></div>
<p>La fución de log-versomilitud para nuestro problema la podemos escribir en R como</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>lver_poisson <span class="ot">&lt;-</span> <span class="cf">function</span>(lambda, x){</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>  ans <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dpois</span>(x, lambda, <span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ans)</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Podemos encontrar el máximo de forma visual</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">15</span>, <span class="at">by=</span><span class="fl">0.5</span>)</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>lv <span class="ot">&lt;-</span> <span class="fu">sapply</span>(lambdas, <span class="cf">function</span>(x) {<span class="fu">lver_poisson</span>(x, alumnos)})</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">lambda =</span> lambdas, <span class="at">lv=</span> lv)</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>lambda, <span class="at">y=</span>lv))<span class="sc">+</span></span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size=</span><span class="dv">4</span>,<span class="at">color=</span><span class="st">&quot;dodgerblue&quot;</span>)<span class="sc">+</span></span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Lambda&quot;</span>) <span class="sc">+</span></span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Log-Verosimilitud&quot;</span>)<span class="sc">+</span></span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>(<span class="at">base_size =</span> <span class="dv">16</span>) <span class="sc">+</span></span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> lambdas[<span class="fu">which.max</span>(lv)], <span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">size=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="fig/plotll-1.png" width="672" /></p>
<p>En general, podemos usar <code>optim()</code> para buscar el máximo de cualquier función. En este caso</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="fu">optim</span>(<span class="at">par=</span><span class="dv">2</span>, <span class="at">fn=</span>lver_poisson, <span class="at">x=</span>alumnos, </span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">control=</span><span class="fu">list</span>(<span class="at">fnscale=</span><span class="sc">-</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>$par
[1] 4

$value
[1] -40.02868

$counts
function gradient 
      30       NA 

$convergence
[1] 0

$message
NULL</code></pre>
<div id="ejercicio" class="section level3 hasAnchor" number="4.10.1">
<h3 class="hasAnchor"><span class="header-section-number">4.10.1</span> Ejercicio<a href="#ejercicio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p><strong>Entrega en Moodle</strong>: P2-Regresión lineal función):</p>
<p>Consideremos el siguiente modelo de regresión:</p>
<p><span class="math display">\[\begin{align*}
\textrm{altura}_i &amp;\sim N(\mu_i, \sigma^2), \\
\mu_i &amp;= 105 + 0.9 \textrm{peso}_i, \\
\sigma &amp;= 8, \\
\textrm{peso} &amp;\sim Normal(45, 144).
\end{align*}\]</span></p>
<p>El siguiente código permite simular un conjunto de datos de valores con la estructura anterior.</p>
</blockquote>
<pre><code>n &lt;- 1000
peso &lt;- rnorm(n=n, mean=45, sd=12)
altura &lt;- rnorm(n=n, mean=105 + 0.9 * peso, sd=8)</code></pre>
<blockquote>
<p>Estima los parámetros del modelo lineal (<span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>) utilizando R tal que minimicen el RSS</p>
<p><span class="math display">\[
\operatorname {RSS} = \sum_ {i = 1} ^ n ((\beta_0 + \beta_1\textrm{peso}_i) - \textrm{altura}_i) ^ 2
\]</span></p>
<p>OPCIONAL: Haz lo mismo maximizando el logaritmo de la verosimilitud</p>
</blockquote>
<p>Sin embargo, R tiene incorporado una función para obtener los estimadores máximos verosímiles utilizando algoritmos más eficientes basados en la estimación por mínimos cuadrados vista en secciones anteriores y que están implementados en la función <code>lm()</code>.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(count <span class="sc">~</span> temperature, <span class="at">data =</span> day))</span></code></pre></div>
<pre><code>
Call:
lm(formula = count ~ temperature, data = day)

Residuals:
    Min      1Q  Median      3Q     Max 
-4615.3 -1134.9  -104.4  1044.3  3737.8 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1214.6      161.2   7.537 1.43e-13 ***
temperature   6640.7      305.2  21.759  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1509 on 729 degrees of freedom
Multiple R-squared:  0.3937,    Adjusted R-squared:  0.3929 
F-statistic: 473.5 on 1 and 729 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(day, <span class="fu">aes</span>(temperature, count)) <span class="sc">+</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se=</span>F) <span class="sc">+</span></span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;riders ~ temperature, mediante regresión lineal&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-21-1.png" width="672" /></p>
<p>Interpretemos estos coeficientes del modelo:</p>
<ul>
<li><p><strong>intercept</strong>: 1214.6 representa el número de pasajeros pronosticado cuando la temperatura es igual a 0. El <em>intercept</em> no es significativo porque la temperatura mínima en el conjunto de datos es . Podríamos hacerlo significativo al centrar la variable de temperatura en 0, en cuyo caso el <em>intercept</em> representaría el número de pasajeros promedio a la temperatura promedio. (Recuerde: las transformaciones lineales como el centrado no cambian el ajuste del modelo). La función <code>summary()</code> también genera un error estándar, valor t y valor p (“Pr (&gt; | t |)”) para el <em>intercept</em>ar. Explicaremos estos valores a continuación cuando revisemos la inferencia en el contexto de la regresión.</p></li>
<li><p><em>temperatura</em>: 6640.7 representa el cambio previsto en el número de pasajeros asociado con un aumento de la temperatura de 1 unidad. Desafortunadamente, este coeficiente, como el <em>intercept</em>, no es muy interpretable porque el rango de la variable de temperatura es solo -, lo que significa que la temperatura realmente puede no aumenta en 1 unidad. Podríamos aplicar aquí otra transformación lineal, para desnormalizar la temperatura, pero, nuevamente, esa transformación no cambiaría el ajuste: la pendiente de la recta de regresión permanecería igual.</p></li>
</ul>
<p>Ahora podemos preguntar: ¿cuál de estos dos modelos de pasajeros, el modelo paramétrico que usa regresión lineal o el modelo no paramétrico que usa KNN, es mejor? ¿Qué entendemos por mejor? Una respuesta a esa pregunta está en términos del ajuste en la muestra. ¿Cuál es el RMSE del modelo KNN en comparación con el RMSE del modelo lineal?</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1507.322</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(knn_fit), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1321.889</code></pre>
<p>(<code>predict()</code> es equivalente a <code>adjust()</code> en este contexto.) Aquí podemos ver que el modelo KNN supera al modelo lineal en la muestra: en promedio, el modelo KNN está desfasado en aproximadamente 1322 ciclistas por día, mientras que el modelo lineal tiene una diferencia de 1507. Este tipo de comparación de modelos puede resultar muy útil. En este caso, sugiere que hay margen de mejora en el modelo lineal. Por un lado, podemos ver que la relación entre la temperatura y los pasajeros no es exactamente lineal: el número de pasajeros aumenta con la temperatura hasta aproximadamente .6, momento en el que se estabiliza y disminuye. La regresión KNN es mejor para modelar esta no linealidad. Sin embargo, podemos usar un modelo lineal para modelar un resultado no lineal agregando predictores.</p>
<p>Es probable que el número de pasajeros varíe bastante según la temporada. Agreguemos una variable por temporada para ver si mejora el modelo. Necesitamos definir la temporada explícitamente como un factor, lo cual podemos hacer dentro de la función <code>lm ()</code> usando <code>factor ()</code>. Esto es apropiado porque la estación no es una variable continua, sino un número entero que representa las diferentes estaciones y que toma solo cuatro valores: 1 - 4. R malinterpretará la estación como una variable continua a menos que la definamos explícitamente como un factor. El orden numérico de los valores de temporada definirá automáticamente los niveles. La función <code>lm ()</code> tratará el primer nivel, temporada = 1, como el nivel de referencia, con el que se compararán los otros niveles.</p>
<p>¿Cómo sabemos cuándo un predictor debe definirse como continuo y cuándo debe definirse como factor? Aquí hay una regla general: si restamos un nivel de otro y la diferencia tiene sentido, entonces podemos representar con seguridad esa variable como un número entero. Pensemos en la variable años de educación. La diferencia entre 10 años de escolaridad y 11 años es un año de educación, lo cual es una diferencia significativa. No estamos <em>obligados</em> a representar la educación como una variable continua, pero podríamos. (Codificar la educación como un factor esencialmente encajaría en una regresión separada para cada nivel, lo que podría correr el riesgo de sobreajuste.) Por el contrario, consideremos el código postal: una diferencia de 1 entre dos códigos postales de 5 dígitos no tiene sentido porque los códigos postales no tienen un orden intrínseco; representan diferencias categóricas, que nunca deben codificarse como números enteros. En cambio, estas variables siempre deben codificarse como factores. En este <a href="https://stats.idre.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-variables-de-intervalo/">link</a> podéis encontrar más información al respecto.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear_fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(count <span class="sc">~</span> temperature <span class="sc">+</span> <span class="fu">factor</span>(season), <span class="at">data =</span> day))</span></code></pre></div>
<pre><code>
Call:
lm(formula = count ~ temperature + factor(season), data = day)

Residuals:
    Min      1Q  Median      3Q     Max 
-4812.9  -996.8  -271.3  1240.9  3881.1 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        745.8      187.5   3.978 7.65e-05 ***
temperature       6241.3      518.1  12.046  &lt; 2e-16 ***
factor(season)2    848.7      197.1   4.306 1.89e-05 ***
factor(season)3    490.2      259.0   1.893   0.0588 .  
factor(season)4   1342.9      164.6   8.159 1.49e-15 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1433 on 726 degrees of freedom
Multiple R-squared:  0.4558,    Adjusted R-squared:  0.4528 
F-statistic:   152 on 4 and 726 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1507.322</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit2), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1428.151</code></pre>
<p>El ajuste ha mejorado; el modelo con temporada (season) tiene un RMSE más bajo. Pero, ¿cómo interpretamos los coeficientes de una variable factor?. Observamos que sólo hay 3 coeficientes para 4 temporadas. ¿No debería haber 4 coeficientes? ¿Ha cometido un error la función <code>lm ()</code>? No. Para una variable factor como la temporada, cada coeficiente representa el cambio en la respuesta asociado con un cambio en el predictor desde el primer nivel o nivel de referencia a cada nivel de factor subsiguiente. (Esta codificación, la predeterminada en <code>lm ()</code>, se puede ajustar con el argumento <code>contrasts</code>). El nivel de referencia normalmente no se muestra en la salida del modelo. Si un predictor tiene <span class="math inline">\(k\)</span> niveles, entonces habrá <span class="math inline">\(k-1\)</span> coeficientes que representan los cambios previstos en el resultado asociados con aumentos desde el nivel de referencia en el predictor.</p>
<ul>
<li><p><em>factor(temporada)2</em>: 848,7 es el cambio previsto en los ciclistas de primavera con respecto al invierno (temporada = 1).</p></li>
<li><p><em>factor(temporada)3</em>: 490,2 es el cambio previsto en los ciclistas de verano, nuevamente respecto al invierno, que es la categoría de referencia.</p></li>
</ul>
<p>Los aumentos de temperatura pueden tener diferentes impactos en el número de ciclistas en diferentes estaciones. Podríamos probar esta hipótesis al incluir una interacción entre la estación y la temperatura.</p>
<p>La salida de la función <code>summary ()</code> puede volverse difícil de manejar. En su lugar, usaremos la función <code>display ()</code> del paquete arm, que ofrece un resumen del modelo más conciso.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(linear_fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(count <span class="sc">~</span> temperature <span class="sc">*</span> <span class="fu">factor</span>(season), <span class="at">data =</span> day))</span></code></pre></div>
<pre><code>lm(formula = count ~ temperature * factor(season), data = day)
                            coef.est coef.se 
(Intercept)                  -111.04   321.28
temperature                  9119.04  1020.33
factor(season)2              1513.43   571.76
factor(season)3              6232.96  1079.33
factor(season)4              2188.52   534.98
temperature:factor(season)2 -2524.78  1326.47
temperature:factor(season)3 -9795.26  1774.32
temperature:factor(season)4 -2851.25  1414.93
---
n = 731, k = 8
residual sd = 1406.35, R-Squared = 0.48</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit2), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1428.151</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit3), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1398.634</code></pre>
<p>La interacción mejora el ajuste del modelo.</p>
<ul>
<li><p><em>temperatura: factor (temporada) 2</em>: -2524.8 representa la diferencia en la pendiente de la temperatura comparando la temporada 2 con la temporada 1. El coeficiente negativo significa que un aumento de 1 unidad la temperatura se asocia con un cambio * menor * en el número de pasajeros en primavera en comparación con el invierno.</p></li>
<li><p><em>temperatura: factor (temporada) 3</em>: -9795.3 representa la diferencia en la pendiente de la temperatura comparando la temporada 3 con la temporada 1 Y así sucesivamente.</p></li>
</ul>
<p>En un modelo con interacciones, debemos tener cuidado de interpretar los efectos principales con precisión.</p>
<ul>
<li><p><em>temperatura</em>: 9119 es el efecto principal de la temperatura y representa el cambio previsto en los ciclistas asociado con un aumento de 1 unidad en la temperatura cuando la temporada = 1 (la categoría de referencia) . En un modelo sin la interacción, el coeficiente de temperatura representaría el cambio promedio en los ciclistas asociado con un cambio de 1 unidad en la temperatura * manteniendo constante la temporada *.</p></li>
<li><p><em>factor (temporada) 2</em>: 1513.4 representa el cambio previsto en los ciclistas asociado con un aumento de 1 unidad en la temporada (es decir, de la temporada 1 a la temporada 2) cuando la temperatura = 0. Y así sucesivamente. Debido a que la temperatura no es igual a 0 en estos datos, los efectos principales de la temporada no son significativos.</p></li>
</ul>
<p>Para entender una interacción ¡es fundamental visualizarla! De hecho, en estadística deberíamos siempre empezar por esto antes de hacer inferencia</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(day, <span class="fu">aes</span>(temperature, count)) <span class="sc">+</span></span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="fu">aes</span>(<span class="at">group =</span> <span class="fu">factor</span>(season), <span class="at">col =</span> <span class="fu">factor</span>(season)), <span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Riders ~ temperature, según estación (season)&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-26-1.png" width="672" /></p>
<p>Aquí podemos ver que la relación entre la temperatura y los ciclistas es más fuertemente positiva (más pronunciada) en la temporada 1, más plana en las temporadas 2 y 4, y negativa en la temporada 3. Claramente, la temperatura tiene diferentes efectos en diferentes estaciones. En enero y febrero, un día más cálido provoca un gran aumento de ciclistas: el clima es mejor para ir en bici. En julio, un día más cálido provoca una disminución de ciclistas: el clima es “peor” para ir en bici (peor = cuesta más).</p>
<p>Los coeficientes del modelo lineal proporcionan una gran información sobre de los factores que influyen en el número de pasajeros. Sin embargo, nuestro modelo lineal todavía tiene un rendimiento inferior al modelo KNN.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(knn_fit), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1321.889</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(<span class="fu">predict</span>(linear_fit3), day<span class="sc">$</span>count)</span></code></pre></div>
<pre><code>[1] 1398.634</code></pre>
<p>La regresión lineal a menudo tendrá un sesgo más alto que un método flexible como la regresión KNN, pero también tenderá a tener una varianza más baja. Exploraremos estas propiedades más a fondo cuando lleguemos a la validación cruzada.</p>
<p>Echemos un vistazo a la matriz del modelo.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(linear_fit3))</span></code></pre></div>
<pre><code>  (Intercept) temperature factor(season)2 factor(season)3 factor(season)4 temperature:factor(season)2
1           1    0.344167               0               0               0                           0
2           1    0.363478               0               0               0                           0
3           1    0.196364               0               0               0                           0
4           1    0.200000               0               0               0                           0
5           1    0.226957               0               0               0                           0
6           1    0.204348               0               0               0                           0
  temperature:factor(season)3 temperature:factor(season)4
1                           0                           0
2                           0                           0
3                           0                           0
4                           0                           0
5                           0                           0
6                           0                           0</code></pre>
<p>Podemos ver que <code>lm()</code> ha convertido la variable de temporada en 3 vectores variables ficticias: factor (temporada) 2, factor (temporada) 3 y factor (temporada) 4. (Si un factor tiene niveles de $k $, entonces una variable ficticia para ese factor codifica $k - 1 $de esos niveles como variables binarias, con los valores 0 o 1 indicando la ausencia o presencia de ese nivel). Los términos de interacción consisten en los productos de los vectores componentes.</p>
</div>
</div>
<div id="predicción" class="section level2 hasAnchor" number="4.11">
<h2 class="hasAnchor"><span class="header-section-number">4.11</span> Predicción<a href="#predicción" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Podemos usar un modelo lineal no solo para la descripción sino también para la predicción. Si, por ejemplo, estuviéramos interesados en usar el modelo anterior para predecir el número de pasajeros para una temporada y temperatura en particular, digamos, un día caluroso en primavera, simplemente podríamos usar la ecuación de regresión. Definiremos un día caluroso como .85 (ojo con las escalas y las unidades de medida). Así:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">111</span> <span class="sc">+</span> <span class="dv">9119</span><span class="sc">*</span>.<span class="dv">85</span> <span class="sc">+</span> <span class="dv">1513</span><span class="sc">*</span><span class="dv">1</span> <span class="sc">+</span> <span class="dv">6233</span><span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> <span class="dv">2189</span><span class="sc">*</span><span class="dv">0</span> <span class="sc">-</span> <span class="dv">2525</span><span class="sc">*</span>.<span class="dv">85</span><span class="sc">*</span><span class="dv">1</span> <span class="sc">-</span> <span class="dv">9795</span><span class="sc">*</span>.<span class="dv">85</span><span class="sc">*</span><span class="dv">0</span> <span class="sc">-</span> <span class="dv">2851</span><span class="sc">*</span>.<span class="dv">85</span><span class="sc">*</span><span class="dv">0</span> </span></code></pre></div>
<pre><code>[1] 7006.9</code></pre>
<p>Aquí hay una forma más precisa de hacer el cálculo que evita errores de redondeo al hacer referencia al objeto del modelo:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> .<span class="dv">85</span></span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(linear_fit3)</span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>coefs[<span class="dv">1</span>] <span class="sc">+</span> coefs[<span class="dv">2</span>]<span class="sc">*</span>t <span class="sc">+</span> coefs[<span class="dv">3</span>]<span class="sc">*</span><span class="dv">1</span> <span class="sc">+</span> coefs[<span class="dv">4</span>]<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> </span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>  coefs[<span class="dv">5</span>]<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> coefs[<span class="dv">6</span>]<span class="sc">*</span>t<span class="sc">*</span><span class="dv">1</span> <span class="sc">+</span> coefs[<span class="dv">7</span>]<span class="sc">*</span>t<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> coefs[<span class="dv">8</span>]<span class="sc">*</span>t<span class="sc">*</span><span class="dv">0</span>  </span></code></pre></div>
<pre><code>(Intercept) 
   7007.501 </code></pre>
<p>Los resultados son diferentes debido al error de redondeo en el primer caso. El segundo método es más preciso.</p>
<p>Podemos hacer el mismo cálculo tratando el vector de coeficientes como una matriz y usando la multiplicación de matrices. Esto requiere menos escritura pero, al igual que con el método anterior, requiere prestar mucha atención al orden de los términos.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">1</span>, t, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, t<span class="sc">*</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span></code></pre></div>
<pre><code>         [,1]
[1,] 7007.501</code></pre>
<p>Lo más simple de todo es definir un marco de datos con nuestros valores deseados y usar <code>predecir ()</code>:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(linear_fit3, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">season =</span> <span class="dv">2</span>, <span class="at">temperature =</span> .<span class="dv">85</span>))</span></code></pre></div>
<pre><code>       1 
7007.501 </code></pre>
</div>
<div id="inferencia-en-el-contexto-de-regresión" class="section level2 hasAnchor" number="4.12">
<h2 class="hasAnchor"><span class="header-section-number">4.12</span> Inferencia en el contexto de regresión<a href="#inferencia-en-el-contexto-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Además de las estimaciones de coeficientes para cada variable predictora (incluido el <em>intercept</em>), la salida de <code>lm ()</code> (usando <code>summary ()</code>) contiene lo siguiente: “Error estándar”, “valor t” y “Pr (&gt; | t |)” (el valor p). Repasemos estos conceptos.</p>
<p>Recordemos que la inferencia estadística nos permite estimar las características de la población a partir de las propiedades de una muestra. Por lo general, queremos saber si una diferencia o una relación que observamos en una muestra es verdadera en la población — es “estadísticamente significativa” — o es probable que se deba al azar. En el contexto de la regresión, queremos saber específicamente si la pendiente de la recta de regresión, <span class="math inline">\(\beta\)</span>, que resume la relación de una variable con el resultado es diferente de 0. ¿Existe una relación positiva o negativa? En el paradigma frecuentista, respondemos a esta pregunta utilizando pruebas estadísticas basadas en test de hipótesis.</p>
<p>De otros cursos sabemos que una prueba de hipótesis se basa en plantear una “hipótesis nula”, <span class="math inline">\(H_0\)</span>. En la regresión, <span class="math inline">\(H_0\)</span> corresponde a que la pendiente de la recta de regresión, <span class="math inline">\(\beta\)</span>, es 0. Una pendiente de 0 significa que un predictor no tiene efecto o no tiene relación con el resultado. <code>R</code> calcula automáticamente una prueba de hipótesis para <span class="math inline">\(\beta\)</span> usando el estadístico t, definido como:</p>
<p><span class="math display">\[
t = \frac {\beta - 0} {SE (\beta)}
\]</span></p>
<p>El estadístico <span class="math inline">\(t\)</span> para una muestra sigue la distribución <span class="math inline">\(t\)</span> de Student con n - 2 grados de libertad. Para la regresión lineal multivariante, el estadístico <span class="math inline">\(t\)</span>sigue la distribución <span class="math inline">\(t\)</span> de Student con $n - k - 1 $ grados de libertad, donde <span class="math inline">\(k\)</span> representa el número de predictores en el modelo. Se utiliza la distribución <span class="math inline">\(t\)</span> porque es más conservadora que una distribución normal cuando <span class="math inline">\(n\)</span> es pequeño ya que en ese caso no podemos asumir el teorema central del límite que nos permitiría determinar que la distribución del estadístico sigue una distribución normal. La distribución <span class="math inline">\(t\)</span> de Student tiene una cola más pesada pero converge a la normal cuando <span class="math inline">\(n\)</span> aumenta (por encima de aproximadamente <span class="math inline">\(n\)</span>= 30). Por otro lado, <span class="math inline">\(SE (\beta)\)</span> se define como</p>
<p><span class="math display">\[
SE (\beta) = \frac {RSE} {\sqrt {\sum_{i = 1} ^ n (x_i - \bar {x} _i)}},
\]</span></p>
<p>donde error estándar residual (RSE) se calcula como</p>
<p><span class="math display">\[
RSE = \sqrt {\frac {RSS} {n - 2}},
\]</span></p>
<p>y la suma de cuadrados residual (RSS) se puede definir como (en una formulación ligeramente diferente a la que hemos usado antes):</p>
<p><span class="math display">\[
RSS = \sum_ {i = 1} ^ n (y_i - f (x_i)) ^ 2.
\]</span></p>
<p>Después de calcular el estadístico t, usamos una prueba t para compararlo con el valor crítico dado un nivel de significación que suele ser del 5% para la distribución <span class="math inline">\(t\)</span> con n - 2 grados de libertad.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear_fit)</span></code></pre></div>
<pre><code>
Call:
lm(formula = count ~ temperature, data = day)

Residuals:
    Min      1Q  Median      3Q     Max 
-4615.3 -1134.9  -104.4  1044.3  3737.8 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1214.6      161.2   7.537 1.43e-13 ***
temperature   6640.7      305.2  21.759  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1509 on 729 degrees of freedom
Multiple R-squared:  0.3937,    Adjusted R-squared:  0.3929 
F-statistic: 473.5 on 1 and 729 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>rse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((day<span class="sc">$</span>count <span class="sc">-</span> <span class="fu">predict</span>(linear_fit))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">nrow</span>(day) <span class="sc">-</span> <span class="dv">2</span>))</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>(seb <span class="ot">&lt;-</span> rse<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">sum</span>((day<span class="sc">$</span>temperature <span class="sc">-</span></span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">mean</span>(day<span class="sc">$</span>temperature))<span class="sc">^</span><span class="dv">2</span>)))</span></code></pre></div>
<pre><code>[1] 305.188</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>(t <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>((<span class="fu">coef</span>(linear_fit)[<span class="dv">2</span>] <span class="sc">-</span> <span class="dv">0</span>) <span class="sc">/</span> seb))</span></code></pre></div>
<pre><code>[1] 21.75941</code></pre>
<p>Nuestro cálculo coincide exactamente con la salida del modelo lineal.</p>
<p>Grafiquemos este estadístico t contra la distribución nula de una t de Student con 729 grados de libertad. Usamos la función <code>dt ()</code> para generar una gráfica de densidad para una distribución t con 729 grados de libertad, y <code>qt ()</code> para identificar los valores críticos para un IC del 95% en la distribución nula; los valores con baja probabilidad (p &lt;.05) estarán a la izquierda del IC inferior oa la derecha del IC superior. Los valores P y los IC proporcionan la misma información sobre lo inusual de un valor observado bajo el nulo.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>tdist <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">25</span>, .<span class="dv">01</span>), <span class="at">y =</span> <span class="fu">dt</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">25</span>, .<span class="dv">01</span>), <span class="at">df =</span> <span class="dv">729</span>))</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb192-3"><a href="#cb192-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>), <span class="at">df =</span> <span class="dv">729</span>)</span></code></pre></div>
<pre><code>[1] -1.963223  1.963223</code></pre>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tdist, <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb194-3"><a href="#cb194-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> t, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb194-4"><a href="#cb194-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">qt</span>(.<span class="dv">025</span>, <span class="at">df =</span> <span class="dv">729</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb194-5"><a href="#cb194-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">qt</span>(.<span class="dv">975</span>, <span class="at">df =</span> <span class="dv">729</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb194-6"><a href="#cb194-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;t(n - 2 = 729) según valores críticos (negro) y el estadístico t observado (rojo)&quot;</span>) <span class="sc">+</span></span>
<span id="cb194-7"><a href="#cb194-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;t-statistic&quot;</span>) <span class="sc">+</span></span>
<span id="cb194-8"><a href="#cb194-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-34-1.png" width="672" /></p>
<p>Un estadístico t de 21.76 esencialmente nunca ocurriría bajo la distribución nula, lo que nos permite “rechazar <span class="math inline">\(H_0\)</span>” con un nivel de confianza del 95% (suponiendo un nivel de significación del 5%). El valor p asociado con el coeficiente <span class="math inline">\(\beta\)</span> para la temperatura en el resumen del modelo — esencialmente cero — refleja este resultado. Podemos calcular nuestro propio valor p con el siguiente código:</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pt</span>(t, <span class="at">df =</span> <span class="dv">729</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>[1] 2.810622e-81</code></pre>
<p>Usamos <code>lower.tail = F</code> porque estamos interesados en la probabilidad de t =<code>r round (as.numeric (t), 2)</code>en la cola <em>superior</em> además esta forma es más informativa que hacerlo con:</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span>  <span class="fu">pt</span>(t, <span class="at">df =</span> <span class="dv">729</span>)</span></code></pre></div>
<pre><code>[1] 0</code></pre>
<p>que nos daría un p-valor de 0 por un problema de tolerancia de nuestra máquina (del orden de <span class="math inline">\(10^{-21}\)</span>)</p>
<p>El resumen del modelo también genera otro estadístico basado en la distribución F con un valor p asociado:</p>
<p><span class="math display">\[
F = \frac{\frac{TSS - RSS}{p - 1}}{\frac{RSS}{n - p}}
\]</span></p>
<p>La hipótesis nula para esta prueba F es: <span class="math inline">\(H_0: \beta_1 = ... \beta_ {p-1} = 0\)</span>. En otras palabras, la prueba responde a la pregunta: “¿Alguno de los predictores es útil para predecir la respuesta?” Esta no es una medida muy útil del rendimiento del modelo, ya que los modelos casi siempre tienen <em>algún</em> valor predictivo.</p>
<p>NOTA (Avanzado por si lo necesitáis en el futuro): Podríamos estimar muy fácilmente <span class="math inline">\(SE(\beta)\)</span> usando bootstrap (<a href="https://uc-r.github.io/bootstrapping">aquí</a> tenéis una descripción de este método). Utilizaremos este enfoque si tenemos motivos para desconfiar de cómo se calcula <span class="math inline">\(SE(\beta)\)</span> analíticamente usando <code>lm ()</code>. Por ejemplo, en el caso de errores heterocedásticos (discutidos a continuación) <code>lm ()</code> tenderá a subestimar <span class="math inline">\(SE(\beta)\)</span> y tendríamos muchos resultados significativos que serían falsos. Obtener resultados similares utilizando boostrap nos haría confiar en los resultados reportados por <code>lm ()</code>.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>temperature_coef <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-3"><a href="#cb199-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){</span>
<span id="cb199-4"><a href="#cb199-4" aria-hidden="true" tabindex="-1"></a>  rows <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(day), <span class="at">replace =</span> T)</span>
<span id="cb199-5"><a href="#cb199-5" aria-hidden="true" tabindex="-1"></a>  boot_sample <span class="ot">&lt;-</span> day[rows, ]</span>
<span id="cb199-6"><a href="#cb199-6" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">lm</span>(count <span class="sc">~</span> temperature, <span class="at">data =</span> boot_sample)</span>
<span id="cb199-7"><a href="#cb199-7" aria-hidden="true" tabindex="-1"></a>  temperature_coef[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(model)[<span class="dv">2</span>]</span>
<span id="cb199-8"><a href="#cb199-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb199-9"><a href="#cb199-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-10"><a href="#cb199-10" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(temperature_coef)</span></code></pre></div>
<pre><code>[1] 278.8941</code></pre>
<p>En este caso, la estimación de <span class="math inline">\(SE (\beta_{temp})\)</span> es similar pero menor que la calculada analíticamente. Por lo tanto, la estimación <code>lm()</code> es en realidad más conservadora en este caso.</p>
<p>El <span class="math inline">\(SE\)</span> para los coeficientes en la salida de <code>lm ()</code> se puede usar para calcular los IC para la estimación del coeficiente. <span class="math inline">\(\hat {\beta} + 1.96 (SE)\)</span> nos da el límite superior al 95%, y $ - 1.96 (SE) $ el límite inferior. Los IC del 95% que no incluyen 0 indican que el coeficiente es estadísticamente significativo, equivalente a un valor p del coeficiente menor de .05.</p>
<p>El uso de IC en lugar de p-valores nos da una forma más flexible de hacer inferencia. Además, también suele ser útil porque nos indica qué posibles valores puede tomar nuestros parámetros (si quisiéramos cuantificar el efecto). Ésta es otra razón para usar la función <code>display ()</code> del paquete arm. No solo presenta la salida de <code>lm ()</code> de manera más compacta, sino que tampoco reporta estadísticas t ni valores p. Como hemos visto, <span class="math inline">\(SE\)</span>s transmiten la misma información.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(linear_fit)</span></code></pre></div>
<pre><code>lm(formula = count ~ temperature, data = day)
            coef.est coef.se
(Intercept) 1214.64   161.16
temperature 6640.71   305.19
---
n = 731, k = 2
residual sd = 1509.39, R-Squared = 0.39</code></pre>
<p>Los valores posibles (recordamos que el verdadero valor del parámetro es desconocido en la población) para la temperatura son <span class="math inline">\(6641 \pm 2(305)\)</span> o aproximadamente [6031,<code>r 6641 + 2 * 305</code>].<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Este IC no incluye 0, de lo cual podemos concluir que la temperatura se asocia con el resultado de forma estadísticamente significativa. (El valor p para la temperatura informado en el <code>summary()</code> concuerda).</p>
</div>
<div id="asunciones-de-un-modelo-de-regresión" class="section level2 hasAnchor" number="4.13">
<h2 class="hasAnchor"><span class="header-section-number">4.13</span> Asunciones de un modelo de regresión<a href="#asunciones-de-un-modelo-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los resultados de la regresión solo son precisos si se dan un conjunto de supuestos (en orden de importancia):<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<ol style="list-style-type: decimal">
<li><p><em>Validez de los datos</em> para responder a la pregunta de investigación.</p></li>
<li><p><em>Linealidad de la relación</em> entre el resultado y las variables predictoras.</p></li>
<li><p><em>Independencia de los errores</em> (en particular, sin correlación entre errores consecutivos como en el caso de los datos de series de tiempo).</p></li>
<li><p><em>Varianza igual de errores</em> (homocedasticidad).</p></li>
<li><p><em>Normalidad de errores.</em></p></li>
</ol>
<p>La mayoría de estos problemas no son fatales y se pueden solucionar mejorando el modelo, seleccionando variables diferentes o adicionales o utilizando una distribución de modelización diferente (los conocidos como modelos lineales generalizados o GLMs). Los gráficos de residuos son la mejor herramienta para evaluar si se han cumplido los supuestos del modelo.</p>
<p><em>1. Validez de los datos para responder a la pregunta de investigación </em></p>
<p>Esto puede parecer obvio pero es necesario enfatizarlo:</p>
<ul>
<li><p>La medida de resultado debe reflejar con precisión el fenómeno de interés.</p></li>
<li><p>El modelo debe incluir todas las variables relevantes.</p></li>
<li><p>El modelo debe generalizarse a todos los casos a los que se aplica.</p></li>
</ul>
<p>En resumen, debemos asegurarnos de que nuestros datos proporcionan información <em>precisa</em> y <em>relevante</em> para responder a la pregunta de investigación.</p>
<p><em>2. Supuesto de linealidad</em></p>
<p>La suposición matemática más importante del modelo de regresión es que el resultado es una función lineal determinista de los predictores separados: <span class="math inline">\(y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2}...\)</span>. Podemos comprobar este supuesto visualmente trazando las variables predictoras contra el resultado:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(day, <span class="fu">aes</span>(temperature, count)) <span class="sc">+</span> </span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb203-3"><a href="#cb203-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb203-4"><a href="#cb203-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;count ~ temperature&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-39-1.png" width="672" /></p>
<p>Los datos son claramente <em>no</em> lineales, ¿qué hacemos? Podemos agregar predictores al modelo, como la temporada, que permiten que un modelo <em>lineal</em> se ajuste mejor a datos <em>no</em> lineales. También podríamos considerar añadir un término cuadrático al modelo: conteo ~ temperatura + temperatura<span class="math inline">\(^2\)</span>.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a>linear_fit4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(count <span class="sc">~</span> temperature <span class="sc">+</span> <span class="fu">I</span>(temperature<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> day)</span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(day, <span class="fu">aes</span>(temperature, count)) <span class="sc">+</span></span>
<span id="cb204-3"><a href="#cb204-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb204-4"><a href="#cb204-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(temperature, <span class="fu">fitted</span>(linear_fit4)), <span class="at">col=</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb204-5"><a href="#cb204-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;count ~ temperature + temperature^2&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-40-1.png" width="672" /></p>
<p>Una vez que se han añadido predictores adicionales, podemos verificar los gráficos de residuos, ya que si el modelo no cumple la condición de linealidad se mostrará en los residuos. <code>plot ()</code> es una función R incorporada para verificar la distribución de errores de un modelo.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(linear_fit, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-41-1.png" width="672" /></p>
<p>Podemos ver, como era de esperar, una no linealidad significativa en la gráfica residual para el modelo con temperatura solamente. Esperamos que los residuos no tengan una estructura visible, ningún patrón. En términos del supuesto de linealidad, la línea de resumen roja no debe tener curvatura. Cuando agregamos temporada, la parcela residual, aunque no es perfecta, mejora mucho.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(linear_fit2, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-42-1.png" width="672" /></p>
<p>Sin embargo, el modelo todavía lucha con días de gran volumen, con más de 5000 ciclistas previstos. Veamos si agregar una interacción entre la estación y la temperatura ayuda:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(linear_fit3, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-43-1.png" width="672" /></p>
<p>Quizás esto sea mejor. La no linealidad implica menos observaciones, la mayoría de ellas en los días con valores ajustados superiores a 6000. Pero ha surgido otro problema con este modelo: los errores heterocedásticos. Discutiremos este supuesto antes de la independencia de errores.</p>
<p><em>4. Igual varianza de errores</em> (homocedasticidad)</p>
<p>Observamos cómo los errores en el gráfico residual anterior tienen forma de embudo. Los errores del modelo no se distribuyen por igual en el rango de los valores ajustados, una situación conocida como heterocedasticidad. Una solución es transformar la variable de resultado tomando el registro (solo funciona con valores positivos). Si esto no funciona, recuerde que la principal consecuencia de los errores heterocedásticos es que los <span class="math inline">\(SE (\beta)\)</span>s son más pequeños de lo que deberían ser, lo que lleva a valores p más significativos de los que debería haber. Un remedio para este problema inferencial es calcular los errores estándar ajustados que son robustos a la varianza desigual; el paquete MASS ofrece la función <code>rlm ()</code> para ajustar tal modelo.</p>
<p>Aquí está la gráfica residual para un modelo de log (recuento):</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">lm</span>(<span class="fu">log</span>(count) <span class="sc">~</span> temperature <span class="sc">*</span> season, <span class="at">data =</span> day), <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-44-1.png" width="672" /></p>
<p>Es posible que la heterocedasticidad haya mejorado, pero ahora han surgido algunos valores atípicos y todavía tenemos un problema de no linealidad. ¿Qué hacemos?</p>
<p>Después de revisar estos gráficos de residuos, deberíamos dar un paso atrás y pensar en nuestros datos. Un problema queda claro. Es probable que el número de pasajeros en días consecutivos sea muy similar debido a la temperatura, el clima y la temporada. En consecuencia, los residuos del modelo se agruparán (veríamos clusters). Si el modelo no hace un buen trabajo al contabilizar el número de pasajeros en, digamos, días de alta temperatura, los errores grandes no se distribuirán al azar sino que ocurrirán juntos, producidos por una ola de calor en julio, por ejemplo. Los errores de los días siguientes serán similares. En estos casos, la regresión lineal no sería un buen modelo ya que el supuesto de independencia de errores no se cumpliría. Estos problemas ocurren en la mayoría de casos que nuestros datos se recogen de forma seriada (series temporales). Es por ello que en estos casos se debe de utilizar otros modelos más complejos como la regresión KNN (entre otros). Sin embargo, debemos tener en cuenta que la regresión KNN puede ajustarse mejor a los datos y posiblemente ofrecer mejores predicciones, pero no ofrece ninguna ayuda para comprender las relaciones entre las variables y muchas veces (sobre todo en medicina) esto es muy importante. La regresión lineal, incluso si el modelo no es perfecto, proporciona información sobre los factores que afectan a la cantidad de usuarios, información que puede ser extremadamente valiosa, por ejemplo, para los administradores del programa de bicicletas compartidas, mientras que la regresión KNN solo puede ofrecer una predicción.</p>
<p><em>3. No independencia de errores (residuales correlacionados)</em></p>
<p>La falta de independencia de los errores ocurre en los datos de series de tiempo o en los datos con observaciones agrupadas, cuando, por ejemplo, varios puntos de datos provienen de individuos de un mismo barrio, país, , tiendas o aulas. Podemos diagnosticar los residuos correlacionados en los datos de los usuarios de bicicletas mirando un gráfico de residuos por fecha.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">day =</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="fu">nrow</span>(day)),</span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">residuals =</span> <span class="fu">residuals</span>(linear_fit3)) <span class="sc">%&gt;%</span></span>
<span id="cb209-3"><a href="#cb209-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(day, residuals)) <span class="sc">+</span></span>
<span id="cb209-4"><a href="#cb209-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb209-5"><a href="#cb209-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Residuales según el día: count ~ temperature * season&quot;</span>) <span class="sc">+</span></span>
<span id="cb209-6"><a href="#cb209-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-45-1.png" width="672" /></p>
<p>Podemos ver muy claramente que los errores ocurren en grupos relacionados con la fecha. Quizás el patrón más importante venga dado por la variable año. Sin una variable que determine el año, el modelo tiene problemas ya que predice de forma insuficiente en el primer año y prediciendo de más en el segundo. Si agregamos un año al modelo, los residuos se ven mejor pero la agrupación sigue siendo evidente.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">day =</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="fu">nrow</span>(day)),</span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">residuals =</span> <span class="fu">residuals</span>(<span class="fu">update</span>(linear_fit3, <span class="sc">~</span> . <span class="sc">+</span> year))) <span class="sc">%&gt;%</span></span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(day, residuals)) <span class="sc">+</span></span>
<span id="cb210-4"><a href="#cb210-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb210-5"><a href="#cb210-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Residuales según el día: count ~ temperature * season + year&quot;</span>) <span class="sc">+</span></span>
<span id="cb210-6"><a href="#cb210-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-46-1.png" width="672" /></p>
<p>¿Cómo abordamos los errores no independientes? Si la no independencia está relacionada con el tiempo, entonces deberíamos usar un modelo apropiado para datos de series de tiempo, como ARIMA (que se podrá ver en otras asignaturas). Si la agrupación se debe a alguna otra estructura en los datos, por ejemplo, la agrupación debido a la ubicación, entonces podríamos considerar el uso de un modelo jerárquico o multinivel (también se podrá ver en otras asignaturas). Para manejar errores no independientes con un modelo lineal, necesitamos agregar variables que controlen el agrupamiento. La agrupación en este caso se debe a la estacionalidad, por lo que agregamos predictores como año, temporada, mes o día de la semana. Si el modelo resultante aún no se ajusta bien a los datos y solo nos interesa la predicción, entonces podríamos considerar el uso de un modelo no paramétrico como KNN.</p>
<p><em>5. Normalidad de los residuales</em></p>
<p>Comparado con los otros supuestos, este no es muy importante. La regresión lineal es extremadamente robusta a las violaciones de la normalidad. Podemos comprobar visualmente la normalidad de los residuales con un histograma:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">residuals =</span> <span class="fu">residuals</span>(linear_fit3)) <span class="sc">%&gt;%</span></span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(residuals)) <span class="sc">+</span></span>
<span id="cb211-3"><a href="#cb211-3" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb211-4"><a href="#cb211-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Residuales:  count ~ temperature * season&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-47-1.png" width="672" /></p>
<p>Queda bastante claro que el modelo sin año no es normal. La bimodalidad de esta distribución ofrece una pista de que el año es un término estacional clave. La librería car incluye una función, <code>qqPlot ()</code> que “muestra cuantiles empíricos de una variable, o de residuales studentizados de un modelo lineal, contra cuantiles teóricos de una distribución teórica con la que podemos comparar”.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb212-2"><a href="#cb212-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqPlot</span>(linear_fit3, <span class="at">pch =</span> <span class="dv">20</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-48-1.png" width="672" /></p>
<pre><code>[1] 239 668</code></pre>
<p>Aquí podemos ver desviaciones de la normalidad que también tienen una estructura anual discernible.</p>
<p>En resumen, utilizamos gráficos de residuos para validar y mejorar el ajuste del modelo. Si bien hay funciones disponibles para probar formalmente la mayoría de los supuestos del modelo anterior, es mejor (en mi opinión) evitar tales pruebas binarias a favor de graficar los residuos y pensar en los datos y cómo mejorar un modelo.</p>
</div>
<div id="ejemplos-adicionales-de-interpretación-de-modelos" class="section level2 hasAnchor" number="4.14">
<h2 class="hasAnchor"><span class="header-section-number">4.14</span> Ejemplos adicionales de interpretación de modelos<a href="#ejemplos-adicionales-de-interpretación-de-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para estos ejemplos, usaremos el conjunto de datos de vivienda de Boston, que registra los precios de la vivienda en el área de Boston en la década de 1970 junto con varios predictores. La variable de resultado es el valor mediano de las viviendas ocupadas por sus propietarios en $1000, codificado como “medv”. Los predictores incluyen lo siguiente:</p>
<ul>
<li><p>chas: variable ficticia de Charles River (= 1 si el tramo limita con el río; 0 en caso contrario).</p></li>
<li><p>lstat: menor estatus de la población (porcentaje). El diccionario de datos no es explícito, pero esta variable parece ser una medida del estatus socioeconómico de un barrio, representado como el porcentaje de clase trabajadora o familias pobres. Centraremos esta variable para que los efectos principales sean interpretables.</p></li>
<li><p>rm: número medio de habitaciones por vivienda en un área geográfica determinada. Centraremos esta variable para que los efectos principales sean interpretables.</p></li>
</ul>
<div id="interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos" class="section level3 hasAnchor" number="4.14.1">
<h3 class="hasAnchor"><span class="header-section-number">4.14.1</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos<a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Boston)</span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>rm_centered  <span class="ot">&lt;-</span> Boston<span class="sc">$</span>rm <span class="sc">-</span> <span class="fu">mean</span>(Boston<span class="sc">$</span>rm)</span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>lstat_centered <span class="ot">&lt;-</span>  Boston<span class="sc">$</span>lstat <span class="sc">-</span> <span class="fu">mean</span>(Boston<span class="sc">$</span>lstat)</span>
<span id="cb214-5"><a href="#cb214-5" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> rm_centered <span class="sc">+</span> lstat_centered, <span class="at">data =</span> Boston))</span></code></pre></div>
<pre><code>lm(formula = medv ~ rm_centered + lstat_centered, data = Boston)
               coef.est coef.se
(Intercept)    22.53     0.25  
rm_centered     5.09     0.44  
lstat_centered -0.64     0.04  
---
n = 506, k = 3
residual sd = 5.54, R-Squared = 0.64</code></pre>
<ul>
<li><p>La intersección con el eje Y (<em>intercept</em>) es el valor predicho de la variable de resultado cuando los predictores son 0. A veces, la intersección no será interpretable porque un predictor no puede = 0. La solución es centrar la variable para que 0 tenga sentido.</p></li>
<li><p><strong>intercept</strong>: El valor predicho de medv cuando todos los predictores son 0: 22.53 + 5.09 (0) - .64 (0).</p></li>
<li><p><em>rm_centered</em>: 5.09 representa el cambio predicho en medv cuando rm_centered aumenta en una unidad (1 habitación), mientras se mantienen constantes las otras variables.</p></li>
<li><p><em>lstat_centered</em>: -.64 representa el cambio predicho en medv cuando lstat_centered aumenta en una unidad, mientras se mantienen constantes las otras variables.</p></li>
</ul>
</div>
<div id="interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos" class="section level3 hasAnchor" number="4.14.2">
<h3 class="hasAnchor"><span class="header-section-number">4.14.2</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos<a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> rm_centered <span class="sc">+</span> lstat_centered <span class="sc">+</span> chas, <span class="at">data =</span> Boston))</span></code></pre></div>
<pre><code>lm(formula = medv ~ rm_centered + lstat_centered + chas, data = Boston)
               coef.est coef.se
(Intercept)    22.25     0.25  
rm_centered     4.96     0.44  
lstat_centered -0.64     0.04  
chas            4.12     0.96  
---
n = 506, k = 4
residual sd = 5.45, R-Squared = 0.65</code></pre>
<ul>
<li><p>La intersección (<em>intercept</em>) es el valor predicho de la variable de resultado cuando el predictor binario es 0 y la variable continua es 0 (que, para las variables centradas, es el promedio).</p></li>
<li><p><strong>intercept</strong>: El valor predicho de medv cuando todos los predictores son 0: 22.25 + 4.96 (0) -.64 (0) + 4.12 (0).</p></li>
<li><p><em>rm_centered</em>: 4.96 representa el cambio predicho en medv cuando rm_centered aumenta en una unidad (1 habitación), mientras se mantienen constantes las otras variables.</p></li>
<li><p><em>lstat_centered</em>: -.64 representa el cambio predicho en medv cuando lstat_centered aumenta en una unidad, mientras se mantienen constantes las otras variables.</p></li>
<li><p><em>chas</em>: 4.12 representa el cambio predicho en medv cuando chas aumenta en una unidad, mientras se mantienen constantes las otras variables.</p></li>
</ul>
</div>
<div id="interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones" class="section level3 hasAnchor" number="4.14.3">
<h3 class="hasAnchor"><span class="header-section-number">4.14.3</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos, con interacciones<a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> rm_centered<span class="sc">*</span> chas <span class="sc">+</span> lstat_centered, <span class="at">data =</span> Boston))</span></code></pre></div>
<pre><code>lm(formula = medv ~ rm_centered * chas + lstat_centered, data = Boston)
                 coef.est coef.se
(Intercept)      22.25     0.25  
rm_centered       4.98     0.46  
chas              4.17     0.99  
lstat_centered   -0.64     0.04  
rm_centered:chas -0.22     1.13  
---
n = 506, k = 5
residual sd = 5.45, R-Squared = 0.65</code></pre>
<p>Recordemos que la visualización de datos en estadística es muy necesaria!</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(rm_centered, medv, <span class="at">col=</span> <span class="fu">factor</span>(chas))) <span class="sc">+</span> </span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb220-3"><a href="#cb220-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se=</span>F)<span class="sc">+</span></span>
<span id="cb220-4"><a href="#cb220-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;medv ~ rm_centered según chas&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-51-1.png" width="672" /></p>
<p>Estas rectas de regresión son prácticamente paralelas, lo que indica que no hay interacción. Este resultado se confirma por el hecho de que el valor p para rm_centered: chas es .85 (p&gt; .05).</p>
<ul>
<li><p><strong>intercept</strong>: 4.98 es el valor predicho de medv cuando todos los predictores son 0.</p></li>
<li><p><em>rm_centered</em>: 4.98 representa el cambio predicho en medv cuando rm_centered aumenta en una unidad (1 habitación), entre aquellas casas donde chas = 0.</p></li>
<li><p><em>chas</em>: 4.17 representa el cambio predicho en medv cuando chas aumenta en una unidad, entre hogares con habitaciones promedio (rm_centered = 0).</p></li>
<li><p><em>lstat_centered</em>: -.64 representa el cambio predicho en medv cuando lstat_centered aumenta en una unidad, mientras se mantienen constantes las otras variables.</p></li>
<li><p><em>rm_centered: chas</em>: -.21 se agrega a la pendiente de rm_centered, 4.98, para chas aumenta de 0 a 1. O, alternativamente, se agrega -.21 a la pendiente de chas, 4.17, por cada unidad adicional de rm__centrado.</p></li>
</ul>
</div>
<div id="interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones" class="section level3 hasAnchor" number="4.14.4">
<h3 class="hasAnchor"><span class="header-section-number">4.14.4</span> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos, con interacciones<a href="#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> rm_centered <span class="sc">*</span> lstat_centered, <span class="at">data =</span> Boston))</span></code></pre></div>
<pre><code>lm(formula = medv ~ rm_centered * lstat_centered, data = Boston)
                           coef.est coef.se
(Intercept)                21.04     0.23  
rm_centered                 3.57     0.39  
lstat_centered             -0.85     0.04  
rm_centered:lstat_centered -0.48     0.03  
---
n = 506, k = 4
residual sd = 4.70, R-Squared = 0.74</code></pre>
<p>Primero, visualizaremos la interacción dicotomizando lstat.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>lstat_bin <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Boston<span class="sc">$</span>lstat <span class="sc">&gt;</span> <span class="fu">mean</span>(Boston<span class="sc">$</span>lstat), <span class="st">&quot;above avg&quot;</span>,<span class="st">&quot;below avg&quot;</span>)</span>
<span id="cb223-2"><a href="#cb223-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(rm_centered, medv, <span class="at">col=</span> lstat_bin) ) <span class="sc">+</span> </span>
<span id="cb223-3"><a href="#cb223-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb223-4"><a href="#cb223-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb223-5"><a href="#cb223-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;medv ~ rm según lstat&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-53-1.png" width="672" /></p>
<p>El número de habitaciones en una casa claramente afecta el valor — ambas rectas de regresión son positivas. Pero esta relación positiva es más pronunciada entre los hogares con menor lstat. Aumentar la cantidad de habitaciones tiene un impacto mayor en los vecindarios más pobres que en los vecindarios más ricos.</p>
<p>A continuación, dicotomizamos rm.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>Boston<span class="sc">$</span>rm_bin <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Boston<span class="sc">$</span>rm <span class="sc">&gt;</span> <span class="fu">mean</span>(Boston<span class="sc">$</span>rm), <span class="st">&quot;above avg&quot;</span>,<span class="st">&quot;below avg&quot;</span>)</span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Boston, <span class="fu">aes</span>(lstat_centered, medv, <span class="at">col =</span> rm_bin) ) <span class="sc">+</span> </span>
<span id="cb224-3"><a href="#cb224-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb224-4"><a href="#cb224-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb224-5"><a href="#cb224-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;medv ~ lstat según rm&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-54-1.png" width="672" /></p>
<p>El nivel socioeconómico promedio en un vecindario afecta claramente el valor de la vivienda; ambas rectas de regresión son negativas. Pero esta relación negativa es más pronunciada entre los hogares con habitaciones por encima del promedio. El nivel socioeconómico bajo (lstat aumentado) tiene un mayor impacto en el valor de las viviendas con habitaciones por encima del promedio que en las casas con habitaciones por debajo del promedio.</p>
<ul>
<li><p><strong>intercept</strong>: 21.04 es el valor predicho de medv cuando tanto rm como lstat son promedios.</p></li>
<li><p><em>rm_centered</em>: 3.57 es el cambio predicho en medv si rm_centered aumenta en 1 unidad, entre aquellos hogares donde lstat_centered es promedio (= 0).</p></li>
<li><p><em>lstat_centered</em>: .85 es el cambio predicho en medv si lstat_centered aumenta en 1 unidad, entre aquellos hogares donde rm_centered es promedio (= 0)</p></li>
<li><p><em>rm_centered: lstat_centered</em>: .48 se agrega a la pendiente de rm_centered, 3.57, por cada unidad adicional de lstat_centered. O, alternativamente, se agrega -.48 a la pendiente de lstat_centered, -.85, para cada unidad adicional de rm__centered. Podemos entender la interacción diciendo que la importancia de lstat como predictor de medv disminuye a mayor número de habitaciones y, de manera similar, que la importancia de rm como predictor de medv disminuye a niveles más altos de lstat.</p></li>
</ul>
</div>
</div>
<div id="centrado-y-escalado" class="section level2 hasAnchor" number="4.15">
<h2 class="hasAnchor"><span class="header-section-number">4.15</span> Centrado y escalado<a href="#centrado-y-escalado" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hemos visto cómo los predictores centrados pueden ayudar a la interpretación del modelo. Además de centrar, podemos <em>escalar</em> predictores, lo que hace que los coeficientes del modelo resultante sean directamente comparables (nos puede servir para discernir qué variable influye más en el resultado). La función <code>rescale ()</code> en el paquete arm automáticamente centra una variable y divide por 2 desviaciones estándar (<span class="math inline">\(\frac {x_i - \bar {x}}{2sd}\)</span>). La configuración predeterminada ignora las variables binarias. La división por 2 desviaciones estándar, en lugar de 1 (como cuando se calcula una puntuación z tradicional), hace que las variables continuas reescaladas sean comparables a las variables binarias no transformadas. Después de centrar y escalar, los coeficientes del modelo se pueden usar para evaluar los tamaños del efecto e identificar los predictores más fuertes.</p>
<p>¿Cuál es un predictor más sólido del número de ciclistas, la velocidad del viento o el año?</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(count <span class="sc">~</span> windspeed <span class="sc">+</span> year, <span class="at">data =</span> day))</span></code></pre></div>
<pre><code>lm(formula = count ~ windspeed + year, data = day)
            coef.est coef.se 
(Intercept)  4496.05   161.80
windspeed   -5696.31   733.60
year         2183.75   113.63
---
n = 731, k = 3
residual sd = 1535.95, R-Squared = 0.37</code></pre>
<p>Este modelo hace que parezca que windpseed es, con mucho, el predictor más fuerte: el valor absoluto del coeficiente es más de 2 veces mayor. Pero este resultado es engañoso, un artefacto de escala variable.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(count <span class="sc">~</span> arm<span class="sc">::</span><span class="fu">rescale</span>(windspeed) <span class="sc">+</span> year, <span class="at">data =</span> day))</span></code></pre></div>
<pre><code>lm(formula = count ~ arm::rescale(windspeed) + year, data = day)
                        coef.est coef.se
(Intercept)             3410.98    80.40
arm::rescale(windspeed) -882.90   113.70
year                    2183.75   113.63
---
n = 731, k = 3
residual sd = 1535.95, R-Squared = 0.37</code></pre>
<p>El ajuste del modelo no ha cambiado — <span class="math inline">\(R^2\)</span> es el mismo en ambos modelos — pero el centrado y la escala nos permiten ver que el año en realidad tiene un tamaño de efecto mucho mayor que la velocidad del viento: se asocia un aumento de 1 unidad en el año con un mayor cambio en el número de pasajeros. Podríamos, de manera equivalente, usar la función <code>estandardize ()</code>, también del paquete arm, que convenientemente cambia la escala de todas las variables en un modelo a la vez.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">standardize</span>(<span class="fu">lm</span>(count <span class="sc">~</span> windspeed <span class="sc">+</span> year, <span class="at">data=</span> day)))</span></code></pre></div>
<pre><code>lm(formula = count ~ z.windspeed + c.year, data = day)
            coef.est coef.se
(Intercept) 4504.35    56.81
z.windspeed -882.90   113.70
c.year      2183.75   113.63
---
n = 731, k = 3
residual sd = 1535.95, R-Squared = 0.37</code></pre>
<p>La función <code>standardize()</code> nos advierte que la velocidad del viento es ahora un z-score (z.windspeed), y que ese año se ha centrado (c.year). La interpretación de c.year es la misma que para año: un aumento de 1 unidad (-.5 a .5) se asocia con un aumento previsto de 2183,75 pasajeros. Sin embargo, la interpretación de z.windspeed ahora es diferente, ya que un aumento de 1 unidad en z.windspeed es 2 desviaciones estándar. Por lo tanto, un aumento de 2 desviaciones estándar en la velocidad del viento (0.15) se asocia con un cambio previsto en el número de pasajeros de -882.</p>
<p>¿Por qué nos importa poder comparar coeficientes? El valor absoluto de <span class="math inline">\(\beta\)</span> es una medida de la fuerza de la relación entre un predictor y el resultado y, por lo tanto, de la importancia de ese predictor para explicar el resultado. Los valores p no ofrecen orientación sobre la <em>fuerza</em> de un predictor: un predictor estadísticamente significativo podría tener un tamaño de efecto minúsculo y prácticamente intrascendente. El valor absoluto de <span class="math inline">\(\beta\)</span> es, por tanto, una medida de importancia práctica, en oposición a la significación estadística. La significancia estadística expresa la improbabilidad de un resultado, mientras que <span class="math inline">\(\beta\)</span> representa el tamaño del efecto, cuánto esperamos que cambie el resultado como resultado de variar el predictor. Estandarizar <span class="math inline">\(\beta\)</span> nos permite interpretar el tamaño del efecto sin dejarnos engañar por diferencias arbitrarias en la escala variable.</p>
</div>
<div id="transformación-de-variables" class="section level2 hasAnchor" number="4.16">
<h2 class="hasAnchor"><span class="header-section-number">4.16</span> Transformación de variables<a href="#transformación-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hasta ahora hemos considerado transformaciones que no cambian el ajuste del modelo, sino que simplemente ayudan a la interpretación. A veces, sin embargo, queremos cambiar las variables para que un modelo lineal se ajuste mejor. La transformación logarítmica ampliamente utilizada es un ejemplo. Deberíamos considerar una transformación logarítmica si nuestros datos están sesgados, muestran un aumento no lineal o tienen un rango grande. Regla empírica: si una variable tiene un margen superior a dos órdenes de magnitud (x 100), la transformación logarítmica probablemente mejorará el modelo.</p>
<p>Para la transformación logarítmica usaremos el logaritmo natural, designado <span class="math inline">\(\log_e\)</span>, o <span class="math inline">\(\ln\)</span>, o, en código R: <code>log()</code>. El logaritmo natural es la función inversa de la función exponencial (y viceversa): se deshacen entre sí. Por lo tanto, estas identidades: <span class="math inline">\(e ^ {\ln (x)} = x\)</span> (si <span class="math inline">\(x&gt; 0\)</span>); <span class="math inline">\(\ln (e ^ x) = x\)</span>. Para volver a poner una variable transformada logarítmica en la escala original, simplemente exponenciamos: <span class="math inline">\(x = e ^ {\ln (x)}\)</span>. En código R: <code>x = exp (log (x)</code>). Una razón para usar registros naturales es que <em>los coeficientes en la escala logarítmica natural son, aproximadamente, interpretables como diferencias proporcionales.</em> Ejemplo: para una variable transformada logarítmicamente, un coeficiente de .06 significa que una diferencia de 1 unidad en <span class="math inline">\(x\)</span> corresponde a una diferencia aproximada del 6% en <span class="math inline">\(y\)</span>, y así sucesivamente. ¿Por qué? <code>exp (.06)</code> = 1.06, un aumento del 6% desde 1 como referencia. Sin embargo, con coeficientes más grandes, esto no funciona exactamente: <code>exp (.42)</code> = 1.52, una diferencia del 52%.</p>
<p>La población de EE. UU. De 1790 a 1970 es un ejemplo de una variable que nos gustaría transformar, ya que el aumento no es lineal y es grande:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;uspop&quot;</span>)</span>
<span id="cb231-2"><a href="#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(uspop, <span class="at">main =</span> <span class="st">&quot;US population, 1790 - 1970, en millones&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-58-1.png" width="672" /></p>
<p>Pero cuando tomamos el logaritmo de la población, el aumento es (más) lineal:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">log</span>(uspop), <span class="at">main =</span> <span class="st">&quot;US population (scala logartímica), 1790 - 1970, en millones&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-59-1.png" width="672" /></p>
<p>La transformación logarítmica se usa con frecuencia con precios o ingresos, ya que el extremo superior de la escala para tales variables suele ser exponencialmente mayor que el inferior. Podemos registrar los valores de las viviendas en el conjunto de datos de viviendas de Boston para mejorar el ajuste del modelo.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>Boston <span class="sc">%&gt;%</span></span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(medv) <span class="sc">%&gt;%</span></span>
<span id="cb233-3"><a href="#cb233-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">observations =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="fu">length</span>(medv)),</span>
<span id="cb233-4"><a href="#cb233-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">log_medv =</span> <span class="fu">log</span>(medv)) <span class="sc">%&gt;%</span></span>
<span id="cb233-5"><a href="#cb233-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(medv, log_medv, observations) <span class="sc">%&gt;%</span></span>
<span id="cb233-6"><a href="#cb233-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(type, home_value, <span class="sc">-</span>observations) <span class="sc">%&gt;%</span></span>
<span id="cb233-7"><a href="#cb233-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(observations, home_value)) <span class="sc">+</span></span>
<span id="cb233-8"><a href="#cb233-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb233-9"><a href="#cb233-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>type, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>)<span class="sc">+</span></span>
<span id="cb233-10"><a href="#cb233-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Comparación de log(medv) y medv&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-60-1.png" width="672" /></p>
<p>Tomar el logaritmo de medv no ha desplazado medv hacia la linealidad tanto como podríamos haber esperado. No obstante, ¿mejorará el ajuste?</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">standardize</span>(<span class="fu">lm</span>(medv <span class="sc">~</span> rm <span class="sc">+</span> lstat, <span class="at">data =</span> Boston)))</span></code></pre></div>
<pre><code>lm(formula = medv ~ z.rm + z.lstat, data = Boston)
            coef.est coef.se
(Intercept) 22.53     0.25  
z.rm         7.16     0.62  
z.lstat     -9.17     0.62  
---
n = 506, k = 3
residual sd = 5.54, R-Squared = 0.64</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">standardize</span>(<span class="fu">lm</span>(<span class="fu">log</span>(medv) <span class="sc">~</span> rm <span class="sc">+</span> lstat, <span class="at">data =</span> Boston)))</span></code></pre></div>
<pre><code>lm(formula = log(medv) ~ z.rm + z.lstat, data = Boston)
            coef.est coef.se
(Intercept)  3.03     0.01  
z.rm         0.18     0.03  
z.lstat     -0.55     0.03  
---
n = 506, k = 3
residual sd = 0.23, R-Squared = 0.68</code></pre>
<p>Un poco. <span class="math inline">\(R^2\)</span> ha mejorado de .64 a .68.</p>
<p>Se debe tener cuidado al interpretar un modelo transformado logarítmicamente.</p>
<ul>
<li><p><strong>intercept</strong>: 3.03 representa el valor log (medv) predicho cuando tanto rm como lstat son promedios (ya que ambas variables se han centrado y escalado). Para volver a poner esto en la escala original, exponencial: $e ^ {3.03} $= 20.7. Por lo tanto, el medv predicho del modelo para hogares con lstat y rm promedio en dólares es $2.07^{4}.</p></li>
<li><p><em>z.rm</em>: .18 o 18% representa el cambio porcentual previsto en medv asociado con un aumento de dos desviaciones estándar en rm (1.41).</p></li>
<li><p><em>z.lstat</em>: .55 o 55% representa el cambio porcentual previsto en medv asociado con un aumento de dos desviaciones estándar en lstat (14.28).</p></li>
<li><p><em>residual se</em>: .23 es la desviación estándar de los residuos registrados. Para volver a poner esto en la escala original, exponencial: $e ^ .23 $= $1.2586.</p></li>
</ul>
<p>¿Y si tanto el resultado como el predictor se transforman logarítmicamente?</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(<span class="fu">log</span>(medv) <span class="sc">~</span> <span class="fu">log</span>(lstat), <span class="at">data =</span> Boston))</span></code></pre></div>
<pre><code>lm(formula = log(medv) ~ log(lstat), data = Boston)
            coef.est coef.se
(Intercept)  4.36     0.04  
log(lstat)  -0.56     0.02  
---
n = 506, k = 2
residual sd = 0.23, R-Squared = 0.68</code></pre>
<p>La transformación del registro de un predictor, así como el resultado, es una táctica perfectamente razonable si cree que la no normalidad en ambos podría estar contribuyendo a gráficos residuales problemáticos. En este caso, <span class="math inline">\(R^2\)</span> no ha cambiado, lo que sugiere que la transformación logarítmica de lstat no es necesaria.</p>
<ul>
<li><p><strong>intercept</strong>: log (medv) es 4.36 cuando lstat = 1. (Tenga en cuenta que no podemos centrar lstat en este caso porque no podemos tomar el logaritmo de un número negativo).</p></li>
<li><p><em>log (lstat)</em>: -.56 o -56% representa el cambio porcentual previsto en medv asociado con un aumento del 1% en lstat.</p></li>
</ul>
<p>En este artículo <a href="https://pubmed.ncbi.nlm.nih.gov/25643111/">Models with transformed variables: interpretation and software</a> se muesrta cómo reportar e interpretar efectos en escalas originales de las variables en el caso de los modelos de regresión lineal, logística y Poisson con transformaciones logarítmicas y de potencia.</p>
</div>
<div id="colinealidad" class="section level2 hasAnchor" number="4.17">
<h2 class="hasAnchor"><span class="header-section-number">4.17</span> Colinealidad<a href="#colinealidad" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La colinealidad ocurre cuando dos variables predictoras están fuertemente correlacionadas entre sí. Si bien no es un supuesto de regresión per se, la colinealidad puede afectar la precisión de los coeficientes, así como inflar los errores estándar. La colinealidad es menos preocupante cuando solo nos interesa la predicción.</p>
<p>Un buen ejemplo es la temperatura y la temperatura percibida, atemp, en los datos de la bicicleta. Estas medidas de temperatura están muy cerca:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(day, <span class="fu">aes</span>(temperature)) <span class="sc">+</span> </span>
<span id="cb240-2"><a href="#cb240-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>()<span class="sc">+</span></span>
<span id="cb240-3"><a href="#cb240-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(atemp), <span class="at">col=</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb240-4"><a href="#cb240-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Densidad de la temperatura (black) vs. la temperatura percibida (red)&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-63-1.png" width="672" /></p>
<p>Ahora compare el modelo de uso de la bicicleta con solo la temperatura como predictor con el modelo con temperatura y temperatura. Observe lo que sucede con los errores estándar y los coeficientes:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">standardize</span>(<span class="fu">lm</span>(count <span class="sc">~</span> temperature, <span class="at">data =</span> day)))</span></code></pre></div>
<pre><code>lm(formula = count ~ z.temperature, data = day)
              coef.est coef.se
(Intercept)   4504.35    55.83
z.temperature 2431.18   111.73
---
n = 731, k = 2
residual sd = 1509.39, R-Squared = 0.39</code></pre>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(model <span class="ot">&lt;-</span> <span class="fu">standardize</span>(<span class="fu">lm</span>(count <span class="sc">~</span> temperature <span class="sc">+</span> atemp, <span class="at">data =</span> day)))</span></code></pre></div>
<pre><code>lm(formula = count ~ z.temperature + z.atemp, data = day)
              coef.est coef.se
(Intercept)   4504.35    55.65
z.temperature  390.34   866.32
z.atemp       2057.91   866.32
---
n = 731, k = 3
residual sd = 1504.60, R-Squared = 0.40</code></pre>
<p>Los <span class="math inline">\(SE\)</span>s se hacen enormes y los coeficientes se vuelven poco fiables.</p>
<p>La solución práctica en el caso anterior es usar solo una de estas variables sabiendo que contienen la misma información. Pero las variables a menudo están correlacionadas. ¿Cuánta correlación está bien? El factor de inflación de la varianza (VIF) puede ayudarnos a decidir.</p>
<p>La varianza muestral estimada del coeficiente de regresión <span class="math inline">\(j\)</span>-ésimo se puede escribir como:</p>
<p><span class="math display">\[{\rm \widehat {var}} (\hat {\beta} _j) = \frac {\hat {\sigma} ^ 2} {(n-1) s_j ^ 2} \cdot \frac {1} {1-R_j ^ 2}\]</span></p>
<p>donde <span class="math inline">\(\hat {\sigma} ^ 2\)</span> es la varianza del error estimada, <span class="math inline">\(s_j ^ 2\)</span> es la varianza muestral de $x_j $y <span class="math inline">\(\frac {1} {1-R_j ^ 2}\)</span> es el factor de inflación de la varianza o <span class="math inline">\(VIF_j\)</span>.</p>
<p>El término <span class="math inline">\(R_j ^ 2\)</span> es el <span class="math inline">\(R ^ 2\)</span> de un modelo de regresión lineal en el que el predictor <span class="math inline">\(X_j\)</span> se utiliza como variable de respuesta y todas las demás covariables como variables explicativas. Un <span class="math inline">\(R ^ 2\)</span> alto en dicho modelo significa que la mayor parte de la variación en el predictor <span class="math inline">\(X_j\)</span> se explica por todas las demás covariables, lo que significa que hay colinealidad. Esto infla los errores estándar, ensanchando los IC y disminuyendo la probabilidad de detectar un efecto. Para evaluar la colinealidad entre los predictores, use <code>vif ()</code> del paquete car:</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(day<span class="sc">$</span>temperature, day<span class="sc">$</span>atemp)</span></code></pre></div>
<pre><code>[1] 0.9917016</code></pre>
<p>Estas variables están casi perfectamente correlacionadas.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(model)</span></code></pre></div>
<pre><code>z.temperature       z.atemp 
     60.50328      60.50328 </code></pre>
<p>Este resultado significa que los errores estándar son aproximadamente <span class="math inline">\(\sqrt {60.5}\)</span>= 7.8 más grandes de lo que serían sin la otra variable. El punto críto es ver que valor se considera grande … Hay autores que consideran un umbral de VIF de 4 (John Fox) o 5-10 (Hastie &amp; Tibshirani) para eliminar una variable. Lo que hay que hacer es decir cuál es nuestro criterio y dejar que el lector considere si es mucho o poco.</p>
</div>
<div id="valores-atípicos" class="section level2 hasAnchor" number="4.18">
<h2 class="hasAnchor"><span class="header-section-number">4.18</span> Valores atípicos<a href="#valores-atípicos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los valores atípicos pueden afectar el ajuste de un modelo de regresión. Es mejor no eliminarlos (al menos no al principio) sino comprenderlos. (Por supuesto, algunos valores extremos podrían ser errores de codificación, en cuyo caso querrá eliminarlos). Recuerde que los valores atípicos son principalmente una preocupación <em>después</em> de que el modelo se ha ajustado, en cuyo caso aparecen entre los residuos. Los predictores incluidos en el modelo pueden ocuparse de las observaciones que aparecen como valores atípicos en el análisis univariado o bivariado. Como ejemplo, consideremos un conjunto de datos incluido en la librería ISLR, Hitters, que contiene información de las estadísticas de rendimiento y los salarios de los jugadores de béisbol de las grandes ligas en la temporada de 1986. Creemos un modelo para predecir el salario usando el número de turnos al bate, hits, años en la liga, home-runs, carreras impulsadas, bases por bolas y asistencias.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb249-2"><a href="#cb249-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Hitters)</span>
<span id="cb249-3"><a href="#cb249-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb249-4"><a href="#cb249-4" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">standardize</span>(m <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(Salary) <span class="sc">~</span> AtBat <span class="sc">+</span> Hits <span class="sc">+</span></span>
<span id="cb249-5"><a href="#cb249-5" aria-hidden="true" tabindex="-1"></a>                              Years <span class="sc">+</span> HmRun <span class="sc">+</span> RBI <span class="sc">+</span> Walks <span class="sc">+</span></span>
<span id="cb249-6"><a href="#cb249-6" aria-hidden="true" tabindex="-1"></a>                              Assists, <span class="at">data =</span> Hitters)))</span></code></pre></div>
<pre><code>lm(formula = log(Salary) ~ z.AtBat + z.Hits + z.Years + z.HmRun + 
    z.RBI + z.Walks + z.Assists, data = Hitters)
            coef.est coef.se
(Intercept)  5.88     0.04  
z.AtBat     -0.81     0.34  
z.Hits       1.29     0.32  
z.Years      0.91     0.08  
z.HmRun      0.11     0.17  
z.RBI        0.02     0.23  
z.Walks      0.34     0.10  
z.Assists    0.03     0.09  
---
n = 263, k = 8
residual sd = 0.63, R-Squared = 0.51</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m, <span class="at">which=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-67-1.png" width="672" /></p>
<p>Los salarios de tres jugadores — Mike Schmidt, Terry Kennedy y Steve Sax — claramente no están muy bien explicados por este modelo. El modelo predice que a los dos primeros se les debería pagar menos y que al tercero se les debería pagar más. Podemos obtener otra perspectiva de estas observaciones utilizando una métrica llamada “distancia de Cook”, que es una medida de influencia de uso común.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m, <span class="at">which=</span><span class="dv">4</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-68-1.png" width="672" /></p>
<p>Un punto influyente es aquel que, si se elimina de los datos, cambiaría significativamente el ajuste. El punto podría ser un valor atípico o tener un alto apalancamiento. La distancia de Cook&gt; 1 se usa a menudo como un umbral aproximado para identificar puntos influyentes. La diferencia de Cook para estos tres jugadores es menor que 1, pero al mismo tiempo no están bien explicados por el modelo. ¿Qué debemos hacer?</p>
<p>Primero, pensar en los datos. Hablar con expertos, generalmente con los investigadores que han diseñado el estudio y han recogido la información para que nos ayuden a comprender si dichos valores tienen sentido (quizás podrían ser errores de medida o de entrada de datos).</p>
<ul>
<li><p>En el caso del conjunto de datos de los bateadores, tenemos datos de solo un año, 1986 — puede haber mucha variabilidad — Pero tenemos estadísticas de carrera en el conjunto de datos. ¿Quizás deberíamos usar estadísticas de carrera promedio como predictores en su lugar?</p></li>
<li><p>Podríamos hacer una investigación histórica para averiguar por qué a Schmidt y Kennedy se les pagó tanto en relación con sus prestaciones (¿quizás se lesionaron durante la temporada?) Y por qué a Sax se le pagó comparativamente poco. Dicha investigación podría ayudarnos a identificar información explicativa adicional que podría codificarse en variables e incluirse en el modelo y que podría mejorar el ajuste del modelo.</p></li>
<li><p>¿Hay alguna característica compartida por estos valores atípicos que podamos codificar en una variable e incluir como predictor en la regresión?</p></li>
</ul>
<p>En pocas palabras: no existen reglas estrictas y rápidas sobre qué hacer con los valores atípicos (o incluso lo que cuenta como un valor atípico). Usamos estas herramientas de diagnóstico, las gráficas de distancia y residuales de Cook, para comprender mejor nuestros datos y diseñar enfoques que tengan sentido en el contexto de nuestro proyecto. NOTA IMPORTANTE: Debemos tener mucho cuidado al descartar datos (a parte que no es una buena conducta). Tan sólo podríamos descartarlos si estuviéramos 100% seguros que son errores.</p>
<!--chapter:end:03-regresion_lineal.Rmd-->
</div>
</div>
<div id="ajuste-de-modelos" class="section level1 hasAnchor" number="5">
<h1 class="hasAnchor"><span class="header-section-number">5</span> Ajuste de modelos<a href="#ajuste-de-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Este capítulo cubre varios temas adicionales relacionados con el ajuste de modelos, como la selección de variables, la comparación de modelos, la validación cruzada y la imputación de datos faltantes. Los conceptos y métodos discutidos aquí se aplican tanto a la regresión lineal como a la logística.</p>
<p>Qué pretendemos aprender en este capítulo:</p>
<ul>
<li>Saber cuales son las reglas generales para seleccionar variables en un modelo.</li>
<li>Aprender a llevar a cabo esta selección con métodos automáticos (stepwise).</li>
<li>Cómo comparar dos modelos</li>
<li>Cómo determinar si un modelo tiene sobre-ajuste (overfitting)</li>
<li>Dar una pequeña idea a qué hacer cuando tenemos datos faltantes (missing data)</li>
</ul>
<div id="reglas-generales-para-la-selección-de-variables" class="section level2 hasAnchor" number="5.1">
<h2 class="hasAnchor"><span class="header-section-number">5.1</span> Reglas generales para la selección de variables<a href="#reglas-generales-para-la-selección-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>¿Cómo sabemos qué variables (independientes) deben incluirse en un modelo? La respuesta sencilla es: a menudo no lo sabemos. Aquí hay algunas reglas generales cuando se piensa en la selección de variables:</p>
<ul>
<li><p><em>Piensa en los datos</em>. ¿Qué variables tiene sentido incluir dada la situación? ¿Alguna literatura publicada ofrece orientación? Si estamos en modo descriptivo, es posible que solo nos interesen determinadas variables y utilicemos las demás como controles. Si estamos en modo predictivo, incluimos todas las variables que, por razones aditivas, podrían ser importantes para predecir el resultado. Sin embargo, esta es una guía muy general, ya que diferentes contextos exigen diferentes enfoques para el ajuste del modelo.</p></li>
<li><p><em>Incluir términos cuadráticos si hay evidencia de gráficos bivariados de una relación no lineal entre predictor y resultado.</em> En general, no incluimos términos polinomiales con grados superiores a 2. Para hacerlo, se corre el riesgo de sobreajuste (término del que hablaremos más tarde).</p></li>
<li><p><em>Buscar posibles interacciones entre variables con los efectos principales más grandes.</em> En general, no incluimos interacciones de orden superior (mayores que 2) a menos que tengamos una razón lógica y podamos explicarla. También hay que tener en cuenta que las interacciones son bastante difíciles de explicar.</p></li>
<li><p><em>Considerar combinar predictores separados en un solo predictor — un “puntaje total” — obtenido al sumarlos o promediarlos.</em></p></li>
<li><p><em>Simplicidad.</em> Los modelos sencillos son casi siempre mejores — son más interpretables y tienden a tener menor variación (<em>principio de parsimonia</em>).</p></li>
</ul>
</div>
<div id="selección-paso-a-paso-stepwise" class="section level2 hasAnchor" number="5.2">
<h2 class="hasAnchor"><span class="header-section-number">5.2</span> Selección paso a paso (stepwise)<a href="#selección-paso-a-paso-stepwise" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La técnica tradicional en estadística para seleccionar variables es <em>selección paso a paso</em> (o <em>stepwise</em> en inglés).</p>
<p>Con <em>selección hacia adelante</em> comenzamos con un modelo nulo (solo contiene el <em>intercept</em>) y agregamos una variable a la vez. Si la variable agregada mejora el modelo, la mantenemos y agregamos otra. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura:</p>
<div class="figure">
<img src="figures/fwd_stepwise.png" style="width:40.0%" alt="" />
<p class="caption">Selección hacia adelante</p>
</div>
<p>Con <em>selección hacia atrás</em> comenzamos con un modelo completo (todos los términos disponibles) y eliminamos variables en serie (una a una). Si el modelo es mejor después de eliminar una variable, lo dejamos fuera. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura:</p>
<div class="figure">
<img src="figures/bwd_stepwise.png" style="width:40.0%" alt="" />
<p class="caption">Selección hacia atrás</p>
</div>
<p><em>Selección hacia adelante seguida de selección hacia atrás (saltos)</em>. Consiste en ir realizando en cada paso una selección hacia adelante o hacia atrás en función del mejor paso que podamos hacer.</p>
<p>Desafortunadamente, estos procedimientos de ajuste manual son defectuosos. Dependen del orden en el que se agregan o excluyen las variables y, a menudo, no seleccionarán el mejor modelo. Además, por ejemplo, supongamos que tenemos una base de datos con <span class="math inline">\(k\)</span> = 13 variables predictoras, lo que significa que hay <span class="math inline">\(2^k\)</span> o 8192 modelos posibles que podríamos ajustar y eso sin tener encuenta la posible introducción de interacciones o términos polinómicos. Este es un espacio extremadamente grande para buscar el mejor modelo, y la búsqueda es computacionalmente costosa y requiere mucho tiempo. Realizar tal búsqueda manualmente sería prácticamente imposible.</p>
</div>
<div id="comparación-de-modelos" class="section level2 hasAnchor" number="5.3">
<h2 class="hasAnchor"><span class="header-section-number">5.3</span> Comparación de modelos<a href="#comparación-de-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ya estamos familiarizados con los términos <span class="math inline">\(R^2\)</span>, RMSE y RSS. Éstos nos servirán como herramientas para comparar modelos. En general, si agregamos una variable y <span class="math inline">\(R ^2\)</span> sube y RMSE / RSS baja, entonces el modelo con la variable adicional siempre es mejor. La cantidad de variación explicada ha aumentado. Sin embargo, como siempre en estadística debemos preguntarnos ¿es este aumento estadísticamente significativo?. Este hecho también introduce un nuevo problema: el sobreajuste. Sabemos que el, <span class="math inline">\(R^2\)</span> ajustado penaliza el ajuste teniendo en cuenta el número de predictores y podría ser una solución. También tenemos otra posibilidad para penalizar la complejidad de los modelos usando métodos de criterio de información como el AIC (Akaike Information Criterion).</p>
<p><span class="math display">\[\mathrm {AIC} = - 2 \ln(L) + 2k\]</span></p>
<p>donde <span class="math inline">\(k\)</span> es el número de parámetros estimados en el modelo, <span class="math inline">\(L\)</span> es el valor maximizado de la función de verosimilitud del modelo y <span class="math inline">\(ln\)</span> es el logaritmo natural. Dado un conjunto de modelos candidatos para los datos, el modelo preferido es el que tiene el valor de AIC más bajo. Al penalizar por <span class="math inline">\(k\)</span> más grandes (garantizados por el término final, <span class="math inline">\(+ 2k\)</span>), AIC intenta protegerse contra el sobreajuste. Es posible, entonces, observar <span class="math inline">\(R^2\)</span> aumentar con la adición de predictores, mientras que AIC baja.</p>
<p>También podemos comparar modelos con una prueba estadística formal utilizando la
prueba de razón de verosimilitud (LRT por sus siglas en inglés):</p>
<p><span class="math display">\[
2 \times [\ln(L_{a}) - \ln(L_{c})]
\]</span>
donde <span class="math inline">\(\ln(L_{c})\)</span> es el logaritmo de la probabilidad del modelo actual (o basal) y <span class="math inline">\(\ln (L_{a})\)</span> es el logaritmo de la probabilidad del modelo alternativo con predictores adicionales. La función <code>lrtest ()</code> en el paquete <code>lmtest</code> implementa el test LRT. La función <code>anova ()</code> en R base también comparará modelos usando una prueba F.</p>
<p>Vamos a ilustrar algunos de ejemplos de comparación de modelos usando los datos de Hitters del paquete ISLR que tiene información sobre bateadores de la Major League de USA entre los años 1986 y 1987. Estamos interesados en crear un modelo para predecir el salario de los bateadores (variable <code>Salary</code>). Partimos de un modelo nulo:</p>
<pre><code>           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells  5517107 294.7   10345047 552.5 10345047 552.5
Vcells 25832435 197.1   55254244 421.6 55239624 421.5</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb254-2"><a href="#cb254-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Hitters)</span>
<span id="cb254-3"><a href="#cb254-3" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(null <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> Hitters))</span></code></pre></div>
<pre><code>lm(formula = Salary ~ 1, data = Hitters)
            coef.est coef.se
(Intercept) 535.93    27.82 
---
n = 263, k = 1
residual sd = 451.12, R-Squared = 0.00</code></pre>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(Hitters<span class="sc">$</span>Salary, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),<span class="dv">2</span>)</span></code></pre></div>
<pre><code>[1] 535.93</code></pre>
<p>Un modelo nulo consiste solo en una intersección, cuyo coeficiente, como podemos ver, es solo la media de Salario. La pregunta clave es si a medida que hacemos un modelo más complejo esa complejidad está justificada. Es decir, si agregar predictores no solo reduce el sesgo sino que lo hace sin aumentar indebidamente la varianza. Veámos qué ocurre si agreguamos más predictores.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb258-2"><a href="#cb258-2" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(h1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> Hits, <span class="at">data =</span> Hitters))</span></code></pre></div>
<pre><code>lm(formula = Salary ~ Hits, data = Hitters)
            coef.est coef.se
(Intercept) 63.05    64.98  
Hits         4.39     0.56  
---
n = 263, k = 2
residual sd = 406.17, R-Squared = 0.19</code></pre>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(null, h1)</span></code></pre></div>
<pre><code>
Model 1: Salary ~ 1
Model 2: Salary ~ Hits

L.R. Chisq       d.f.          P 
        NA          1         NA </code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(null, h1)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: Salary ~ 1
Model 2: Salary ~ Hits
  Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    
1    262 53319113                                  
2    261 43058621  1  10260491 62.194 8.531e-14 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(<span class="fu">AIC</span>(null, h1))</span></code></pre></div>
<pre><code>     df      AIC
null  2 3964.130
h1    3 3909.918</code></pre>
<p>La variable Hits es estadísticamente significativ, ya que el IC del 95% no incluye 0 (4,39 <span class="math inline">\(\pm\)</span> 2 x 0,56) (o el p-valor del test de Score es <span class="math inline">\(&lt;0.05\)</span>). Estos tres métodos coinciden en que el modelo con Hits es una mejora con respecto al modelo nulo. En el caso de <code>lrtest ()</code> y <code>anova ()</code>, el p-valor representa los resultados de una prueba estadística (prueba chi-cuadrado y prueba F, respectivamente) para determinar si el segundo modelo más complejo es un mejor ajuste a los datos. ¿Agregar un predictor adicional, AtBat, mejora aún más el modelo?</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(h2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> Hits <span class="sc">+</span> AtBat, <span class="at">data =</span> Hitters))</span></code></pre></div>
<pre><code>lm(formula = Salary ~ Hits + AtBat, data = Hitters)
            coef.est coef.se
(Intercept) 141.27    76.55 
Hits          8.21     2.08 
AtBat        -1.22     0.64 
---
n = 263, k = 3
residual sd = 404.13, R-Squared = 0.20</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(h1, h2)</span></code></pre></div>
<pre><code>
Model 1: Salary ~ Hits
Model 2: Salary ~ Hits + AtBat

L.R. Chisq       d.f.          P 
        NA          1         NA </code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(h1, h2)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: Salary ~ Hits
Model 2: Salary ~ Hits + AtBat
  Res.Df      RSS Df Sum of Sq      F  Pr(&gt;F)  
1    261 43058621                              
2    260 42463750  1    594871 3.6423 0.05743 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(<span class="fu">AIC</span>(h1, h2))</span></code></pre></div>
<pre><code>   df      AIC
h1  3 3909.918
h2  4 3908.260</code></pre>
<p>Los resultados son ambiguos. El <span class="math inline">\(R^2\)</span> aumenta, mientras que AIC, el logaritmo de la probabilidad y el RSS disminuyen, pero la disminución en los dos últimos casos no es estadísticamente significativa. (Este resultado es consistente con el hecho de que AtBat no es en sí mismo estadísticamente significativo, ya que el IC del 95% para AtBat incluye 0: -1.22 <span class="math inline">\(\pm\)</span> 2 x .64). ¿Deberíamos dejar AtBat en el modelo? No mejora mucho el ajuste, si es que lo hace, al tiempo que agrega complejidad. Entonces, deberíamos sacarlo. Desafortunadamente, estas opciones a menudo no son claras, razón por la cual el ajuste de modelos a veces parece más un arte que una ciencia.</p>
<p>Para implementar el método de selección, seguiríamos agregando variables y comparando modelos usando <code>lrtest ()</code> o <code>anova ()</code> con el fin de encontrar el mejor ajuste posible. Sin embargo, un problema con este procedimiento es que el orden en el que recorremos los predictores afectará nuestras decisiones de selección porque el impacto de cada predictor en el ajuste del modelo depende de la presencia de los demás. Por ejemplo, supongamos que agregamos AtBat más adelante en el proceso de selección:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>h3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> Hits <span class="sc">+</span> Years <span class="sc">+</span> HmRun <span class="sc">+</span> RBI <span class="sc">+</span> Walks <span class="sc">+</span> Assists, </span>
<span id="cb274-2"><a href="#cb274-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> Hitters)</span>
<span id="cb274-3"><a href="#cb274-3" aria-hidden="true" tabindex="-1"></a>h4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> Hits <span class="sc">+</span> Years <span class="sc">+</span> HmRun <span class="sc">+</span> RBI <span class="sc">+</span> Walks <span class="sc">+</span> Assists <span class="sc">+</span> AtBat,</span>
<span id="cb274-4"><a href="#cb274-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> Hitters)</span>
<span id="cb274-5"><a href="#cb274-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(h3, h4)</span></code></pre></div>
<pre><code>
Model 1: Salary ~ Hits + Years + HmRun + RBI + Walks + Assists
Model 2: Salary ~ Hits + Years + HmRun + RBI + Walks + Assists + AtBat

L.R. Chisq       d.f.          P 
        NA          1         NA </code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(<span class="fu">AIC</span>(h3, h4))</span></code></pre></div>
<pre><code>   df      AIC
h3  8 3849.311
h4  9 3840.198</code></pre>
<p>Ahora AtBat mejora claramente el ajuste, pero nunca lo hubiéramos descubierto si ya lo hubiéramos descartado. Esto es preocupante. ¿Existe una forma mejor de seleccionar variables? Quizás, veámoslo.</p>
</div>
<div id="métodos-de-selección-automática" class="section level2 hasAnchor" number="5.4">
<h2 class="hasAnchor"><span class="header-section-number">5.4</span> Métodos de selección automática<a href="#métodos-de-selección-automática" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se han desarrollado algoritmos para buscar en el espacio de modelos de manera eficiente el modelo óptimo. Sin embargo, desde el principio conviene tener cuidado con la selección automática de variables. <em>La elección de variables no debe ser un proceso mecánico.</em> Debemos, en cambio, buscar comprender el proceso de generación de datos. De hecho, el mayor beneficio de la selección manual por pasos consiste menos en producir un buen modelo que en la comprensión obtenida al ajustar muchos modelos y ver, mediante prueba y error, qué predictores son más reactivos con el resultado. Especialmente cuando se trata de descripción, los algoritmos de selección automática de variables son solo herramientas para explorar sus datos y pensar en modelos.</p>
<p>La función <code>step ()</code> en R base automatiza la selección de variables paso a paso usando AIC.</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>mod.fow <span class="ot">&lt;-</span> stats<span class="sc">::</span><span class="fu">step</span>(<span class="fu">lm</span>(Salary <span class="sc">~</span> ., <span class="at">data =</span> Hitters), <span class="at">trace =</span> <span class="cn">FALSE</span>,</span>
<span id="cb278-2"><a href="#cb278-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>)</span>
<span id="cb278-3"><a href="#cb278-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.fow)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + 
    Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + 
    League + Division + PutOuts + Assists + Errors + NewLeague, 
    data = Hitters)

Residuals:
    Min      1Q  Median      3Q     Max 
-907.62 -178.35  -31.11  139.09 1877.04 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  163.10359   90.77854   1.797 0.073622 .  
AtBat         -1.97987    0.63398  -3.123 0.002008 ** 
Hits           7.50077    2.37753   3.155 0.001808 ** 
HmRun          4.33088    6.20145   0.698 0.485616    
Runs          -2.37621    2.98076  -0.797 0.426122    
RBI           -1.04496    2.60088  -0.402 0.688204    
Walks          6.23129    1.82850   3.408 0.000766 ***
Years         -3.48905   12.41219  -0.281 0.778874    
CAtBat        -0.17134    0.13524  -1.267 0.206380    
CHits          0.13399    0.67455   0.199 0.842713    
CHmRun        -0.17286    1.61724  -0.107 0.914967    
CRuns          1.45430    0.75046   1.938 0.053795 .  
CRBI           0.80771    0.69262   1.166 0.244691    
CWalks        -0.81157    0.32808  -2.474 0.014057 *  
LeagueN       62.59942   79.26140   0.790 0.430424    
DivisionW   -116.84925   40.36695  -2.895 0.004141 ** 
PutOuts        0.28189    0.07744   3.640 0.000333 ***
Assists        0.37107    0.22120   1.678 0.094723 .  
Errors        -3.36076    4.39163  -0.765 0.444857    
NewLeagueN   -24.76233   79.00263  -0.313 0.754218    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 315.6 on 243 degrees of freedom
  (59 observations deleted due to missingness)
Multiple R-squared:  0.5461,    Adjusted R-squared:  0.5106 
F-statistic: 15.39 on 19 and 243 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>NOTE: Uso <code>stats::step()</code> en vez de <code>step()</code> para asegurar que usamos la función <code>step()</code> de la librería <code>stats</code> ya que la función <code>step()</code> también está en otra libería que también está carga a posteriori (<code>recipies</code>) y R siempre usa la función que tiene en el nivel más alto.</p>
<p>La selección hacia adelante se estableció en 19 predictores con un <span class="math inline">\(R^2\)</span> de .55. Notamos que no todas las variables son significativas mediante el test de Score (ver columna <code>Pr(&gt;|t|)</code>), ya que el criterio de entrada no es del 0.05 si no del 0.1</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a>mod.back <span class="ot">&lt;-</span> stats<span class="sc">::</span><span class="fu">step</span>(<span class="fu">lm</span>(Salary <span class="sc">~</span> ., <span class="at">data =</span> Hitters), <span class="at">trace =</span> <span class="cn">FALSE</span>, </span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>)</span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.back)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + 
    CRBI + CWalks + Division + PutOuts + Assists, data = Hitters)

Residuals:
    Min      1Q  Median      3Q     Max 
-939.11 -176.87  -34.08  130.90 1910.55 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  162.53544   66.90784   2.429 0.015830 *  
AtBat         -2.16865    0.53630  -4.044 7.00e-05 ***
Hits           6.91802    1.64665   4.201 3.69e-05 ***
Walks          5.77322    1.58483   3.643 0.000327 ***
CAtBat        -0.13008    0.05550  -2.344 0.019858 *  
CRuns          1.40825    0.39040   3.607 0.000373 ***
CRBI           0.77431    0.20961   3.694 0.000271 ***
CWalks        -0.83083    0.26359  -3.152 0.001818 ** 
DivisionW   -112.38006   39.21438  -2.866 0.004511 ** 
PutOuts        0.29737    0.07444   3.995 8.50e-05 ***
Assists        0.28317    0.15766   1.796 0.073673 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 311.8 on 252 degrees of freedom
  (59 observations deleted due to missingness)
Multiple R-squared:  0.5405,    Adjusted R-squared:  0.5223 
F-statistic: 29.64 on 10 and 252 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>La selección hacia detrás se estableció en 10 predictores con un <span class="math inline">\(R^2\)</span> de .54. Con muchas menos variables, somos capaces de explicar prácticamente la misma variabilidad. Además prácticamente todas las variables son significativas según el test de score.</p>
<p>La función <code>regsubsets ()</code> en el paquete <code>leaps</code> realiza una búsqueda exhaustiva del espacio modelo utilizando el algoritmo de saltos (adelante y atrás) para la selección de variables.</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">regsubsets</span>(Salary <span class="sc">~</span> ., <span class="at">data =</span> Hitters, <span class="at">method =</span> <span class="st">&quot;exhaustive&quot;</span>, <span class="at">nbest =</span> <span class="dv">1</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-77-1.png" width="672" /></p>
<p>El gráfico presenta diferentes modelos que pueden ser buenos candidatos organizados según el BIC (<span class="math inline">\(\mathrm{BIC} = {\ln(n) k - 2 \ ln ({L})}\)</span>, donde <span class="math inline">\(L\)</span> es el valor de máxima verosimilitud, <span class="math inline">\(n\)</span> es el número de observaciones, <span class="math inline">\(k\)</span> es el número de parámetros y <span class="math inline">\(ln\)</span> es el logaritmo natural). Como el AIC, el BIC penaliza por la complejidad del modelo. Un BIC más bajo es mejor. El modelo con el BIC más bajo es el bastante simple en la parte superior de la figura: <em>intercept</em>, AtBat, Hits, Walks, CRBI, Division y PutOuts. Si reajustamos un modelo con estos predictores usando <code>lm ()</code> encontramos que tiene un <span class="math inline">\(R^2\)</span> de .4972 , que tampoco está muy lejos del valor obtenido con un método hacia adelante y con muchísimas menos variables (principio de parsimonia). Notemos que, además, todos los coefecientes de este modelo (a excepción del <em>intercept</em>, pero que es necesario introducir) son estadísticamente significativos según el test de score:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a>mod.regsub <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> AtBat <span class="sc">+</span> Hits <span class="sc">+</span> Walks <span class="sc">+</span> CRBI <span class="sc">+</span> Division <span class="sc">+</span> PutOuts,</span>
<span id="cb283-2"><a href="#cb283-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> Hitters)</span>
<span id="cb283-3"><a href="#cb283-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod.regsub)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Salary ~ AtBat + Hits + Walks + CRBI + Division + 
    PutOuts, data = Hitters)

Residuals:
    Min      1Q  Median      3Q     Max 
-873.11 -181.72  -25.91  141.77 2040.47 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   91.51180   65.00006   1.408 0.160382    
AtBat         -1.86859    0.52742  -3.543 0.000470 ***
Hits           7.60440    1.66254   4.574 7.46e-06 ***
Walks          3.69765    1.21036   3.055 0.002488 ** 
CRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***
DivisionW   -122.95153   39.82029  -3.088 0.002239 ** 
PutOuts        0.26431    0.07477   3.535 0.000484 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 319.9 on 256 degrees of freedom
  (59 observations deleted due to missingness)
Multiple R-squared:  0.5087,    Adjusted R-squared:  0.4972 
F-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>**IMPORTANTE:** ¿Es este modelo realmente mejor? El algoritmo hizo una búsqueda exhaustiva del espacio de modelos y, sin embargo, arrojó un modelo con $R^2$ un poco más bajo. ¿Cómo podría ser mejor? (probablemente lo sea). Si bien el sesgo en este modelo será mayor que en el modelo más grande seleccionado por la función `step ()`, la varianza probablemente sea menor. Recuerde: el sesgo se refiere al rendimiento del modelo dentro de la muestra y la varianza se refiere al rendimiento del modelo fuera de la muestra: cómo se comporta el modelo cuando encuentra nuevos datos. Si el modelo tiene un rendimiento deficiente en datos nuevos, con una gran discrepancia entre el rendimiento dentro y fuera de la muestra, entonces está sobreajustado. AIC, BIC y $R^2$ ajustado penalizan por la complejidad del modelo para evitar el sobreajuste y tenderán a seleccionar modelos con mayor sesgo y menor varianza.</code></pre>
</div>
<div id="validación-cruzada" class="section level2 hasAnchor" number="5.5">
<h2 class="hasAnchor"><span class="header-section-number">5.5</span> Validación cruzada<a href="#validación-cruzada" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La validación cruzada (CV por sus siglas en inglés) es la técnica que usamos para evaluar si un modelo está sobreajustado y para estimar cómo funcionará con nuevos datos.</p>
<p>El sobreajuste es un peligro importante en el análisis predictivo, especialmente cuando se utilizan algoritmos de aprendizaje automático que, sin el ajuste adecuado, puede aprender datos de nuestra muestra casi a la perfección, esencialmente ajustando el ruido (o variabilidad). Cuando se utiliza un modelo de este tipo para predecir nuevos datos, con un ruido (o variabilidad) diferente, el rendimiento del modelo puede ser sorprendentemente malo. Usamos CV para ayudarnos a identificar y evitar tales situaciones. ¿Cómo podemos hacer esto? Muchos algoritmos de aprendizaje automático requieren que el usuario especifique ciertos parámetros (hiper-parámetros). Veremos más adelante que, por ejemplo, necesitaremos especificar un valor para <span class="math inline">\(m\)</span> que corresponde al número de predictores elegidos al azar que se utilizarán en cada división de árbol cuando usemos “random forest” como algoritmo de aprendizaje. Cuanto menor sea <span class="math inline">\(m\)</span>, más simple será el árbol. Podemos usar CV para elegir el valor de <span class="math inline">\(m\)</span> que minimiza la variación y reduce el sobreajuste. La regresión lineal no tiene parámetros que debe especificar el usuario, pero la CV aún nos ayuda a evaluar cuánto podría sobreajustarse un modelo a los datos de muestra.</p>
<p>De manera breve, los algoritmos de cross-validation se pueden resumir como:</p>
<ul>
<li>Reserva una parte pequeña de los datos</li>
<li>Crea (o entrena) el modelo usando el resto de datos</li>
<li>Testa el modelo en los datos reservados.</li>
</ul>
<p>A continuación se describen algunas de las distintas técnicas de validación cruzada que existen.</p>
<div id="validación-en-un-conjunto-de-datos-externo" class="section level3 hasAnchor" number="5.5.1">
<h3 class="hasAnchor"><span class="header-section-number">5.5.1</span> Validación en un conjunto de datos externo<a href="#validación-en-un-conjunto-de-datos-externo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La versión más simple de CV es el llamado método de conjunto de validación, que consta de los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><em>Dividir los datos de la muestra en dos partes: un conjunto de entrenamiento y otro de validacións.</em> Los investigadores usan diferentes proporciones, pero es común seleccionar al azar el 70% de los datos como conjunto de entrenamiento y el 30% como conjunto de prueba o validación. . (Obviamente, debemos tener suficientes datos en la muestra para ajustar un modelo después de dividir los datos). Debido a que CV se basa en un muestreo aleatorio, nuestros resultados variarán a menos que usemos <code>set.seed ()</code>. Demostraremos usando los datos de Hitters, usando solo casos completos (esto es importante, no tener missings - veremos más adelante alguna forma de solucionar este problema).</li>
</ol>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>Hitters_complete <span class="ot">&lt;-</span> Hitters[<span class="fu">complete.cases</span>(Hitters), ]</span>
<span id="cb286-3"><a href="#cb286-3" aria-hidden="true" tabindex="-1"></a>rows <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(Hitters_complete), .<span class="dv">7</span> <span class="sc">*</span> <span class="fu">nrow</span>(Hitters_complete))</span>
<span id="cb286-4"><a href="#cb286-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> Hitters_complete[rows, ]</span>
<span id="cb286-5"><a href="#cb286-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> Hitters_complete[<span class="sc">-</span>rows, ]</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><em>Ajustar un modelo en el conjunto de entrenamiento</em> usando un procedimiento de selección de variables apropiado. Crearemos dos modelos para comparar: uno con todas las variables, luego otro con solo las variables elegidas por <code>regsubsets ()</code>.</li>
</ol>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>full_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span>., <span class="at">data =</span> train)</span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>select_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Salary <span class="sc">~</span> AtBat <span class="sc">+</span> Hits <span class="sc">+</span> Walks <span class="sc">+</span> CRBI <span class="sc">+</span> Division <span class="sc">+</span> PutOuts, <span class="at">data =</span> train)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><em>Utilizar ese modelo para predecir en el conjunto de prueba.</em> El rendimiento en el conjunto de prueba es la estimación de CV para el rendimiento fuera de la muestra del modelo.</li>
</ol>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Model =</span> <span class="fu">c</span>(<span class="st">&quot;Modelo completo muestra entrenamiento&quot;</span>,</span>
<span id="cb288-2"><a href="#cb288-2" aria-hidden="true" tabindex="-1"></a>                                <span class="st">&quot;Modelo seleccionado muestra entrenamiento&quot;</span>,</span>
<span id="cb288-3"><a href="#cb288-3" aria-hidden="true" tabindex="-1"></a>                                <span class="st">&quot;Modelo completo muestra validación&quot;</span>,</span>
<span id="cb288-4"><a href="#cb288-4" aria-hidden="true" tabindex="-1"></a>                                <span class="st">&quot;Modelo seleccionado muestra validación&quot;</span>),</span>
<span id="cb288-5"><a href="#cb288-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">RMSE =</span> <span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">rmse</span>(<span class="fu">fitted</span>(full_model), train<span class="sc">$</span>Salary),</span>
<span id="cb288-6"><a href="#cb288-6" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">rmse</span>(<span class="fu">fitted</span>(select_model), train<span class="sc">$</span>Salary),</span>
<span id="cb288-7"><a href="#cb288-7" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">rmse</span>(<span class="fu">predict</span>(full_model, <span class="at">newdata =</span> test), test<span class="sc">$</span>Salary), </span>
<span id="cb288-8"><a href="#cb288-8" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">rmse</span>(<span class="fu">predict</span>(select_model, <span class="at">newdata =</span> test), test<span class="sc">$</span>Salary)),<span class="dv">1</span>))</span>
<span id="cb288-9"><a href="#cb288-9" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>                                      Model  RMSE
1     Modelo completo muestra entrenamiento 297.8
2 Modelo seleccionado muestra entrenamiento 326.1
3        Modelo completo muestra validación 368.2
4    Modelo seleccionado muestra validación 306.4</code></pre>
<p>Podemos ver que el modelo completo está sobreajustado — el RMSE dentro de la muestra es mejor que el RMSE fuera de muestra — mientras que el modelo seleccionado elegido por <code>regsubsets ()</code> usando BIC no está sobreajustado. De hecho, el modelo seleccionado funciona mucho mejor fuera de la muestra que dentro de la muestra, aunque este resultado en particular es probablemente una cuestión de azar, una función de división aleatoria que estamos usando. Sin embargo, en general, estos resultados ilustran el peligro de la complejidad del modelo y por qué tiene sentido elegir predictores utilizando medidas de ajuste del modelo que penalicen la complejidad. Los modelos simples tienden a generalizar mejor. Esta figura muestra estas relaciones:</p>
<div class="figure">
<img src="figures/overfit.png" alt="" />
<p class="caption">Sobreajuste</p>
</div>
</div>
<div id="leave-one-out-cross-validation-loocv" class="section level3 hasAnchor" number="5.5.2">
<h3 class="hasAnchor"><span class="header-section-number">5.5.2</span> Leave-one-out cross validation (LOOCV)<a href="#leave-one-out-cross-validation-loocv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este método funciona de la siguiente manera:</p>
<ul>
<li>Extrae una observación de los datos y usa el resto para entrenar el modelo</li>
<li>Testa el modelo con la observación que ha sido extraída en el paso anterior y guarda el error asociado a esa predicción</li>
<li>Repite el proceso para todos los puntos</li>
<li>Calcula el error de predicción global usando el promedio de todos los errores estimados en el paso 2.</li>
</ul>
<p>Veremos más adelante cómo hacer estos cálculos con una libería específica. De momento, para que aprendáis cómo funciona esta metodología, debéis realizar el siguiente ejercicio</p>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-LOOCV):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento de LOOCV y estima el valor de LOOCV para el modelo completo (<code>full_model</code>) y el modelo seleccionado (<code>select_model</code>) del ejemplo anterior.</td>
</tr>
</tbody>
</table>
</div>
<div id="k-fold-cross-validation-k-fold-cv" class="section level3 hasAnchor" number="5.5.3">
<h3 class="hasAnchor"><span class="header-section-number">5.5.3</span> K-fold cross validation (K-fold CV)<a href="#k-fold-cross-validation-k-fold-cv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La diferencia con LOOCV es que este método evalúa el comportamiento del modelo en un conjunto de datos de distingo tamaño (K). El algoritmo es el siguiente:</p>
<ul>
<li>Separa los datos en k-subconjuntos (k-fold) de forma aleatoria</li>
<li>Guarda uno de los subconjuntos de datos y entrena el modelo con el resto de individuos</li>
<li>Testa el modelo con los datos resevados y guarda el error de predicción promedio.</li>
<li>Repite el proceso hasta que los k subconjuntos hayan servido de muestra test.</li>
<li>Calcula el promedio de los k errores que han sido guardados. Este valor es el error de cross-validación y nos sirve para evaluar el comportamiento de nuestro modelo como si lo usáramos en una base de datos externa.</li>
</ul>
<p>La principal ventaja de este método respecto a LOOCV es el coste computacional. Otra ventaja que no es tan obvia, es que este método a menudo da mejores estimaciones del error del modelo que LOOCV<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>Una pregunta típica es cómo se escoje el valor óptimo de K. Valores pequeños de K da estimaciones sesgadas. Por otro lado, valores grandes de K están menos sesgados, pero tienen mucha variabilidad. En la práctica, normalmente se usan valores de k = 5 or k = 10, ya que estos valores se han mostrado de forma empírica como los que tienen tasas de error estimadas no demasiado sesgadas ni con mucha varianza.</p>
<p>Al igual que en el caso anterior veremos unas liberías adecuadas para hacer estos análisis de forma eficiente. De momento realiza el siguiente ejercicio:</p>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-Kfold):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento de K-fold CV y estima el valor de K-fold CV para el modelo completo (<code>full_model</code>) y el modelo seleccionado (<code>select_model</code>) del ejemplo anterior. Haz que la función tenga un parámetro que dependa de K, y da los resultados para K=5 y K=10.</td>
</tr>
</tbody>
</table>
</div>
<div id="uso-de-cv-para-estimar-el-hiper-parámetro" class="section level3 hasAnchor" number="5.5.4">
<h3 class="hasAnchor"><span class="header-section-number">5.5.4</span> Uso de CV para estimar el hiper-parámetro<a href="#uso-de-cv-para-estimar-el-hiper-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si el algoritmo de aprendizaje automático que vamos a utilizar para realizar predicciones tiene un parámetro que controla el comportamiento (por ejemplo grado de polinomio en regresión no lineal, o el número de nodos en árboles de clasificación) éste podría elegirse de forma que minimizara el error de clasificación. Esta selección también puede dar problemas de sobre ajuste ya que podríamos seleccionar de forma que ajustara perféctamente a nuestros datos.</p>
<p>Para evitar el problema, se puede utilizar cualquiera de las técnicas vistas con anterioridad. Aquí tenemos un ejemplo donde se ha usado un modelo de aprendizaje que se basa en introducir términos polinómicos de varaibles para realizar una mejor predicción mediante regresión lineal usando sólo términos lineales.</p>
<div class="figure">
<img src="figures/cv_hyper.png" style="width:60.0%" alt="" />
<p class="caption">Sobreajuste según un hiper-parámetro</p>
</div>
</div>
<div id="uso-de-bootstrap" class="section level3 hasAnchor" number="5.5.5">
<h3 class="hasAnchor"><span class="header-section-number">5.5.5</span> Uso de bootstrap<a href="#uso-de-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si en vez de partir nuestra muestra en <span class="math inline">\(K\)</span> submuestras, realizamos una selección aleatoria de muestras con reemplazamiento, nos encontraremos ante una aproximación de tipo <em>bootstrap</em> que es una técnica muy usada en estadística para hacer inferencia cuando la distribución del estadístico es desconocida basada en el remuestreo [<a href="https://biocosas.github.io/R/100_bootstrap.html">aquí</a> tenéis una descripción sencilla de esta metodología].</p>
<div class="figure">
<img src="figures/bootstrap_1.jpg" style="width:60.0%" alt="" />
<p class="caption">Boostrap</p>
</div>
<div class="figure">
<img src="figures/bootstrap_2.png" style="width:60.0%" alt="" />
<p class="caption">Boostrap</p>
</div>
<p>De manera que el procedimiento <em>bootstrap</em> aplicado a regresión sería:</p>
<ul>
<li>Sacar una muestra aleatoria con remplazamiento de tamaño <span class="math inline">\(n\)</span> de nuestros datos (tenemos <span class="math inline">\(n\)</span> observaciones)</li>
<li>Guardar las muestras que no han sido seleccionadas (datos de prueba)</li>
<li>Entrena el modelo con la muestra <em>bootstrap</em></li>
<li>Testa el modelo con los datos de prueba y guarda el error de predicción promedio.</li>
<li>Repite el proceso <span class="math inline">\(B\)</span> veces</li>
<li>Calcula el promedio de los <span class="math inline">\(B\)</span> errores que han sido guardados. Este valor es el error <em>bootstrap</em> y nos sirve para evaluar el comportamiento de nuestro modelo.</li>
</ul>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-bootstrap):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento <em>boostrap</em> y estima el valor de este método para el modelo completo (<code>full_model</code>) y el modelo seleccionado (<code>select_model</code>) del ejemplo anterior. Haz que la función tenga un parámetro que dependa de <span class="math inline">\(B\)</span>, y da los resultados para B=25, B=50 y B=100. Comenta brevemente los resultados</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="imputación-de-datos-faltantes" class="section level2 hasAnchor" number="5.6">
<h2 class="hasAnchor"><span class="header-section-number">5.6</span> Imputación de datos faltantes<a href="#imputación-de-datos-faltantes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La mayoría de métodos para aprendizaje automático requiren casos completos. Sin embargo, los datos reales a menudo tienen observaciones faltantes. La función <code>lm ()</code>, analiza casos completos sin indicar nada al usuario, pero … ¿Deberíamos eliminar estas filas o imputar las observaciones que faltan? Casi siempre es mejor imputar, aunque, en la práctica puede que no valga la pena imputar algunas observaciones faltantes, ya que eliminarlas no suele cambiar el ajuste en absoluto. La imputación de datos faltantes es un tema extenso y complicado; aquí haremos una breve introducción y discutiremos los principales temas a tener en cuenta.</p>
<p>Tipos de valores perdidos:</p>
<ul>
<li><p><em>Falta completamente al azar (MCAR por sus siglas en inglés)</em>: la probabilidad de que falte una observación es la misma para todos los casos. Eliminar los casos que faltan en esta instancia no causará sesgos, aunque es posible que perdamos información.</p></li>
<li><p><em>Missing at random (MAR pos sus siglas en inglés)</em>: la probabilidad de que falte una observación depende de un mecanismo conocido. Por ejemplo, es menos probable que algunos grupos respondan encuestas. Si conocemos la pertenencia a un grupo, podemos eliminar las observaciones faltantes siempre que incluyamos el grupo como factor en una regresión. Sin embargo, generalmente podemos hacer algo mejor que simplemente eliminar estos casos.</p></li>
<li><p><em>Missing not at random (MNAR por sus siglas en inglés) </em>: la probabilidad de que falte una observación depende de algún mecanismo desconocido — una variable no observada. Tratar los problemas del MNAR es difícil o incluso imposible.</p></li>
</ul>
<p>Nos centraremos en los problemas MAR. Una solución simple es completar o <em>imputar</em> los valores MAR. Hay dos estrategias principales:</p>
<p><strong>Imputación simple</strong> reemplaza los valores perdidos según una estadística univariante o un modelo de regresión multivariable. Existen muchas librerías que implementan diferentes métodos (en este curso veremos algunas). En la imputación con medianas imputamos los datos faltantes usando la mediana de la variable que presenta datos faltantes (La mediana es mejor que la media cuando los datos de la columna están sesgados). Podemos imputar también usando KNN o <em>random forest</em> creando un modelo multivariante de las observaciones faltantes usando otras variables y usar ese modelo para predecir los valores faltantes.</p>
<p>El problema con la imputación simple, teóricamente, es que la variabilidad de la variable imputada es menor de lo que habría sido la variabilidad en la variable real, creando un sesgo hacia 0 en los coeficientes. Por tanto, mientras que la eliminación pierde información, la imputación única puede provocar sesgos. (Sin embargo, no me queda claro cuán grande es este problema en la práctica).</p>
<p>La <strong>imputación múltiple</strong> aborda estos problemas imputando los valores faltantes con un modelo multivariante, pero agregando la variabilidad de nuevo al volver a incluir la variación del error que normalmente veríamos en los datos. El término “múltiple” en la imputación múltiple se refiere a los múltiples conjuntos de datos creados en el proceso de estimación de los coeficientes de regresión. Los pasos son los siguientes:</p>
<ol style="list-style-type: decimal">
<li><p>Crear <span class="math inline">\(m\)</span> conjuntos de datos completos con valores perdidos imputados. Las imputaciones se realizan extrayendo aleatoriamente distribuciones de valores plausibles para cada vector de columna (variables).</p></li>
<li><p>Ajustar un modelo lineal en cada conjunto de datos imputados y almacene <span class="math inline">\(\hat \beta\)</span>s y SE.</p></li>
<li><p>Promediar los <span class="math inline">\(\hat \beta\)</span>s y combinar los SE para producir coeficientes basados en múltiples conjuntos de datos imputados. Específicamente,</p></li>
</ol>
<p><span class="math display">\[\hat \beta_ {j} = \frac {1} {m} \sum_ {i} \hat \beta_ {ij}\]</span>
y</p>
<p><span class="math display">\[s ^ 2_j = \frac {1} {m} \sum_{i} s^2_{ij} + var \hat \beta_ {ij} (1 + 1 / m),\]</span></p>
<p>donde <span class="math inline">\(\hat \beta_{ij}\)</span> y <span class="math inline">\(s_{ij}\)</span> son las estimaciones y los errores estándar del resultado imputado <span class="math inline">\(i^{th}\)</span> para <span class="math inline">\(i=1, ..., m\)</span> y para el parámetro <span class="math inline">\(j^{th}\)</span>.</p>
<p>La imputación múltiple funciona mejor para la descripción que para la predicción, y probablemente sea preferible a la imputación única si sólo queremos estimar coeficientes. Para la predicción (como es el caso del aprendizaje automático), normalmente bastará con utilizar imputación simple.</p>
<p>Demostraremos métodos de imputación utilizando los datos de Carseats del paquete ISLR. Este es un conjunto de datos simulado de ventas de asientos de coche, del cual eliminaremos aleatoriamente el 25% de las observaciones usando la función <code>prodNA ()</code> en el paquete <code>missForest</code> (teniendo cuidado de dejar la variable de resultado, Sales, intacta).</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(missForest)</span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Carseats, <span class="at">package=</span><span class="st">&quot;ISLR&quot;</span>)</span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(Carseats<span class="sc">$</span>ShelveLoc) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Bad&quot;</span>,<span class="st">&quot;Medium&quot;</span>,<span class="st">&quot;Good&quot;</span>) <span class="co"># Reordenamos los niveles de la variable</span></span>
<span id="cb290-4"><a href="#cb290-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-5"><a href="#cb290-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb290-6"><a href="#cb290-6" aria-hidden="true" tabindex="-1"></a>carseats_missx <span class="ot">&lt;-</span> <span class="fu">prodNA</span>(Carseats[,<span class="sc">-</span><span class="dv">1</span>], <span class="at">noNA=</span>.<span class="dv">25</span>)</span>
<span id="cb290-7"><a href="#cb290-7" aria-hidden="true" tabindex="-1"></a>carseats_miss <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">Sales=</span>Carseats[, <span class="dv">1</span>], carseats_missx)</span>
<span id="cb290-8"><a href="#cb290-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(carseats_miss)</span></code></pre></div>
<pre><code>Rows: 400
Columns: 11
$ Sales       &lt;dbl&gt; 9.50, 11.22, 10.06, 7.40, 4.15, 10.81, 6.63, 11.85, 6.54, 4.69, 9.01, 11.96, 3.98…
$ CompPrice   &lt;dbl&gt; 138, 111, 113, 117, 141, 124, 115, NA, NA, NA, 121, 117, NA, 115, 107, NA, 118, N…
$ Income      &lt;dbl&gt; 73, 48, 35, 100, 64, 113, NA, 81, 110, 113, 78, 94, NA, 28, 117, 95, 32, 74, 110,…
$ Advertising &lt;dbl&gt; 11, 16, NA, 4, 3, 13, NA, 15, 0, 0, 9, 4, 2, NA, 11, 5, NA, 13, 0, 16, 2, 12, 6, …
$ Population  &lt;dbl&gt; 276, 260, 269, NA, 340, 501, 45, 425, 108, 131, 150, 503, NA, 29, 148, 400, 284, …
$ Price       &lt;dbl&gt; 120, NA, NA, 97, 128, 72, 108, 120, NA, 124, 100, NA, NA, NA, 118, 144, 110, 131,…
$ ShelveLoc   &lt;fct&gt; Bad, NA, Good, NA, Bad, Bad, Good, NA, Good, Good, Bad, Medium, NA, Medium, Mediu…
$ Age         &lt;dbl&gt; 42, 65, NA, 55, 38, NA, 71, 67, 76, 76, 26, 50, NA, 53, 52, 76, 63, 52, 46, 69, N…
$ Education   &lt;dbl&gt; NA, 10, 12, NA, 13, 16, 15, 10, 10, 17, 10, 13, NA, NA, NA, 18, 13, 10, 17, 12, 1…
$ Urban       &lt;fct&gt; NA, Yes, Yes, Yes, Yes, NA, NA, Yes, No, NA, NA, Yes, Yes, Yes, Yes, No, Yes, Yes…
$ US          &lt;fct&gt; Yes, Yes, Yes, Yes, No, Yes, No, Yes, NA, Yes, Yes, Yes, No, Yes, Yes, No, No, NA…</code></pre>
<p>Observamos que hay datos faltantes. Podemos tener una estadística global de la falta de información que hay en nuestros tanto de forma numérica mediante la librería <code>skimr</code>:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(carseats_miss)</span></code></pre></div>
<table>
<caption>(#tab:unnamed-chunk-83)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">carseats_miss</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">400</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="10%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ShelveLoc</td>
<td align="right">93</td>
<td align="right">0.77</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">Goo: 164, Bad: 73, Med: 70</td>
</tr>
<tr class="even">
<td align="left">Urban</td>
<td align="right">101</td>
<td align="right">0.75</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 207, No: 92</td>
</tr>
<tr class="odd">
<td align="left">US</td>
<td align="right">104</td>
<td align="right">0.74</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 193, No: 103</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="15%" />
<col width="7%" />
<col width="7%" />
<col width="3%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sales</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">7.50</td>
<td align="right">2.82</td>
<td align="right">0</td>
<td align="right">5.39</td>
<td align="right">7.49</td>
<td align="right">9.32</td>
<td align="right">16.27</td>
<td align="left">▁▆▇▃▁</td>
</tr>
<tr class="even">
<td align="left">CompPrice</td>
<td align="right">94</td>
<td align="right">0.76</td>
<td align="right">123.88</td>
<td align="right">14.97</td>
<td align="right">77</td>
<td align="right">115.00</td>
<td align="right">123.00</td>
<td align="right">134.00</td>
<td align="right">161.00</td>
<td align="left">▁▃▇▆▂</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">100</td>
<td align="right">0.75</td>
<td align="right">68.63</td>
<td align="right">27.85</td>
<td align="right">21</td>
<td align="right">43.50</td>
<td align="right">68.50</td>
<td align="right">90.25</td>
<td align="right">120.00</td>
<td align="left">▆▆▇▆▅</td>
</tr>
<tr class="even">
<td align="left">Advertising</td>
<td align="right">94</td>
<td align="right">0.76</td>
<td align="right">6.70</td>
<td align="right">6.71</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">5.00</td>
<td align="right">12.00</td>
<td align="right">29.00</td>
<td align="left">▇▃▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">Population</td>
<td align="right">107</td>
<td align="right">0.73</td>
<td align="right">268.47</td>
<td align="right">147.29</td>
<td align="right">10</td>
<td align="right">144.00</td>
<td align="right">272.00</td>
<td align="right">402.00</td>
<td align="right">509.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Price</td>
<td align="right">96</td>
<td align="right">0.76</td>
<td align="right">115.34</td>
<td align="right">24.02</td>
<td align="right">24</td>
<td align="right">100.75</td>
<td align="right">117.00</td>
<td align="right">131.00</td>
<td align="right">191.00</td>
<td align="left">▁▂▇▅▁</td>
</tr>
<tr class="odd">
<td align="left">Age</td>
<td align="right">104</td>
<td align="right">0.74</td>
<td align="right">52.88</td>
<td align="right">16.04</td>
<td align="right">25</td>
<td align="right">39.00</td>
<td align="right">54.00</td>
<td align="right">65.00</td>
<td align="right">80.00</td>
<td align="left">▇▆▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Education</td>
<td align="right">107</td>
<td align="right">0.73</td>
<td align="right">13.82</td>
<td align="right">2.63</td>
<td align="right">10</td>
<td align="right">11.00</td>
<td align="right">14.00</td>
<td align="right">16.00</td>
<td align="right">18.00</td>
<td align="left">▇▇▃▆▇</td>
</tr>
</tbody>
</table>
<p>Comprobamos como la falta de información en las variables (excepto ‘Sales’) es de aproximadamente el 25% (columna <code>complete_rate</code> ~ 75%). Pero si tuviéramos que analizar datos de dos o más covariables, el porcentaje de datos completos disminuiría radicalmente.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Total de individuos</span></span>
<span id="cb293-2"><a href="#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(carseats_miss)</span></code></pre></div>
<pre><code>[1] 400</code></pre>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Total de individuos con casos completos</span></span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a>carseats_miss <span class="sc">%&gt;%</span> <span class="fu">complete.cases</span>() <span class="sc">%&gt;%</span> <span class="fu">sum</span>()</span></code></pre></div>
<pre><code>[1] 23</code></pre>
<p>Es decir, si tuviéramos que estimar un modelo con todas las variables de nuestra base de datos sólo dispondríamos de información efectiva para 23 individuos del total de 400.</p>
<p>La librería <code>VIM</code> nos puede ayudar a tener esta información de forma gráfica:</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VIM)</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a><span class="fu">aggr</span>(carseats_miss)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-85-1.png" width="672" /></p>
<p>Ahora faltan muchas observaciones. Cuando ajustamos un modelo de regresión para la variable Sales observamos que <code>lm ()</code> analiza casos completos y se estima un modelo basado en un subconjunto muy pequeño de datos.</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="fu">lm</span>(Sales <span class="sc">~</span> CompPrice <span class="sc">+</span> Income <span class="sc">+</span> Advertising <span class="sc">+</span> Population <span class="sc">+</span> Price, <span class="at">data =</span> carseats_miss))</span></code></pre></div>
<pre><code>lm(formula = Sales ~ CompPrice + Income + Advertising + Population + 
    Price, data = carseats_miss)
            coef.est coef.se
(Intercept)  6.24     1.99  
CompPrice    0.10     0.02  
Income       0.01     0.01  
Advertising  0.13     0.03  
Population   0.00     0.00  
Price       -0.11     0.01  
---
n = 93, k = 6
residual sd = 2.06, R-Squared = 0.59</code></pre>
<p>Sólo tenemos 93 observaciones de las 400 originales! Demostraremos la imputación múltiple usando la función <code>mice ()</code> de la librería <code>mice</code>.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Carseats)</span></code></pre></div>
<pre><code> [1] &quot;Sales&quot;       &quot;CompPrice&quot;   &quot;Income&quot;      &quot;Advertising&quot; &quot;Population&quot;  &quot;Price&quot;       &quot;ShelveLoc&quot;  
 [8] &quot;Age&quot;         &quot;Education&quot;   &quot;Urban&quot;       &quot;US&quot;         </code></pre>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a>carseats_imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(carseats_miss, <span class="at">printFlag =</span> F)</span></code></pre></div>
<p>El objeto <code>carseats_imp</code> incluye (entre muchas otras cosas) <span class="math inline">\(m\)</span> conjuntos de datos imputados (la configuración predeterminada es <span class="math inline">\(m\)</span> = 5). Los conjuntos de datos imputados difieren porque las imputaciones se extraen aleatoriamente de distribuciones de valores plausibles. Podemos visualizar la variabilidad de los predictores en estos conjuntos de datos imputados usando la función <code>densityplot ()</code>.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lattice)</span>
<span id="cb303-2"><a href="#cb303-2" aria-hidden="true" tabindex="-1"></a><span class="fu">densityplot</span>(carseats_imp)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-88-1.png" width="672" /></p>
<p>Las líneas azules continuas representan la distribución real de los predictores, mientras que las líneas rojas muestran las distribuciones imputadas. El siguiente paso es usar estos conjuntos de datos imputados para promediar los <span class="math inline">\(\beta\)</span>s y los SE utilizando la función <code>pool ()</code> de la librería <code>mice</code>.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>carseats_model_imp <span class="ot">&lt;-</span> <span class="fu">with</span>(<span class="at">data =</span> carseats_imp, </span>
<span id="cb304-2"><a href="#cb304-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">exp =</span> <span class="fu">lm</span>(Sales <span class="sc">~</span> CompPrice <span class="sc">+</span> Income <span class="sc">+</span> Advertising <span class="sc">+</span> Population <span class="sc">+</span> Price))</span>
<span id="cb304-3"><a href="#cb304-3" aria-hidden="true" tabindex="-1"></a>mi <span class="ot">&lt;-</span> <span class="fu">summary</span>(<span class="fu">pool</span>(carseats_model_imp))</span></code></pre></div>
<p>Estos coeficientes son similares a los del modelo anterior ajustado utilizando los datos no imputados, pero deberían estar más cerca de los valores de la población porque, en lugar de simplemente eliminar los casos incompletos, utiliza información de distribución para hacer suposiciones fundamentadas sobre los datos faltantes. La imputación múltiple funciona mejor para fines de descripción — estimar coeficientes para informar en un artículo académico, por ejemplo — pero usarla para predecir nuevos datos es incómodo o imposible, por las siguientes razones:</p>
<ul>
<li>Si los nuevos datos están completos, podemos utilizar las estimaciones de coeficientes derivadas de la imputación múltiple en una ecuación de regresión para la predicción. Pero esto es difícil ya que hay que hacerlo manualmente. Usamos los datos originales de Carseats como ilustración.</li>
</ul>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> mi[<span class="dv">1</span>, <span class="dv">2</span>] <span class="sc">+</span> </span>
<span id="cb305-2"><a href="#cb305-2" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">2</span>, <span class="dv">2</span>]<span class="sc">*</span>Carseats<span class="sc">$</span>CompPrice <span class="sc">+</span></span>
<span id="cb305-3"><a href="#cb305-3" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">3</span>, <span class="dv">2</span>]<span class="sc">*</span>Carseats<span class="sc">$</span>Income <span class="sc">+</span></span>
<span id="cb305-4"><a href="#cb305-4" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">4</span>, <span class="dv">2</span>]<span class="sc">*</span>Carseats<span class="sc">$</span>Advertising <span class="sc">+</span></span>
<span id="cb305-5"><a href="#cb305-5" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">5</span>, <span class="dv">2</span>]<span class="sc">*</span>Carseats<span class="sc">$</span>Population <span class="sc">+</span></span>
<span id="cb305-6"><a href="#cb305-6" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">6</span>, <span class="dv">2</span>]<span class="sc">*</span>Carseats<span class="sc">$</span>Price</span>
<span id="cb305-7"><a href="#cb305-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb305-8"><a href="#cb305-8" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb305-9"><a href="#cb305-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(preds)</span></code></pre></div>
<pre><code>[1]  9.044928 10.251755  9.775482  8.417813  7.358304 12.816057</code></pre>
<ul>
<li>Si los nuevos datos no están completos, entonces estos coeficientes imputados son inútiles para predecir en filas con observaciones faltantes. Esto, por ejemplo, es el resultado de intentar predecir utilizando los datos con observaciones faltantes.</li>
</ul>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> mi[<span class="dv">1</span>, <span class="dv">2</span>] <span class="sc">+</span> </span>
<span id="cb307-2"><a href="#cb307-2" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">2</span>, <span class="dv">2</span>]<span class="sc">*</span>carseats_miss<span class="sc">$</span>CompPrice <span class="sc">+</span></span>
<span id="cb307-3"><a href="#cb307-3" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">3</span>, <span class="dv">2</span>]<span class="sc">*</span>carseats_miss<span class="sc">$</span>Income <span class="sc">+</span></span>
<span id="cb307-4"><a href="#cb307-4" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">4</span>, <span class="dv">2</span>]<span class="sc">*</span>carseats_miss<span class="sc">$</span>Advertising <span class="sc">+</span></span>
<span id="cb307-5"><a href="#cb307-5" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">5</span>, <span class="dv">2</span>]<span class="sc">*</span>carseats_miss<span class="sc">$</span>Population <span class="sc">+</span></span>
<span id="cb307-6"><a href="#cb307-6" aria-hidden="true" tabindex="-1"></a>  mi[<span class="dv">6</span>, <span class="dv">2</span>]<span class="sc">*</span>carseats_miss<span class="sc">$</span>Price</span>
<span id="cb307-7"><a href="#cb307-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb307-8"><a href="#cb307-8" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb307-9"><a href="#cb307-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(preds)</span></code></pre></div>
<pre><code>[1]  9.044928        NA        NA        NA  7.358304 12.816057</code></pre>
<ul>
<li><p>La imputación múltiple, por lo tanto, no resuelve el principal problema al que nos enfrentamos a menudo con los datos faltantes, que es que, aunque hayamos ajustado con éxito un modelo en nuestros datos, el conjunto de validación también puede tener observaciones faltantes, y nuestras predicciones utilizando esos datos puede no poder realizarse.</p></li>
<li><p>Podríamos usar uno de los conjuntos de datos imputados, pero entonces ya no estamos haciendo imputación múltiple sino imputación simple. En ese momento, los métodos disponibles en el paquete <code>mice</code> ya no ofrecen ninguna ventaja especial sobre los de los paquetes <code>caret</code> y <code>missForest</code>. De hecho, podrían ser peores ya que la función <code>mice ()</code> no fue diseñado para producir la mejor imputación individual, sino más bien una gama de imputaciones plausibles.</p></li>
</ul>
<p>Usando <code>caret</code>, podemos hacer una imputación simple usando knnImpute, medianImpute o bagImpute. Estos métodos solo funcionan para variables numéricas, por lo que crearemos una función personalizada para convertir los factores — Shelveloc, Urban y US — en números enteros. (Al usar el conjunto de datos imputados para la regresión, podríamos dejar estas variables como números enteros, siempre que los valores enteros correspondan a los niveles de los factores).</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a>make_df_numeric <span class="ot">&lt;-</span> <span class="cf">function</span>(df){</span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="fu">sapply</span>(df, <span class="cf">function</span>(x) <span class="fu">as.numeric</span>(x)))</span>
<span id="cb309-3"><a href="#cb309-3" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb309-4"><a href="#cb309-4" aria-hidden="true" tabindex="-1"></a>carseats_miss_num <span class="ot">&lt;-</span> <span class="fu">make_df_numeric</span>(carseats_miss)</span>
<span id="cb309-5"><a href="#cb309-5" aria-hidden="true" tabindex="-1"></a>med_imp <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">preProcess</span>(carseats_miss_num, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;medianImpute&quot;</span>)), carseats_miss_num)</span>
<span id="cb309-6"><a href="#cb309-6" aria-hidden="true" tabindex="-1"></a>knn_imp <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">preProcess</span>(carseats_miss_num, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;knnImpute&quot;</span>)), carseats_miss_num)</span>
<span id="cb309-7"><a href="#cb309-7" aria-hidden="true" tabindex="-1"></a>bag_imp <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">preProcess</span>(carseats_miss_num, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;bagImpute&quot;</span>)), carseats_miss_num)</span></code></pre></div>
<p>El paquete <code>missForest</code> ofrece otra solución de imputación única, que es más simple que las funciones de <code>caret</code> porque maneja datos categóricos automáticamente. Si bien <code>missForest</code> funciona bien para conjuntos de datos pequeños y proporciona imputaciones de buena calidad, es muy lento en conjuntos de datos grandes. De hecho, lo mismo ocurrirá con la función <code>bagImpute ()</code> de <code>caret</code>. En tales casos, podría tener sentido usar la función <code>medianImpute ()</code> de <code>caret</code> en su lugar que es muy rápida.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>mf_imp <span class="ot">&lt;-</span> <span class="fu">missForest</span>(carseats_miss, <span class="at">verbose =</span> F)</span></code></pre></div>
<p>Comparemos los errores asociados con estos diferentes métodos de imputación. Podemos hacer esto porque, habiendo creado las observaciones faltantes en primer lugar, podemos comparar las observaciones imputadas con las observaciones verdaderas calculando la suma de los cuadrados de la diferencia. Para las imputaciones usando <code>mice ()</code> calculamos los errores para cada uno de los 5 conjuntos de datos imputados. Los resultados de <code>knnImpute ()</code> no son comparables porque la función automáticamente centra y escala las variables y los hemos omitido.</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Method =</span> <span class="fu">c</span>(<span class="st">&quot;mice 1&quot;</span>, </span>
<span id="cb311-2"><a href="#cb311-2" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;mice 2&quot;</span>, </span>
<span id="cb311-3"><a href="#cb311-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;mice 3&quot;</span>, </span>
<span id="cb311-4"><a href="#cb311-4" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;mice 4&quot;</span>, </span>
<span id="cb311-5"><a href="#cb311-5" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;mice 5&quot;</span>, </span>
<span id="cb311-6"><a href="#cb311-6" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;medianImpute&quot;</span>, </span>
<span id="cb311-7"><a href="#cb311-7" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;bagImpute&quot;</span>, </span>
<span id="cb311-8"><a href="#cb311-8" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;missForest&quot;</span>),</span>
<span id="cb311-9"><a href="#cb311-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">RSS =</span> <span class="fu">c</span>(<span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(<span class="fu">complete</span>(carseats_imp, <span class="dv">1</span>)), <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-10"><a href="#cb311-10" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(<span class="fu">complete</span>(carseats_imp, <span class="dv">2</span>)), <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-11"><a href="#cb311-11" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(<span class="fu">complete</span>(carseats_imp, <span class="dv">3</span>)), <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-12"><a href="#cb311-12" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(<span class="fu">complete</span>(carseats_imp, <span class="dv">4</span>)), <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-13"><a href="#cb311-13" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(<span class="fu">complete</span>(carseats_imp, <span class="dv">5</span>)), <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-14"><a href="#cb311-14" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(med_imp, <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-15"><a href="#cb311-15" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(bag_imp, <span class="fu">make_df_numeric</span>(Carseats)),</span>
<span id="cb311-16"><a href="#cb311-16" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rss</span>(<span class="fu">make_df_numeric</span>(mf_imp<span class="sc">$</span>ximp), <span class="fu">make_df_numeric</span>(Carseats))))</span>
<span id="cb311-17"><a href="#cb311-17" aria-hidden="true" tabindex="-1"></a>                         </span>
<span id="cb311-18"><a href="#cb311-18" aria-hidden="true" tabindex="-1"></a>comparison <span class="sc">%&gt;%</span></span>
<span id="cb311-19"><a href="#cb311-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">RSS =</span> <span class="fu">round</span>(RSS)) <span class="sc">%&gt;%</span></span>
<span id="cb311-20"><a href="#cb311-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(RSS)</span></code></pre></div>
<pre><code>        Method     RSS
1   missForest 2371284
2 medianImpute 2538059
3    bagImpute 2770171
4       mice 5 4226391
5       mice 4 4406142
6       mice 3 4494585
7       mice 2 4672300
8       mice 1 5180281</code></pre>
<p><code>missforest</code> obtiene los mejores resultados, aunque medianImpute compara muy bien. Los resultados de <code>mice</code> no son muy buenos, probablemente por las razones mencionadas anteriormente: está diseñado para una imputación múltiple, no simple.</p>
<!--chapter:end:04-creacion_modelos.Rmd-->
</div>
</div>
<div id="regresión-logística" class="section level1 hasAnchor" number="6">
<h1 class="hasAnchor"><span class="header-section-number">6</span> Regresión logística<a href="#regresión-logística" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Este capítulo introduce la regresión logística como el método más sencillo para crear modelos predictivos en problemas de clasificación que es el principal objetivo de la asignatura. Se cubrirán los siguientes temas:</p>
<ul>
<li>Conocer la función logística</li>
<li>Cómo interpretar los coeficientes de los modelos</li>
<li>Cómo evaluar la capacidad predictiva de un modelo</li>
<li>Cómo interpretar variables</li>
<li>Ilustrar un ejemplo de análisis completo</li>
<li>Aprender a hacer nomogramas fijos y dinámicos</li>
</ul>
<p>Hasta ahora, nuestra variable de resultado era continua. Pero si la variable de resultado es binaria (0/1, “No”/“Sí”), entonces nos enfrentamos a un problema de <em>clasificación</em>. El objetivo de la clasificación es crear un modelo capaz de <em>clasificar</em> el resultado — y, cuando se usa el modelo para la predicción, nuevas observaciones— en una de dos categorías. La regresión logística se introduce en el contexto de la epidemiología como un modelo de regresión que extiende el modelo lineal cuando nuestra variable respuesta es binaria, pero tambié es, probablemente, el método estadístico más utilizado para la clasificación y el más sencillo. Una de las grandes ventajas de estos modelos respecto a otros que veremo más adelante es que este método produce un <em>modelo de probabilidad</em> para nuestra variable resultado. En otras palabras, los valores ajustados en un modelo logístico o logit no son binarios sino que son <em>probabilidades</em> que representan la probabilidad de que el resultado pertenezca a una de nuestras dos categorías.</p>
<p>Desafortunadamente, debemos afrontar nuevas complicaciones cuando trabajamos con regresión logística, lo que hace que estos modelos sean inherentemente más difíciles de interpretar que los modelos lineales. Las complicaciones surgen del hecho de que con la regresión logística modelamos la probabilidad de que <span class="math inline">\(y\)</span> = 1, y la probabilidad siempre se escala entre 0 y 1. Pero el predictor lineal, <span class="math inline">\(X_i \beta\)</span>, oscila entre <span class="math inline">\(\pm \infty\)</span> (donde <span class="math inline">\(X\)</span> representa todos los predictores del modelo). Esta diferencia de escala requiere transformar la variable de resultado, lo cual se logra con la función logit:</p>
<p><span class="math display">\[
\text{logit}(x) = \text{log}\left( \frac{x}{1-x} \right)
\]</span></p>
<p>La función logit asigna el rango del resultado (0,1) al rango del predictor lineal <span class="math inline">\((-\infty, +\infty)\)</span>. El resultado transformado, <span class="math inline">\(\text{logit} (x)\)</span>, se expresa en logaritmos de probabilidades (<span class="math inline">\(\frac{x}{1-x}\)</span> se conoce como probabilidades del resultado - razón de odds en inglés - momios en castellano). Así que el modelo también se puede escribir como:</p>
<p><span class="math display">\[\text{Pr}(y_i = 1) = p_i\]</span></p>
<p><span class="math display">\[\text{logit}(p_i) =  X_i\beta\]</span></p>
<p>Las probabilidades logarítmicas (e.g. el log-odds) no tienen interpretación (que no sea el signo y la magnitud) y deben transformarse nuevamente en cantidades interpretables, ya sea en <em>probabilidades</em>, usando el logit inverso, o en <em>razones de probabilidades</em>, mediante el uso de la función exponencial. Discutimos ambas transformaciones a continuación.</p>
<div id="la-función-logit-inversa" class="section level2 hasAnchor" number="6.1">
<h2 class="hasAnchor"><span class="header-section-number">6.1</span> La función logit inversa<a href="#la-función-logit-inversa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El modelo logístico se puede escribir, alternativamente, usando el logit inverso:</p>
<p><span class="math display">\[
\operatorname{Pr}(y_i = 1 | X_i) = \operatorname{logit}^{-1}(X_i \beta)
\]</span></p>
<p>donde <span class="math inline">\(y_i\)</span> es la respuesta binaria, <span class="math inline">\(\operatorname{logit}^{- 1}\)</span> es la función logit inversa y <span class="math inline">\(X_i \beta\)</span> es el predictor lineal. Podemos interpretar esta formulación diciendo que la probabilidad de que <span class="math inline">\(y = 1\)</span> es igual al logit inverso del predictor lineal <span class="math inline">\((X_i, \ beta)\)</span>. Por lo tanto, podemos expresar los valores ajustados del modelo logístico y los coeficientes como probabilidades utilizando la transformación logit inversa. Pero, ¿qué es exactamente el logit inverso? Pues es:</p>
<p><span class="math display">\[\operatorname{logit}^{-1}(x) = \frac{e^{x}}{1 + e^{x}}\]</span></p>
<p>donde <span class="math inline">\(e\)</span> es la función exponencial.</p>
<p>Podemos tener una idea de cómo la función logit inversa transforma el predictor lineal mediante una gráfica. Aquí usamos un rango arbitrario de valores de x en (-6, 6) para demostrar la transformación.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>, .<span class="dv">01</span>)</span>
<span id="cb313-2"><a href="#cb313-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x))</span>
<span id="cb313-3"><a href="#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb313-4"><a href="#cb313-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb313-5"><a href="#cb313-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(logit<span class="sc">^-</span><span class="dv">1</span>,<span class="st">&quot;(x)&quot;</span>))) <span class="sc">+</span></span>
<span id="cb313-6"><a href="#cb313-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;y = &quot;</span>, logit<span class="sc">^-</span><span class="dv">1</span>,<span class="st">&quot;(x)&quot;</span>)))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-95-1.png" width="672" /></p>
<p>Los valores <span class="math inline">\(x\)</span>, que van de -6 a 6, son comprimidos por la función logit inversa en el rango 0-1. El logit inverso es curvo, por lo que la diferencia esperada en <span class="math inline">\(y\)</span> correspondiente a una diferencia fija en <span class="math inline">\(x\)</span> no es constante. A valores bajos y valores altos de <span class="math inline">\(x\)</span>, un cambio de unidad corresponde a un cambio muy pequeño en <span class="math inline">\(y\)</span>, mientras que en la mitad de la curva un pequeño cambio en <span class="math inline">\(x\)</span> corresponde a un cambio relativamente grande en <span class="math inline">\(y\)</span>. En la regresión lineal, la diferencia esperada en <span class="math inline">\(y\)</span> correspondiente a una diferencia fija en <span class="math inline">\(x\)</span> es, por el contrario, constante. <em>Por lo tanto, cuando interpretamos los resultados logísticos debemos elegir en qué parte de la curva queremos evaluar la probabilidad del resultado, dado el modelo.</em></p>
</div>
<div id="ejemplo-de-regresión-logística" class="section level2 hasAnchor" number="6.2">
<h2 class="hasAnchor"><span class="header-section-number">6.2</span> Ejemplo de regresión logística<a href="#ejemplo-de-regresión-logística" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ilustremos estos conceptos utilizando el conjunto de datos “Default” del ISLR. Este conjunto de datos simulado contiene una variable binaria que representa el incumplimiento en los pagos de la tarjeta de crédito (variable “default”), que modelaremos como una función de la variable “balance” (la cantidad de deuda que tiene la tarjeta) y la variable “income” (ingresos). Primero visualizaremos cómo es esta relación.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb314-2"><a href="#cb314-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Default)</span>
<span id="cb314-3"><a href="#cb314-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Default)</span></code></pre></div>
<pre><code>&#39;data.frame&#39;:   10000 obs. of  4 variables:
 $ default: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ student: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 1 2 1 2 1 1 ...
 $ balance: num  730 817 1074 529 786 ...
 $ income : num  44362 12106 31767 35704 38463 ...</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Default, <span class="fu">aes</span>(<span class="at">x =</span> balance, <span class="at">y =</span> income, <span class="at">col =</span> default)) <span class="sc">+</span></span>
<span id="cb316-2"><a href="#cb316-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb316-3"><a href="#cb316-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Balance vs. Income by Default&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-96-1.png" width="672" /></p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(</span>
<span id="cb317-2"><a href="#cb317-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Default, <span class="fu">aes</span>(default, balance)) <span class="sc">+</span> </span>
<span id="cb317-3"><a href="#cb317-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb317-4"><a href="#cb317-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Balance by Default&quot;</span>) <span class="sc">+</span> </span>
<span id="cb317-5"><a href="#cb317-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;balance&quot;</span>),</span>
<span id="cb317-6"><a href="#cb317-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Default, <span class="fu">aes</span>(default, income)) <span class="sc">+</span> </span>
<span id="cb317-7"><a href="#cb317-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb317-8"><a href="#cb317-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Income by Default&quot;</span>) <span class="sc">+</span> </span>
<span id="cb317-9"><a href="#cb317-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;income&quot;</span>),</span>
<span id="cb317-10"><a href="#cb317-10" aria-hidden="true" tabindex="-1"></a><span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-96-2.png" width="672" /></p>
<p>Claramente, los valores altos de saldo están asociados con el incumplimiento en todos los niveles de ingresos. Esto sugiere que los ingresos en realidad no son un fuerte predictor de incumplimiento, en comparación con el saldo, que es exactamente lo que vemos en los diagramas de cajas.</p>
<p>Exploremos estas relaciones usando la regresión logística. En R ajustamos un modelo logístico usando la función <code>glm ()</code> con <code>family = binomial</code>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> Centraremos y escalaremos las variables para facilitar la interpretación.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income, </span>
<span id="cb318-2"><a href="#cb318-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> Default, </span>
<span id="cb318-3"><a href="#cb318-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial) <span class="sc">%&gt;%</span></span>
<span id="cb318-4"><a href="#cb318-4" aria-hidden="true" tabindex="-1"></a>    standardize <span class="sc">%&gt;%</span></span>
<span id="cb318-5"><a href="#cb318-5" aria-hidden="true" tabindex="-1"></a>    display</span></code></pre></div>
<pre><code>glm(formula = default ~ z.balance + z.income, family = binomial, 
    data = Default)
            coef.est coef.se
(Intercept) -6.13     0.19  
z.balance    5.46     0.22  
z.income     0.56     0.13  
---
  n = 10000, k = 3
  residual deviance = 1579.0, null deviance = 2920.6 (difference = 1341.7)</code></pre>
<p>NOTA: Se puede apreciar la ventaja del uso de tidyverse (pipe) - no se necesita crear las variables estandarizadas, ni guardar el resultado para luego hacer un print</p>
<p>Interpretamos esta salida exactamente como lo haríamos para un modelo lineal con un predictor centrado y escalado:</p>
<ul>
<li><em>Intercept</em>: -6,13 representa las probabilidades logarítmicas (log odds) de incumplimiento cuando el saldo es promedio (835.37) y el ingreso es promedio (3.351698^{4} ). (Promedio porque las variables se han centrado).</li>
<li><em>z.balance</em>: 5.46 representa el cambio predicho en las probabilidades logarítmicas de incumplimiento asociado con un aumento de 1 unidad en el saldo (z.balance), manteniendo constante el ingreso (z.income). Un aumento de 1 unidad en el saldo (z.balance) es equivalente a un aumento de 2 desviaciones estándar en el saldo (balance) (967.43). Este coeficiente es estadísticamente significativo ya que 5.46 - 2 x .22 &gt; 0 (el IC del 95% que no contiene 0 indica significación estadística).</li>
<li><em>z.income</em>: .56 representa el cambio predicho en las probabilidades logarítmicas (log odds) de incumplimiento asociadas con un aumento de 1 unidad en el ingreso (z.income), manteniendo constante el balance (z.balance). Un aumento de 1 unidad en el ingreso (z.income) es equivalente a un aumento de 2 desviaciones estándar en el ingreso (income) (2.667328^{4}). Este coeficiente también es estadísticamente significativo ya que .56 - 2 x .13 &gt; 0.</li>
</ul>
<p>¿Qué significa que las probabilidades logarítmicas de incumplimiento aumenten en 5.46 o .56? En términos precisos, ¿quién sabe? Para que estas cantidades tengan una mejor interpretación, necesitamos transformarlas, ya sea en probabilidades (odds) o en razones de probabilidades (razón de odds -&gt; odds ratio). Sin embargo, debemos señalar que el signo y la magnitud de los coeficientes si son informativas: la relación con el incumplimiento del pago es positiva en ambos casos y, como ya se había visto de forma gráfica en los diagramas de cajas, el efecto del saldo (balance) es mucho mayor que el del ingreso (income).</p>
</div>
<div id="coeficientes-de-regresión-logística-como-probabilidades" class="section level2 hasAnchor" number="6.3">
<h2 class="hasAnchor"><span class="header-section-number">6.3</span> Coeficientes de regresión logística como probabilidades<a href="#coeficientes-de-regresión-logística-como-probabilidades" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Podemos dar una interpretación más específica de la regresión logística más allá del efecto y magnitud. Para ello, podemos usar la función logit inversa para convertir las probabilidades logarítmicas (log-odds) de incumplimiento de pago en las tarjetas (cuando el saldo y los ingresos son promedio) en una probabilidad:</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a>invlogit <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">exp</span>(x)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x))</span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">invlogit</span>(<span class="sc">-</span><span class="fl">6.13</span> <span class="sc">+</span> <span class="fl">5.46</span> <span class="sc">*</span> <span class="dv">0</span> <span class="sc">+</span> .<span class="dv">56</span> <span class="sc">*</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>[1] 0.002171854</code></pre>
<p>La probabilidad de incumplimiento para aquellos con un saldo promedio de tarjeta de crédito de (835.37) y un ingreso promedio de (3.351698^{4}) es de hecho bastante bajo: solo 0.002. Asimismo, podemos calcular el cambio en la probabilidad de incumplimiento en el pago asociado con un aumento de 1 unidad en el saldo, manteniendo el ingreso constante en el promedio (z.ingreso=0). Esto equivaldría a aumentar el saldo en casi 1000$, de 835.37 a 1802.8.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="fu">invlogit</span>(<span class="sc">-</span><span class="fl">6.13</span> <span class="sc">+</span> <span class="fl">5.46</span> <span class="sc">*</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="fu">invlogit</span>(<span class="sc">-</span><span class="fl">6.13</span> <span class="sc">+</span> <span class="fl">5.46</span> <span class="sc">*</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>[1] 0.336325</code></pre>
</div>
<div id="coeficientes-de-regresión-logística-como-razones-de-odds" class="section level2 hasAnchor" number="6.4">
<h2 class="hasAnchor"><span class="header-section-number">6.4</span> Coeficientes de regresión logística como razones de odds<a href="#coeficientes-de-regresión-logística-como-razones-de-odds" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>También podemos interpretar los coeficientes de regresión logística como <em>razones de odds</em> (OR).<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Si dos resultados tienen probabilidades <span class="math inline">\((p, 1-p)\)</span>, entonces <span class="math inline">\(\frac {p} {1-p}\)</span> se conoce como <em>odds</em> (probabilidades o momio) del resultado. Las <em>odds</em> son simplemente diferentes formas de representar la misma información: <span class="math inline">\(\text{odds} = \frac{p}{1-p}\)</span> y <span class="math inline">\(p = \frac{\text{odds}} {1+ \text{odds}}\)</span>. Por ejemplo, una <em>odds</em> de 1 es equivalente a una <em>odds</em> de .5 — es decir, resultados igualmente probables para <span class="math inline">\(p\)</span> y <span class="math inline">\(1-p\)</span>: <span class="math inline">\(\text{odds(p = .5)} = \frac{.5}{1-.5} = 1\)</span> y <span class="math inline">\(p(\text{oods} = 1) = \frac{\text{1}}{1 + 1} = .5.\)</span></p>
<p>La razón de dos odds es una OR:</p>
<p><span class="math display">\[
\frac{\frac{p_2}{1-p_2}}{\frac{p_1}{1-p_1}}
\]</span></p>
<p>Una razón de <em>odds</em> se puede interpretar como un cambio en la probabilidad. Por ejemplo, un cambio en la probabilidad de <span class="math inline">\(p_1 = .33\)</span> a <span class="math inline">\(p_2 = .5\)</span> da como resultado un OR de 2, de la siguiente manera:</p>
<p><span class="math display">\[
\frac{\frac{.5}{.5}}{\frac{.33}{.66}} = \frac{1}{.5} = 2
\]</span></p>
<p>También podemos interpretar el OR como el aumento porcentual de las probabilidades de un evento. Aquí, un OR de 2 equivale a aumentar las probabilidades en un 100%, de 0,5 a 1.</p>
<p>Recordemos que representamos el modelo logit de esta manera:</p>
<p><span class="math display">\[
\text{log} \left(\frac{p}{1-p}\right) = \alpha + \beta x
\]</span></p>
<p>La parte izquierda de la ecuación, expresado como logaritmos de probabilidades, está en la misma escala que la derecha derecho: <span class="math inline">\(\pm \infty\)</span>. Por lo tanto, no hay no linealidad en esta relación, y aumentar <span class="math inline">\(x\)</span> en 1 unidad tiene el mismo efecto que en la regresión lineal: cambia el resultado predicho en <span class="math inline">\(\beta\)</span>. Entonces, pasar de <span class="math inline">\(x\)</span> a <span class="math inline">\(x + 1\)</span> equivale a sumar <span class="math inline">\(\beta\)</span> a ambos lados de la ecuación anterior. Centrándonos solo en el lado izquierdo, tenemos, después de exponenciar, las probabilidades originales multiplicadas por <span class="math inline">\(e^\beta\)</span>:</p>
<p><span class="math display">\[
e^{\text{log} \left(\frac{p}{1-p}\right) + \beta} = \frac{p}{1-p} *e^ \beta
\]</span></p>
<p>(ya que <span class="math inline">\(e^{a+b} = e^a*e^b\)</span>).</p>
<p>Podemos pensar en <span class="math inline">\(e^\beta\)</span> como el cambio de la odds del resultado cuando <span class="math inline">\(x\)</span> cambia en 1 unidad, que se puede representar, utilizando la formulación anterior, como una OR:</p>
<p><span class="math display">\[
\frac{\frac{p_2}{1-p_2}}{\frac{p_1}{1-p_1}} = \frac{\frac{p_1}{1-p_1} * e^\beta
}{\frac{p_1}{1-p_1}} = e^\beta.
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(e^\beta\)</span> se puede interpretar como el cambio en las probabilidades asociadas con un aumento de 1 unidad en <span class="math inline">\(x\)</span>, expresado en términos porcentuales. En el caso de OR = <span class="math inline">\(\frac{1}{. 5} = 2\)</span>, el porcentaje de aumento en las probabilidades del resultado es del 100%. Cuando la OR es <span class="math inline">\(&gt;2\)</span> se suele expresar como x-veces más (OR=3.5, hay 3.5 veces más probabilidad de observar el evento que no observarlo cuando se cambia <span class="math inline">\(x\)</span> en 1 unidad), y cuando la OR es <span class="math inline">\(&lt;1\)</span> se suele hablar de protección a no tener el evento y el porcentaje se calcula como 1-OR.</p>
<p>Apliquemos esta información a nuestro modelo anterior de aplicando la exponencial a los coeficientes de saldo e ingresos:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">5.46</span>)</span></code></pre></div>
<pre><code>[1] 235.0974</code></pre>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(.<span class="dv">56</span>)</span></code></pre></div>
<pre><code>[1] 1.750673</code></pre>
<p>Podemos interpretar estos ORs como el porcentaje o cambio multiplicativo en las probabilidades asociadas con un aumento de 1 unidad en el predictor (mientras se mantienen constantes los demás), de 1 a 235 (un aumento de 23,400%) en el caso de balance, y de 1 a 1,75 (un aumento del 75%) para los ingresos. Por ejemplo, podemos decir que la probabilidad de incumplimiento es un 75% mayor cuando los ingresos aumentan en 1 unidad.</p>
<p>Cuando las variables predictoras son categóricas (como en biomedicina: sexo, estadío tumoral, fumar, beber, …) la interpretación se hace más sencilla porque el cambio de 1 unidad en estas variables, supone el cambio de una categoría respecto a la basal (ya que se usan <em>dummy variables</em>). Así, por ejemplo, si nuestro outcomes tener cáncer de pulmón o no, y nuestro predictor es ser fumanor o no, si nuestros análisis nos dan una OR de 6 asociado a ser fumador, la interpretación sería: “La odds (probabilidad, abusando de lenguaje - también riesgo si el outcome es poco frecuente) de sufrir cáncer de pulmón es 6 veces mayor en los fumadores que en los no fumadores.</p>
</div>
<div id="capacidad-predictiva-de-un-modelo-de-clasificación" class="section level2 hasAnchor" number="6.5">
<h2 class="hasAnchor"><span class="header-section-number">6.5</span> Capacidad predictiva de un modelo de clasificación<a href="#capacidad-predictiva-de-un-modelo-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Podemos evaluar el rendimiento (es decir, la capacidad predictiva) del modelo logístico utilizando el AIC, así como mediante el uso de otras medidas como: la desviación (<em>deviance</em>) residual, la precisión, la sensibilidad, la especificidad y el área bajo la curva (AUC).</p>
<p>Al igual que AIC, la <em>deviance</em> es una medida de error, por lo que una <em>deviance</em> más baja significa un mejor ajuste a los datos. Esperamos que la desviación disminuya en 1 para cada predictor, por lo que con un predictor informativo (e.g. variable imporante para el modleo), la <em>deviance</em> disminuirá en más de 1. Deviance = <span class="math inline">\(-2ln(L)\)</span>, donde <span class="math inline">\(ln\)</span> es el logaritmo natural y <span class="math inline">\(L\)</span> es la función de verosimilitud . Veámoslo con nuestro ejemplo:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a>logistic_model1 <span class="ot">&lt;-</span> </span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> balance, </span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> Default, </span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)</span>
<span id="cb328-5"><a href="#cb328-5" aria-hidden="true" tabindex="-1"></a>logistic_model1<span class="sc">$</span>deviance</span></code></pre></div>
<pre><code>[1] 1596.452</code></pre>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a>logistic_model2 <span class="ot">&lt;-</span> </span>
<span id="cb330-2"><a href="#cb330-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income, </span>
<span id="cb330-3"><a href="#cb330-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> Default, </span>
<span id="cb330-4"><a href="#cb330-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)</span>
<span id="cb330-5"><a href="#cb330-5" aria-hidden="true" tabindex="-1"></a>logistic_model2<span class="sc">$</span>deviance</span></code></pre></div>
<pre><code>[1] 1578.966</code></pre>
<p>En este caso, la <em>deviance</em> se redujo en más de 1, lo que indica que los ingresos mejoran el ajuste del modelo. Podemos hacer una prueba formal de la diferencia usando, como para los modelos lineales, la prueba de razón de verosimilitud:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(logistic_model1, logistic_model2)</span></code></pre></div>
<pre><code>
Model 1: default ~ balance
Model 2: default ~ balance + income

  L.R. Chisq         d.f.            P 
1.748541e+01 1.000000e+00 2.895205e-05 </code></pre>
<p>También podemos traducir las probabilidades de un modelo logístico para el incumplimiento del pago en predicciones de clase asignando “Sí” (predeterminado) a probabilidades mayores o iguales a .5 y “No” (sin valor predeterminado) a probabilidades menores que .5, y luego contar el número de veces que el modelo asigna la clase predeterminada correcta. Si dividimos este número por el total de observaciones, habremos calculado la “precisión”. La precisión se utiliza a menudo como medida del rendimiento del modelo.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="#cb334-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="fu">fitted</span>(logistic_model2) <span class="sc">&gt;=</span> .<span class="dv">5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>) </span>
<span id="cb334-2"><a href="#cb334-2" aria-hidden="true" tabindex="-1"></a>(<span class="fu">length</span>(<span class="fu">which</span>(preds <span class="sc">==</span> Default<span class="sc">$</span>default)) <span class="sc">/</span> <span class="fu">nrow</span>(Default))<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>[1] 97.37</code></pre>
<p>El modelo es 97.37% preciso. Valores superirores al 50% mostrarían una mejora en la predicción ya que por azar, se espera que el modelo tenga una precisión del 50%.</p>
<table>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega Moodle P2-Precisión)</td>
</tr>
<tr class="even">
<td align="left">Utiliza una simulación sencilla para demostrar que is asignamos por azar que una persona va a incumplir o no con los pagos, el valor esperado de la precisión de la variable “Default$default” es del 50%. NOTA: realiza 1000 simulaciones.</td>
</tr>
</tbody>
</table>
<p>Una forma sencilla de obtener un buen modelo de clasificación sería asignar a todos la categoría más frecuente. Por ejemplo, en nuestros datos, la clase mayoritaria es “No” para la variable incimpliminto por un amplio margen (9667 a 333). La mayoría de las personas no incumplen. ¿Cuál es nuestra precisión, entonces, si simplemente predecimos “No” para todos los casos? La proporción de “No” en los datos es 96.67%, por lo que si siempre predijimos “No” esa sería nuestra precisión (9667 / (9667 + 333) = .9667). El modelo logístico, sorprendentemente, ofrece solo una ligera mejora.</p>
<p>Sin embargo, al evaluar el rendimiento del clasificador, debemos reconocer que no todos los errores son iguales y que la precisión tiene limitaciones como métrica de rendimiento. En algunos casos, el modelo puede haber predicho el incumplimiento cuando no lo había. Esto se conoce como “falso positivo”. En otros casos, el modelo puede haber predicho que no hubo incumplimiento cuando hubo incumplimiento. Esto se conoce como “falso negativo”. En la clasificación, utilizamos lo que se conoce como matriz de confusión para resumir estos diferentes tipos de errores del modelo, denominados así porque la matriz resume cómo se confunde el modelo. Usaremos la función <code>confusionMatrix ()</code> de la librería <code>caret</code> para calcular rápidamente estos valores:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">as.factor</span>(preds), Default<span class="sc">$</span>default, <span class="at">positive =</span> <span class="st">&quot;Yes&quot;</span>)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   No  Yes
       No  9629  225
       Yes   38  108
                                          
               Accuracy : 0.9737          
                 95% CI : (0.9704, 0.9767)
    No Information Rate : 0.9667          
    P-Value [Acc &gt; NIR] : 3.067e-05       
                                          
                  Kappa : 0.4396          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.3243          
            Specificity : 0.9961          
         Pos Pred Value : 0.7397          
         Neg Pred Value : 0.9772          
             Prevalence : 0.0333          
         Detection Rate : 0.0108          
   Detection Prevalence : 0.0146          
      Balanced Accuracy : 0.6602          
                                          
       &#39;Positive&#39; Class : Yes             
                                          </code></pre>
<p>Esta función produce una gran cantidad de resultados. Podemos ver que informa la misma precisión que calculamos anteriormente: .97. La matriz de confusión 2 x 2 está en la parte superior. Podemos caracterizar estos 4 valores en la matriz de la siguiente manera:</p>
<ol style="list-style-type: decimal">
<li>9629 negativos verdaderos (TN): cuando el modelo predice correctamente “No”</li>
<li>108 verdaderos positivos (TP): cuando el modelo predice correctamente “Sí”</li>
<li>225 falsos negativos (FN): cuando el modelo predice incorrectamente “No”</li>
<li>38 falsos positivos (FP): cuando el modelo predice incorrectamente “Sí”</li>
</ol>
<p>La siguiente tabla resume estas posibilidades:</p>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">Reference</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Predicted</td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">No</td>
<td align="left">TN</td>
<td align="left">FN</td>
</tr>
<tr class="even">
<td align="left">Yes</td>
<td align="left">FP</td>
<td align="left">TP</td>
</tr>
</tbody>
</table>
<p>Hay dos medidas clave, además de la precisión, para caracterizar el rendimiento del modelo. Mientras que la precisión mide el error general, la sensibilidad y la especificidad miden errores específicos de clase.</p>
<ul>
<li><em>Precisión</em> = 1 - (FP + FN) / Total:</li>
</ul>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (<span class="dv">38</span> <span class="sc">+</span> <span class="dv">225</span>) <span class="sc">/</span> <span class="dv">10000</span></span></code></pre></div>
<pre><code>[1] 0.9737</code></pre>
<ul>
<li><em>Sensibilidad</em> (o la tasa de verdaderos positivos): TP / (TP + FN). En este caso, la sensibilidad mide la proporción de incumplimientos que se clasificaron correctamente como tales.</li>
</ul>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="dv">108</span> <span class="sc">/</span> (<span class="dv">108</span> <span class="sc">+</span> <span class="dv">225</span>) </span></code></pre></div>
<pre><code>[1] 0.3243243</code></pre>
<ul>
<li><em>Especificidad</em> (o la tasa de verdaderos negativos): TN / (TN + FP). En este caso, la especificidad mide la proporción de no incumplimientos que se clasificaron correctamente como tales.</li>
</ul>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="dv">9629</span> <span class="sc">/</span> (<span class="dv">9629</span> <span class="sc">+</span> <span class="dv">38</span>) </span></code></pre></div>
<pre><code>[1] 0.9960691</code></pre>
<p>¿Por qué deberíamos considerar estos errores específicos de clase? Todos los modelos tienen errores, pero no todos los errores del modelo son igualmente importantes. Por ejemplo, un falso negativo — prediciendo incorrectamente que un prestatario no incurrirá en incumplimiento — puede ser un error costoso para un banco, si el incumplimiento se hubiera podido prevenir mediante la intervención. Pero, por otro lado, un falso positivo, que predice incorrectamente que un prestatario incurrirá en incumplimiento, puede desencadenar una advertencia innecesaria que irrita a los clientes. Los errores que comete un modelo se pueden controlar ajustando el umbral de decisión utilizado para asignar probabilidades predichas a las clases. Usamos un umbral de probabilidad de .5 para clasificar los incumplimientos en los pagos. Si el umbral se establece en .1, por el contrario, la precisión general disminuiría, pero también lo haría el número de falsos negativos, lo que podría ser deseable. El modelo luego atraparía a más morosos, lo que ahorraría dinero al banco, pero eso tendría un costo: más falsos positivos (clientes potencialmente irritados).</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(<span class="fu">fitted</span>(logistic_model2) <span class="sc">&gt;=</span> .<span class="dv">1</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(preds, Default<span class="sc">$</span>default)<span class="sc">$</span>table</span></code></pre></div>
<pre><code>          Reference
Prediction   No  Yes
       No  9105   90
       Yes  562  243</code></pre>
<p>La pregunta de cómo establecer el umbral de decisión —. 5, .1 o algo más — debe responderse con referencia al contexto empresarial.</p>
<p>Una curva de característica operativa del receptor (ROC por sus siglas en ingles) visualiza las compensaciones entre los tipos de errores trazando la especificidad frente a la sensibilidad. El cálculo del área bajo la curva ROC (AUC) nos permite, además, resumir el rendimiento del modelo y comparar modelos. La curva en sí muestra los tipos de errores que cometería el modelo en diferentes umbrales de decisión. Para crear una curva ROC usamos la función <code>roc ()</code> del paquete pROC, y mostramos los valores de sensibilidad / especificidad asociados con los umbrales de decisión de .1 y .5:</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb346-2"><a href="#cb346-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotROC)</span>
<span id="cb346-3"><a href="#cb346-3" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">plot</span>(<span class="fu">roc</span>(<span class="fu">factor</span>(<span class="fu">ifelse</span>(Default<span class="sc">$</span>default <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)), </span>
<span id="cb346-4"><a href="#cb346-4" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">fitted</span>(logistic_model2)), <span class="at">print.thres =</span> <span class="fu">c</span>(.<span class="dv">1</span>, .<span class="dv">5</span>), </span>
<span id="cb346-5"><a href="#cb346-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">print.auc =</span> T))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-110-1.png" width="672" /></p>
<p>Un modelo con una precisión del 50%, es decir, un clasificador aleatorio, tendría una curva ROC que siguiera la línea de referencia diagonal. Un modelo con una precisión del 100%, un clasificador perfecto, tendría una curva ROC siguiendo los márgenes del triángulo superior. Cada punto de la curva ROC representa un par de sensibilidad / especificidad correspondiente a un umbral de decisión particular. Cuando establecimos el umbral de decisión en .1, la sensibilidad fue .73 (243 / (243 + 90)) y la especificidad fue .94 (9105 / (9105 + 562)). Ese punto se muestra en la curva. Del mismo modo, cuando establecimos el umbral de decisión en .5, la sensibilidad fue .32 y la especificidad fue .996. Ese punto también está en la curva. ¿Qué umbral de decisión es óptimo? Nuevamente, depende del problema (pensad en cáncer o en este ejemplo de dinero). Las curvas ROC nos permiten elegir los errores específicos de clase que podemos cometer.</p>
<p>El AUC es el resumen de cómo funciona el modelo en cada umbral de decisión. En general, los modelos con AUC más altos son mejores. Esta medida nos servirá para comparar métodos de aprendizaje automático que iremos aprendiendo durante el curso.</p>
</div>
<div id="ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes" class="section level2 hasAnchor" number="6.6">
<h2 class="hasAnchor"><span class="header-section-number">6.6</span> Ejemplo de regresión logística: modelización de riesgo diabetes<a href="#ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para este ejemplo usaremos el conjunto de datos Pima, incluido en la librería <code>MASS</code> que contienen esta información:</p>
<blockquote>
<p>Una población de mujeres que tenían al menos 21 años, de ascendencia indígena Pima y que vivían cerca de Phoenix, Arizona, se sometieron a pruebas de diabetes de acuerdo con los criterios de la Organización Mundial de la Salud. Los datos fueron recopilados por el Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales de EE. UU. Usaremos información para 532 mujeres con datos completos después de eliminar los datos (principalmente faltantes) sobre la insulina sérica.</p>
</blockquote>
<p>El conjunto de datos incluye las siguientes variables:</p>
<ol style="list-style-type: decimal">
<li>npreg: número de embarazos</li>
<li>glu: concentración de glucosa en plasma a 2 horas en una prueba de tolerancia oral a la glucosa</li>
<li>bp: presión arterial diastólica (mm Hg)</li>
<li>piel: grosor del pliegue cutáneo del tríceps (mm)</li>
<li>bmi: índice de masa corporal (peso en kg / (altura en m) ^ 2)</li>
<li>ped: función del pedigrí de la diabetes</li>
<li>age: Edad (años)</li>
<li>type: Sí o No (diabetes)</li>
</ol>
<p>La variable resultado es “type”, que indica si una persona tiene diabetes. Los datos están divididos en un conjunto de entrenamiento y otro test que combinaremos para ilustrar este ejemplo.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb347-2"><a href="#cb347-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Pima.tr&quot;</span>)</span>
<span id="cb347-3"><a href="#cb347-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Pima.te&quot;</span>)</span>
<span id="cb347-4"><a href="#cb347-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">rbind</span>(Pima.te, Pima.tr)</span>
<span id="cb347-5"><a href="#cb347-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span></code></pre></div>
<pre><code>&#39;data.frame&#39;:   532 obs. of  8 variables:
 $ npreg: int  6 1 1 3 2 5 0 1 3 9 ...
 $ glu  : int  148 85 89 78 197 166 118 103 126 119 ...
 $ bp   : int  72 66 66 50 70 72 84 30 88 80 ...
 $ skin : int  35 29 23 32 45 19 47 38 41 35 ...
 $ bmi  : num  33.6 26.6 28.1 31 30.5 25.8 45.8 43.3 39.3 29 ...
 $ ped  : num  0.627 0.351 0.167 0.248 0.158 0.587 0.551 0.183 0.704 0.263 ...
 $ age  : int  50 31 21 26 53 51 31 33 27 29 ...
 $ type : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 1 1 2 2 2 2 1 1 2 ...</code></pre>
<p>Todos los predictores son enteros o numéricos. Nuestro objetivo es construir un modelo logístico de diabetes para ilustrar cómo interpretar los coeficientes del modelo.</p>
<div id="modelo-simple" class="section level3 hasAnchor" number="6.6.1">
<h3 class="hasAnchor"><span class="header-section-number">6.6.1</span> Modelo simple<a href="#modelo-simple" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Comencemos con un modelo simple.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a>bin_model1 <span class="ot">&lt;-</span> </span>
<span id="cb349-2"><a href="#cb349-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(type <span class="sc">~</span> bmi <span class="sc">+</span> age, </span>
<span id="cb349-3"><a href="#cb349-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> d, </span>
<span id="cb349-4"><a href="#cb349-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)</span>
<span id="cb349-5"><a href="#cb349-5" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(bin_model1)</span></code></pre></div>
<pre><code>glm(formula = type ~ bmi + age, family = binomial, data = d)
            coef.est coef.se
(Intercept) -6.26     0.67  
bmi          0.10     0.02  
age          0.06     0.01  
---
  n = 532, k = 3
  residual deviance = 577.2, null deviance = 676.8 (difference = 99.6)</code></pre>
<ul>
<li><em>Intercept</em>: -6.26 es el logaritmo de la probabilidad de tener diabetes cuando bmi = 0 y edad = 0. Dado que ni la edad ni el bmi pueden ser iguales a 0, el intercept no es interpretable en este modelo. Por tanto, tendría sentido centrar las variables para facilitar la interpretación.</li>
<li><em>bmi</em>: .1 es el cambio previsto en el <em>log-odds</em> de diabetes asociado con un aumento de 1 unidad en el bmi, manteniendo la edad constante. Este coeficiente es estadísticamente significativo ya que .1 - 2 x .02 &gt; 0. (Un IC del 95% que no contiene 0 indica significancia estadística) y también porque su p-valor asociacio mediante el test de score es <span class="math inline">\(&lt;0.05\)</span> (usar la función <code>summary ()</code> . Podemos traducir este coeficiente en un OR mediante la exponencial: <span class="math inline">\(e^.1\)</span> = 1.11. Un aumento de 1 unidad en el IMC, manteniendo la edad constante, se asocia con un aumento del 11% en la <em>odds</em> (o, más coloquialmente, la probabilidad) de diabetes.</li>
<li><em>edad</em>: .06 es el cambio predicho en el <em>log-oods</em> de diabetes asociado con un aumento de 1 unidad en la edad, manteniendo constante el bmi. Este coeficiente también es estadísticamente significativo ya que .06 - 2 x .01&gt; 0. El OR para la edad es <span class="math inline">\(e^.06\)</span> = 1.06 lo que indica un aumento del 6% en la probabilidad de sufrir diabetes asociada con un aumento de 1 unidad en la edad.</li>
</ul>
</div>
<div id="agregar-predictores-y-evaluar-el-ajuste" class="section level3 hasAnchor" number="6.6.2">
<h3 class="hasAnchor"><span class="header-section-number">6.6.2</span> Agregar predictores y evaluar el ajuste<a href="#agregar-predictores-y-evaluar-el-ajuste" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora ajustaremos un modelo completo (excluyendo “skin”, ya que parece medir casi lo mismo que bmi). ¿Mejora el ajuste?</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a>bin_model2 <span class="ot">&lt;-</span> </span>
<span id="cb351-2"><a href="#cb351-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(type <span class="sc">~</span> bmi <span class="sc">+</span> age <span class="sc">+</span> ped <span class="sc">+</span> glu <span class="sc">+</span> npreg <span class="sc">+</span> bp , </span>
<span id="cb351-3"><a href="#cb351-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> d, </span>
<span id="cb351-4"><a href="#cb351-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial) </span>
<span id="cb351-5"><a href="#cb351-5" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(bin_model2)</span></code></pre></div>
<pre><code>glm(formula = type ~ bmi + age + ped + glu + npreg + bp, family = binomial, 
    data = d)
            coef.est coef.se
(Intercept) -9.59     0.99  
bmi          0.09     0.02  
age          0.03     0.01  
ped          1.31     0.36  
glu          0.04     0.00  
npreg        0.12     0.04  
bp          -0.01     0.01  
---
  n = 532, k = 7
  residual deviance = 466.5, null deviance = 676.8 (difference = 210.3)</code></pre>
<p>La <em>deviance</em> disminuye de 577 en el modelo anterior a 466.5 en este modelo, muy por encima de los 4 puntos que debería bajar simplemente al incluir 4 predictores adicionales. Además, el LRT nos indica que estas diferencias son estadísticamente significativas:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(bin_model1, bin_model2)</span></code></pre></div>
<pre><code>
Model 1: type ~ bmi + age
Model 2: type ~ bmi + age + ped + glu + npreg + bp

L.R. Chisq       d.f.          P 
  110.6664     4.0000     0.0000 </code></pre>
<p>El segundo modelo es mucho mejor que el primero, lo que también es evidente cuando observamos las matrices de confusión (con el umbral de decisión establecido en .5)</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(<span class="fu">fitted</span>(bin_model1) <span class="sc">&gt;</span> .<span class="dv">5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb355-2"><a href="#cb355-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(preds, d<span class="sc">$</span>type)<span class="sc">$</span>table</span></code></pre></div>
<pre><code>          Reference
Prediction  No Yes
       No  312 112
       Yes  43  65</code></pre>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="#cb357-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(<span class="fu">fitted</span>(bin_model2) <span class="sc">&gt;</span> .<span class="dv">5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb357-2"><a href="#cb357-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(preds, d<span class="sc">$</span>type)<span class="sc">$</span>table</span></code></pre></div>
<pre><code>          Reference
Prediction  No Yes
       No  318  73
       Yes  37 104</code></pre>
<p>Como era de esperar, el modelo completo comete menos errores. Podemos formalizar esta impresión calculando y comparando la precisión del modelo: 1 - (112 + 43) / (112 + 43 + 312 + 65) = 0.71 para el primer modelo, en comparación con 1 - (73 + 37) / (73 + 37 + 318 + 104) =<code>r round (1 - (73 + 37) / (73 + 37 + 318 + 104 ), 2)</code> para el segundo modelo más grande. Los números de verdaderos negativos son cercanos, pero el modelo más grande aumenta sustancialmente el número de verdaderos positivos y reduce el número de falsos negativos, prediciendo incorrectamente que una persona no tiene diabetes (aunque esta sigue siendo la clase de error más grande). Deberíamos comprobar para ver que estos modelos mejoran la precisión sobre un modelo que siempre predice la clase mayoritaria. En este conjunto de datos, “No” es la categoría mayoritaria con 66,7%. Entonces, si siempre predijimos “No”, estaríamos en lo correcto el 66.7% de las veces, que es una precisión menor que cualquiera de los modelos. Las curvas ROC proporcionan una descripción más sistemática del rendimiento del modelo en términos de errores de clasificación errónea.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="#cb359-1" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">plot</span>(<span class="fu">roc</span>(d<span class="sc">$</span>type,</span>
<span id="cb359-2"><a href="#cb359-2" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">fitted</span>(bin_model1)),</span>
<span id="cb359-3"><a href="#cb359-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, </span>
<span id="cb359-4"><a href="#cb359-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">main =</span> <span class="st">&quot;ROC curves: logistic model 1 (red) vs. logistic model 2 (blue)&quot;</span>))</span>
<span id="cb359-5"><a href="#cb359-5" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">plot</span>(<span class="fu">roc</span>(d<span class="sc">$</span>type,</span>
<span id="cb359-6"><a href="#cb359-6" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">fitted</span>(bin_model2)),</span>
<span id="cb359-7"><a href="#cb359-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">print.auc =</span> T, </span>
<span id="cb359-8"><a href="#cb359-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, </span>
<span id="cb359-9"><a href="#cb359-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">add =</span> T))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-117-1.png" width="672" /></p>
<p>El modelo más grande es claramente mejor: el AUC es más alto.</p>
</div>
<div id="análisis-de-interacciones" class="section level3 hasAnchor" number="6.6.3">
<h3 class="hasAnchor"><span class="header-section-number">6.6.3</span> Análisis de interacciones<a href="#análisis-de-interacciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Agreguemos una interacción entre dos predictores continuos, ped y glu. Centraremos y escalaremos las entradas para que el coeficiente de la interacción sea interpretable.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a>bin_model3 <span class="ot">&lt;-</span> </span>
<span id="cb360-2"><a href="#cb360-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">standardize</span>(<span class="fu">glm</span>(type <span class="sc">~</span> bmi  <span class="sc">+</span> ped <span class="sc">*</span> glu <span class="sc">+</span>  age <span class="sc">+</span> npreg <span class="sc">+</span> bp , </span>
<span id="cb360-3"><a href="#cb360-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> d, </span>
<span id="cb360-4"><a href="#cb360-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> binomial)) </span>
<span id="cb360-5"><a href="#cb360-5" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(bin_model3)</span></code></pre></div>
<pre><code>glm(formula = type ~ z.bmi + z.ped * z.glu + z.age + z.npreg + 
    z.bp, family = binomial, data = d)
            coef.est coef.se
(Intercept) -1.02     0.13  
z.bmi        1.29     0.26  
z.ped        1.02     0.24  
z.glu        2.31     0.27  
z.age        0.53     0.30  
z.npreg      0.87     0.29  
z.bp        -0.19     0.26  
z.ped:z.glu -1.15     0.41  
---
  n = 532, k = 8
  residual deviance = 460.0, null deviance = 676.8 (difference = 216.7)</code></pre>
<p>La interacción mejora el modelo pero no cambia la imagen general del ajuste del modelo en el gráfico de residuos agrupados (no incluido).</p>
<ul>
<li><em>Intercept </em>: -1.02 es el <em>log-odds</em> de diabetes cuando todos los predictores son promedio (ya que hemos centrado y escalado las entradas). La probabilidad de tener diabetes para la mujer promedio en este conjunto de datos es logit<span class="math inline">\(^{- 1}\)</span> (- 1.02) = 0.27.</li>
<li><em>z.bmi</em>: 1.29 es el <em>log-odds</em> de diabetes asociado con un aumento de 1 unidad en z.bmi, manteniendo constantes los demás predictores. <span class="math inline">\(e^{1.29}\)</span> = 3.63 por lo que un aumento de 1 unidad en z.bmi, manteniendo constantes los otros predictores, se asocia con un aumento del 263% en la probabilidad de sufrir diabetes.</li>
<li><em>z.ped</em>: 1.02 es el <em>log-odds</em> de diabetes asociado con un aumento de 1 unidad en z.ped, cuando z.glu = 0 y manteniendo constantes los otros predictores. <span class="math inline">\(e^{1.02}\)</span> = 2.77 por lo que un aumento de 1 unidad en z.ped, cuando z.glu = 0 y manteniendo los otros predictores constantes, se asocia con un aumento del 177% en la probabilidad de sufrir diabetes.</li>
<li><em>z.glu</em>: 2.31 es el <em>log-odds</em> de diabetes asociado con un aumento de 1 unidad en z.glu, cuando z.ped = 0 y manteniendo constantes los demás predictores. <span class="math inline">\(e^{2.31}\)</span> = 10.07 por lo que un aumento de 1 unidad en z.glu, cuando z.ped = 0 y manteniendo los otros predictores constantes, se asocia con un aumento del 907% en la probabilidad de sufrir diabetes.</li>
<li>…. el resto de predictores igual</li>
<li></li>
<li><em>z.ped:z.glu </em>: se añade -1.15 al <em>log-odds</em> de diabetes de z.ped cuando z.glu aumenta en 1 unidad, manteniendo constantes los otros predictores. O, alternativamente, se añade -1.15 al <em>log-odds</em> de diabetes de z.glu por cada unidad adicional de z.ped. Calculamos el OR, como en los otros casos, exponenciando: <span class="math inline">\(e^ {- 1.15}\)</span> = 0.32. El OR para z.ped disminuye en un 68% (1 - .32 = .68) cuando z.glu aumenta en 1 unidad, manteniendo constantes los demás predictores. O, alternativamente, el OR para z.glu disminuye en un 68% con cada unidad adicional de z.ped.</li>
</ul>
</div>
<div id="gráfico-de-la-interacción" class="section level3 hasAnchor" number="6.6.4">
<h3 class="hasAnchor"><span class="header-section-number">6.6.4</span> Gráfico de la interacción<a href="#gráfico-de-la-interacción" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como siempre, debemos visualizar la interacción para comprenderla. Esto es especialmente necesario cuando las relaciones se expresan en términos de probabilidades logarítmicas y razones de probabilidades. Como hemos hecho anteriormente para fines de visualización, dicotomizaremos los predictores en la interacción y, en este caso, para facilitar la interpretación, presentaremos las relaciones en términos de probabilidades. El propósito de los gráficos es la comprensión y la ilustración, por lo que no nos preocupa demasiado la precisión estadística. Resumiremos las relaciones usando una curva loess (estimación no paramétrica de la regresión) para capturar la no linealidad del efecto del predictor (<span class="math inline">\(\pm \infty\)</span>) al rango del resultado binario (0, 1).</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>ped_bin <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(d<span class="sc">$</span>ped <span class="sc">&gt;</span> <span class="fu">mean</span>(d<span class="sc">$</span>ped), <span class="st">&quot;above avg&quot;</span>,<span class="st">&quot;below avg&quot;</span>)</span>
<span id="cb362-2"><a href="#cb362-2" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>glu_bin <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(d<span class="sc">$</span>glu <span class="sc">&gt;</span> <span class="fu">mean</span>(d<span class="sc">$</span>glu), <span class="st">&quot;above avg&quot;</span>,<span class="st">&quot;below avg&quot;</span>)</span>
<span id="cb362-3"><a href="#cb362-3" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>prob <span class="ot">&lt;-</span> <span class="fu">fitted</span>(bin_model3)</span>
<span id="cb362-4"><a href="#cb362-4" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>type_num <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(d<span class="sc">$</span>type <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb362-5"><a href="#cb362-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(glu, type_num)) <span class="sc">+</span></span>
<span id="cb362-6"><a href="#cb362-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb362-7"><a href="#cb362-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="fu">aes</span>(glu, prob, <span class="at">col =</span> ped_bin), <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb362-8"><a href="#cb362-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Pr(diabetes)&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Diabetes ~ glu varying by ped_bin&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-119-1.png" width="672" /></p>
<p>La relación entre glu y diabetes depende claramente de los niveles de ped. Como en el caso lineal, las líneas no paralelas indican una interacción. El coeficiente de <em>log-odds</em> negativo para la interacción del modelo indica que a medida que ped aumenta, la fuerza de la relación entre glu y type (diabetes) disminuye. Esto es exactamente lo que vemos en este gráfico:</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(ped, type_num)) <span class="sc">+</span></span>
<span id="cb363-2"><a href="#cb363-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb363-3"><a href="#cb363-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="fu">aes</span>(ped, prob, <span class="at">col =</span> glu_bin), <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb363-4"><a href="#cb363-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Pr(diabetes)&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Diabetes ~ ped varying by glu_bin&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-120-1.png" width="672" /></p>
<p>La interacción es más difícil de ver aquí porque la escala de ped está comprimida, con la mayoría de las observaciones cercanas a 0. Sin embargo, podemos ver que a medida que glu aumenta, la fuerza de la relación entre ped y diabetes disminuye. Nuevamente, las líneas no paralelas indican la presencia de una interacción.</p>
</div>
<div id="uso-del-modelo-para-predecir-probabilidades" class="section level3 hasAnchor" number="6.6.5">
<h3 class="hasAnchor"><span class="header-section-number">6.6.5</span> Uso del modelo para predecir probabilidades<a href="#uso-del-modelo-para-predecir-probabilidades" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El tamaño del efecto más grande en el modelo anterior con la interacción, con mucho, es z.glu. Por tanto, para comunicar los resultados de este modelo deberíamos concentrarnos en glu. Pero los coeficientes expresados como logaritmos de probabilidades son algo confusos y, lamentablemente, las razones de probabilidades no ayudan a aclarar mucho las cosas. Deberíamos ir al trabajo adicional de traducir los coeficientes del modelo en probabilidades, pero para hacerlo debemos identificar en qué parte de la curva de probabilidad nos gustaría evaluar glu. Escogeremos la región cercana al promedio de z.glu — 0 — y examinaremos el efecto de aumentar z.glu en 1 unidad (que es igual a 2 desviaciones estándar de glu) cuando los otros predictores son promedio. La forma más sencilla de hacer esto es crear una base de datos con los valores de predicción deseados para usar con la función <code>predict ()</code>.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="#cb364-1" aria-hidden="true" tabindex="-1"></a>basal <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">z.bmi =</span> <span class="dv">0</span>, <span class="at">z.ped =</span> <span class="dv">0</span>, <span class="at">z.glu =</span> <span class="dv">0</span>, <span class="at">z.age =</span> <span class="dv">0</span>, <span class="at">z.npreg =</span> <span class="dv">0</span>, <span class="at">z.bp =</span> <span class="dv">0</span>)</span>
<span id="cb364-2"><a href="#cb364-2" aria-hidden="true" tabindex="-1"></a>glucosa <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">z.bmi =</span> <span class="dv">0</span>, <span class="at">z.ped =</span> <span class="dv">0</span>, <span class="at">z.glu =</span> <span class="dv">1</span>, <span class="at">z.age =</span> <span class="dv">0</span>, <span class="at">z.npreg =</span> <span class="dv">0</span>, <span class="at">z.bp =</span> <span class="dv">0</span>)</span>
<span id="cb364-3"><a href="#cb364-3" aria-hidden="true" tabindex="-1"></a>(lo <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">invlogit</span>(<span class="fu">predict</span>(bin_model3, <span class="at">newdata =</span> basal))))</span></code></pre></div>
<pre><code>[1] 0.2652028</code></pre>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a>(hi <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">invlogit</span>(<span class="fu">predict</span>(bin_model3, <span class="at">newdata =</span> ))))</span></code></pre></div>
<pre><code>  [1] 0.716146591 0.025911688 0.017983270 0.029013744 0.893018807 0.665405710 0.395033985 0.211066662
  [9] 0.431695033 0.225375587 0.032840692 0.443676401 0.022607120 0.418795847 0.194085484 0.411388311
 [17] 0.122928759 0.771984610 0.760725696 0.088470567 0.953485181 0.785645203 0.028409690 0.026232726
 [25] 0.055457646 0.038181372 0.757850071 0.007630220 0.110507313 0.066603557 0.213559028 0.017048355
 [33] 0.294579371 0.213686248 0.245378175 0.147939308 0.058529536 0.047092679 0.169073996 0.023421517
 [41] 0.434375748 0.123923484 0.796680824 0.257623355 0.236877492 0.032937565 0.075796893 0.459769771
 [49] 0.014969537 0.214416331 0.409898562 0.024597682 0.736084480 0.071421984 0.863089942 0.109813203
 [57] 0.415148971 0.192888308 0.671705524 0.707181753 0.222687051 0.074378276 0.047288218 0.250211485
 [65] 0.102873418 0.451885105 0.016412055 0.839500999 0.593725195 0.887724350 0.023636511 0.972427462
 [73] 0.421875342 0.240818110 0.193220347 0.275433738 0.029285367 0.858427986 0.792694816 0.428056807
 [81] 0.241389504 0.359146427 0.159848949 0.126229936 0.089106804 0.965646716 0.021565093 0.504101659
 [89] 0.255700597 0.303575110 0.316087819 0.695623695 0.059157940 0.023850831 0.703188586 0.768676985
 [97] 0.198583192 0.736445668 0.019832290 0.911158959 0.794437117 0.023391174 0.082335119 0.536540158
[105] 0.491636172 0.875915114 0.830550408 0.453101254 0.050024142 0.017749687 0.151803493 0.175667620
[113] 0.900329614 0.125898408 0.410586667 0.586540636 0.832688763 0.035561910 0.252327286 0.110864806
[121] 0.054988088 0.131662542 0.393097130 0.492496368 0.513182966 0.032671230 0.036078371 0.218212971
[129] 0.686096496 0.281975363 0.145884637 0.351411775 0.239547073 0.725330877 0.392954359 0.354585338
[137] 0.328110094 0.183872054 0.649535926 0.189835213 0.750660386 0.100154335 0.253081898 0.306902095
[145] 0.138876568 0.112315917 0.602945913 0.033225614 0.021023766 0.126008933 0.074805807 0.593242488
[153] 0.276438109 0.030025810 0.388107478 0.814468072 0.819988723 0.320406177 0.512019175 0.189866084
[161] 0.019102564 0.778045038 0.063532324 0.021660839 0.087123658 0.371697775 0.017831740 0.174573799
[169] 0.072586081 0.050795966 0.321374939 0.390300727 0.242283766 0.101281785 0.477098938 0.177832066
[177] 0.851704388 0.421578801 0.059594070 0.801660505 0.263016503 0.158261796 0.629712769 0.680147379
[185] 0.627289909 0.143229332 0.371021820 0.048405335 0.155912833 0.844592024 0.774738072 0.074975116
[193] 0.094313006 0.034029316 0.156403796 0.765185930 0.162409946 0.941491860 0.098203334 0.096782855
[201] 0.013696456 0.086137707 0.665930779 0.328426313 0.230933621 0.045364772 0.067599667 0.128835144
[209] 0.552086895 0.192049128 0.391808734 0.634609576 0.138796509 0.034537822 0.402157076 0.473285370
[217] 0.915578006 0.109882027 0.060813059 0.078347861 0.511021110 0.046236210 0.637413042 0.057352160
[225] 0.060578365 0.328120324 0.117022441 0.150080125 0.033383541 0.548421342 0.727231653 0.273012605
[233] 0.006665104 0.023959522 0.212622505 0.263913260 0.304803089 0.282446484 0.528587177 0.053303093
[241] 0.042787259 0.895978588 0.951451693 0.260631793 0.057999466 0.077448786 0.039445750 0.078320973
[249] 0.521759602 0.120793953 0.109749728 0.115212481 0.063160685 0.315382778 0.186348273 0.242141093
[257] 0.800887574 0.866564275 0.147824356 0.483279794 0.458255040 0.058388003 0.052876258 0.244883311
[265] 0.761115562 0.021394588 0.531937078 0.751371443 0.307274782 0.801133302 0.005240345 0.656336098
[273] 0.109766806 0.101435208 0.023548802 0.056804667 0.081720211 0.513341731 0.014456472 0.127221754
[281] 0.744369844 0.498650317 0.182496315 0.605638441 0.021059011 0.094691510 0.633177077 0.189201907
[289] 0.229657632 0.818999683 0.081933947 0.793780642 0.798845854 0.137588419 0.275762056 0.057395933
[297] 0.445742740 0.584089416 0.070998635 0.209775098 0.174014948 0.294145785 0.743857124 0.126042513
[305] 0.893349297 0.712229694 0.217225821 0.135596074 0.343239883 0.187767754 0.233598292 0.822021476
[313] 0.082764167 0.102210424 0.113711375 0.122461316 0.828791325 0.107099346 0.054386091 0.931938668
[321] 0.326454054 0.678618259 0.863704140 0.217542759 0.056249096 0.816489720 0.491806299 0.084796292
[329] 0.943486215 0.302404878 0.132747361 0.037305147 0.053261653 0.902996173 0.042527808 0.787771463
[337] 0.031525411 0.220902831 0.054775507 0.642266770 0.520264613 0.707148463 0.902568015 0.695527581
[345] 0.848650675 0.466017086 0.291730904 0.027601848 0.133315806 0.771592655 0.383831136 0.090423918
[353] 0.020481869 0.115239515 0.038125985 0.017056834 0.070184592 0.755542001 0.050653582 0.481007350
[361] 0.195086963 0.187977925 0.169394579 0.377212811 0.151859655 0.475032680 0.186324471 0.612248541
[369] 0.023804839 0.007054577 0.085213924 0.171343641 0.900710787 0.150595032 0.257766676 0.013926514
[377] 0.035750449 0.185105131 0.253500436 0.369424730 0.640522481 0.841160836 0.060643162 0.051633327
[385] 0.731126069 0.154040714 0.063202801 0.337255163 0.087712142 0.059196122 0.446522479 0.839581017
[393] 0.899946965 0.051162921 0.569809764 0.085461942 0.080315826 0.343678259 0.504516436 0.092545675
[401] 0.175360179 0.310167781 0.720652085 0.094860697 0.905656358 0.432122047 0.742494468 0.704660222
[409] 0.065240504 0.044936864 0.086384200 0.460776518 0.058306508 0.538740077 0.360529087 0.413937339
[417] 0.248787673 0.063168325 0.205549345 0.143823024 0.121451790 0.204643255 0.028047843 0.262047997
[425] 0.797845942 0.020192814 0.067782381 0.880235920 0.067820578 0.093376849 0.145058897 0.885115279
[433] 0.023833728 0.172919691 0.023186441 0.343149266 0.491733925 0.334336420 0.182785009 0.107602309
[441] 0.159470782 0.480057756 0.718226410 0.110307283 0.282105476 0.504892387 0.023457816 0.246497165
[449] 0.288819782 0.406440777 0.333499471 0.789228958 0.024672867 0.158285199 0.915532293 0.083660243
[457] 0.616972917 0.156244026 0.066104438 0.117576505 0.582609228 0.935907656 0.494078320 0.906231057
[465] 0.044752423 0.098120327 0.817658808 0.063067848 0.048103513 0.094446457 0.009656172 0.457728456
[473] 0.371287692 0.732871561 0.239173153 0.048538537 0.427026826 0.838680152 0.005916331 0.639747396
[481] 0.192937289 0.044098532 0.307301900 0.771646053 0.893235289 0.633989608 0.325705459 0.861507987
[489] 0.924405484 0.211878609 0.232857992 0.553168378 0.199630964 0.167297598 0.636698113 0.102745817
[497] 0.412260537 0.037681077 0.499347951 0.561847838 0.108622049 0.036902563 0.275679034 0.142289294
[505] 0.929821372 0.853111736 0.052948764 0.186298288 0.034369934 0.468239290 0.021331580 0.617803456
[513] 0.083865824 0.751272138 0.115022996 0.496356896 0.458485256 0.303064449 0.512265744 0.935001789
[521] 0.011659745 0.243551235 0.234201771 0.733582682 0.439827183 0.132566837 0.200183137 0.254534757
[529] 0.620459940 0.187218540 0.128750723 0.801532793</code></pre>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(hi <span class="sc">-</span> lo, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>  [1]  0.45 -0.24 -0.25 -0.24  0.63  0.40  0.13 -0.05  0.17 -0.04 -0.23  0.18 -0.24  0.15 -0.07  0.15
 [17] -0.14  0.51  0.50 -0.18  0.69  0.52 -0.24 -0.24 -0.21 -0.23  0.49 -0.26 -0.15 -0.20 -0.05 -0.25
 [33]  0.03 -0.05 -0.02 -0.12 -0.21 -0.22 -0.10 -0.24  0.17 -0.14  0.53 -0.01 -0.03 -0.23 -0.19  0.19
 [49] -0.25 -0.05  0.14 -0.24  0.47 -0.19  0.60 -0.16  0.15 -0.07  0.41  0.44 -0.04 -0.19 -0.22 -0.01
 [65] -0.16  0.19 -0.25  0.57  0.33  0.62 -0.24  0.71  0.16 -0.02 -0.07  0.01 -0.24  0.59  0.53  0.16
 [81] -0.02  0.09 -0.11 -0.14 -0.18  0.70 -0.24  0.24 -0.01  0.04  0.05  0.43 -0.21 -0.24  0.44  0.50
 [97] -0.07  0.47 -0.25  0.65  0.53 -0.24 -0.18  0.27  0.23  0.61  0.57  0.19 -0.22 -0.25 -0.11 -0.09
[113]  0.64 -0.14  0.15  0.32  0.57 -0.23 -0.01 -0.15 -0.21 -0.13  0.13  0.23  0.25 -0.23 -0.23 -0.05
[129]  0.42  0.02 -0.12  0.09 -0.03  0.46  0.13  0.09  0.06 -0.08  0.38 -0.08  0.49 -0.17 -0.01  0.04
[145] -0.13 -0.15  0.34 -0.23 -0.24 -0.14 -0.19  0.33  0.01 -0.24  0.12  0.55  0.55  0.06  0.25 -0.08
[161] -0.25  0.51 -0.20 -0.24 -0.18  0.11 -0.25 -0.09 -0.19 -0.21  0.06  0.13 -0.02 -0.16  0.21 -0.09
[177]  0.59  0.16 -0.21  0.54  0.00 -0.11  0.36  0.41  0.36 -0.12  0.11 -0.22 -0.11  0.58  0.51 -0.19
[193] -0.17 -0.23 -0.11  0.50 -0.10  0.68 -0.17 -0.17 -0.25 -0.18  0.40  0.06 -0.03 -0.22 -0.20 -0.14
[209]  0.29 -0.07  0.13  0.37 -0.13 -0.23  0.14  0.21  0.65 -0.16 -0.20 -0.19  0.25 -0.22  0.37 -0.21
[225] -0.20  0.06 -0.15 -0.12 -0.23  0.28  0.46  0.01 -0.26 -0.24 -0.05  0.00  0.04  0.02  0.26 -0.21
[241] -0.22  0.63  0.69  0.00 -0.21 -0.19 -0.23 -0.19  0.26 -0.14 -0.16 -0.15 -0.20  0.05 -0.08 -0.02
[257]  0.54  0.60 -0.12  0.22  0.19 -0.21 -0.21 -0.02  0.50 -0.24  0.27  0.49  0.04  0.54 -0.26  0.39
[273] -0.16 -0.16 -0.24 -0.21 -0.18  0.25 -0.25 -0.14  0.48  0.23 -0.08  0.34 -0.24 -0.17  0.37 -0.08
[289] -0.04  0.55 -0.18  0.53  0.53 -0.13  0.01 -0.21  0.18  0.32 -0.19 -0.06 -0.09  0.03  0.48 -0.14
[305]  0.63  0.45 -0.05 -0.13  0.08 -0.08 -0.03  0.56 -0.18 -0.16 -0.15 -0.14  0.56 -0.16 -0.21  0.67
[321]  0.06  0.41  0.60 -0.05 -0.21  0.55  0.23 -0.18  0.68  0.04 -0.13 -0.23 -0.21  0.64 -0.22  0.52
[337] -0.23 -0.04 -0.21  0.38  0.26  0.44  0.64  0.43  0.58  0.20  0.03 -0.24 -0.13  0.51  0.12 -0.17
[353] -0.24 -0.15 -0.23 -0.25 -0.20  0.49 -0.21  0.22 -0.07 -0.08 -0.10  0.11 -0.11  0.21 -0.08  0.35
[369] -0.24 -0.26 -0.18 -0.09  0.64 -0.11 -0.01 -0.25 -0.23 -0.08 -0.01  0.10  0.38  0.58 -0.20 -0.21
[385]  0.47 -0.11 -0.20  0.07 -0.18 -0.21  0.18  0.57  0.63 -0.21  0.30 -0.18 -0.18  0.08  0.24 -0.17
[401] -0.09  0.04  0.46 -0.17  0.64  0.17  0.48  0.44 -0.20 -0.22 -0.18  0.20 -0.21  0.27  0.10  0.15
[417] -0.02 -0.20 -0.06 -0.12 -0.14 -0.06 -0.24  0.00  0.53 -0.25 -0.20  0.62 -0.20 -0.17 -0.12  0.62
[433] -0.24 -0.09 -0.24  0.08  0.23  0.07 -0.08 -0.16 -0.11  0.21  0.45 -0.15  0.02  0.24 -0.24 -0.02
[449]  0.02  0.14  0.07  0.52 -0.24 -0.11  0.65 -0.18  0.35 -0.11 -0.20 -0.15  0.32  0.67  0.23  0.64
[465] -0.22 -0.17  0.55 -0.20 -0.22 -0.17 -0.26  0.19  0.11  0.47 -0.03 -0.22  0.16  0.57 -0.26  0.37
[481] -0.07 -0.22  0.04  0.51  0.63  0.37  0.06  0.60  0.66 -0.05 -0.03  0.29 -0.07 -0.10  0.37 -0.16
[497]  0.15 -0.23  0.23  0.30 -0.16 -0.23  0.01 -0.12  0.66  0.59 -0.21 -0.08 -0.23  0.20 -0.24  0.35
[513] -0.18  0.49 -0.15  0.23  0.19  0.04  0.25  0.67 -0.25 -0.02 -0.03  0.47  0.17 -0.13 -0.07 -0.01
[529]  0.36 -0.08 -0.14  0.54</code></pre>
</div>
</div>
<div id="creación-de-un-modelo-y-validación" class="section level2 hasAnchor" number="6.7">
<h2 class="hasAnchor"><span class="header-section-number">6.7</span> Creación de un modelo y validación<a href="#creación-de-un-modelo-y-validación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Todo lo explicado en la sección de selección de variables para un modelo lineal, aplica para el caso de la regresión logística. Las funciones reconocen que el objeto es un glm con familia binomial y realiza los cálculos requeridos para este tipo de regresión (progamación orientada a objetos). El tema de validación cruzada para evaluar un modelo también aplica. Veámoslo con un ejemplo.</p>
<p>Supongamos que queremos elegir el mejor modelo para predecir el riesgo de diabetes y queremos validarlo con valización cruzada. Todos los pasos y métodos que hemos aprendido en las lecciones anteriores, podemos realizarlos de la siguiente manera. Usaremos los datos train y test que hay por defecto (Pima.tr y Pima.te). Para la validación cruzada usaremos la librería <code>caret</code> que veremos en detalle más adelante.</p>
<p>Empecemos seleccionando el mejor modelo en los datos de entrenamiento con un stepwise hacia atrás</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a>mod.all <span class="ot">&lt;-</span> <span class="fu">glm</span>(type <span class="sc">~</span> ., <span class="at">data=</span>Pima.tr, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb370-2"><a href="#cb370-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> stats<span class="sc">::</span><span class="fu">step</span>(mod.all, <span class="at">trace=</span><span class="cn">FALSE</span>, <span class="at">direction=</span><span class="st">&quot;backward&quot;</span>)</span>
<span id="cb370-3"><a href="#cb370-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div>
<pre><code>
Call:
glm(formula = type ~ npreg + glu + bmi + ped + age, family = &quot;binomial&quot;, 
    data = Pima.tr)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.0009  -0.6816  -0.3664   0.6467   2.2898  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -9.938059   1.541571  -6.447 1.14e-10 ***
npreg        0.103142   0.064517   1.599  0.10989    
glu          0.031809   0.006667   4.771 1.83e-06 ***
bmi          0.079672   0.032649   2.440  0.01468 *  
ped          1.811417   0.661048   2.740  0.00614 ** 
age          0.039286   0.020967   1.874  0.06097 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 256.41  on 199  degrees of freedom
Residual deviance: 178.47  on 194  degrees of freedom
AIC: 190.47

Number of Fisher Scoring iterations: 5</code></pre>
<p>Podemos evaluar la capacidad predictiva en la muestra test mediante</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod, <span class="at">newdata =</span> Pima.te, <span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb372-2"><a href="#cb372-2" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(preds <span class="sc">&gt;=</span> .<span class="dv">5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>) )</span>
<span id="cb372-3"><a href="#cb372-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(preds, Pima.te<span class="sc">$</span>type)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  199  42
       Yes  24  67
                                          
               Accuracy : 0.8012          
                 95% CI : (0.7542, 0.8428)
    No Information Rate : 0.6717          
    P-Value [Acc &gt; NIR] : 1.116e-07       
                                          
                  Kappa : 0.5294          
                                          
 Mcnemar&#39;s Test P-Value : 0.03639         
                                          
            Sensitivity : 0.8924          
            Specificity : 0.6147          
         Pos Pred Value : 0.8257          
         Neg Pred Value : 0.7363          
             Prevalence : 0.6717          
         Detection Rate : 0.5994          
   Detection Prevalence : 0.7259          
      Balanced Accuracy : 0.7535          
                                          
       &#39;Positive&#39; Class : No              
                                          </code></pre>
<p>y calcular la capacidad predictiva en la muestra train utilizando un método de 5-fold cross-validation con:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb374-2"><a href="#cb374-2" aria-hidden="true" tabindex="-1"></a>mod.test <span class="ot">&lt;-</span> <span class="fu">train</span>(type <span class="sc">~</span> ., <span class="at">data=</span>Pima.tr, </span>
<span id="cb374-3"><a href="#cb374-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;cv&quot;</span>, <span class="at">number=</span><span class="dv">5</span>),</span>
<span id="cb374-4"><a href="#cb374-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb374-5"><a href="#cb374-5" aria-hidden="true" tabindex="-1"></a>mod.test</span></code></pre></div>
<pre><code>Generalized Linear Model 

200 samples
  7 predictor
  2 classes: &#39;No&#39;, &#39;Yes&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 160, 160, 159, 160, 161 
Resampling results:

  Accuracy   Kappa    
  0.7553283  0.4381235</code></pre>
</div>
<div id="nomogramas" class="section level2 hasAnchor" number="6.8">
<h2 class="hasAnchor"><span class="header-section-number">6.8</span> Nomogramas<a href="#nomogramas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez que ya tenemos creado y validad un modelo predictivo, nos puede interesar aplicarlo en otros individuos para poder tomar decisiones. Para ello, podemos usar nomogramas.</p>
<p>Un nomograma es una representación gráfica que permite realizar con rapidez cálculos numéricos aproximados. Dentro del campo de la medicina, es frecuente que este tipo de gráficos este asociado al calculo de probabilidades de ocurrencia de un evento o una característica asociada a una enfermedad. Es lo que se conoce como <strong>Medicina Translacional</strong>.</p>
<p>Aunque existen otro tipo de herramientas de cálculo vía web para estas probabilidades (Shiny), el uso de nomogramas esta muy extendido en el campo de la biomedicina como por ejemplo en el calculo de probabilidades de recurrencia en distintos tipos de cáncer, la probabilidad de supervivencia a un mes tras un infarto, o el pronóstico tras un diagnóstico de cáncer a cierto tiempo (en ese caso se usan modelos de supervivencia. Así pues, la regresión logística será una de las herramientas con una aplicación más directa y sencilla en el aprendizaje automático, donde el uso de los modelos predictivos suelen tener un aplicabilidad directa en la población.</p>
<p>Existen numerosas herramientas para crear nomogramas en R, empecemos con la creación de nomogramas sencillos. Para ello usaremos los datos del ejemplo de diabetes con el modelo que hemos obtenido y validado anteriormente. Para usar la librería <code>rms</code> necesitamos que el modelo esté estimado con la función <code>lrm ()</code></p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="#cb376-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rms)</span>
<span id="cb376-2"><a href="#cb376-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb376-3"><a href="#cb376-3" aria-hidden="true" tabindex="-1"></a>t.data <span class="ot">&lt;-</span> <span class="fu">datadist</span>(Pima.tr)</span>
<span id="cb376-4"><a href="#cb376-4" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">datadist =</span> <span class="st">&#39;t.data&#39;</span>)</span>
<span id="cb376-5"><a href="#cb376-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb376-6"><a href="#cb376-6" aria-hidden="true" tabindex="-1"></a>mod.lrm <span class="ot">&lt;-</span> <span class="fu">lrm</span>(type <span class="sc">~</span> npreg <span class="sc">+</span> glu <span class="sc">+</span> bmi <span class="sc">+</span> ped <span class="sc">+</span> age, <span class="at">data=</span>Pima.tr)</span>
<span id="cb376-7"><a href="#cb376-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb376-8"><a href="#cb376-8" aria-hidden="true" tabindex="-1"></a>nom <span class="ot">&lt;-</span> <span class="fu">nomogram</span>(mod.lrm, <span class="at">fun =</span> plogis, <span class="at">funlabel=</span><span class="st">&quot;Risk of diabetes&quot;</span>)</span>
<span id="cb376-9"><a href="#cb376-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nom)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-125-1.png" width="768" /></p>
<p>Supongamos que llega a la consulta una persona con un bmi de 35. Eso sumaría 30 puntos (basta con subir hacia arriba y ver qué valor de ‘Points’ corresponde a un bmi de 35). Una edad de 50 años (~22 puntos), una función del pedigrí de la diabetes de 1.8 (~62 puntos), una glucosa de 120 (~50 puntos) y 0 embarazos que sumaría 0 puntos. En total, el paciente suma un total de 164 puntos. Si ahora vamos a la línea de ‘Total Points’ y proyectamos sobre el predictor lineal de aproximadamente ~1.9 que se asocia con un riesgo de diabetes ligeramente superior al 80% (proyectar sobre ‘Risk of diabetes’).</p>
<p>Obviamente estos cálculos se pueden hacer de forma más directa calculando la predicción sobre este individuo con el objeto de R</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>indiv <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">bmi=</span><span class="dv">35</span>, <span class="at">age=</span><span class="dv">50</span>, <span class="at">ped=</span><span class="fl">1.8</span>, <span class="at">glu=</span><span class="dv">120</span>, <span class="at">npreg=</span><span class="dv">0</span>)</span>
<span id="cb377-2"><a href="#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod.lrm, <span class="at">newdata =</span> indiv, <span class="at">type=</span><span class="st">&quot;lp&quot;</span>)</span></code></pre></div>
<pre><code>       1 
1.892376 </code></pre>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mod.lrm, <span class="at">newdata =</span> indiv, <span class="at">type =</span> <span class="st">&quot;fitted&quot;</span>)</span></code></pre></div>
<pre><code>        1 
0.8690262 </code></pre>
<p>Estos cálculos se pueden programar en R y hace una función, o también una aplicación Shiny para aquellos médicos que no sepan usar R (los nomogramas se siguen utilizando). Otra opción es que hagamos uso de una librería para hacer nomogramas dinámicos (crea Shiny app) de forma sencilla con la librería <code>DynNom</code></p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DynNom)</span>
<span id="cb381-2"><a href="#cb381-2" aria-hidden="true" tabindex="-1"></a><span class="fu">DynNom</span>(mod, Pima.tr)</span></code></pre></div>
<p>Con estas simples instrucciones obtendríamos esta aplicación Shiny (Figura abajo) donde cada intervalo de confianza corresponde a un cálculo obtenido variando alguna de las variables predictoras</p>
<div class="figure">
<img src="figures/nomograma.png" alt="" />
<p class="caption">Nomograma para el modelo de predicción para diabetes</p>
</div>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P-Práctica regresión logística):</td>
</tr>
<tr class="even">
<td align="left">En esta página <a href="https://vincentarelbundock.github.io/Rdatasets/datasets.html" class="uri">https://vincentarelbundock.github.io/Rdatasets/datasets.html</a> tienes acceso a cientos de bases de datos que hay en R y que también puedes descargar como ficheros .csv.</td>
</tr>
<tr class="odd">
<td align="left">Elige una base de datos donde la pregunta científica <strong>requiera el análisis de una variable respuesta binaria</strong>. Selecciona unas 8-15 variables independientes (intenta que hayan categóricas y continuas). <strong>Crea un pdf</strong> en el que muestres un análisis completo de los datos incluyendo:</td>
</tr>
<tr class="even">
<td align="left">1. Descripción de tu pregunta científica</td>
</tr>
<tr class="odd">
<td align="left">2. Análisis descriptivo de las variables independientes en función de tu variable respuesta</td>
</tr>
<tr class="even">
<td align="left">3. Imputación de datos en caso de ser necesario</td>
</tr>
<tr class="odd">
<td align="left">4. Creación de un modelo predictivo</td>
</tr>
<tr class="even">
<td align="left">5. Descripción de las ORs para el modelo final</td>
</tr>
<tr class="odd">
<td align="left">6. Validación del modelo mediante CV</td>
</tr>
<tr class="even">
<td align="left">7. Descripción de la capacidad predictiva del modelo (Sensibilidad, Precisión, curva ROC, …)</td>
</tr>
<tr class="odd">
<td align="left">8. Creación de un nomograma estático que incluya la ilustración del cálculo de riesgo para un individuo ficticio.</td>
</tr>
<tr class="even">
<td align="left">9. Apéndice con el código R utilizado</td>
</tr>
<tr class="odd">
<td align="left">Se trata de crear un documento de unas 2-3 páginas (figuras y tablas aparte) explicando los principales resultados del estudio donde cada párrafo podría corresponder a cada una de las tareas anteriores. El documento debe incluir las tablas y/o figuras que creas conveniente que sostengan los resultados descritos en el documento. Se trata de intentar escribir el apartado de resultados de un artículo científico. Antes de escribir este apartado de resultados, el documento deberá empezar con un apartado breve de métodos describiendo los datos (brevemente - podéis usar la información que hay en la página de donde habéis descargado los datos) y los métodos estadísticos utilizados. Aquellos que quieran, lo pueden hacer con R Markdown. <strong>NOTA</strong>: El que no suba un pdf tendrá un 0 en la práctica.</td>
</tr>
</tbody>
</table>
<!--chapter:end:05-regresion_logistica.Rmd-->
</div>
</div>
<div id="modelos-de-regularización" class="section level1 hasAnchor" number="7">
<h1 class="hasAnchor"><span class="header-section-number">7</span> Modelos de regularización<a href="#modelos-de-regularización" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introducción-2" class="section level2 hasAnchor" number="7.1">
<h2 class="hasAnchor"><span class="header-section-number">7.1</span> Introducción<a href="#introducción-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este capítulo, exploraremos los modelos de regularización (y el concepto de regresión penalizada), que es una técnica poderosa para lidiar con el sobreajuste en modelos de aprendizaje automático. El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento pero tiene un rendimiento deficiente en datos no vistos. La regularización es un método que introduce un término de penalización en la función de pérdida del modelo para evitar el sobreajuste. A grandes rasgos podemos resumir que</p>
<p>Hay dos tipos comunes de regularización utilizados en la regresión penalizada:</p>
<ol style="list-style-type: decimal">
<li><p>Regularización L1 (Regresión Lasso): Agrega el valor absoluto de los coeficientes como término de penalización a la función de pérdida.</p></li>
<li><p>Regularización L2 (Regresión Ridge): Agrega el cuadrado de los coeficientes como término de penalización a la función de pérdida.</p></li>
</ol>
<p>La regularización ridge es suave y la regularización lasso es áspera tal y como se puede ver en la siguiente figura</p>
<p><img src="figures/lasso_ridge_1.jpg" /></p>
<p>Es esta diferencia entre las restricciones suaves y ásperas lo que resulta en que el Lasso tenga estimaciones de coeficientes que son exactamente cero, mientras que Ridge no lo hace. Ilustramos esto aún más en la siguiente figura. La solución de mínimos cuadrados se marca como <span class="math inline">\(\hat{\beta}\)</span>, mientras que el diamante azul y el círculo representan las restricciones de regresión Lasso y Ridge (como en la Figura anterior). Si la penalización (<span class="math inline">\(t\)</span> en la figura anterior) es lo suficientemente grande (aumentar la penalización hace que el diamante y el círculo sean más grandes, respectivamente), entonces las regiones de restricción contendrán a <span class="math inline">\(\hat{\beta}\)</span>, por lo que las estimaciones de Ridge y Lasso serán iguales a las estimaciones de mínimos cuadrados.</p>
<p>Las curvas que están centradas alrededor de <span class="math inline">\(\hat{\beta}\)</span> representan regiones de RSS constante. A medida que las elipses se alejan de las estimaciones de coeficientes de mínimos cuadrados, el RSS aumenta. Las estimaciones de coeficientes de regresión Lasso y Ridge se dan en el primer punto en el que una elipse toca la región de restricción.</p>
<p><img src="figures/lasso_ridge_1.jpg" /></p>
<p>La regularización proporciona varios beneficios:</p>
<ul>
<li>Ayuda a prevenir el sobreajuste al reducir la complejidad del modelo.</li>
<li>Mejora la generalización, lo que hace que el modelo tenga un mejor rendimiento en datos no vistos.</li>
<li>Puede realizar automáticamente la selección de características al establecer algunos coeficientes en cero.</li>
</ul>
<p>Regularización L1 (Regresión Lasso)
La regresión Lasso agrega la suma de los valores absolutos de los coeficientes como término de penalización a la función de pérdida. Esta penalización fomenta que algunos coeficientes sean exactamente cero, lo que efectivamente realiza la selección de características.</p>
</div>
<div id="cómo-regularizar" class="section level2 hasAnchor" number="7.2">
<h2 class="hasAnchor"><span class="header-section-number">7.2</span> Cómo regularizar<a href="#cómo-regularizar" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El procedimiento habitual para ajustar un modelo de regresión lineal es emplear mínimos cuadrados, es decir, utilizar como criterio de error la suma de cuadrados residual</p>
<p><span class="math display">\[\mbox{RSS} = \sum\limits_{i=1}^{n}\left(  y_{i} - \beta_0 - \boldsymbol{\beta}^t \mathbf{x}_{i} \right)^{2}\]</span></p>
<p>Si el modelo lineal es razonablemente adecuado, utilizar RSS va a dar lugar a estimaciones con poco sesgo, y si además <span class="math inline">\(n\gg p\)</span>, entonces el modelo también va a tener poca varianza. Las dificultades surgen cuando <span class="math inline">\(p\)</span> es grande o cuando hay correlaciones altas entre las variables predictoras: tener muchas variables dificulta la interpretación del modelo, y si además hay problemas de colinealidad o se incumple <span class="math inline">\(n\gg p\)</span>, entonces la estimación del modelo va a tener muchas varianza y el modelo estará sobreajustado. La solución pasa por forzar a que el modelo tenga menos complejidad para así reducir su varianza. Una forma de conseguirlo es mediante la regularización (regularization o shrinkage) de la estimación de los parámetros <span class="math inline">\(\beta_1, \beta_2,\ldots, \beta_p\)</span> que consiste en considerar todas las variables predictoras pero forzando a que algunos de los parámetros se estimen mediante valores muy próximos a cero, o directamente con ceros. Esta técnica va a provocar un pequeño aumento en el sesgo pero a cambio una notable reducción en la varianza y una interpretación más sencilla del modelo resultante.</p>
<p>Como ya hemos anticipado, hay dos formas básicas de lograr esta simplificación de los parámetros (con la consiguiente simplificación del modelo), utilizando una penalización cuadrática (norma <span class="math inline">\(L_2\)</span>) o en valor absoluto (norma <span class="math inline">\(L_1\)</span>):</p>
<p>Hay dos formas básicas de lograr esta simplificación de los parámetros (con la consiguiente simplificación del modelo), utilizando una penalización cuadrática (norma <span class="math inline">\(L_2\)</span>) o en valor absoluto (norma <span class="math inline">\(L_1\)</span>):</p>
<ul>
<li><p><em>Ridge regression</em>
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS} + \lambda\sum_{j=1}^{p}\beta_{j}^{2}\]</span></p>
<p>Equivalentemente,
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS}\]</span>
sujeto a
<span class="math display">\[\sum_{j=1}^{p}\beta_{j}^{2} \le s\]</span></p></li>
<li><p><em>Lasso</em> [<em>least absolute shrinkage and selection operator</em>]
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} RSS + \lambda\sum_{j=1}^{p}|\beta_{j}|\]</span></p>
<p>Equivalentemente,
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS}\]</span>
sujeto a
<span class="math display">\[\sum_{j=1}^{p}|\beta_{j}| \le s\]</span></p></li>
</ul>
<p>Una formulación unificada consiste en considerar el problema
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} RSS + \lambda\sum_{j=1}^{p}|\beta_{j}|^d\]</span></p>
<p>Si <span class="math inline">\(d=0\)</span>, la penalización consiste en el número de variables utilizadas, por tanto se corresponde con el problema de selección de variables; <span class="math inline">\(d=1\)</span> se corresponde con <em>lasso</em> y <span class="math inline">\(d=2\)</span> con <em>ridge</em>.</p>
<p>La ventaja de utilizar <em>lasso</em> es que va a forzar a que algunos parámetros sean cero, con lo cual también se realiza una selección de las variables más influyentes.
Por el contrario, <em>ridge regression</em> va a incluir todas las variables predictoras en el modelo final, si bien es cierto que algunas con parámetros muy próximos a cero: de este modo va a reducir el riesgo del sobreajuste, pero no resuelve el problema de la interpretabilidad.
Otra posible ventaja de utilizar <em>lasso</em> es que cuando hay variables predictoras correlacionadas tiene tendencia a seleccionar una y anular las demás (esto también se puede ver como un inconveniente, ya que pequeños cambios en los datos pueden dar lugar a distintos modelos), mientras que <em>ridge</em> tiende a darles igual peso.</p>
<p>Una generalización de <em>lasso</em> muy utilizada en ciencias ómicas es <em>elastic net</em> que combina las ventajas de <em>ridge</em> y <em>lasso</em>, minimizando
<span class="math display">\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \ \mbox{RSS} + \lambda \left( \frac{1 - \alpha}{2}\sum_{j=1}^{p}\beta_{j}^{2} + \alpha \sum_{j=1}^{p}|\beta_{j}| \right)\]</span>
con <span class="math inline">\(0 \leq \alpha \leq 1\)</span>.</p>
<p><strong>IMPORTANTE:</strong> Es crucial estandarizar (centrar y reescalar) las variables predictoras antes de realizar estas técnicas. Fijémonos en que, así como <span class="math inline">\(\mbox{RSS}\)</span> es insensible a los cambios de escala, la penalización es muy sensible. Previa estandarización, el término independiente <span class="math inline">\(\beta_0\)</span> (que no interviene en la penalización) tiene una interpretación muy directa, ya que
<span class="math display">\[\widehat \beta_0 = \bar y =\sum_{i=1}^n \frac{y_i}{n}\]</span></p>
<p>Los dos métodos de regularización comentados dependen del hiperparámetro <span class="math inline">\(\lambda\)</span> (equivalentemente, <span class="math inline">\(s\)</span>). Como en cualquier otro método de aprendizaje automático, es muy importante seleccionar adecuadamente el valor del hiperparámetro. Un método que podemos usar es, por ejemplo, <em>validación cruzada</em>. Hay algoritmos muy eficientes que permiten el ajuste, tanto de <em>ridge regression</em> como de <em>lasso</em> de forma conjunta (simultánea) para todos los valores de <span class="math inline">\(\lambda\)</span>.</p>
</div>
<div id="implementación-en-r" class="section level2 hasAnchor" number="7.3">
<h2 class="hasAnchor"><span class="header-section-number">7.3</span> Implementación en R<a href="#implementación-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hay varios paquetes que implementan estos métodos: <code>h2o</code>, <code>elasticnet</code>, <code>penalized</code>, <code>lasso2</code>, <code>biglasso</code>, etc., pero el paquete <code>glmnet</code>(<a href="https://glmnet.stanford.edu" class="uri">https://glmnet.stanford.edu</a>)` es el más usado y tiene una implementación muy eficiente (tener el cuenta que la minimización puede ser costosa computacionalmente)</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span></code></pre></div>
<p>El paquete <code>glmnet</code> no emplea formulación de modelos (es decir, no usa el simbolo ‘~’), hay que establecer la respuesta <code>y</code> y la matriz numérica <code>x</code> correspondiente a las variables explicativas.
Por tanto no se pueden incluir directamente predictores categóricos, habrá que codificarlos empleando variables auxiliares numéricas. Se puede emplear la función <code>model.matrix()</code>(o <code>Matrix::sparse.model.matrix()</code> si el conjunto de datos es muy grande) para construir la matriz de diseño <code>x</code> a partir de una fórmula (alternativamente se pueden emplear la herramientas implementadas en el paquete <code>caret</code>). Además, esta función tampoco admite datos faltantes.</p>
<p>La función principal es:</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glmnet</span>(x, y, family, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> <span class="cn">NULL</span>, ...)</span></code></pre></div>
<ul>
<li><p><code>family</code>: familia del modelo lineal generalizado (ver Sección @ref(reg-glm)); por defecto <code>"gaussian"</code> (modelo lineal con ajuste cuadrático), también admite <code>"binomial"</code>, <code>"poisson"</code>, <code>"multinomial"</code>, <code>"cox"</code> o <code>"mgaussian"</code> (modelo lineal con respuesta multivariante).</p></li>
<li><p><code>alpha</code>: parámetro <span class="math inline">\(\alpha\)</span> de elasticnet <span class="math inline">\(0 \leq \alpha \leq 1\)</span>. Por defecto <code>alpha = 1</code> penalización <em>lasso</em> (<code>alpha = 0</code> para <em>ridge regression</em>).</p></li>
<li><p><code>lambda</code>: secuencia (opcional) de valores de <span class="math inline">\(\lambda\)</span>; si no se especifica se establece una secuencia por defecto (en base a los argumentos adicionales <code>nlambda</code> y <code>lambda.min.ratio</code>). Se devolverán los ajustes para todos los valores de esta secuencia (también se podrán obtener posteriormente para otros valores).</p></li>
</ul>
<p>Entre los métodos genéricos disponibles del objeto resultante, <code>coef()</code> y <code>predict()</code> permiten obtener los coeficientes y las predicciones para un valor concreto de <span class="math inline">\(\lambda\)</span>, que se debe especificar mediante el argumento <code>s = valor</code> (los autores usan <code>s</code> en vez de <code>lambda</code> ya que inicialmente usaban ese nombre).</p>
<p>El valor “óptimo” del hiperparámetro <span class="math inline">\(\lambda\)</span> se puede calcular mediante validación cruzada con la siguiente instrucción:</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="#cb384-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cv.glmnet</span>(x, y, family, alpha, lambda, <span class="at">type.measure =</span> <span class="st">&quot;default&quot;</span>, <span class="at">nfolds =</span> <span class="dv">10</span>, ...)</span></code></pre></div>
<p>Esta función también devuelve los ajustes con toda la muestra de entrenamiento (en la componente <code>$glmnet.fit</code>) y se puede emplear el resultado directamente para predecir o obtener los coeficientes del modelo. Por defecto, selecciona <span class="math inline">\(\lambda\)</span> mediante la regla de “un error estándar” (componente <code>$lambda.1se</code>), aunque también calcula el valor óptimo (componente <code>$lambda.min</code>; que se puede seleccionar con estableciendo <code>s = "lambda.min"</code>). Para más detalles consultar la vignette del paquete <a href="https://glmnet.stanford.edu/articles/glmnet.html">An Introduction to glmnet</a>.</p>
<p>Para ilustrar cómo llevar a cabo estos análisis utilizaremos los datos de cáncer de mama que ya hemos trabajado en el capítulo de preproceso de datos. Este ejemplo tiene mucho sentido (aunque no se cumpla que <span class="math inline">\(p \gg n\)</span>) ya que también existe mucha correlación entre las variables dependientes, que es un caso donde también se suele utilizar estos modelos.</p>
<p>Los datos ya pre-procesados se pueden cargar de la siguiente manera (nota, yo uso “data” porque están en ese directorio en mi ordenador):</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;data/breast.Rdata&quot;</span>)</span></code></pre></div>
<p>Ahora debemos extraer la matriz de datos <span class="math inline">\(x\)</span> (variables independientes) y el vector con la variable que queremos predecir <span class="math inline">\(y\)</span> (<em>outcome</em>). Recordemos que las variables son las siguientes:</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="#cb386-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(breast_train_prep)</span></code></pre></div>
<pre><code> [1] &quot;texture_mean&quot;            &quot;area_mean&quot;               &quot;smoothness_mean&quot;        
 [4] &quot;compactness_mean&quot;        &quot;symmetry_mean&quot;           &quot;fractal_dimension_mean&quot; 
 [7] &quot;texture_se&quot;              &quot;area_se&quot;                 &quot;smoothness_se&quot;          
[10] &quot;compactness_se&quot;          &quot;concavity_se&quot;            &quot;concave points_se&quot;      
[13] &quot;symmetry_se&quot;             &quot;fractal_dimension_se&quot;    &quot;smoothness_worst&quot;       
[16] &quot;compactness_worst&quot;       &quot;concave points_worst&quot;    &quot;symmetry_worst&quot;         
[19] &quot;fractal_dimension_worst&quot; &quot;diagnosis&quot;              </code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(breast_train_prep[, <span class="sc">-</span><span class="fu">ncol</span>(breast_train_prep)])</span>
<span id="cb388-2"><a href="#cb388-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> breast_train_prep<span class="sc">$</span>diagnosis</span></code></pre></div>
<p>También podemos extraer x de forma más “clara” con tidyverse</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> breast_train_prep <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>diagnosis) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span></code></pre></div>
<p>o usando el diseño del modelo sin el intercept (nota: en vez de ‘.’ se pueden poner el nombre de las variables predictoras)</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(diagnosis <span class="sc">~</span> <span class="sc">-</span> <span class="dv">1</span> <span class="sc">+</span> . , <span class="at">data=</span>breast_train_prep)</span></code></pre></div>
<div id="ejemplo-ridge-regression" class="section level3 hasAnchor" number="7.3.1">
<h3 class="hasAnchor"><span class="header-section-number">7.3.1</span> Ejemplo: Ridge Regression<a href="#ejemplo-ridge-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ajustamos los modelos de regresión ridge (con la secuencia de valores de <span class="math inline">\(\lambda\)</span> por defecto) con la función <code>glmnet()</code> con <code>alpha=0</code> (ridge penalty) y la opción <code>family = binomial</code> porque estamos ante un problema de clasificación binaria:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb391-2"><a href="#cb391-2" aria-hidden="true" tabindex="-1"></a>fit.ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">family =</span> binomial)</span>
<span id="cb391-3"><a href="#cb391-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit.ridge, <span class="at">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-136-1.png" width="672" /></p>
<p>Podemos obtener el modelo o predicciones para un valor concreto de <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit.ridge, <span class="at">s =</span> <span class="dv">2</span>) <span class="co"># lambda = 2</span></span></code></pre></div>
<pre><code>20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                                   s1
(Intercept)             -0.5555635957
texture_mean             0.0735405177
area_mean                0.1206458718
smoothness_mean          0.0413289772
compactness_mean         0.0815272858
symmetry_mean            0.0433533589
fractal_dimension_mean  -0.0226349104
texture_se              -0.0062811918
area_se                  0.0911190933
smoothness_se           -0.0165352515
compactness_se           0.0342444176
concavity_se             0.0449677702
`concave points_se`      0.0603394789
symmetry_se             -0.0114723777
fractal_dimension_se     0.0003898276
smoothness_worst         0.0591408831
compactness_worst        0.0844100996
`concave points_worst`   0.1249016680
symmetry_worst           0.0631948865
fractal_dimension_worst  0.0395917038</code></pre>
<p>Para seleccionar el parámetro de penalización por validación cruzada empleamos <code>cv.glmnet()</code> (usamos la semilla para que sea reproducible en cualquier ordenador):</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb394-2"><a href="#cb394-2" aria-hidden="true" tabindex="-1"></a>cv.ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb394-3"><a href="#cb394-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.ridge)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-138-1.png" width="672" /></p>
<p>En este caso el parámetro óptimo (según la regla de un error estándar) sería:</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>cv.ridge<span class="sc">$</span>lambda<span class="fl">.1</span>se</span></code></pre></div>
<pre><code>[1] 0.05646944</code></pre>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cv.ridge$lambda.min</span></span></code></pre></div>
<p>y el correspondiente modelo contiene todas las variables explicativas:</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="#cb398-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv.ridge) <span class="co"># s = &quot;lambda.1se&quot;</span></span></code></pre></div>
<pre><code>20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                                 s1
(Intercept)             -0.72707742
texture_mean             0.51292464
area_mean                0.79924145
smoothness_mean          0.10549462
compactness_mean         0.26016484
symmetry_mean            0.09346757
fractal_dimension_mean  -0.34641170
texture_se              -0.01697213
area_se                  0.59895989
smoothness_se           -0.06167636
compactness_se          -0.05639525
concavity_se             0.14078849
`concave points_se`      0.21961982
symmetry_se             -0.14877280
fractal_dimension_se    -0.17141822
smoothness_worst         0.27744261
compactness_worst        0.32579681
`concave points_worst`   0.68781501
symmetry_worst           0.36925943
fractal_dimension_worst  0.15699353</code></pre>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coef(cv.ridge, s = &quot;lambda.min&quot;)</span></span></code></pre></div>
<p>Finalmente evaluamos la precisión en la muestra de test:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="#cb401-1" aria-hidden="true" tabindex="-1"></a>newx <span class="ot">&lt;-</span> breast_test_prep <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>diagnosis) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb401-2"><a href="#cb401-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv.ridge, <span class="at">newx =</span> newx, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>) <span class="co"># s = &quot;lambda.1se&quot;</span></span>
<span id="cb401-3"><a href="#cb401-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-4"><a href="#cb401-4" aria-hidden="true" tabindex="-1"></a><span class="co"># es necesario poner `pred` como un vector</span></span>
<span id="cb401-5"><a href="#cb401-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-6"><a href="#cb401-6" aria-hidden="true" tabindex="-1"></a>xtab <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">as.vector</span>(pred), breast_test_prep<span class="sc">$</span>diagnosis) </span>
<span id="cb401-7"><a href="#cb401-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-8"><a href="#cb401-8" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(xtab)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

   
      B   M
  B 105   6
  M   2  57
                                          
               Accuracy : 0.9529          
                 95% CI : (0.9094, 0.9795)
    No Information Rate : 0.6294          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.8978          
                                          
 Mcnemar&#39;s Test P-Value : 0.2888          
                                          
            Sensitivity : 0.9813          
            Specificity : 0.9048          
         Pos Pred Value : 0.9459          
         Neg Pred Value : 0.9661          
             Prevalence : 0.6294          
         Detection Rate : 0.6176          
   Detection Prevalence : 0.6529          
      Balanced Accuracy : 0.9430          
                                          
       &#39;Positive&#39; Class : B               
                                          </code></pre>
</div>
<div id="ejemplo-lasso" class="section level3 hasAnchor" number="7.3.2">
<h3 class="hasAnchor"><span class="header-section-number">7.3.2</span> Ejemplo: Lasso<a href="#ejemplo-lasso" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También podríamos ajustar modelos lasso con la opción por defecto de <code>glmnet()</code> (<code>alpha = 1</code>, lasso penalty).
Pero en este caso lo haremos al mismo tiempo que seleccionamos el parámetro de penalización por validación cruzada:</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb403-2"><a href="#cb403-2" aria-hidden="true" tabindex="-1"></a>cv.lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb403-3"><a href="#cb403-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.lasso)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-142-1.png" width="672" /></p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="#cb404-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.lasso<span class="sc">$</span>glmnet.fit, <span class="at">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)    </span>
<span id="cb404-2"><a href="#cb404-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">log</span>(cv.lasso<span class="sc">$</span>lambda<span class="fl">.1</span>se), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb404-3"><a href="#cb404-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">log</span>(cv.lasso<span class="sc">$</span>lambda.min), <span class="at">lty =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-142-2.png" width="672" /></p>
<p>El modelo resultante (oneSE rule) solo contiene 9 variables explicativas:</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="#cb405-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cv.lasso) <span class="co"># s = &quot;lambda.1se&quot;</span></span></code></pre></div>
<pre><code>20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                                 s1
(Intercept)             -0.55527533
texture_mean             0.89281924
area_mean                2.06965054
smoothness_mean          .         
compactness_mean         .         
symmetry_mean            .         
fractal_dimension_mean   .         
texture_se               .         
area_se                  1.30248883
smoothness_se            .         
compactness_se          -0.02882114
concavity_se             .         
`concave points_se`      .         
symmetry_se             -0.08721175
fractal_dimension_se    -0.01522821
smoothness_worst         0.28720064
compactness_worst        .         
`concave points_worst`   2.01615906
symmetry_worst           0.66553914
fractal_dimension_worst  .         </code></pre>
<p>Por tanto este método también podría ser empleando para la selección de variables (puede hacerse automáticamente estableciendo <code>relax = TRUE</code>, ajustará los modelos sin regularización).</p>
<p>Finalmente evaluamos también la precisión en la muestra de test:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="#cb407-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv.lasso, <span class="at">newx =</span> newx, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb407-2"><a href="#cb407-2" aria-hidden="true" tabindex="-1"></a>xtab <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">as.vector</span>(pred), breast_test_prep<span class="sc">$</span>diagnosis) </span>
<span id="cb407-3"><a href="#cb407-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-4"><a href="#cb407-4" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(xtab)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

   
      B   M
  B 105   4
  M   2  59
                                          
               Accuracy : 0.9647          
                 95% CI : (0.9248, 0.9869)
    No Information Rate : 0.6294          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.9238          
                                          
 Mcnemar&#39;s Test P-Value : 0.6831          
                                          
            Sensitivity : 0.9813          
            Specificity : 0.9365          
         Pos Pred Value : 0.9633          
         Neg Pred Value : 0.9672          
             Prevalence : 0.6294          
         Detection Rate : 0.6176          
   Detection Prevalence : 0.6412          
      Balanced Accuracy : 0.9589          
                                          
       &#39;Positive&#39; Class : B               
                                          </code></pre>
<p>Podemos observar que lo hace mejor que el modelo Ridge que tiene más sobreajuste.</p>
</div>
<div id="ejemplo-elastic-net" class="section level3 hasAnchor" number="7.3.3">
<h3 class="hasAnchor"><span class="header-section-number">7.3.3</span> Ejemplo: Elastic Net<a href="#ejemplo-elastic-net" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos ajustar modelos elastic net para un valor concreto de <code>alpha</code> empleando la función <code>glmnet()</code>, pero las opciones del paquete no incluyen la selección de este hiperparámetro.
Aunque se podría implementar fácilmente (como se muestra en <code>help(cv.glmnet)</code>), resulta mucho más cómodo emplear el método <code>"glmnet"</code> de <code>caret</code> (NOTA: en este caso no hace falta indicarle `family = binomial” ya que le pasamos una variable factor como variable respuesta):</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="#cb409-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb409-2"><a href="#cb409-2" aria-hidden="true" tabindex="-1"></a><span class="fu">modelLookup</span>(<span class="st">&quot;glmnet&quot;</span>) </span></code></pre></div>
<pre><code>   model parameter                    label forReg forClass probModel
1 glmnet     alpha        Mixing Percentage   TRUE     TRUE      TRUE
2 glmnet    lambda Regularization Parameter   TRUE     TRUE      TRUE</code></pre>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb411-2"><a href="#cb411-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Se podría emplear train(fidelida ~ ., data = train, ...)</span></span>
<span id="cb411-3"><a href="#cb411-3" aria-hidden="true" tabindex="-1"></a>caret.glmnet <span class="ot">&lt;-</span> <span class="fu">train</span>(x, y, <span class="at">method =</span> <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb411-4"><a href="#cb411-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb411-5"><a href="#cb411-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb411-6"><a href="#cb411-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">.alpha =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),  <span class="co"># optimize an elnet regression</span></span>
<span id="cb411-7"><a href="#cb411-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">.lambda =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="at">length.out =</span> <span class="dv">20</span>)</span>
<span id="cb411-8"><a href="#cb411-8" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb411-9"><a href="#cb411-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-10"><a href="#cb411-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-11"><a href="#cb411-11" aria-hidden="true" tabindex="-1"></a>caret.glmnet</span></code></pre></div>
<pre><code>glmnet 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 359, 359, 359, 360, 359, 359, ... 
Resampling results across tuning parameters:

  alpha      lambda      Accuracy   Kappa    
  0.0000000  0.00000000  0.9575000  0.9070474
  0.0000000  0.01052632  0.9575000  0.9070474
  0.0000000  0.02105263  0.9575000  0.9070474
  0.0000000  0.03157895  0.9575000  0.9070474
  0.0000000  0.04210526  0.9575000  0.9070474
  0.0000000  0.05263158  0.9500000  0.8905369
  0.0000000  0.06315789  0.9475000  0.8846684
  0.0000000  0.07368421  0.9475000  0.8840697
  0.0000000  0.08421053  0.9475000  0.8840697
  0.0000000  0.09473684  0.9475000  0.8840697
  0.0000000  0.10526316  0.9424359  0.8731520
  0.0000000  0.11578947  0.9399359  0.8671269
  0.0000000  0.12631579  0.9399359  0.8671269
  0.0000000  0.13684211  0.9374359  0.8617234
  0.0000000  0.14736842  0.9349359  0.8561699
  0.0000000  0.15789474  0.9349359  0.8561699
  0.0000000  0.16842105  0.9349359  0.8561699
  0.0000000  0.17894737  0.9349359  0.8561699
  0.0000000  0.18947368  0.9299359  0.8444259
  0.0000000  0.20000000  0.9274359  0.8387244
  0.1111111  0.00000000  0.9675000  0.9300161
  0.1111111  0.01052632  0.9750000  0.9457920
  0.1111111  0.02105263  0.9575000  0.9070474
  0.1111111  0.03157895  0.9550000  0.9011875
  0.1111111  0.04210526  0.9500000  0.8902304
  0.1111111  0.05263158  0.9475000  0.8840697
  0.1111111  0.06315789  0.9475000  0.8840697
  0.1111111  0.07368421  0.9475000  0.8840697
  0.1111111  0.08421053  0.9449359  0.8784093
  0.1111111  0.09473684  0.9449359  0.8784093
  0.1111111  0.10526316  0.9449359  0.8784093
  0.1111111  0.11578947  0.9449359  0.8784093
  0.1111111  0.12631579  0.9424359  0.8723842
  0.1111111  0.13684211  0.9399359  0.8668307
  0.1111111  0.14736842  0.9374359  0.8614272
  0.1111111  0.15789474  0.9324359  0.8505967
  0.1111111  0.16842105  0.9324359  0.8496833
  0.1111111  0.17894737  0.9299359  0.8439755
  0.1111111  0.18947368  0.9274359  0.8381070
  0.1111111  0.20000000  0.9274359  0.8381070
  0.2222222  0.00000000  0.9625000  0.9190533
  0.2222222  0.01052632  0.9750000  0.9457920
  0.2222222  0.02105263  0.9600000  0.9121584
  0.2222222  0.03157895  0.9550000  0.9011875
  0.2222222  0.04210526  0.9525000  0.8954917
  0.2222222  0.05263158  0.9475000  0.8840697
  0.2222222  0.06315789  0.9475000  0.8840697
  0.2222222  0.07368421  0.9474359  0.8838147
  0.2222222  0.08421053  0.9474359  0.8838147
  0.2222222  0.09473684  0.9474359  0.8838147
  0.2222222  0.10526316  0.9499359  0.8890778
  0.2222222  0.11578947  0.9499359  0.8890778
  0.2222222  0.12631579  0.9474359  0.8836724
  0.2222222  0.13684211  0.9449359  0.8781189
  0.2222222  0.14736842  0.9424359  0.8724112
  0.2222222  0.15789474  0.9399359  0.8663861
  0.2222222  0.16842105  0.9349359  0.8548098
  0.2222222  0.17894737  0.9349359  0.8548098
  0.2222222  0.18947368  0.9374359  0.8600412
  0.2222222  0.20000000  0.9324359  0.8489281
  0.3333333  0.00000000  0.9625000  0.9190533
  0.3333333  0.01052632  0.9700000  0.9345266
  0.3333333  0.02105263  0.9650000  0.9237261
  0.3333333  0.03157895  0.9575000  0.9067571
  0.3333333  0.04210526  0.9575000  0.9067571
  0.3333333  0.05263158  0.9575000  0.9061517
  0.3333333  0.06315789  0.9550000  0.9005982
  0.3333333  0.07368421  0.9524359  0.8949378
  0.3333333  0.08421053  0.9499359  0.8890778
  0.3333333  0.09473684  0.9474359  0.8836724
  0.3333333  0.10526316  0.9474359  0.8836724
  0.3333333  0.11578947  0.9474359  0.8836724
  0.3333333  0.12631579  0.9449359  0.8782670
  0.3333333  0.13684211  0.9424359  0.8727135
  0.3333333  0.14736842  0.9399359  0.8665406
  0.3333333  0.15789474  0.9374359  0.8606720
  0.3333333  0.16842105  0.9374359  0.8606720
  0.3333333  0.17894737  0.9349359  0.8551185
  0.3333333  0.18947368  0.9324359  0.8490823
  0.3333333  0.20000000  0.9324359  0.8490823
  0.4444444  0.00000000  0.9625000  0.9190533
  0.4444444  0.01052632  0.9725000  0.9403866
  0.4444444  0.02105263  0.9675000  0.9291315
  0.4444444  0.03157895  0.9625000  0.9174256
  0.4444444  0.04210526  0.9600000  0.9120202
  0.4444444  0.05263158  0.9600000  0.9120202
  0.4444444  0.06315789  0.9524359  0.8949378
  0.4444444  0.07368421  0.9499359  0.8890778
  0.4444444  0.08421053  0.9499359  0.8890778
  0.4444444  0.09473684  0.9474359  0.8836724
  0.4444444  0.10526316  0.9474359  0.8836724
  0.4444444  0.11578947  0.9474359  0.8832072
  0.4444444  0.12631579  0.9474359  0.8832072
  0.4444444  0.13684211  0.9374359  0.8609871
  0.4444444  0.14736842  0.9374359  0.8609871
  0.4444444  0.15789474  0.9374359  0.8609871
  0.4444444  0.16842105  0.9349359  0.8551185
  0.4444444  0.17894737  0.9324359  0.8492500
  0.4444444  0.18947368  0.9299359  0.8432138
  0.4444444  0.20000000  0.9274359  0.8373452
  0.5555556  0.00000000  0.9625000  0.9190533
  0.5555556  0.01052632  0.9700000  0.9348331
  0.5555556  0.02105263  0.9650000  0.9231334
  0.5555556  0.03157895  0.9625000  0.9174256
  0.5555556  0.04210526  0.9600000  0.9120202
  0.5555556  0.05263158  0.9575000  0.9064667
  0.5555556  0.06315789  0.9524359  0.8949464
  0.5555556  0.07368421  0.9499359  0.8890778
  0.5555556  0.08421053  0.9474359  0.8836724
  0.5555556  0.09473684  0.9474359  0.8832072
  0.5555556  0.10526316  0.9449359  0.8776537
  0.5555556  0.11578947  0.9449359  0.8776537
  0.5555556  0.12631579  0.9399359  0.8660774
  0.5555556  0.13684211  0.9349359  0.8551185
  0.5555556  0.14736842  0.9349359  0.8551185
  0.5555556  0.15789474  0.9349359  0.8551185
  0.5555556  0.16842105  0.9324359  0.8495650
  0.5555556  0.17894737  0.9199359  0.8200478
  0.5555556  0.18947368  0.9149359  0.8081288
  0.5555556  0.20000000  0.9124359  0.8017349
  0.6666667  0.00000000  0.9600000  0.9137920
  0.6666667  0.01052632  0.9725000  0.9402385
  0.6666667  0.02105263  0.9675000  0.9286869
  0.6666667  0.03157895  0.9625000  0.9174256
  0.6666667  0.04210526  0.9575000  0.9064667
  0.6666667  0.05263158  0.9550000  0.9006068
  0.6666667  0.06315789  0.9524359  0.8949464
  0.6666667  0.07368421  0.9549359  0.9001890
  0.6666667  0.08421053  0.9499359  0.8892301
  0.6666667  0.09473684  0.9449359  0.8776537
  0.6666667  0.10526316  0.9424359  0.8717852
  0.6666667  0.11578947  0.9399359  0.8663798
  0.6666667  0.12631579  0.9324359  0.8495650
  0.6666667  0.13684211  0.9299359  0.8435288
  0.6666667  0.14736842  0.9299359  0.8435288
  0.6666667  0.15789474  0.9224359  0.8259163
  0.6666667  0.16842105  0.9199359  0.8202085
  0.6666667  0.17894737  0.9149359  0.8076035
  0.6666667  0.18947368  0.9099359  0.7961880
  0.6666667  0.20000000  0.9049359  0.7842832
  0.7777778  0.00000000  0.9575000  0.9086749
  0.7777778  0.01052632  0.9725000  0.9402385
  0.7777778  0.02105263  0.9675000  0.9286869
  0.7777778  0.03157895  0.9650000  0.9229791
  0.7777778  0.04210526  0.9575000  0.9064667
  0.7777778  0.05263158  0.9524359  0.8949464
  0.7777778  0.06315789  0.9524359  0.8944812
  0.7777778  0.07368421  0.9499359  0.8890758
  0.7777778  0.08421053  0.9474359  0.8835223
  0.7777778  0.09473684  0.9374359  0.8614375
  0.7777778  0.10526316  0.9374359  0.8614375
  0.7777778  0.11578947  0.9324359  0.8501824
  0.7777778  0.12631579  0.9324359  0.8501824
  0.7777778  0.13684211  0.9299359  0.8444747
  0.7777778  0.14736842  0.9274359  0.8386061
  0.7777778  0.15789474  0.9224359  0.8270298
  0.7777778  0.16842105  0.9199359  0.8205370
  0.7777778  0.17894737  0.9149359  0.8089607
  0.7777778  0.18947368  0.9124359  0.8027495
  0.7777778  0.20000000  0.9049359  0.7842832
  0.8888889  0.00000000  0.9575000  0.9086749
  0.8888889  0.01052632  0.9750000  0.9456439
  0.8888889  0.02105263  0.9675000  0.9286869
  0.8888889  0.03157895  0.9625000  0.9174256
  0.8888889  0.04210526  0.9500000  0.8900863
  0.8888889  0.05263158  0.9474359  0.8845420
  0.8888889  0.06315789  0.9424359  0.8737368
  0.8888889  0.07368421  0.9374359  0.8624851
  0.8888889  0.08421053  0.9374359  0.8624851
  0.8888889  0.09473684  0.9374359  0.8620488
  0.8888889  0.10526316  0.9349359  0.8564953
  0.8888889  0.11578947  0.9374359  0.8622030
  0.8888889  0.12631579  0.9349359  0.8565014
  0.8888889  0.13684211  0.9299359  0.8450921
  0.8888889  0.14736842  0.9224359  0.8274950
  0.8888889  0.15789474  0.9149359  0.8102110
  0.8888889  0.16842105  0.9124359  0.8041747
  0.8888889  0.17894737  0.9124359  0.8032061
  0.8888889  0.18947368  0.9073718  0.7913259
  0.8888889  0.20000000  0.9023718  0.7784392
  1.0000000  0.00000000  0.9550000  0.9035657
  1.0000000  0.01052632  0.9725000  0.9400904
  1.0000000  0.02105263  0.9650000  0.9239989
  1.0000000  0.03157895  0.9525000  0.8962252
  1.0000000  0.04210526  0.9525000  0.8960710
  1.0000000  0.05263158  0.9424359  0.8735983
  1.0000000  0.06315789  0.9399359  0.8681929
  1.0000000  0.07368421  0.9374359  0.8626394
  1.0000000  0.08421053  0.9349359  0.8570859
  1.0000000  0.09473684  0.9324359  0.8518433
  1.0000000  0.10526316  0.9324359  0.8518433
  1.0000000  0.11578947  0.9299359  0.8461418
  1.0000000  0.12631579  0.9349359  0.8565014
  1.0000000  0.13684211  0.9349359  0.8565014
  1.0000000  0.14736842  0.9299359  0.8450921
  1.0000000  0.15789474  0.9224359  0.8276472
  1.0000000  0.16842105  0.9173718  0.8159432
  1.0000000  0.17894737  0.9098718  0.7981742
  1.0000000  0.18947368  0.8998077  0.7740354
  1.0000000  0.20000000  0.8896795  0.7496070

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 0.1111111 and lambda = 0.01052632.</code></pre>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="#cb413-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(caret.glmnet, <span class="at">highlight =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-145-1.png" width="672" /></p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="#cb414-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(caret.glmnet<span class="sc">$</span>finalModel, newx, </span>
<span id="cb414-2"><a href="#cb414-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">type=</span><span class="st">&quot;class&quot;</span>, <span class="at">s =</span> caret.glmnet<span class="sc">$</span>finalModel<span class="sc">$</span>lambdaOpt)</span>
<span id="cb414-3"><a href="#cb414-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb414-4"><a href="#cb414-4" aria-hidden="true" tabindex="-1"></a>xtab <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">as.vector</span>(pred), breast_test_prep<span class="sc">$</span>diagnosis) </span>
<span id="cb414-5"><a href="#cb414-5" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(xtab)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

   
      B   M
  B 104   3
  M   3  60
                                          
               Accuracy : 0.9647          
                 95% CI : (0.9248, 0.9869)
    No Information Rate : 0.6294          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.9243          
                                          
 Mcnemar&#39;s Test P-Value : 1               
                                          
            Sensitivity : 0.9720          
            Specificity : 0.9524          
         Pos Pred Value : 0.9720          
         Neg Pred Value : 0.9524          
             Prevalence : 0.6294          
         Detection Rate : 0.6118          
   Detection Prevalence : 0.6294          
      Balanced Accuracy : 0.9622          
                                          
       &#39;Positive&#39; Class : B               
                                          </code></pre>
<p>Observamos que <code>alpha</code> está cerca de 1 (Lasso) y tiene un <code>alpha</code> un poco mayor que al que se obtiene con la regresión Lasso, pero la matriz de confusión es la misma.</p>
<!--chapter:end:05b-penalizaed_regression.Rmd-->
</div>
</div>
</div>
<div id="dealing-with-big-data-in-r" class="section level1 hasAnchor" number="8">
<h1 class="hasAnchor"><span class="header-section-number">8</span> Dealing with Big Data in R<a href="#dealing-with-big-data-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the era of big data, we can have access to large volumes of data obtained from our population of interest. Traditional algorithms implemented for even the simplest statistical methods (descriptive, linear regression, …) require a lot of computing time. To address this issue, one of the approaches we have is to divide our data into smaller sets that do not require as much computational cost and to combine these results in a clever way that allows us to solve the largest problem. This can be done by parallelizing the calculations since even laptops already have multiple computing cores, and/or combining the calculations with paradigms such as <em>MapReduce</em> that has been designed to deal with Big Data efficiently. In this section we will learn how to:</p>
<ul>
<li>Parallelize in R</li>
<li>Use MapReduce</li>
<li>Implement multiple linear regression in a distributed system using MapReduce paradigm</li>
</ul>
<div id="nodes-cores-processes-and-threads" class="section level2 hasAnchor" number="8.1">
<h2 class="hasAnchor"><span class="header-section-number">8.1</span> Nodes, cores, processes and threads<a href="#nodes-cores-processes-and-threads" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The terminology of nodes, cores, processes and threads is not universal. Depending on the computer, software (etc.), they can have various meanings. Typical examples: socket instead of node; cpu instead of core; task instead of process. Supercomputers have complex architectures, mainly due to their processors capability to work together on the same memory space. More precisely, the smallest computing units, called cores, are grouped in nodes. All the cores in one node share the same memory space. In other terms, the cores of the same node can operate on the same data, at the same time; no need for sending the data back and forth. This hardware architecture is summarized in this figure that shows a simple schematic of a 16-core node. The node contains two CPUs and each CPU consists of 8 cores. The schematic also shows the attached memory and the connections between the CPUs and memory.</p>
<div class="figure">
<img src="figures/hpc_node-cpu-core.png" style="width:50.0%" alt="" />
<p class="caption">Nodes, cores and processors</p>
</div>
<p><strong>Nodes</strong>: Refers to the physical machine/server. In current systems, a node would typically include one or more processors, as well as memory and other hardware.</p>
<p><strong>Processor</strong>: Refers to the central processing unit (CPU), which contains one or more cores.</p>
<p><strong>Cores</strong>: Refers to the basic computation unit of the CPU. This is unit that carries out the actual computations.</p>
<p>So in essence, each compute node contains one or more processors/CPUs and each CPU will typically consist of one or more cores.</p>
</div>
<div id="paralelización" class="section level2 hasAnchor" number="8.2">
<h2 class="hasAnchor"><span class="header-section-number">8.2</span> Paralelización<a href="#paralelización" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When using a single CPU, or serial computing, the problem size is limited by the available memory and performance. As data sizes become larger and systems become more complex, programs/applications rapidly run out of resources. Effectively utilising parallel computing can overcome these limitations. Parallel computing has become essential to solving big problems (high resolution, lots of timesteps, etc.) in science and engineering.</p>
<p>Parallel computing can be simply defined as the simultaneous use of multiple processors/computers, i.e. parallel computers, to solve a computational problem. The general pattern is:</p>
<ul>
<li>The problem is broken down into discrete sections or separate tasks.</li>
<li>Each processor works on its task or section of the problem. With multiple processors this means that several tasks can be processed at any given time.</li>
<li>Processors exchange information with other processors, when required.</li>
</ul>
<p>It allows leveraging the resources of multiple processors/computers, increasing the resources available to the application/software. This enables the execution of tasks that do not fit on a single CPU and the completion of the tasks in a reasonable time. This has many benefits. For instance, we can add more data points which can translate to the use of bigger domains, improved spatial resolution or the inclusion of more particles in a simulation. Faster execution time can translate to increased number of solutions in a given time or a faster time to solution.</p>
<div id="shared-memory-programming" class="section level3 hasAnchor" number="8.2.1">
<h3 class="hasAnchor"><span class="header-section-number">8.2.1</span> Shared Memory Programming<a href="#shared-memory-programming" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Parallel programming for shared memory machines is easier since the all cores have access to the same memory address space and so all have access to the same data structures. This greatly simplifies the task of parallelisation. Use can be made of auto-parallelisation via compiler options, loop-level parallelism through compiler directives or OpenMP. On the other hand, speedup and scalability are limited by the number of cores in the shared memory machine, and this is generally a relatively small number. In addition, code can only be used on a shared memory machine.</p>
</div>
<div id="distributed-memory-programming" class="section level3 hasAnchor" number="8.2.2">
<h3 class="hasAnchor"><span class="header-section-number">8.2.2</span> Distributed Memory Programming<a href="#distributed-memory-programming" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Programming for distributed memory machines provides a means to take advantage of more resources than those available on a shared memory machine. In addition, code developed for distributed memory machines can be used on shared memory machines. However, this type of programming is generally more difficult than shared memory programming. Since each processor only has access to its local memory, the programmer is responsible for mapping data structures across the separate nodes. In addition, there is a need to coordinate the communications between nodes, i.e. message passing, to ensure that a node can access remote data when it is needed for a local computation. The standard library used for this is MPI.</p>
<p>Next figure illustrate the difference between both approaches</p>
<div class="figure">
<img src="figures/shared_distributed_memory.jpg" style="width:70.0%" alt="" />
<p class="caption">Memory Organization: (a) Shared Memory, (b) Distributed Memory</p>
</div>
<p>Doing these tasks in R without strong knowledge in informatics can be hard. However, there are several R packages to perform parallel computing. The reason for using <code>doParallel</code> package, and not <code>parallel</code>, is that the <code>parallel</code> package is not working entirely on Windows and you had to write different code for it to work. The <code>doParallel</code> package is trying to make it happen on all platforms: UNIX, LINUX and WINDOWS, so it’s a pretty decent wrapper. To me, the most simple way of doing parallelization is to use <code>mclapply()</code> function from <code>parallel</code> but this cannot be used in Window.</p>
<p>Let us assume we want to compute <span class="math inline">\(f(x)=x^2 + x\)</span> of 10 numbers stored in a vector called <code>vec</code>.</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="#cb416-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb416-2"><a href="#cb416-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x</span>
<span id="cb416-3"><a href="#cb416-3" aria-hidden="true" tabindex="-1"></a>vec <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">10</span>, <span class="at">lambda=</span><span class="dv">200</span>)</span></code></pre></div>
<p>We can do the following strategies:</p>
<ol style="list-style-type: decimal">
<li>Looping</li>
</ol>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="#cb417-1" aria-hidden="true" tabindex="-1"></a>forFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {  </span>
<span id="cb417-2"><a href="#cb417-2" aria-hidden="true" tabindex="-1"></a>  ans <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="fu">length</span>(x))</span>
<span id="cb417-3"><a href="#cb417-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> vec)</span>
<span id="cb417-4"><a href="#cb417-4" aria-hidden="true" tabindex="-1"></a>   {</span>
<span id="cb417-5"><a href="#cb417-5" aria-hidden="true" tabindex="-1"></a>    ans[i] <span class="ot">&lt;-</span> <span class="fu">f</span>(i)</span>
<span id="cb417-6"><a href="#cb417-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb417-7"><a href="#cb417-7" aria-hidden="true" tabindex="-1"></a>  ans</span>
<span id="cb417-8"><a href="#cb417-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>lapply ()</code> or <code>sapply ()</code> function</li>
</ol>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>lapplyFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb418-2"><a href="#cb418-2" aria-hidden="true" tabindex="-1"></a>  ans <span class="ot">&lt;-</span> <span class="fu">sapply</span>(x, f)</span>
<span id="cb418-3"><a href="#cb418-3" aria-hidden="true" tabindex="-1"></a>  ans</span>
<span id="cb418-4"><a href="#cb418-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Using <code>doParallel::parLapply()</code> function</li>
</ol>
<p>We need first to create the cluster</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="#cb419-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb419-2"><a href="#cb419-2" aria-hidden="true" tabindex="-1"></a>ncores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span>  </span>
<span id="cb419-3"><a href="#cb419-3" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(<span class="at">cores=</span>ncores)  </span>
<span id="cb419-4"><a href="#cb419-4" aria-hidden="true" tabindex="-1"></a>cl <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(ncores) </span></code></pre></div>
<p>Then, we can use the parallel implementation of <code>lapply</code></p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="#cb420-1" aria-hidden="true" tabindex="-1"></a>parLapplyFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(cl, x, f){</span>
<span id="cb420-2"><a href="#cb420-2" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> <span class="fu">parLapply</span>(<span class="at">cl=</span>cl, <span class="at">X=</span>x, <span class="at">fun=</span>f)  </span>
<span id="cb420-3"><a href="#cb420-3" aria-hidden="true" tabindex="-1"></a>  result</span>
<span id="cb420-4"><a href="#cb420-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>doParallel::foreach()</code> function</li>
</ol>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="#cb421-1" aria-hidden="true" tabindex="-1"></a>foreachDoParFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb421-2"><a href="#cb421-2" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> <span class="fu">foreach</span>(<span class="at">i=</span>x, <span class="at">.export=</span><span class="st">&quot;f&quot;</span>) <span class="sc">%dopar%</span> <span class="fu">f</span>(i)</span>
<span id="cb421-3"><a href="#cb421-3" aria-hidden="true" tabindex="-1"></a>  result</span>
<span id="cb421-4"><a href="#cb421-4" aria-hidden="true" tabindex="-1"></a>}  </span></code></pre></div>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="#cb422-1" aria-hidden="true" tabindex="-1"></a>foreachDoFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb422-2"><a href="#cb422-2" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> <span class="fu">foreach</span>(<span class="at">i=</span>x, <span class="at">.export=</span><span class="st">&quot;f&quot;</span>) <span class="sc">%do%</span> <span class="fu">f</span>(i)</span>
<span id="cb422-3"><a href="#cb422-3" aria-hidden="true" tabindex="-1"></a>  result</span>
<span id="cb422-4"><a href="#cb422-4" aria-hidden="true" tabindex="-1"></a>}  </span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li>Using <code>parallel::mclapply()</code> function</li>
</ol>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Only works in Linux (Windows ncores must be set equal to 1)</span></span>
<span id="cb423-2"><a href="#cb423-2" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">mclapply</span>(x, f, <span class="at">mc.cores=</span>ncores)</span></code></pre></div>
<p>In order to compare computation time, we can run</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(result <span class="ot">&lt;-</span> <span class="fu">lapply</span>(vec, f))</span></code></pre></div>
<pre><code>   user  system elapsed 
      0       0       0 </code></pre>
<p>Nonetheless, <code>rbenchmark</code> function serves as a more accurate replacement of the often seen <code>system.time()</code> function and the more sophisticated <code>system.time(replicate(1000, expr))</code> expression (that incorporates variability). It tries hard to accurately measure only the time it takes to evaluate expr. To achieved this, the sub-millisecond (supposedly nanosecond) accurate timing functions most modern operating systems provide are used. Additionally all evaluations of the expressions are done in C code to minimize any overhead. In our example:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rbenchmark)</span>
<span id="cb426-2"><a href="#cb426-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb426-3"><a href="#cb426-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-4"><a href="#cb426-4" aria-hidden="true" tabindex="-1"></a>ncores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span>  </span>
<span id="cb426-5"><a href="#cb426-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(<span class="at">cores=</span>ncores)  </span>
<span id="cb426-6"><a href="#cb426-6" aria-hidden="true" tabindex="-1"></a>cl <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(ncores) </span>
<span id="cb426-7"><a href="#cb426-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-8"><a href="#cb426-8" aria-hidden="true" tabindex="-1"></a>testdata1 <span class="ot">&lt;-</span> <span class="fu">benchmark</span>(<span class="st">&quot;For loop&quot;</span> <span class="ot">=</span> <span class="fu">forFunction</span>(vec),</span>
<span id="cb426-9"><a href="#cb426-9" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;lapply&quot;</span> <span class="ot">=</span> <span class="fu">lapplyFunction</span>(vec),</span>
<span id="cb426-10"><a href="#cb426-10" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;Foreach dopar&quot;</span> <span class="ot">=</span> <span class="fu">foreachDoParFunction</span>(vec),</span>
<span id="cb426-11"><a href="#cb426-11" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;Foreach do&quot;</span> <span class="ot">=</span> <span class="fu">foreachDoFunction</span>(vec),</span>
<span id="cb426-12"><a href="#cb426-12" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;parLapply&quot;</span> <span class="ot">=</span> <span class="fu">parLapplyFunction</span>(<span class="at">cl=</span>cl, <span class="at">x=</span>vec, <span class="at">f=</span>f),</span>
<span id="cb426-13"><a href="#cb426-13" aria-hidden="true" tabindex="-1"></a>                      <span class="at">columns=</span><span class="fu">c</span>(<span class="st">&#39;test&#39;</span>, <span class="st">&#39;elapsed&#39;</span>, <span class="st">&#39;replications&#39;</span>),</span>
<span id="cb426-14"><a href="#cb426-14" aria-hidden="true" tabindex="-1"></a>                      <span class="at">replications =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">500</span>))</span>
<span id="cb426-15"><a href="#cb426-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-16"><a href="#cb426-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-17"><a href="#cb426-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-18"><a href="#cb426-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-19"><a href="#cb426-19" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb426-20"><a href="#cb426-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> replications, <span class="at">y =</span> elapsed, <span class="at">colour =</span> test), <span class="at">data =</span> testdata1)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-147-1.png" width="672" /></p>
<p>Another example could be to compare the performance of the five methods for matrix multiplication</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb427-2"><a href="#cb427-2" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">20</span>), <span class="at">nrow=</span><span class="dv">4</span>, <span class="at">ncol=</span><span class="dv">5</span>)</span>
<span id="cb427-3"><a href="#cb427-3" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">20</span>), <span class="at">nrow=</span><span class="dv">4</span>, <span class="at">ncol=</span><span class="dv">5</span>)</span>
<span id="cb427-4"><a href="#cb427-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-5"><a href="#cb427-5" aria-hidden="true" tabindex="-1"></a>FUN <span class="ot">&lt;-</span> <span class="cf">function</span>(i, A, B){</span>
<span id="cb427-6"><a href="#cb427-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">crossprod</span>(A,B)</span>
<span id="cb427-7"><a href="#cb427-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb427-8"><a href="#cb427-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-9"><a href="#cb427-9" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">as.list</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb427-10"><a href="#cb427-10" aria-hidden="true" tabindex="-1"></a>testdata2 <span class="ot">&lt;-</span> <span class="fu">benchmark</span>(<span class="st">&quot;For loop&quot;</span> <span class="ot">=</span> <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a)){<span class="fu">FUN</span>(i, A, B)},</span>
<span id="cb427-11"><a href="#cb427-11" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;lapply&quot;</span> <span class="ot">=</span> <span class="fu">lapply</span>(a, <span class="at">FUN =</span> FUN, <span class="at">A=</span>A, <span class="at">B=</span>B), </span>
<span id="cb427-12"><a href="#cb427-12" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;Foreach dopar&quot;</span> <span class="ot">=</span> <span class="fu">foreach</span>(<span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%dopar%</span> <span class="fu">FUN</span>(i, A, B),</span>
<span id="cb427-13"><a href="#cb427-13" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;Foreach do&quot;</span> <span class="ot">=</span> <span class="fu">foreach</span>(<span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%do%</span> <span class="fu">FUN</span>(i, A, B),</span>
<span id="cb427-14"><a href="#cb427-14" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;parLapply&quot;</span> <span class="ot">=</span> <span class="fu">parLapply</span>(<span class="at">cl =</span> cl, <span class="at">X =</span> a, <span class="at">fun =</span> FUN, <span class="at">A=</span>A, <span class="at">B=</span>B),</span>
<span id="cb427-15"><a href="#cb427-15" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;parSapply&quot;</span> <span class="ot">=</span> <span class="fu">parSapply</span>(<span class="at">cl =</span> cl, <span class="at">X =</span> a, <span class="at">FUN =</span> FUN, <span class="at">A=</span>A, <span class="at">B=</span>B),</span>
<span id="cb427-16"><a href="#cb427-16" aria-hidden="true" tabindex="-1"></a>                       <span class="at">columns=</span><span class="fu">c</span>(<span class="st">&#39;test&#39;</span>, <span class="st">&#39;elapsed&#39;</span>, <span class="st">&#39;replications&#39;</span>),</span>
<span id="cb427-17"><a href="#cb427-17" aria-hidden="true" tabindex="-1"></a>                       <span class="at">replications =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">500</span>))</span>
<span id="cb427-18"><a href="#cb427-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-19"><a href="#cb427-19" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb427-20"><a href="#cb427-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> replications, <span class="at">y =</span> elapsed, <span class="at">colour =</span> test), <span class="at">data =</span> testdata2)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-148-1.png" width="672" /></p>
<p>Finally, we could also compare the performance of the five methods for fitting generalized linear model</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="#cb428-1" aria-hidden="true" tabindex="-1"></a>FUN <span class="ot">&lt;-</span> <span class="cf">function</span>(i) {</span>
<span id="cb428-2"><a href="#cb428-2" aria-hidden="true" tabindex="-1"></a>  ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">100</span>, <span class="dv">100</span>, <span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb428-3"><a href="#cb428-3" aria-hidden="true" tabindex="-1"></a>  mod <span class="ot">&lt;-</span> <span class="fu">glm</span>(Species <span class="sc">~</span> Sepal.Length, <span class="at">family=</span><span class="fu">binomial</span>(logit), <span class="at">data =</span> iris[ind,])</span>
<span id="cb428-4"><a href="#cb428-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coefficients</span>(mod)</span>
<span id="cb428-5"><a href="#cb428-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb428-6"><a href="#cb428-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb428-7"><a href="#cb428-7" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">as.list</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb428-8"><a href="#cb428-8" aria-hidden="true" tabindex="-1"></a>testdata3 <span class="ot">&lt;-</span> <span class="fu">benchmark</span>(<span class="st">&quot;For loop&quot;</span> <span class="ot">=</span> <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(a)){ <span class="fu">FUN</span>(a[[i]])},</span>
<span id="cb428-9"><a href="#cb428-9" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;lapply&quot;</span> <span class="ot">=</span> <span class="fu">lapply</span>(a, <span class="at">FUN =</span> FUN), </span>
<span id="cb428-10"><a href="#cb428-10" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;Foreach dopar&quot;</span> <span class="ot">=</span> <span class="fu">foreach</span>(<span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%dopar%</span> <span class="fu">FUN</span>(i),</span>
<span id="cb428-11"><a href="#cb428-11" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;Foreach do&quot;</span> <span class="ot">=</span> <span class="fu">foreach</span>(<span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%do%</span> <span class="fu">FUN</span>(i),</span>
<span id="cb428-12"><a href="#cb428-12" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;parLapply&quot;</span> <span class="ot">=</span> <span class="fu">parLapply</span>(<span class="at">cl =</span> cl, <span class="at">X =</span> a, <span class="at">fun =</span> FUN),</span>
<span id="cb428-13"><a href="#cb428-13" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;parSapply&quot;</span> <span class="ot">=</span> <span class="fu">parSapply</span>(<span class="at">cl =</span> cl, <span class="at">X =</span> a, <span class="at">FUN =</span> FUN),</span>
<span id="cb428-14"><a href="#cb428-14" aria-hidden="true" tabindex="-1"></a>                       <span class="at">columns=</span><span class="fu">c</span>(<span class="st">&#39;test&#39;</span>, <span class="st">&#39;elapsed&#39;</span>, <span class="st">&#39;replications&#39;</span>),</span>
<span id="cb428-15"><a href="#cb428-15" aria-hidden="true" tabindex="-1"></a>                       <span class="at">replications =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">500</span>))</span>
<span id="cb428-16"><a href="#cb428-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb428-17"><a href="#cb428-17" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb428-18"><a href="#cb428-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> replications, <span class="at">y =</span> elapsed, <span class="at">colour =</span> test), <span class="at">data =</span> testdata3)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-149-1.png" width="672" /></p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cl)</span></code></pre></div>
<p>To sum up, generally, <code>parLapply ()</code> perform better than <code>foreach ()</code>. However, for all parallel implementation methods, the increase in terms of efficiency is not proportional to the number of cores being used (Theoretical efficiency).</p>
</div>
</div>
<div id="mapreduce" class="section level2 hasAnchor" number="8.3">
<h2 class="hasAnchor"><span class="header-section-number">8.3</span> MapReduce<a href="#mapreduce" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster. A MapReduce program is composed of a map procedure, which performs filtering and sorting (such as sorting students by first name into queues, one queue for each name), and a reduce method, which performs a summary operation (such as counting the number of students in each queue, yielding name frequencies). The “MapReduce System” (also called “infrastructure” or “framework”) orchestrates the processing by marshalling the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, and providing for redundancy and fault tolerance. The model is a specialization of the split-apply-combine strategy for data analysis. It is inspired by the map and reduce functions commonly used in <a href="https://en.wikipedia.org/wiki/Functional_programming">functional programming</a>. There are two main frameworks to deal with Big Data and where MapReduce can be applied efficiently</p>
<ul>
<li><strong><a href="https://hadoop.apache.org/">Hadoop</a></strong> provides support to perform MapReduce operations over a distributed file system of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage.</li>
<li><strong><a href="https://spark.apache.org/">Spark</a></strong> provides a richer set of verbs beyond MapReduce to facilitate optimizing code running in multiple machines. Spark also loaded data in-memory, making operations much faster than Hadoop’s on-disk storage.</li>
</ul>
<p>Thre are some pacakges to connect R and both <a href="https://datascienceplus.com/integrating-r-with-apache-hadoop/">Hadoop</a> and <a href="https://spark.apache.org/docs/latest/sparkr.html">Spark</a>, but they use is beyond the scope of this short introduction to Big Data analysis.</p>
<p>Next figure illustrate how to use MapReduce to count words in two different text files stored in different machines. The map operation splits each word in the original file and outputs a new word-counting file with a mapping of words and counts. The reduce operation can be defined to take two word-counting files and combine them by aggregating the totals for each word; this last file will contain a list of word counts across all the original files. Counting words is often the most basic MapReduce example, but we can also use MapReduce for much more sophisticated and interesting applications in statistics.</p>
<p><img src="figures/mapreduce.png" style="width:60.0%" alt="MapReduce example counting words across files" />
The MapReduce paradigm has long been a staple of big data computational strategies. However, properly leveraging MapReduce in R can be a challenge, even for experienced users. To get the most out of MapReduce, it is helpful to understand its relationship to functional programming. Functional programming, in a broad sense, is the one that some functions allows to have another function in one of its arguments. For instance, the function <code>sapply()</code>:</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="#cb430-1" aria-hidden="true" tabindex="-1"></a>ff <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="cf">if</span>(x <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="fu">log</span>(x) <span class="cf">else</span> <span class="fu">log</span>(<span class="sc">-</span>x)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb430-2"><a href="#cb430-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">10</span>, ff)</span></code></pre></div>
<pre><code> [1] 1.9218121 1.2069490 0.4804530 0.0000000       Inf 0.0000000 0.6931472 1.0986123 1.3862944
[10] 1.6094379 1.7917595 1.9459101 2.0794415 2.1972246 2.3025851</code></pre>
<p>Functional programming is a very powerful tool that allows you to program in the following way:</p>
<ul>
<li>Create small and simple functions that solve a small and bounded problem</li>
<li>Apply these functions to homogeneous groups of values.</li>
</ul>
<p>In the previous example, we have built an <code>ff</code> function and through the <code>sapply ()</code> function we have applied it to a list of homogeneous values: the numbers from -4 to 10.</p>
<p>There are many functions in R, some of which you have already seen, that take others as arguments. Some of the most common are:</p>
<ul>
<li>sapply y lapply</li>
<li>tapply</li>
<li>apply y mapply</li>
<li>Las funciones ddply, ldply, etc. del paquete <code>plyr</code></li>
</ul>
<p>A very common example of this type of functions is used to inspect the type of columns in a table since they take advantage of the fact that a table is a list of columns and go through them one by one</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="#cb432-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(iris, class)</span></code></pre></div>
<pre><code>$Sepal.Length
[1] &quot;numeric&quot;

$Sepal.Width
[1] &quot;numeric&quot;

$Petal.Length
[1] &quot;numeric&quot;

$Petal.Width
[1] &quot;numeric&quot;

$Species
[1] &quot;factor&quot;

$Y
[1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(iris, length)</span></code></pre></div>
<pre><code>Sepal.Length  Sepal.Width Petal.Length  Petal.Width      Species            Y 
         150          150          150          150          150          150 </code></pre>
<p>One of the advantages of this type of programming is that the code is shorter and more readable. We must remember that these functions include the argument <code>...</code> that allows to pass additional arguments to the function they call. For example this function would do the same as the previous one, but it would be more generic since it would allow calculations by varying the <code>s</code> argument.</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="#cb436-1" aria-hidden="true" tabindex="-1"></a>ff2 <span class="ot">&lt;-</span> <span class="cf">function</span>(x, s) {</span>
<span id="cb436-2"><a href="#cb436-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(x <span class="sc">&gt;</span> s) <span class="fu">log</span>(x) <span class="cf">else</span> <span class="fu">log</span>(<span class="sc">-</span>x)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb436-3"><a href="#cb436-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb436-4"><a href="#cb436-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(<span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">10</span>, ff2, <span class="at">s=</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code> [1] 1.9218121 1.2069490 0.4804530 0.0000000       Inf 0.0000000 0.6931472 1.0986123 1.3862944
[10] 1.6094379 1.7917595 1.9459101 2.0794415 2.1972246 2.3025851</code></pre>
<div id="map" class="section level3 hasAnchor" number="8.3.1">
<h3 class="hasAnchor"><span class="header-section-number">8.3.1</span> Map<a href="#map" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The MapReduce methodology is also implemented in base R (<code>Map ()</code> and <code>Reduce ()</code> functions) as well as in <code>tidyverse</code>. Function <code>Map ()</code> applies one function to all elements from a list o vector:</p>
<p><code>map(YOUR_LIST, YOUR_FUNCTION)</code></p>
<p>or, graphically:</p>
<div class="figure">
<img src="figures/map.png" style="width:30.0%" alt="" />
<p class="caption">Map</p>
</div>
<p>Previous operations could also be executed by using this code (<code>sapply ()</code> es un caso especial de la función <code>Map ()</code>):</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Map</span>(ff, <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">16</span>, <span class="dv">25</span>))</span></code></pre></div>
<pre><code>[[1]]
[1] 2.197225

[[2]]
[1] 2.772589

[[3]]
[1] 3.218876</code></pre>
<p>y</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="#cb440-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Map</span>(ff2, <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">16</span>, <span class="dv">25</span>), <span class="at">s=</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code>[[1]]
[1] 2.197225

[[2]]
[1] 2.772589

[[3]]
[1] 3.218876</code></pre>
<p>Another advantage appears when we want to <strong>vary more than one argument</strong>. With <code>lapply ()</code>, only one argument varies; the others are fixed. For example, how would you find a weighted mean when you have two lists, one of observations and the other of weights?</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="#cb442-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data</span></span>
<span id="cb442-2"><a href="#cb442-2" aria-hidden="true" tabindex="-1"></a>xs <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">5</span>, <span class="fu">runif</span>(<span class="dv">10</span>), <span class="at">simplify =</span> <span class="cn">FALSE</span>)</span>
<span id="cb442-3"><a href="#cb442-3" aria-hidden="true" tabindex="-1"></a>ws <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">5</span>, <span class="fu">rpois</span>(<span class="dv">10</span>, <span class="dv">5</span>) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">simplify =</span> <span class="cn">FALSE</span>)</span>
<span id="cb442-4"><a href="#cb442-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(xs)</span></code></pre></div>
<pre><code>List of 5
 $ : num [1:10] 0.767 0.671 0.909 0.198 0.436 ...
 $ : num [1:10] 0.296 0.306 0.126 0.518 0.831 ...
 $ : num [1:10] 0.607 0.6956 0.1348 0.0715 0.1021 ...
 $ : num [1:10] 0.655 0.107 0.925 0.557 0.742 ...
 $ : num [1:10] 0.149 0.47 0.668 0.194 0.451 ...</code></pre>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="#cb444-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(ws)</span></code></pre></div>
<pre><code>List of 5
 $ : num [1:10] 6 3 5 4 8 13 5 5 3 5
 $ : num [1:10] 3 9 6 5 6 4 6 6 6 5
 $ : num [1:10] 3 14 12 4 8 8 4 8 3 4
 $ : num [1:10] 7 7 8 5 9 7 6 6 8 4
 $ : num [1:10] 4 5 7 4 3 4 8 4 4 7</code></pre>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="#cb446-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the weighted.mean</span></span>
<span id="cb446-2"><a href="#cb446-2" aria-hidden="true" tabindex="-1"></a><span class="fu">unlist</span>(<span class="fu">Map</span>(weighted.mean, xs, ws))</span></code></pre></div>
<pre><code>[1] 0.4676235 0.5447004 0.3928258 0.4760168 0.5505697</code></pre>
<p>If some of the arguments should be fixed and constant, use an anonymous function:</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="#cb448-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Map</span>(<span class="cf">function</span>(x, w) <span class="fu">weighted.mean</span>(x, w, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), xs, ws)</span></code></pre></div>
<pre><code>[[1]]
[1] 0.4676235

[[2]]
[1] 0.5447004

[[3]]
[1] 0.3928258

[[4]]
[1] 0.4760168

[[5]]
[1] 0.5505697</code></pre>
</div>
<div id="reduce" class="section level3 hasAnchor" number="8.3.2">
<h3 class="hasAnchor"><span class="header-section-number">8.3.2</span> Reduce<a href="#reduce" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another way of thinking about functionals is as a set of general tools for altering, subsetting, and collapsing lists. Every functional programming language has three tools for this: <code>Map()</code>, <code>Reduce()</code>, and <code>Filter()</code>. We have seen <code>Map()</code> already, and next we describe <code>Reduce()</code>, a powerful tool for extending two-argument functions. <code>Filter()</code> is a member of an important class of functionals that work with predicates, functions that return a single TRUE or FALSE (we will not cover that).</p>
<p><code>Reduce()</code> reduces a vector, x, to a single value by recursively calling a function, f, two arguments at a time. It combines the first two elements with f, then combines the result of that call with the third element, and so on. Calling <code>Reduce(f, 1:3)</code> is equivalent to <code>f(f(1, 2), 3)</code></p>
<div class="figure">
<img src="figures/reduce.png" style="width:40.0%" alt="" />
<p class="caption">Reduce</p>
</div>
<p>The following two examples show what Reduce does with an infix and prefix function:</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Reduce</span>(<span class="st">`</span><span class="at">+</span><span class="st">`</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) <span class="co"># -&gt; ((1 + 2) + 3)</span></span></code></pre></div>
<pre><code>[1] 6</code></pre>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Reduce</span>(sum, <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) <span class="co"># -&gt; sum(sum(1, 2), 3)</span></span></code></pre></div>
<pre><code>[1] 6</code></pre>
<p>The essence of <code>Reduce()</code> can be described by a simple for loop:</p>
<pre><code>Reduce2 &lt;- function(f, x) {
  out &lt;- x[[1]]
  for(i in seq(2, length(x))) {
    out &lt;- f(out, x[[i]])
  }
  out
}</code></pre>
<p><code>Reduce()</code> is also an elegant way of extending a function that works with two inputs into a function that can deal with any number of inputs. It is useful for implementing many types of recursive operations, like merges and intersections. Imagine you have a list of numeric vectors, and you want to find the values that occur in every element:</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="#cb455-1" aria-hidden="true" tabindex="-1"></a>l <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">5</span>, <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="at">replace =</span> T), <span class="at">simplify =</span> <span class="cn">FALSE</span>)</span>
<span id="cb455-2"><a href="#cb455-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(l)</span></code></pre></div>
<pre><code>List of 5
 $ : int [1:15] 9 7 9 6 6 6 10 4 3 8 ...
 $ : int [1:15] 8 3 7 1 9 5 3 8 10 7 ...
 $ : int [1:15] 8 6 9 8 9 3 9 10 9 4 ...
 $ : int [1:15] 7 4 10 8 6 6 3 7 6 4 ...
 $ : int [1:15] 10 7 8 10 5 1 6 9 6 8 ...</code></pre>
<p>You could do that by intersecting each element in turn:</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="#cb457-1" aria-hidden="true" tabindex="-1"></a><span class="fu">intersect</span>(<span class="fu">intersect</span>(<span class="fu">intersect</span>(<span class="fu">intersect</span>(l[[<span class="dv">1</span>]], l[[<span class="dv">2</span>]]),</span>
<span id="cb457-2"><a href="#cb457-2" aria-hidden="true" tabindex="-1"></a>                              l[[<span class="dv">3</span>]]), l[[<span class="dv">4</span>]]), l[[<span class="dv">5</span>]])</span></code></pre></div>
<pre><code>[1]  9  6 10  8</code></pre>
<p>That’s hard to read. With <code>Reduce()</code>, the equivalent is:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="#cb459-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Reduce</span>(intersect, l)</span></code></pre></div>
<pre><code>[1]  9  6 10  8</code></pre>
</div>
</div>
<div id="example-linear-regression-for-big-data" class="section level2 hasAnchor" number="8.4">
<h2 class="hasAnchor"><span class="header-section-number">8.4</span> Example: Linear regression for Big Data<a href="#example-linear-regression-for-big-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we describe a very nice application of MapReduce framework to a Big Data problem.</p>
<p>There are several problems that require the analysis of large volumes of information. The analysis at very large scale of data is a challenging task since the available information cannot be practically analyzed on a single machine due to the sheer size of the data to fit in memory. In order to overcome this difficulty, high-performance analytical systems running on distributed environments can be used. To this end standard analytics algorithms need to be adapted to take advantage of cloud computing models which provide scalability and flexibility. Here, we describe an approach that introduces a new distributed training method for Multiple Linear Regression which will be based on the QR decomposition and the ordinary least squares method adapted to MapReduce framework. The method is called MLR-MR and is described in (<a href="https://ieeexplore.ieee.org/document/7345473">Moufida Adjout Rehab and Faouzi Boufares, 2105</a>). The paper is also available in our Moodle.</p>
<p>In this figure we can observe as the model fitting using MLR-MR algorithm is dramatically reduced when the number of MapReduce processors increases.</p>
<div class="figure">
<img src="figures/MLR-MR_time.png" style="width:50.0%" alt="" />
<p class="caption">Speedup training MLR-MR with different MapReduce working nodes</p>
</div>
<p>Let us start by recalling how to describe linear regression using the classical matrix notation:</p>
<p><span class="math display">\[\mathbf{Y}=\mathbf{X}\mathbf{\beta}+\mathbf{\varepsilon}.\]</span></p>
<p>The ordinary least square (OLS) estimate of <span class="math inline">\(\mathbf{\beta}\)</span> is <span class="math display">\[\widehat{\mathbf{\beta}}=[\mathbf{X}^T\mathbf{X}]^{-1}\mathbf{X}^T\mathbf{y}\]</span>. To illustrate, let us consider the “mtcars” example, and run this regression:</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="#cb461-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb461-2"><a href="#cb461-2" aria-hidden="true" tabindex="-1"></a>(mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> cyl, <span class="at">data =</span> mtcars))</span></code></pre></div>
<pre><code>
Call:
lm(formula = mpg ~ wt + cyl, data = mtcars)

Coefficients:
(Intercept)           wt          cyl  
     39.686       -3.191       -1.508  </code></pre>
<p>The algorithm implemented in the <code>lm ()</code> function uses the QR decomposition of <span class="math inline">\(\mathbf{X},\)</span> <span class="math display">\[\mathbf{X}=\mathbf{Q}\mathbf{R},\]</span> where <span class="math inline">\(\mathbf{Q}\)</span> is an orthogonal matrix (i.e. <span class="math inline">\(\mathbf{Q}^T\mathbf{Q}=\mathbb{I}\)</span>).Then,</p>
<p><span class="math display">\[\widehat{\mathbf{\beta}}=[\mathbf{X}^T\mathbf{X}]^{-1}\mathbf{X}^T\mathbf{y}=\mathbf{R}^{-1}\mathbf{Q}^T\mathbf{y}\]</span></p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="#cb463-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>mpg</span>
<span id="cb463-2"><a href="#cb463-2" aria-hidden="true" tabindex="-1"></a><span class="co">#similar to cbind(1, mtcars$wt, mtcars$cyl)</span></span>
<span id="cb463-3"><a href="#cb463-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> wt <span class="sc">+</span> cyl, <span class="at">data=</span>mtcars)</span>
<span id="cb463-4"><a href="#cb463-4" aria-hidden="true" tabindex="-1"></a>QR <span class="ot">&lt;-</span> <span class="fu">qr</span>(<span class="fu">as.matrix</span>(X))</span>
<span id="cb463-5"><a href="#cb463-5" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">qr.R</span>(QR)</span>
<span id="cb463-6"><a href="#cb463-6" aria-hidden="true" tabindex="-1"></a>Q <span class="ot">&lt;-</span> <span class="fu">qr.Q</span>(QR)</span>
<span id="cb463-7"><a href="#cb463-7" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(R) <span class="sc">%*%</span> <span class="fu">t</span>(Q) <span class="sc">%*%</span> Y</span></code></pre></div>
<pre><code>                 [,1]
(Intercept) 39.686261
wt          -3.190972
cyl         -1.507795</code></pre>
<p>We can parallelise computations using the MLR-MR method as follows:</p>
<p>Consider <span class="math inline">\(m\)</span> blocks, for instance 3 (given tha we have 4 cores)</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="#cb465-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">3</span></span></code></pre></div>
<p>and split vectors and matrices</p>
<p><span class="math display">\[\mathbf{y}=\left[\begin{matrix}\mathbf{y}_1\\\mathbf{y}_2\\\vdots \\\mathbf{y}_m\end{matrix}\right]\]</span></p>
<p>and</p>
<p><span class="math display">\[\mathbf{X}=\left[\begin{matrix}\mathbf{X}_1\\\mathbf{X}_2\\\vdots\\\mathbf{X}_m\end{matrix}\right]=\left[\begin{matrix}\mathbf{Q}_1^{(1)}\mathbf{R}_1^{(1)}\\\mathbf{Q}_2^{(1)}\mathbf{R}_2^{(1)}\\\vdots \\\mathbf{Q}_m^{(1)}\mathbf{R}_m^{(1)}\end{matrix}\right]\]</span></p>
<p>In R to split vectors and matrices we can use these two functions:</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="#cb466-1" aria-hidden="true" tabindex="-1"></a>chunk <span class="ot">&lt;-</span> <span class="cf">function</span>(x,n) <span class="fu">split</span>(x, <span class="fu">cut</span>(<span class="fu">seq_along</span>(x), n, <span class="at">labels =</span> <span class="cn">FALSE</span>)) </span>
<span id="cb466-2"><a href="#cb466-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb466-3"><a href="#cb466-3" aria-hidden="true" tabindex="-1"></a>splitMatByRow <span class="ot">=</span> <span class="cf">function</span>(mat, size){</span>
<span id="cb466-4"><a href="#cb466-4" aria-hidden="true" tabindex="-1"></a>  row.index <span class="ot">&lt;-</span> <span class="fu">chunk</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(mat), size)</span>
<span id="cb466-5"><a href="#cb466-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(row.index, <span class="cf">function</span>(val) mat[val, ])</span>
<span id="cb466-6"><a href="#cb466-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can do that with our data</p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="#cb467-1" aria-hidden="true" tabindex="-1"></a>x.block <span class="ot">&lt;-</span> <span class="fu">splitMatByRow</span>(X, m)</span>
<span id="cb467-2"><a href="#cb467-2" aria-hidden="true" tabindex="-1"></a>y.block <span class="ot">&lt;-</span> <span class="fu">splitMatByRow</span>(<span class="fu">matrix</span>(Y, <span class="at">ncol =</span> <span class="dv">1</span>), m)</span></code></pre></div>
<p>Then, we get small QR decomposition (per subset). This step correspond to de <strong>Map</strong> step in the <code>MapReduce</code> framework</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="#cb468-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm 2 Mapper function in step1</span></span>
<span id="cb468-2"><a href="#cb468-2" aria-hidden="true" tabindex="-1"></a>getQR <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb468-3"><a href="#cb468-3" aria-hidden="true" tabindex="-1"></a>  qrresult <span class="ot">&lt;-</span> <span class="fu">qr</span>(x)</span>
<span id="cb468-4"><a href="#cb468-4" aria-hidden="true" tabindex="-1"></a>  ans <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">Q=</span><span class="fu">qr.Q</span>(qrresult), <span class="at">R=</span><span class="fu">qr.R</span>(qrresult))</span>
<span id="cb468-5"><a href="#cb468-5" aria-hidden="true" tabindex="-1"></a>  ans</span>
<span id="cb468-6"><a href="#cb468-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb468-7"><a href="#cb468-7" aria-hidden="true" tabindex="-1"></a>x.block.qr <span class="ot">&lt;-</span> <span class="fu">Map</span>(getQR, x.block)</span></code></pre></div>
<p>Now, consider the QR decomposition of <span class="math inline">\(\mathbf{R}^{(1)}\)</span> which is the first step of the reduce part</p>
<p><span class="math display">\[\mathbf{R}^{(1)}=\left[\begin{matrix}\mathbf{R}_1^{(1)}\\\mathbf{R}_2^{(1)}\\\vdots \\\mathbf{R}_m^{(1)}\end{matrix}\right]=\mathbf{Q}^{(2)}\mathbf{R}^{(2)}\]</span> where</p>
<p><span class="math display">\[\mathbf{Q}^{(2)}=\left[\begin{matrix}\mathbf{Q}^{(2)}_1\\\mathbf{Q}^{(2)}_2\\\vdots\\\mathbf{Q}^{(2)}_m\end{matrix}\right]\]</span></p>
<p>that can be computed as</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="#cb469-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm 3 Reducer function in step1</span></span>
<span id="cb469-2"><a href="#cb469-2" aria-hidden="true" tabindex="-1"></a>Rs <span class="ot">&lt;-</span> <span class="fu">Map</span>(<span class="cf">function</span> (l) l<span class="sc">$</span>R, x.block.qr)</span>
<span id="cb469-3"><a href="#cb469-3" aria-hidden="true" tabindex="-1"></a>Rtemp <span class="ot">&lt;-</span> <span class="fu">Reduce</span>(rbind, Rs)</span>
<span id="cb469-4"><a href="#cb469-4" aria-hidden="true" tabindex="-1"></a>qrresult <span class="ot">&lt;-</span> <span class="fu">qr</span>(Rtemp)</span>
<span id="cb469-5"><a href="#cb469-5" aria-hidden="true" tabindex="-1"></a>Rtemp.qr <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">Q=</span><span class="fu">qr.Q</span>(qrresult), <span class="at">R=</span><span class="fu">qr.R</span>(qrresult))</span>
<span id="cb469-6"><a href="#cb469-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb469-7"><a href="#cb469-7" aria-hidden="true" tabindex="-1"></a>R.final <span class="ot">&lt;-</span> Rtemp.qr<span class="sc">$</span>R</span>
<span id="cb469-8"><a href="#cb469-8" aria-hidden="true" tabindex="-1"></a>Rtemp.Q.divide <span class="ot">&lt;-</span> <span class="fu">splitMatByRow</span>(Rtemp.qr<span class="sc">$</span>Q, m)</span></code></pre></div>
<p>Define – as step 2 of the reduce part</p>
<p><span class="math display">\[\mathbf{Q}^{(3)}_j=\mathbf{Q}^{(2)}_j\mathbf{Q}^{(1)}_j\]</span></p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="#cb470-1" aria-hidden="true" tabindex="-1"></a>Q.result <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb470-2"><a href="#cb470-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m){</span>
<span id="cb470-3"><a href="#cb470-3" aria-hidden="true" tabindex="-1"></a>  Q.result[[i]] <span class="ot">&lt;-</span> x.block.qr[[i]]<span class="sc">$</span>Q <span class="sc">%*%</span> Rtemp.Q.divide[[i]]</span>
<span id="cb470-4"><a href="#cb470-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>and</p>
<p><span class="math display">\[\mathbf{V}_j=\mathbf{Q}^{(3)T}_j\mathbf{y}_j\]</span></p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="#cb471-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm 4 Reduce function in step2</span></span>
<span id="cb471-2"><a href="#cb471-2" aria-hidden="true" tabindex="-1"></a>V <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb471-3"><a href="#cb471-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m){</span>
<span id="cb471-4"><a href="#cb471-4" aria-hidden="true" tabindex="-1"></a>  V[[i]]  <span class="ot">&lt;-</span>  <span class="fu">crossprod</span>(Q.result[[i]], y.block[[i]])  </span>
<span id="cb471-5"><a href="#cb471-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>and finally set – as the step 3 of the reduce part</p>
<p><span class="math display">\[\widehat{\mathbf{\beta}}=[\mathbf{R}^{(2)}]^{-1}\sum_{j=1}^m\mathbf{V}_j\]</span></p>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="#cb472-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithm 5 Reduce function in step3</span></span>
<span id="cb472-2"><a href="#cb472-2" aria-hidden="true" tabindex="-1"></a>V.sum <span class="ot">&lt;-</span> <span class="fu">Reduce</span>(<span class="st">&#39;+&#39;</span>, V)</span>
<span id="cb472-3"><a href="#cb472-3" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">solve</span>(R.final) <span class="sc">%*%</span> V.sum)</span></code></pre></div>
<p>Let us compare the results</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="#cb473-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">lm=</span><span class="fu">coef</span>(mod), <span class="at">parallel=</span>beta)</span></code></pre></div>
<pre><code>                   lm  parallel
(Intercept) 39.686261 39.686261
wt          -3.190972 -3.190972
cyl         -1.507795 -1.507795</code></pre>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="#cb475-1" aria-hidden="true" tabindex="-1"></a><span class="co"># error</span></span>
<span id="cb475-2"><a href="#cb475-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((beta <span class="sc">-</span> <span class="fu">coef</span>(mod)) <span class="sc">**</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>[1] 2.607678e-28</code></pre>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-MapReduce):</td>
</tr>
<tr class="even">
<td align="left">Realiza todos las operaciones que puedas usando Map() o Reduce() para resolver los siguientes ejercicios:</td>
</tr>
<tr class="odd">
<td align="left">1. Genera una lista con 3 vectores que tenga 10 letras seleccionadas al azar (usa <code>letters</code>). Devuelve la intersección de esos tres vectores (<code>intersect()</code>).</td>
</tr>
<tr class="even">
<td align="left">2. Crea una función a la que se le pase una lista con varios vectores de datos continuos (pueden tener distinto tamaño) y que devuelva la media de todos los datos. Pista: usa la idea de la media ponderada. Úsala para calular la media en este ejemplo:</td>
</tr>
<tr class="odd">
<td align="left"><code>X &lt;- list(estudio1=c(120, 134, 156, 167, 122), estudio2=c(134, 116, 123), estudio3=c(110, 145, 124, 145, 160, 134, 122), estudio4=c(114, 113, 129, 178, 155, 144, 134, 145))</code></td>
</tr>
<tr class="even">
<td align="left">3. Re-implementa la función que hay en la solución para LOOCV que vimos en clase usando MapReduce.</td>
</tr>
</tbody>
</table>
<!--chapter:end:06-intro_big_data_in_R.Rmd-->
</div>
</div>
<div id="caret" class="section level1 hasAnchor" number="9">
<h1 class="hasAnchor"><span class="header-section-number">9</span> La librería <code>caret</code><a href="#caret" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>R es uno de los lenguajes de programación que más se usa en muchas disciplinas como la biomedicina, la economía y por supuesto, la estadísica. Al tratarse de un software libre, innumerables usuarios han podido implementar sus algoritmos, dando lugar a un número muy elevado de librerías donde encontrar prácticamente todas las técnicas de machine learning existentes. Sin embargo, esto tiene un lado negativo, cada paquete tiene una sintaxis, estructura e implementación propia, lo que dificulta su aprendizaje. El paquete <a href="http://topepo.github.io/caret/index.html">caret</a> (Classification And REgression Training ), desarrollado por Max Kuhn, es una interfaz que unifica bajo un único marco cientos de funciones de distintos paquetes, facilitando en gran medida todas las etapas de de preprocesado, entrenamiento, optimización y validación de modelos predictivos.</p>
<blockquote>
<p>El paquete caret ofrece tal cantidad de posibilidades que, difícilmente, pueden ser mostradas con un único ejemplo. En este capítulo describiremos toda las capacidades de esta libería con un un ejemplo utilizando regresión logística con la que ya estamos familiarizados. El resto de métodos de aprendizaje automático que veremos en el curso también se llevarán a cabo con esta librería y algunas específicas de cada método.</p>
</blockquote>
<p>Otros proyectos similares a <code>caret</code> son: <a href="https://mlr3.mlr-org.com/">mlr3</a>, <a href="https://h2o-release.s3.amazonaws.com/h2o/rel-lambert/5/docs-website/index.html#">H20</a> que veremos en este curso y que está orientado a Big Data y <a href="https://www.tidymodels.org/">tidymodels</a> que forma parte del mundo <code>tydiverse</code>.</p>
<p>Hay muchas funciones de modelado diferentes en R. Algunas tienen una sintaxis diferente para el entrenamiento y / o predicción de modelos. El paquete comenzó como una forma de proporcionar una interfaz uniforme para las funciones mismas, así como una forma de estandarizar las tareas comunes (como el ajuste de parámetros y la importancia de las variables).</p>
<p>La instalación de <code>caret</code> puede ser muy pesada ya que tiene muchas dependencias (todos las librerías que implementan los métodos de aprendizaje automático que se quieran usar). Es por ello que se recomienda instalar la versión mínima y luego ir instalando aquellas librerías que se requieran en función del método que se pretenda usar.</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="#cb477-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>, </span>
<span id="cb477-2"><a href="#cb477-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">dependencies =</span> <span class="fu">c</span>(<span class="st">&quot;Depends&quot;</span>, <span class="st">&quot;Suggests&quot;</span>))</span></code></pre></div>
<p>Luego la librería se carga de la forma usual</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="#cb478-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<p>En este capítulo veremos como realizar:</p>
<ul>
<li>Preprocesamiento (con <code>caret</code> y con <code>recipes</code>)</li>
<li>Visualización</li>
<li>División de datos</li>
<li>Selección de variables</li>
<li>Ajuste de modelo mediante remuestreo</li>
<li>Estimación de la importancia de variables</li>
</ul>
<p>Para ilustrar el uso de esta librería con datos reales usaremos la base de datos Titanic que está en la librería con su mismo nombre. Este conjunto de datos contiene información sobre los pasajeros del Titanic, el transatlántico británico que se hundió en abril de 1912 durante su viaje inaugural desde Southampton a Nueva York. Entre la información almacenada se encuentran la edad, género, características socio-económicas de los pasajeros y si sobrevivieron o no al naufragio (variable respuesta). Este ejemplo puede que no sea muy útil desde un punto de vista científico (en las prácticas trabajaremos con otrods que sí son útiles), pero tienen una serie de características que los hacen idóneos para ser utilizados como ejemplo introductorio al machine learning:</p>
<ul>
<li><p>Contiene suficientes observaciones para entrenar modelos que consigan un poder predictivo alto.</p></li>
<li><p>Incluye tanto variables continuas como cualitativas, lo que permite mostrar diferentes análisis exploratorios.</p></li>
<li><p>La variable respuesta es binaria. Aunque la mayoría de los algoritmos de clasificación mostrados en este capítulo se generalizan para múltiples clases, su interpretación suele ser más sencilla cuando solo hay dos.</p></li>
<li><p>Contiene valores faltantes (<strong>missing</strong> data). La forma en que se manejan estos registros (eliminación o imputación) influye en gran medida en el modelo final.</p></li>
<li><p>Necesitan realizar un pre-procesamiento de datos (eliminación y creación de variables).</p></li>
</ul>
<p>Además, se trata de unos datos cuyas variables pueden entenderse de forma sencilla. Es intuitivo comprender el impacto que puede tener la edad, el sexo, la localización del camarote… en la supervivencia de los pasajeros. Este aspecto es muy importante a al hora de crear buenos modelos predictivos, ya que, comprender a fondo el problema que se pretende modelar es lo más importante para lograr buenos resultados.</p>
<p>La librería <code>titanic</code> contiene un conjunto de datos de entrenamiento y otros de test facilitados en la plataforma <a href="https://www.kaggle.com/c/titanic/data">Kaggle</a> que contiene muchos conjuntos de datos para trabajar con problemas de aprendizaje automático. Los datos test sólo sirven para tener otro conjunto de datos en los que evaluar el modelo, pero <em>no tienen la variable resultado</em> por lo que no se pueden usar para crear el modelo predictivo (Kaggle los usa para ver quién proponer el mejor modelo).</p>
<p>Los datos se cargan de forma habitual</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="#cb479-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb479-2"><a href="#cb479-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(titanic)</span>
<span id="cb479-3"><a href="#cb479-3" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> titanic_train</span></code></pre></div>
<div id="pre-procesado" class="section level2 hasAnchor" number="9.1">
<h2 class="hasAnchor"><span class="header-section-number">9.1</span> Pre-procesado<a href="#pre-procesado" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="creación-de-variables" class="section level3 hasAnchor" number="9.1.1">
<h3 class="hasAnchor"><span class="header-section-number">9.1.1</span> Creación de variables<a href="#creación-de-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El primer paso antes de realizar cualquier análisis estadístico, y en particular para entrenar un modelo predictivo, es llevar a cabo una exploración descriptiva de los datos. Este proceso permite entender mejor que información contiene cada variable, así como detectar posibles errores ya que podríamos encontrarnos con los siguientes problemas:</p>
<ul>
<li><p>Que una columna se haya almacenado con el tipo incorrecto: una variable numérica está siendo reconocida como texto.</p></li>
<li><p>Que una variable contenga valores que no tienen sentido: para indicar que no se dispone de la altura de una persona se introduce el valor cero o un espacio en blanco. No existe nadie cuya altura sea cero.</p></li>
<li><p>Que en una variable de tipo numérico se haya introducido una palabra en lugar de un número.</p></li>
</ul>
<p>Según la información disponible en Kaggle, nuestras variables contienen la siguiente información:</p>
<ul>
<li><p>PassengerId: identificador único del pasajero.</p></li>
<li><p>Survived: si el pasajero sobrevivió al naufragio, codificada como 0 (no) y 1 (si). Esta es la variable respuesta que interesa predecir.</p></li>
<li><p>Pclass: clase a la que pertenecía el pasajero: 1, 2 o 3.</p></li>
<li><p>Name: nombre del pasajero.</p></li>
<li><p>Sex: sexo del pasajero.</p></li>
<li><p>Age: edad del pasajero.</p></li>
<li><p>SibSp: número de hermanos, hermanas, hermanastros o hermanastras en el barco.</p></li>
<li><p>Parch: número de padres e hijos en el barco.</p></li>
<li><p>Ticket: identificador del billete.</p></li>
<li><p>Fare: precio pagado por el billete.</p></li>
<li><p>Cabin: identificador del camarote asignado al pasajero.</p></li>
<li><p>Embarked: puerto en el que embarcó el pasajero.</p></li>
</ul>
<p>Por ello, empezaremos comprobando que cada variable se ha almacenado con el tipo de valor que le corresponde, es decir, que las variables numéricas sean números y las cualitativas factor, character o booleanas. Recordemos que en R, cuando la variable es cualitativa, conviene convertirla en variable factor para que las funciones que implementan muchos de los métodos estadísticos que queremos usar puedan analizarlas de forma conveniente (i.e. dummy variables).</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="#cb480-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(datos)</span></code></pre></div>
<pre><code>Rows: 891
Columns: 12
$ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23…
$ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, …
$ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, …
$ Name        &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot;,…
$ Sex         &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;…
$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, NA, 31, NA, 35, …
$ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, …
$ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, …
$ Ticket      &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;373450&quot;, &quot;330877&quot;, &quot;17463…
$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0…
$ Cabin       &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;C103&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;…
$ Embarked    &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;…</code></pre>
<p>Observamos que el único caso en el que el tipo de valor no se corresponde con la naturaleza de la variable es <code>Survived</code>. Aunque esta variable está codificada como 1 si el pasajero sobrevivió y 0 si murió, no conviene almacenarla en formato numérico, ya que esto puede llevar a errores como el de tratar de calcular su media. Para evitar este tipo de problemas, se recodifica la variable para que sus dos posibles niveles sean <code>Si/No</code> y se convierte a factor. Además, esta re-codificación también ayudará a que los resultados y gráficas se puedan leer fácilmente.</p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="#cb482-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Survived =</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(Survived <span class="sc">==</span> <span class="dv">1</span>, <span class="st">&quot;Si&quot;</span>, <span class="st">&quot;No&quot;</span>)))</span>
<span id="cb482-2"><a href="#cb482-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Survived)</span></code></pre></div>
<pre><code>
 No  Si 
549 342 </code></pre>
<p>La variable Pclass es cualitativa ordinal, es decir, toma distintos valores cualitativos ordenados siguiendo una escala establecida, aunque no es necesario que el intervalo entre mediciones sea uniforme. Por ejemplo, se asume que la diferencia entre primera y segunda clase es menor que la diferencia entre primera y tercera, sin embargo, las diferencias entre primera-segunda y segunda-tercera no tiene por qué ser iguales. Es por ello que es preferible guardar esta variable como factor</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="#cb484-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Pclass =</span> <span class="fu">as.factor</span>(Pclass))</span>
<span id="cb484-2"><a href="#cb484-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Pclass)</span></code></pre></div>
<pre><code>
  1   2   3 
216 184 491 </code></pre>
<p>Las variables SibSp y Parch son cuantitativas discretas, pueden tomar únicamente determinados valores numéricos. En este caso, al tratarse de número de personas (familiares e hijos), solo pueden ser números enteros. No existe una norma clara sobre como almacenar estas variables. Para este estudio exploratorio, dado que solo toman unos pocos valores, se decide almacenarlas como factor.</p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="#cb486-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">SibSp =</span> <span class="fu">as.factor</span>(SibSp))</span>
<span id="cb486-2"><a href="#cb486-2" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Parch =</span> <span class="fu">as.factor</span>(Parch))</span></code></pre></div>
<p>Las variables Sex y Embarked también se convierten a tipo factor.</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="#cb487-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Sex =</span> <span class="fu">as.factor</span>(Sex))</span>
<span id="cb487-2"><a href="#cb487-2" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Embarked =</span> <span class="fu">as.factor</span>(Embarked))</span></code></pre></div>
<p>Las variables Cabin y Embarked contienen ““. Esto consideraría a este valor como una categoría, por lo que habría que hacer</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="#cb488-1" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>Cabin[datos<span class="sc">$</span>Cabin<span class="sc">==</span><span class="st">&quot;&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb488-2"><a href="#cb488-2" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>Embarked[datos<span class="sc">$</span>Embarked<span class="sc">==</span><span class="st">&quot;&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span></code></pre></div>
</div>
<div id="predictores-con-poca-variabilidad" class="section level3 hasAnchor" number="9.1.2">
<h3 class="hasAnchor"><span class="header-section-number">9.1.2</span> Predictores con poca variabilidad<a href="#predictores-con-poca-variabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En algunas situaciones, el mecanismo de generación de datos puede crear predictores que solo tienen un valor único (es decir, un “predictor de varianza cero”). Para la mayoría de modelos de aprendizaje automático esto puede provocar que el modelo se bloquee o que el ajuste sea inestable.</p>
<p>De manera similar, los predictores categóricos pueden tener alguna categoría que ocurren con frecuencias muy bajas. Por ejemplo, esto ocurre con la variable número de hijos en el barco</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="#cb489-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Parch)</span></code></pre></div>
<pre><code>
  0   1   2   3   4   5   6 
678 118  80   5   4   5   1 </code></pre>
<p>La preocupación aquí es que estos predictores pueden convertirse en predictores de varianza cero cuando los datos se dividen en submuestras de validación cruzada / bootstrap o que algunas muestras pueden tener una influencia muy grande en el modelo (valores influyentes). Es posible que estos predictores de “varianza cercana a cero” deban identificarse y eliminarse antes del modelado.</p>
<p>Para identificar estos tipos de predictores, se pueden calcular las siguientes dos métricas:</p>
<ul>
<li><p>la frecuencia del valor más prevalente sobre el segundo valor más frecuente (llamado “índice de frecuencia”), que estaría cerca de uno para los predictores con buen comportamiento y muy grande para datos altamente desequilibrados y</p></li>
<li><p>el “porcentaje de valores únicos” que es el número de valores únicos dividido por el número total de muestras (multiplicado por 100) que se acerca a cero a medida que aumenta la granularidad de los datos.</p></li>
</ul>
<p>Si la relación de frecuencia es mayor que un umbral preestablecido y el porcentaje de valor único es menor que un umbral, podríamos considerar que un predictor tiene una varianza cercana a cero.</p>
<p>No queremos identificar falsamente los datos que tienen baja granularidad pero están distribuidos de manera uniforme, como los datos de una distribución uniforme discreta. El uso de ambos criterios no debería detectar falsamente tales predictores.</p>
<p>Para realizar estos cálculos podemos usar la función <code>nearZeroVar ()</code> (el argumento saveMetrics se puede usar para mostrar los detalles y - por defecto el valor predeterminado es FALSE):</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="#cb491-1" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="fu">nearZeroVar</span>(datos, <span class="at">saveMetrics=</span> <span class="cn">TRUE</span>)</span>
<span id="cb491-2"><a href="#cb491-2" aria-hidden="true" tabindex="-1"></a>nzv</span></code></pre></div>
<pre><code>            freqRatio percentUnique zeroVar   nzv
PassengerId  1.000000   100.0000000   FALSE FALSE
Survived     1.605263     0.2244669   FALSE FALSE
Pclass       2.273148     0.3367003   FALSE FALSE
Name         1.000000   100.0000000   FALSE FALSE
Sex          1.837580     0.2244669   FALSE FALSE
Age          1.111111     9.8765432   FALSE FALSE
SibSp        2.909091     0.7856341   FALSE FALSE
Parch        5.745763     0.7856341   FALSE FALSE
Ticket       1.000000    76.4309764   FALSE FALSE
Fare         1.023810    27.8338945   FALSE FALSE
Cabin        1.000000    16.4983165   FALSE FALSE
Embarked     3.833333     0.3367003   FALSE FALSE</code></pre>
<p>La función <code>nearZeroVar</code> devuelve las posiciones con las variables marcadas como problemáticas. Podríamos crear una base de datos sin variables problemáticas de las siguiente forma:</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="#cb493-1" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="fu">nearZeroVar</span>(datos)</span>
<span id="cb493-2"><a href="#cb493-2" aria-hidden="true" tabindex="-1"></a>nzv</span></code></pre></div>
<pre><code>integer(0)</code></pre>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="#cb495-1" aria-hidden="true" tabindex="-1"></a>filteredDatos <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(datos, <span class="sc">-</span><span class="fu">all_of</span>(nzv))</span>
<span id="cb495-2"><a href="#cb495-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(datos)</span></code></pre></div>
<pre><code>[1] 891  12</code></pre>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="#cb497-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(filteredDatos)</span></code></pre></div>
<pre><code>[1] 891  12</code></pre>
<p>En este caso no hemos filtrado ninguna porque ninguna ha devuelto TRUE en las columnas <code>zeroVar</code> y <code>nzv</code> del objeto <code>nzv</code> cuando indicamos <code>saveMetrics= TRUE</code>.</p>
</div>
<div id="identificación-de-predictores-correlacionados" class="section level3 hasAnchor" number="9.1.3">
<h3 class="hasAnchor"><span class="header-section-number">9.1.3</span> Identificación de predictores correlacionados<a href="#identificación-de-predictores-correlacionados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Algunos de los modelos que vamos a estudiar pueden tratar con predictores correlacionados (como pls). Sin embargo, otros modelos pueden beneficiarse al reducir el nivel de correlación entre los predictores.</p>
<p>Dada una matriz de correlación, la función <code>findCorrelation()</code> es útil para marcar los predictores que deben ser eliminados por su alta correlación con otros:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="#cb499-1" aria-hidden="true" tabindex="-1"></a>descrCor <span class="ot">&lt;-</span>  <span class="fu">cor</span>(filteredDatos)</span>
<span id="cb499-2"><a href="#cb499-2" aria-hidden="true" tabindex="-1"></a>highCorr <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">abs</span>(descrCor[<span class="fu">upper.tri</span>(descrCor)]) <span class="sc">&gt;</span> .<span class="dv">99</span>)</span></code></pre></div>
<p>Dado que en nuestro caso la mayoría de variables son categóricas, no tiene mucho sentido llevar a cabo este pre-proceso. Además, la función <code>cor()</code> sólo puede aplicarse a datos continuos. Existen otras funciones para calcular las correlaciones entre variables categóricas, que deberían implementarse de forma manual.</p>
</div>
<div id="centrado-y-escalado-1" class="section level3 hasAnchor" number="9.1.4">
<h3 class="hasAnchor"><span class="header-section-number">9.1.4</span> Centrado y escalado<a href="#centrado-y-escalado-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En ocasiones es recomendable centrar y escalar las variables continuas para evitar que aquellas vairables con rangos mayores tengan más importancia. Esto se puede hacer de forma sencilla con la función <code>preProcess</code> de la siguiente manera</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="#cb500-1" aria-hidden="true" tabindex="-1"></a>datosTransf <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(datos, <span class="at">method=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span>
<span id="cb500-2"><a href="#cb500-2" aria-hidden="true" tabindex="-1"></a>datosTransf</span></code></pre></div>
<pre><code>Created from 183 samples and 12 variables

Pre-processing:
  - centered (3)
  - ignored (9)
  - scaled (3)</code></pre>
<p>Vemos que este escalado y centrado no se ha aplicado a 7 de las 12 variables ya que no variables categóricas o carácter.</p>
<p>También podemos transformar nuestros datos para garantizar normalidad utilizando transformacines exponenciales (“expoTrans”), Box-Cox (“BoxCox”) o Yeo-Johnson (“YeoJohnson”). Esto se puede hacer de forma sencilla mediante</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="#cb502-1" aria-hidden="true" tabindex="-1"></a>preProc <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(datos, <span class="at">method=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>, <span class="st">&quot;YeoJohnson&quot;</span>))</span>
<span id="cb502-2"><a href="#cb502-2" aria-hidden="true" tabindex="-1"></a>preProc</span></code></pre></div>
<pre><code>Created from 183 samples and 12 variables

Pre-processing:
  - centered (3)
  - ignored (9)
  - scaled (3)
  - Yeo-Johnson transformation (3)

Lambda estimates for Yeo-Johnson transformation:
0.71, 0.76, -0.1</code></pre>
<p>Los valores Lambda corresponden a las diferentes transformaciones usadas para cada unos de las variables según la definición que se puede encontrar <a href="(https://en.wikipedia.org/wiki/Power_transform)">aquí</a>. Este objeto tiene toda la información para centrar, escalar, transformar, e incluso eliminar o no variables.</p>
</div>
<div id="imputación" class="section level3 hasAnchor" number="9.1.5">
<h3 class="hasAnchor"><span class="header-section-number">9.1.5</span> Imputación<a href="#imputación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el capítulo de modelización ya hablamos de este tema. La librería <code>caret</code> facilita la imputación mediante la función <code>preProcess()</code>. Basta con usar en el argumento <code>method</code> cualquiera de estas approximaciones: “knnImpute”, “bagImpute”, “medianImpute”.</p>
<p><strong>NOTA</strong>: también se podría usar “zv” y “nzv” para eliminar aquellos predictores con poca variabilidad, así que todos los pasos se pueden hacer con la función <code>preProcess()</code> [ver ayuda de la función para más detalles]</p>
</div>
<div id="pre-procesado-con-la-librería-recipes" class="section level3 hasAnchor" number="9.1.6">
<h3 class="hasAnchor"><span class="header-section-number">9.1.6</span> Pre-procesado con la librería <code>recipes</code><a href="#pre-procesado-con-la-librería-recipes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El preprocesado de datos engloba aquellas transformaciones de los datos hechas con la finalidad de que puedan ser aceptados por el algoritmo de machine learning o que mejoren sus resultados. Todo preprocesado de datos debe aprenderse de las observaciones de entrenamiento y luego aplicarse al conjunto de entrenamiento y al de test. Esto es muy importante para no violar la condición de que ninguna información procedente de las observaciones de test puede participar o influir en el ajuste del modelo. Aunque no es posible crear un único listado, algunos pasos de preprocesado que más suelen aplicarse en la práctica son:</p>
<ul>
<li><p>Imputación de valores ausentes</p></li>
<li><p>Exclusión de variables con varianza próxima a cero</p></li>
<li><p>Reducción de dimensionalidad</p></li>
<li><p>Estandarización de las variables numéricas</p></li>
<li><p>Binarización de las variables cualitativas</p></li>
</ul>
<p>El paquete <code>caret</code> incorpora muchas funciones para preprocesar los datos. Sin embargo, para facilitar todavía más el aprendizaje de las transformaciones, únicamente con las observaciones de entrenamiento, y poder aplicarlas después a cualquier conjunto de datos, el mismo autor ha creado el paquete <code>recipes</code>.</p>
<p>La idea detrás de este paquete es la siguiente:</p>
<ol style="list-style-type: decimal">
<li>Definir cuál es la variable respuesta, los predictores y el set de datos de entrenamiento, <code>recipe()</code>.</li>
<li>Definir todas las transformaciones (escalado, selección, filtrado…) que se desea aplicar, <code>step_()</code>.</li>
<li>Aprender los parámetros necesarios para dichas transformaciones con las observaciones de entrenamiento <code>rep()</code>.</li>
<li>Aplicar las trasformaciones aprendidas a cualquier conjunto de datos <code>bake()</code>.</li>
</ol>
<p>En los siguientes apartados, se almacenan en un objeto recipe todos los pasos de preprocesado y, finalmente, se aplican a los datos.</p>
<div id="imputación-de-valores-ausentes" class="section level4 hasAnchor" number="9.1.6.1">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.1</span> Imputación de valores ausentes<a href="#imputación-de-valores-ausentes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para ver qué cantidad de datos faltantes hay podemos crear la siguiente figura:</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="#cb504-1" aria-hidden="true" tabindex="-1"></a>datos_long <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span> <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">&quot;variable&quot;</span>, <span class="at">value =</span> <span class="st">&quot;valor&quot;</span>, <span class="sc">-</span>PassengerId)</span>
<span id="cb504-2"><a href="#cb504-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb504-3"><a href="#cb504-3" aria-hidden="true" tabindex="-1"></a>datos_long <span class="sc">%&gt;%</span></span>
<span id="cb504-4"><a href="#cb504-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(variable) <span class="sc">%&gt;%</span> </span>
<span id="cb504-5"><a href="#cb504-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">porcentaje_NA =</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(valor)) <span class="sc">/</span> <span class="fu">length</span>(valor)) <span class="sc">%&gt;%</span></span>
<span id="cb504-6"><a href="#cb504-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(variable, <span class="fu">desc</span>(porcentaje_NA)), <span class="at">y =</span> porcentaje_NA)) <span class="sc">+</span></span>
<span id="cb504-7"><a href="#cb504-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb504-8"><a href="#cb504-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Porcentaje valores ausentes por variable&quot;</span>,</span>
<span id="cb504-9"><a href="#cb504-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> <span class="st">&quot;Variable&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Porcentaje NAs&quot;</span>) <span class="sc">+</span></span>
<span id="cb504-10"><a href="#cb504-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="fig/unnamed-chunk-187-1.png" width="672" /></p>
<p>Podemos observar que las variables “Cabin”, “Age” y “Embarked” contienen valores ausentes. La gran mayoría de algoritmos no aceptan observaciones incompletas, por lo que, cuando el set de datos contiene valores ausentes, se puede:</p>
<ul>
<li><p>Eliminar aquellas observaciones que estén incompletas.</p></li>
<li><p>Eliminar aquellas variables que contengan valores ausentes.</p></li>
<li><p>Tratar de estimar los valores ausentes empleando el resto de información disponible (imputación).</p></li>
</ul>
<p>Las primeras dos opciones, aunque sencillas, suponen perder información. La eliminación de observaciones solo puede aplicarse cuando se dispone de muchas y el porcentaje de registros incompletos es muy bajo. En el caso de eliminar variables, el impacto dependerá de cuanta información aporten dichas variables al modelo.</p>
<p>Cuando se emplea imputación, es muy importante tener en cuenta el riesgo que se corre al introducir valores en predictores que tengan mucha influencia en el modelo. Supóngase un estudio médico en el que, cuando uno de los predictores es positivo, el modelo predice casi siempre que el paciente está sano. Para un paciente cuyo valor de este predictor se desconoce, el riesgo de que la imputación sea errónea es muy alto, por lo que es preferible obtener una predicción basada únicamente en la información disponible. Esta es otra muestra de la importancia que tiene que el analista conozca el problema al que se enfrenta y pueda así tomar la mejor decisión.</p>
<p>En el conjunto de datos <code>Titanic</code>, si se eliminan las observaciones incompletas, se pasa de 891 observaciones a 714, por lo que esta no es una opción.</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="#cb505-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(datos)</span></code></pre></div>
<pre><code>[1] 891</code></pre>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(datos[<span class="fu">complete.cases</span>(datos),])</span></code></pre></div>
<pre><code>[1] 183</code></pre>
<p>La variable Cabin está ausente para casi un 80% de las observaciones, con un porcentaje tan alto de valores ausentes, no es conveniente imputarla, se excluye directamente del modelo. Esto deja al modelo con dos variables que requieren de imputación: Age y Embarked.</p>
<p>La imputación es un proceso complejo que debe de realizarse con detenimiento, identificando cuidadosamente qué variables son las adecuadas para cada imputación. La librería <code>recipes</code> permite 4 métodos de imputación distintos:</p>
<ul>
<li><p><code>step_impute_bag()</code>: imputación vía Bagged Trees.</p></li>
<li><p><code>step_impute_knn()</code>: imputación vía K-Nearest Neighbors.</p></li>
<li><p><code>step_impute_mean()</code>: imputación vía media del predictor (predictores continuos).</p></li>
<li><p><code>step_impute_mode()</code>: imputación vía moda del predictor (predictores cualitativos).</p></li>
</ul>
<p>Como ya vimos en su momento, las librerías <code>Hmisc</code>, <code>missForest</code> y <code>MICE</code> también permiten aplicar otros métodos.</p>
<p>Se imputa la variable Embarked con el valor C (más frecuene). Como no existe una función <code>step()</code> que haga sustituciones por valores concretos, se realiza una sustitución de forma externa al <code>recipe</code>.</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="#cb509-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span></span>
<span id="cb509-2"><a href="#cb509-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Embarked =</span> <span class="fu">replace</span>(Embarked, <span class="fu">is.na</span>(Embarked), <span class="st">&quot;C&quot;</span>))</span></code></pre></div>
<p>La variable Age se imputa con el método bagging empleando todos los otros predictores.</p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="#cb510-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span>
<span id="cb510-2"><a href="#cb510-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea un objeto recipe() con la variable respuesta y los predictores. </span></span>
<span id="cb510-3"><a href="#cb510-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Las variables *PassengerId*, *Name*, *Ticket* no parecen aportar información</span></span>
<span id="cb510-4"><a href="#cb510-4" aria-hidden="true" tabindex="-1"></a><span class="co"># relevante sobre la supervivencia de los pasajeros. Excluyendo todas estas</span></span>
<span id="cb510-5"><a href="#cb510-5" aria-hidden="true" tabindex="-1"></a><span class="co"># variables, se propone como modelo inicial el formado por los predictores:</span></span>
<span id="cb510-6"><a href="#cb510-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  Pclass + Sex + SibSp + Parch + Fare + Embarked + Age.</span></span>
<span id="cb510-7"><a href="#cb510-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb510-8"><a href="#cb510-8" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(<span class="at">formula =</span> Survived <span class="sc">~</span> Pclass <span class="sc">+</span> Sex <span class="sc">+</span> SibSp <span class="sc">+</span> Parch <span class="sc">+</span></span>
<span id="cb510-9"><a href="#cb510-9" aria-hidden="true" tabindex="-1"></a>                                  Fare <span class="sc">+</span> Embarked <span class="sc">+</span> Age,</span>
<span id="cb510-10"><a href="#cb510-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span>  datos)</span>
<span id="cb510-11"><a href="#cb510-11" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7</code></pre>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="#cb512-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_impute_bag</span>(Age)</span>
<span id="cb512-2"><a href="#cb512-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Operations:

Bagged tree imputation for Age</code></pre>
<p>NOTA: este objeto no es la imputación, es la <code>recipe</code> para realizarla. La idea es seguir haciendo pasos de pre-proceso y al final aplicarlos a nuestros datos</p>
</div>
<div id="variables-con-varianza-próxima-a-cero" class="section level4 hasAnchor" number="9.1.6.2">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.2</span> Variables con varianza próxima a cero<a href="#variables-con-varianza-próxima-a-cero" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>No se deben incluir en el modelo predictores que contengan un único valor (cero-varianza) ya que no aportan información. Tampoco es conveniente incluir predictores que tengan una varianza próxima a cero, es decir, predictores que toman solo unos pocos valores, de los cuales, algunos aparecen con muy poca frecuencia. El problema con estos últimos es que pueden convertirse en predictores con varianza cero cuando se dividen las observaciones por validación cruzada o bootstrap.</p>
<p>La función <code>nearZeroVar()</code> del paquete <code>caret</code> y <code>step_nzv()</code> del paquete <code>recipe</code> identifican como predictores potencialmente problemáticos aquellos que tienen un único valor (cero varianza) o que cumplen las dos siguientes condiciones:</p>
<ul>
<li><p>Ratio de frecuencias: ratio entre la frecuencia del valor más común y la frecuencia del segundo valor más común. Este ratio tiende a 1 si las frecuencias están equidistribuidas y a valores grandes cuando la frecuencia del valor mayoritario supera por mucho al resto (el denominador es un número decimal pequeño). Valor por defecto freqCut = 95/5.</p></li>
<li><p>Porcentaje de valores únicos: número de valores únicos dividido entre el total de muestras (multiplicado por 100). Este porcentaje se aproxima a cero cuanto mayor es la variedad de valores. Valor por defecto uniqueCut = 10.</p></li>
</ul>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="#cb514-1" aria-hidden="true" tabindex="-1"></a>datos <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(Pclass, Sex, SibSp, Parch, Fare, Embarked, Age) <span class="sc">%&gt;%</span></span>
<span id="cb514-2"><a href="#cb514-2" aria-hidden="true" tabindex="-1"></a>          <span class="fu">nearZeroVar</span>(<span class="at">saveMetrics =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>         freqRatio percentUnique zeroVar   nzv
Pclass    2.273148     0.3367003   FALSE FALSE
Sex       1.837580     0.2244669   FALSE FALSE
SibSp     2.909091     0.7856341   FALSE FALSE
Parch     5.745763     0.7856341   FALSE FALSE
Fare      1.023810    27.8338945   FALSE FALSE
Embarked  3.788235     0.3367003   FALSE FALSE
Age       1.111111     9.8765432   FALSE FALSE</code></pre>
<p>Entre los predictores incluidos en el modelo, no se detecta ninguno con varianza cero o próxima a cero. Actualizamos nuestro objeto <code>recipe</code></p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="#cb516-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p>Si bien la eliminación de predictores no informativos podría considerarse un paso propio del proceso de selección de predictores, dado que consiste en un filtrado por varianza, tiene que realizarse antes de estandarizar los datos, ya que después, todos los predictores tienen varianza 1.</p>
</div>
<div id="normalización-de-datos" class="section level4 hasAnchor" number="9.1.6.3">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.3</span> Normalización de datos<a href="#normalización-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como ya hemos mencionado anteriormente, también podemos transformar nuestros datos para garantizar normalidad utilizando transformaciones Box-Cox (“BoxCox”) o Yeo-Johnson (“YeoJohnson”). Esto se puede hacer de forma sencilla mediante</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="#cb517-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_BoxCox</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>ó</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="#cb518-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_YeoJohnson</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>respectivamente.</p>
</div>
<div id="estandarización-y-escalado" class="section level4 hasAnchor" number="9.1.6.4">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.4</span> Estandarización y escalado<a href="#estandarización-y-escalado" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Muchos algoritmos de machine learning (SVM, redes neuronales, lasso…) son sensibles a esto, de forma que, si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza, dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Existen principalmente 2 estrategias para evitarlo:</p>
<ul>
<li><p><em>Centrado</em>: consiste en restarle a cada valor la media del predictor al que pertenece. Si los datos están almacenados en un dataframe, el centrado se consigue restándole a cada valor la media de la columna en la que se encuentra. Como resultado de esta transformación, todos los predictores pasan a tener una media de cero, es decir, los valores se centran en torno al origen.</p></li>
<li><p><em>Normalización (estandarización)</em>: consiste en transformar los datos de forma que todos los predictores estén aproximadamente en la misma escala (centrado + escalado).</p></li>
</ul>
<p>Con este código se normalizan todas las variables numéricas.</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="#cb519-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_center</span>(<span class="fu">all_numeric</span>())</span>
<span id="cb519-2"><a href="#cb519-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>Nunca se debe estandarizar las variables después de ser binarizadas (ver siguiente sección).</p>
</div>
<div id="binarización-de-variables-cuantitativas" class="section level4 hasAnchor" number="9.1.6.5">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.5</span> Binarización de variables cuantitativas<a href="#binarización-de-variables-cuantitativas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La binarización consiste en crear nuevas variables dummy con cada uno de los niveles de las variables cualitativas. Por ejemplo, una variable llamada color que contenga los niveles rojo, verde y azul, se convertirá en tres nuevas variables (color_rojo, color_verde, color_azul), todas con el valor 0 excepto la que coincide con la observación, que toma el valor 1.</p>
<p>Por defecto, la función <code>step_dummy(all_nominal())</code> binariza todas las variables almacenadas como tipo factor o character. Además, elimina uno de los niveles para evitar redundancias. Volviendo al ejemplo anterior, no es necesario almacenar las tres variables, ya que, si color_rojo y color_verde toman el valor 0, la variable color_azul toma necesariamente el valor 1. Si color_rojo o color_verde toman el valor 1, entonces color_azul es necesariamente 0.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="#cb520-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>(),</span>
<span id="cb520-2"><a href="#cb520-2" aria-hidden="true" tabindex="-1"></a>                                              <span class="sc">-</span><span class="fu">all_outcomes</span>())</span></code></pre></div>
<p>Finalmente, esto es lo que hemos preparado para pre-procesar nuestros datos:</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="#cb521-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Operations:

Bagged tree imputation for Age
Sparse, unbalanced variable filter on all_predictors()
Centering for all_numeric()
Scaling for all_numeric()
Dummy variables from all_nominal(), -all_outcomes()</code></pre>
</div>
<div id="obtención-de-datos-para-entrenar" class="section level4 hasAnchor" number="9.1.6.6">
<h4 class="hasAnchor"><span class="header-section-number">9.1.6.6</span> Obtención de datos para entrenar<a href="#obtención-de-datos-para-entrenar" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Una vez que se ha creado el objeto recipe con todas las transformaciones de preprocesado, se aprende con los datos de entrenamiento y se aplican a los dos conjuntos de datos.</p>
<p><strong>IMPORTANTE</strong> Para nosotros el objeto <code>datos</code> es nuestro train, y aplicamos estas <code>recipe</code> a estos datos y luego también tenemos que aplicarlo a los datos train para que las variables con las que hagamos predicciones estén en las mismas escalas, sin valores faltantes, cero-varianza, etc.</p>
<ul>
<li><em>Paso 1</em>: Se entrena el objeto <code>recipe</code></li>
</ul>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="#cb523-1" aria-hidden="true" tabindex="-1"></a>trained_recipe <span class="ot">&lt;-</span> <span class="fu">prep</span>(objeto_recipe, <span class="at">training =</span> datos)</span>
<span id="cb523-2"><a href="#cb523-2" aria-hidden="true" tabindex="-1"></a>trained_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Training data contained 891 data points and 177 incomplete rows. 

Operations:

Bagged tree imputation for Age [trained]
Sparse, unbalanced variable filter removed &lt;none&gt; [trained]
Centering for Fare, Age [trained]
Scaling for Fare, Age [trained]
Dummy variables from Pclass, Sex, SibSp, Parch, Embarked [trained]</code></pre>
<ul>
<li><em>Paso 2</em>: Se aplican las transformaciones al conjunto de entrenamiento y de test (en nuestro caso sólo tenemos train)</li>
</ul>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="#cb525-1" aria-hidden="true" tabindex="-1"></a>datos_train_transf <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> datos)</span>
<span id="cb525-2"><a href="#cb525-2" aria-hidden="true" tabindex="-1"></a><span class="co"># datos_test_prep  &lt;- bake(trained_recipe, new_data = datos_test)</span></span>
<span id="cb525-3"><a href="#cb525-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb525-4"><a href="#cb525-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(datos_train_transf)</span></code></pre></div>
<pre><code>Rows: 891
Columns: 21
$ Fare       &lt;dbl&gt; -0.50216314, 0.78640362, -0.48857985, 0.42049407, -0.48606443, -0.47784805, 0.3955…
$ Age        &lt;dbl&gt; -0.57161891, 0.62175764, -0.27327478, 0.39799954, 0.39799954, -0.04795576, 1.81513…
$ Survived   &lt;fct&gt; No, Si, Si, Si, No, No, No, No, Si, Si, Si, Si, No, No, No, Si, No, Si, No, Si, No…
$ Pclass_X2  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…
$ Pclass_X3  &lt;int&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0…
$ Sex_male   &lt;int&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1…
$ SibSp_X1   &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…
$ SibSp_X2   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ SibSp_X3   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1…
$ SibSp_X4   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ SibSp_X5   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ SibSp_X8   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ Parch_X1   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0…
$ Parch_X2   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…
$ Parch_X3   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ Parch_X4   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ Parch_X5   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…
$ Parch_X6   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ Embarked_C &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0…
$ Embarked_Q &lt;int&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…
$ Embarked_S &lt;int&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1…</code></pre>
</div>
</div>
</div>
<div id="visualización" class="section level2 hasAnchor" number="9.2">
<h2 class="hasAnchor"><span class="header-section-number">9.2</span> Visualización<a href="#visualización" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Podemos empezar con unos gráficos para las variables continuas de la siguiente forma:</p>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="#cb527-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb527-2"><a href="#cb527-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span>
<span id="cb527-3"><a href="#cb527-3" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">4</span>)</span>
<span id="cb527-4"><a href="#cb527-4" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb527-5"><a href="#cb527-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived, </span>
<span id="cb527-6"><a href="#cb527-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;pairs&quot;</span>,</span>
<span id="cb527-7"><a href="#cb527-7" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Add a key at the top</span></span>
<span id="cb527-8"><a href="#cb527-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-201-1.png" width="672" /></p>
<p>ó</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="#cb528-1" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">9</span>)</span>
<span id="cb528-2"><a href="#cb528-2" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb528-3"><a href="#cb528-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived,</span>
<span id="cb528-4"><a href="#cb528-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;density&quot;</span>, </span>
<span id="cb528-5"><a href="#cb528-5" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to xyplot() to </span></span>
<span id="cb528-6"><a href="#cb528-6" aria-hidden="true" tabindex="-1"></a>            <span class="do">## make it prettier</span></span>
<span id="cb528-7"><a href="#cb528-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), </span>
<span id="cb528-8"><a href="#cb528-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>)), </span>
<span id="cb528-9"><a href="#cb528-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">adjust =</span> <span class="fl">1.5</span>, </span>
<span id="cb528-10"><a href="#cb528-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">pch =</span> <span class="st">&quot;|&quot;</span>, </span>
<span id="cb528-11"><a href="#cb528-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), </span>
<span id="cb528-12"><a href="#cb528-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-202-1.png" width="672" /></p>
<p>ó</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="#cb529-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb529-2"><a href="#cb529-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived, </span>
<span id="cb529-3"><a href="#cb529-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;box&quot;</span>, </span>
<span id="cb529-4"><a href="#cb529-4" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to bwplot() </span></span>
<span id="cb529-5"><a href="#cb529-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>),</span>
<span id="cb529-6"><a href="#cb529-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">x =</span> <span class="fu">list</span>(<span class="at">rot =</span> <span class="dv">90</span>)),  </span>
<span id="cb529-7"><a href="#cb529-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), </span>
<span id="cb529-8"><a href="#cb529-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-203-1.png" width="672" /></p>
</div>
<div id="ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama" class="section level2 hasAnchor" number="9.3">
<h2 class="hasAnchor"><span class="header-section-number">9.3</span> Ejemplo completo: creación de modelo diagnóstico para cáncer de mama<a href="#ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para illustrar el uso de esta librería con datos reales, usaremos una base de datos que contiene datos de un estudio sobre diagnóstico del cáncer de mama por imagen. Mediante una punción con aguja fina se extrae una muestra del tejido sospechoso de la paciente. La muestra se tiñe para resaltar los núcleos de las células y se determinan los límites exactos de los núcleos. Las variables consideradas corresponden a distintos aspectos de la forma del núcleo. El fichero <code>breast.csv</code> accesible en el Moodle contiene 30 variables explicativas medidas en pacientes cuyos tumores fueron diagnosticados posteriormente como benignos o malignos (variable <code>diagnosis</code> considerada como la variable resultado). Hay 569 observaciones, de las que 357 corresponden a tumores benignos y 212 a tumores malignos. La primera variable (<code>id</code>) corresponde al identificador de paciente. Información adicional sobre estos datos se pueden encontrar <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">aquí</a>.</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="#cb530-1" aria-hidden="true" tabindex="-1"></a>breast <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_delim</span>(<span class="st">&quot;data/breast.csv&quot;</span>, <span class="at">delim=</span><span class="st">&quot;,&quot;</span>)</span></code></pre></div>
<p>Podemos hacer servir <code>caret</code> o <code>recipes</code> para llevar a cabo todos estos pasos. Lo haremos con <code>recipes</code> que controlamos un poco más qué estamos llevando a cabo en cada momento.</p>
<p><strong>Paso 1</strong>: Visualizar la información de la que disponemos y ver si las variables están en el formato que corresponde</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="#cb531-1" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">glimpse</span>(breast)</span></code></pre></div>
<pre><code>Rows: 569
Columns: 32
$ id                      &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402, 843786, 844359, 8445820…
$ diagnosis               &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;,…
$ radius_mean             &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.450, 18.250, 13.710, 13.00…
$ texture_mean            &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.98, 20.83, 21.82, 24.04,…
$ perimeter_mean          &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, 119.60, 90.20, 87.50, 8…
$ area_mean               &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, 1040.0, 577.9, 519.8, 4…
$ smoothness_mean         &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0.12780, 0.09463, 0.1189…
$ compactness_mean        &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0.17000, 0.10900, 0.1645…
$ concavity_mean          &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0.15780, 0.11270, 0.0936…
$ `concave points_mean`   &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0.08089, 0.07400, 0.0598…
$ symmetry_mean           &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087, 0.1794, 0.2196, 0.235…
$ fractal_dimension_mean  &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0.07613, 0.05742, 0.0745…
$ radius_se               &lt;dbl&gt; 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345, 0.4467, 0.5835, 0.306…
$ texture_se              &lt;dbl&gt; 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902, 0.7732, 1.3770, 1.002…
$ perimeter_se            &lt;dbl&gt; 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.180, 3.856, 2.406, 2.039,…
$ area_se                 &lt;dbl&gt; 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.91, 50.96, 24.32, 23.94…
$ smoothness_se           &lt;dbl&gt; 0.006399, 0.005225, 0.006150, 0.009110, 0.011490, 0.007510, 0.004314,…
$ compactness_se          &lt;dbl&gt; 0.049040, 0.013080, 0.040060, 0.074580, 0.024610, 0.033450, 0.013820,…
$ concavity_se            &lt;dbl&gt; 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0.03672, 0.02254, 0.0248…
$ `concave points_se`     &lt;dbl&gt; 0.015870, 0.013400, 0.020580, 0.018670, 0.018850, 0.011370, 0.010390,…
$ symmetry_se             &lt;dbl&gt; 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0.02165, 0.01369, 0.0148…
$ fractal_dimension_se    &lt;dbl&gt; 0.006193, 0.003532, 0.004571, 0.009208, 0.005115, 0.005082, 0.002179,…
$ radius_worst            &lt;dbl&gt; 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.88, 17.06, 15.49, 15.09,…
$ texture_worst           &lt;dbl&gt; 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.66, 28.14, 30.73, 40.68,…
$ perimeter_worst         &lt;dbl&gt; 184.60, 158.80, 152.50, 98.87, 152.20, 103.40, 153.20, 110.60, 106.20…
$ area_worst              &lt;dbl&gt; 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, 1606.0, 897.0, 739.3, 7…
$ smoothness_worst        &lt;dbl&gt; 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791, 0.1442, 0.1654, 0.170…
$ compactness_worst       &lt;dbl&gt; 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249, 0.2576, 0.3682, 0.540…
$ concavity_worst         &lt;dbl&gt; 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0.53550, 0.37840, 0.2678…
$ `concave points_worst`  &lt;dbl&gt; 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0.17410, 0.19320, 0.1556…
$ symmetry_worst          &lt;dbl&gt; 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985, 0.3063, 0.3196, 0.437…
$ fractal_dimension_worst &lt;dbl&gt; 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0.12440, 0.08368, 0.1151…</code></pre>
<p>Vemos que todas las variables excepto nuestro resultado (diagnosis: tipo de tumor) son continuas. Como la variable resultado es character, es recomendable pasarla a factor</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="#cb533-1" aria-hidden="true" tabindex="-1"></a>breast <span class="ot">&lt;-</span> <span class="fu">mutate</span>(breast, <span class="at">diagnosis=</span><span class="fu">as.factor</span>(diagnosis))</span></code></pre></div>
<p><strong>Paso 2:</strong> Puesto que no tenemos datos de entrenamiento y test, lo crearemos nosotros</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="#cb534-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb534-2"><a href="#cb534-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb534-3"><a href="#cb534-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb534-4"><a href="#cb534-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> breast<span class="sc">$</span>diagnosis, <span class="at">p =</span> <span class="fl">0.7</span>, </span>
<span id="cb534-5"><a href="#cb534-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">list =</span> <span class="cn">FALSE</span>, <span class="at">times =</span> <span class="dv">1</span>)</span>
<span id="cb534-6"><a href="#cb534-6" aria-hidden="true" tabindex="-1"></a>breast_train <span class="ot">&lt;-</span> breast[train, ]</span>
<span id="cb534-7"><a href="#cb534-7" aria-hidden="true" tabindex="-1"></a>breast_test  <span class="ot">&lt;-</span> breast[<span class="sc">-</span>train, ]</span></code></pre></div>
<p><strong>Paso 3:</strong> Crear un objeto <code>recipe</code> con la variable respuesta y los predictores</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span>
<span id="cb535-2"><a href="#cb535-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(<span class="at">formula =</span> diagnosis <span class="sc">~</span> . ,</span>
<span id="cb535-3"><a href="#cb535-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span>  breast_train)</span>
<span id="cb535-4"><a href="#cb535-4" aria-hidden="true" tabindex="-1"></a><span class="co"># debemos eliminar la variable id que irrelevante para predecir</span></span>
<span id="cb535-5"><a href="#cb535-5" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_rm</span>(id)</span>
<span id="cb535-6"><a href="#cb535-6" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         31

Operations:

Variables removed id</code></pre>
<p><strong>Paso 4:</strong> Veamos si tenemos datos faltantes</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="#cb537-1" aria-hidden="true" tabindex="-1"></a><span class="fu">any</span>(<span class="fu">is.na</span>(breast))</span></code></pre></div>
<pre><code>[1] FALSE</code></pre>
<p><strong>Paso 5:</strong> Puesto que no hay, podemos pasar al siguiente paso que sería ver si hay que eliminar variablaes con varianza próxima a cero. Empecemos viendo si hay alguna. Puesto que todas son continuas, esto nos facilitará la escritura en R no teniendo que usar la función <code>select ()</code> para seleccionar las varaibles continuas</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="#cb539-1" aria-hidden="true" tabindex="-1"></a>breast_train <span class="sc">%&gt;%</span> <span class="fu">nearZeroVar</span>(<span class="at">saveMetrics =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>                        freqRatio percentUnique zeroVar   nzv
id                       1.000000   100.0000000   FALSE FALSE
diagnosis                1.677852     0.5012531   FALSE FALSE
radius_mean              1.000000    86.2155388   FALSE FALSE
texture_mean             1.500000    88.9724311   FALSE FALSE
perimeter_mean           1.000000    93.9849624   FALSE FALSE
area_mean                1.000000    95.2380952   FALSE FALSE
smoothness_mean          1.000000    85.7142857   FALSE FALSE
compactness_mean         1.000000    96.4912281   FALSE FALSE
concavity_mean           3.000000    95.7393484   FALSE FALSE
concave points_mean      3.000000    96.7418546   FALSE FALSE
symmetry_mean            1.333333    81.2030075   FALSE FALSE
fractal_dimension_mean   1.500000    92.2305764   FALSE FALSE
radius_se                1.000000    95.4887218   FALSE FALSE
texture_se               1.000000    93.4837093   FALSE FALSE
perimeter_se             2.000000    94.9874687   FALSE FALSE
area_se                  1.500000    95.4887218   FALSE FALSE
smoothness_se            1.000000    97.2431078   FALSE FALSE
compactness_se           1.500000    96.2406015   FALSE FALSE
concavity_se             3.000000    95.2380952   FALSE FALSE
concave points_se        2.000000    91.7293233   FALSE FALSE
symmetry_se              1.000000    90.9774436   FALSE FALSE
fractal_dimension_se     1.000000    97.2431078   FALSE FALSE
radius_worst             1.333333    83.2080201   FALSE FALSE
texture_worst            1.000000    92.2305764   FALSE FALSE
perimeter_worst          1.500000    93.4837093   FALSE FALSE
area_worst               1.000000    96.4912281   FALSE FALSE
smoothness_worst         1.000000    78.9473684   FALSE FALSE
compactness_worst        1.500000    95.7393484   FALSE FALSE
concavity_worst          2.000000    96.7418546   FALSE FALSE
concave points_worst     2.000000    89.9749373   FALSE FALSE
symmetry_worst           1.500000    90.7268170   FALSE FALSE
fractal_dimension_worst  1.000000    96.4912281   FALSE FALSE</code></pre>
<p>Vemos que tampoco hay ninguna variable que tenga que ser eliminada por este motivo. Este paso no sería necesario realizarlo, pero lo dejamos para que sirva como ejemplo para otros casos</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="#cb541-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p><strong>Paso 6:</strong> El siguiente paso sería eliminar aquellas variables con correlación elevada. El argumento <code>threshold</code> nos permite elegir el grado de correlación que por defecto es 0.9.</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="#cb542-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_corr</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p><strong>Paso 7:</strong> Ahora centraremos y normalizaremos los datos (esto último no tiene porqué sere necesario). Recordamos que también se pueden transformar los datos para garantizar normalidad usando <code>preProcess()</code> con el métodos Box-Cox o Yeo-Johnson de <code>caret()</code>.</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="#cb543-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_center</span>(<span class="fu">all_numeric</span>())</span>
<span id="cb543-2"><a href="#cb543-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p><strong>Paso 8</strong>: La binarización de variables no es necesario</p>
<p><strong>Paso 9</strong>: Aprendizaje de las transformaciones de pre-procesado y aplicación a nuestros conjuntos de datos. Empezamos con el entrenamiento</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="#cb544-1" aria-hidden="true" tabindex="-1"></a>trained_recipe <span class="ot">&lt;-</span> <span class="fu">prep</span>(objeto_recipe, <span class="at">training =</span> breast_train)</span>
<span id="cb544-2"><a href="#cb544-2" aria-hidden="true" tabindex="-1"></a>trained_recipe</span></code></pre></div>
<pre><code>Recipe

Inputs:

      role #variables
   outcome          1
 predictor         31

Training data contained 399 data points and no missing data.

Operations:

Variables removed id [trained]
Sparse, unbalanced variable filter removed &lt;none&gt; [trained]
Correlation filter on perimeter_mean, perimeter_se, radius_worst, texture_worst, perim... [trained]
Centering for texture_mean, area_mean, smoothness_mean, compactness_mean, symmetry_m... [trained]
Scaling for texture_mean, area_mean, smoothness_mean, compactness_mean, symmetry_m... [trained]</code></pre>
<p>y continuamos con la aplicación a nuestros datos test y train</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="#cb546-1" aria-hidden="true" tabindex="-1"></a>breast_train_prep <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> breast_train)</span>
<span id="cb546-2"><a href="#cb546-2" aria-hidden="true" tabindex="-1"></a>breast_test_prep  <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> breast_test)</span>
<span id="cb546-3"><a href="#cb546-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb546-4"><a href="#cb546-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(breast_train_prep)</span></code></pre></div>
<pre><code>Rows: 399
Columns: 20
$ texture_mean            &lt;dbl&gt; 0.4958449, 0.2881680, -1.1536351, -0.8289907, 0.3955871, 0.6319091, 1…
$ area_mean               &lt;dbl&gt; 1.57356630, -0.76566930, 1.84274018, -0.50508607, -0.21644003, -0.382…
$ smoothness_mean         &lt;dbl&gt; 0.86440333, 3.11247741, 0.22892950, 2.10801878, 1.49987716, 2.0738535…
$ compactness_mean        &lt;dbl&gt; 1.048709540, 3.387816481, 0.537501491, 1.239233573, 1.135482862, 1.67…
$ symmetry_mean           &lt;dbl&gt; 0.917687339, 2.799401020, -0.008914095, 0.981836669, 1.370296501, 1.9…
$ fractal_dimension_mean  &lt;dbl&gt; -0.42639724, 4.98925612, -0.59414511, 1.90761198, 1.67334340, 1.58368…
$ texture_se              &lt;dbl&gt; -0.80849714, -0.08080732, -0.81953767, -0.60483862, 0.35489967, -0.38…
$ area_se                 &lt;dbl&gt; 1.31855202, -0.28815366, 1.32841354, -0.28911575, 0.28261170, -0.3581…
$ smoothness_se           &lt;dbl&gt; -0.30223259, 0.65056583, 1.41666726, 0.13553966, 0.55238896, -0.43710…
$ compactness_se          &lt;dbl&gt; 0.85265446, 2.83595905, -0.03500649, 0.47288495, 0.29133100, 0.563087…
$ concavity_se            &lt;dbl&gt; 0.30900888, 1.07030125, 1.08153957, 0.24241140, -0.25040990, 0.192879…
$ `concave points_se`     &lt;dbl&gt; 1.630026033, 1.284095782, 1.316696538, -0.038046018, 0.525222612, 0.1…
$ symmetry_se             &lt;dbl&gt; 0.24097383, 4.68326185, -0.35005507, 0.13927857, -0.67308705, 0.11295…
$ fractal_dimension_se    &lt;dbl&gt; 0.392387187, 2.560158937, 0.646704166, 0.631276850, 0.785550017, 0.00…
$ smoothness_worst        &lt;dbl&gt; 0.47944015, 3.24454482, 0.18348094, 1.94655226, 1.36731780, 1.5744892…
$ compactness_worst       &lt;dbl&gt; 1.05036897, 3.78488958, -0.30822603, 1.67179466, 0.70190019, 1.765875…
$ `concave points_worst`  &lt;dbl&gt; 1.96343178, 2.18407810, 0.73846430, 0.91498136, 0.63346709, 1.4004032…
$ symmetry_worst          &lt;dbl&gt; 1.09719973, 5.76429394, -0.82980875, 1.67113661, 0.45383501, 2.277473…
$ fractal_dimension_worst &lt;dbl&gt; 0.17926376, 4.82187666, -0.40772078, 2.18044624, 1.67498733, 1.245619…
$ diagnosis               &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, B, B, M, M, M, M, M, M, M, M, M, …</code></pre>
<p><strong>Paso 10:</strong> Visualización</p>
<p>Hagamos algunos de los gráficos que hemos visto</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="#cb548-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span>
<span id="cb548-2"><a href="#cb548-2" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">4</span>)</span>
<span id="cb548-3"><a href="#cb548-3" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(breast_train_prep, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>), </span>
<span id="cb548-4"><a href="#cb548-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> breast_train_prep<span class="sc">$</span>diagnosis, </span>
<span id="cb548-5"><a href="#cb548-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;pairs&quot;</span>,</span>
<span id="cb548-6"><a href="#cb548-6" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Add a key at the top</span></span>
<span id="cb548-7"><a href="#cb548-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-216-1.png" width="672" /></p>
</div>
<div id="creación-de-un-modelo-predictivo" class="section level2 hasAnchor" number="9.4">
<h2 class="hasAnchor"><span class="header-section-number">9.4</span> Creación de un modelo predictivo<a href="#creación-de-un-modelo-predictivo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez que ya hemos preprocesado nuestros datos, podemos pasar a la parte de creación de un modelo. La librería <code>caret</code> tiene varias funciones que intenta reproducir lo que hasta ahora hemos realizado más o menos de forma manual.</p>
<p>La función <code>train</code> se puede usar para:</p>
<ul>
<li>evaluar, mediante remuestreo, el efecto de los parámetros de ajuste del modelo - elegir el modelo “óptimo” a través de estos parámetros</li>
<li>estimar el rendimiento del modelo a partir de un conjunto de entrenamiento</li>
</ul>
<p>Primero, se debe elegir un modelo específico. Actualmente, hay 238 disponibles que pueden consultarse <a href="https://topepo.github.io/caret/available-models.html">aquí</a>. Estos modelos los iremos viendo de forma individual a lo largo del curso y estudiaremos los parámetros que potencialmente pueden optimizarse. También se pueden crear modelos definidos por el usuario.</p>
<div class="figure">
<img src="figures/TrainAlgo.png" alt="" />
<p class="caption">Algoritmo de entrenamiento</p>
</div>
<p>El primer paso para ajustar el modelo (línea 1 en el algoritmo a continuación) es elegir un conjunto de parámetros para evaluar. Por ejemplo, si se ajusta a un modelo de mínimos cuadrados parciales (PLS), se debe especificar el número de componentes PLS a evaluar.</p>
<p>Una vez que se han definido el modelo y los valores de los parámetros de ajuste, también se debe especificar el tipo de remuestreo. Actualmente, tiene implementado LOOCV, K-fold CV y Bootstrap. Después del remuestreo, se obtiene una medida de ajuste para cada remuestra que permite guiar al usuario sobre qué valores de parámetros de ajuste deben elegirse. De forma predeterminada, la función elige automáticamente los parámetros de ajuste asociados con el mejor valor, aunque se pueden utilizar diferentes métricas.</p>
<p>Veamos cómo funcionaría en nuestro caso utilizando la regresión logística (dado que nuestro outcome es binario) como método de aprendizaje para la creación de un modelo predictivo.</p>
<p>Partimos del hecho que ya hemos hecho un pre-procesado de datos tal y como hemos mostrado anteriormente y que nuestros datos de entrenamiento y validación se llaman <code>breast_train_prep</code> y <code>breast_test_prep</code>, respectivamente. Por defecto el método utiliza boostrap para evaluar la capacidad predictiva del modelo. La función <code>trainControl()</code> se puede utilizar para especificar el tipo de remuestreo. Podéis encontrar más información sobre esta función <a href="https://topepo.github.io/caret/model-training-and-tuning.html#control">aquí</a>:</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="#cb549-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="do">## 10-fold CV</span></span>
<span id="cb549-2"><a href="#cb549-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb549-3"><a href="#cb549-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb549-4"><a href="#cb549-4" aria-hidden="true" tabindex="-1"></a>                           <span class="do">## repeated ten times</span></span>
<span id="cb549-5"><a href="#cb549-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">repeats =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>Estamos haciendo una estimación de la capacidad predictiva del modelo con un 10-fold CV (argumento <code>number</code>) y lo repetimos 10 veces para garantizar aleatoriedad.</p>
<p>Despues usamos la función <code>train()</code></p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="#cb550-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb550-2"><a href="#cb550-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressMessages</span>(fit <span class="ot">&lt;-</span> <span class="fu">train</span>(diagnosis <span class="sc">~</span> ., <span class="at">data =</span> breast_train_prep, </span>
<span id="cb550-3"><a href="#cb550-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb550-4"><a href="#cb550-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">trControl =</span> fitControl))</span>
<span id="cb550-5"><a href="#cb550-5" aria-hidden="true" tabindex="-1"></a>fit</span></code></pre></div>
<pre><code>Generalized Linear Model 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 
Summary of sample sizes: 360, 359, 359, 359, 359, 359, ... 
Resampling results:

  Accuracy   Kappa    
  0.9506731  0.8948839</code></pre>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>EJERCICIO</strong> (Entrega en Moodle: P-Preproceso cáncer de cervix): Vamos analizar los datos pertenecientes a un estudio multicéntrico internacional caso-control de cáncer de cuello uterino realizado en 7 países: Brasil, Marruecos, Filipinas, Tailandia, Perú, España y Colombia. La base de datos contiene información sobre variables identificativas (<code>status</code> es la variable respuesta 0:Control - 1:Caso), demográficas, de riesgo incluyendo la presencia de infección por Virus del Papiloma Humano de 1489 casos de cáncer de cuello uterino y 1421 controles apareados por grupos de edad.</td>
</tr>
<tr class="even">
<td>&gt; Las variables pueden contener valores en blanco que corresponden a información perdida o que no procede.</td>
</tr>
<tr class="odd">
<td>La información de las variables se puede ver en el siguiente archivo html que se puede visualizar en su totalidad con la barra que hay en la derecha:</td>
</tr>
<tr class="even">
<td><embed src="data/multicentric.htm" style="width:105.0%" /></td>
</tr>
<tr class="odd">
<td>- Realiza todos los pasos de preprocesado necesarios para crear una base de datos de entrenamiento (70%) y otra de test (30%) que usaremos para otros ejercicios futuros correspondientes a los diferentes métodos de aprendizaje automático que veremos en este curso. Recordemos que la variable resultado es una variable binaria (status: 0-Control/1-Caso).</td>
</tr>
</tbody>
</table>
<!--chapter:end:07-caret.Rmd-->
</div>
</div>
<div id="KNN" class="section level1 hasAnchor" number="10">
<h1 class="hasAnchor"><span class="header-section-number">10</span> K vecinos más próximos (KNN)<a href="#KNN" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>La regresión de K veinos más próximos (KNN por sus siglas en inglés) es un <strong>método no paramétrico</strong> que, de manera intuitiva, aproxima la asociación entre las variables independientes y el resultado continuo promediando las observaciones en la misma vecindad. El usuario debe establecer el número de vecinos o puede elegirlo mediante validación cruzada (lo veremos más adelante) para seleccionar el tamaño que minimiza el error cuadrático medio.</p>
<p>Si bien el método es bastante atractivo, rápidamente se vuelve poco práctico cuando aumenta la dimensión, es decir, cuando hay muchas variables independientes.</p>
<p>Los métodos del vecino más cercano proporcionan una forma bastante diferente de construir clasificadores y tienen fortalezas (supuestos mínimos, límites de decisión flexibles) y debilidades (carga computacional, falta de interpretabilidad) en comparación con los modelos de regresión logística.</p>
<p>En principio, la idea es sencilla. Recordemos que el conjunto de entrenamiento tendrá tanto predictores <span class="math inline">\(X\)</span> como una variable resultado <span class="math inline">\(Y\)</span> mientras que el conjunto de prueba sólo tendrá
valores de <span class="math inline">\(X\)</span> conocidos. Ambos conjunto de datos son necesarios.</p>
<p>Comenzamos eligiendo un número entero positivo <span class="math inline">\(k\)</span> que especificará el número de vecinos que se utilizarán en la clasificación. Para clasificar un punto
<span class="math inline">\(x\)</span> en el conjunto test, se buscarán los <span class="math inline">\(k\)</span> puntos más cercanos en el conjunto de entrenamiento, y se elige la clase que tenga la representación más alta entre los <span class="math inline">\(k\)</span> puntos. De aquí que el algoritmo se llame KNN (“k vecinos más cercanos”).</p>
<div class="figure">
<img src="figures/knn.jpg" alt="" />
<p class="caption">Algoritmo KNN</p>
</div>
<p>Por ejemplo, supongamos que <span class="math inline">\(k=10\)</span> y los 10 vecinos más cercanos a <span class="math inline">\(x\)</span> tienen clases 1,1,3,2,3,3,3,2,3,2. Como hay cinco 3, tres 2 y dos 1, el punto <span class="math inline">\(x\)</span> se asigna a la clase 3. Supongamos que para otro <span class="math inline">\(x\)</span> los 10 vecinos más cercanos tienen clases 1,1,1,2,3,1,3,3,3,2. En este caso hay cuatro 1s y cuatro 3s, por lo que hay un empate en el liderato. El algoritmo vecino más cercano elegirá entre 1 y 3 al azar.</p>
<p>Aunque, en principio, KNN es sencillo, surgen algunos problemas. Primero, ¿cómo deberíamos elegir <span class="math inline">\(k\)</span>? No hay una respuesta fácil, pero puede ayudar pensar en los valores extremos para <span class="math inline">\(k\)</span>. Podemos seleccionar <span class="math inline">\(k\)</span> lo mas grande posible. Por ejemplo, supongamos que el conjunto de entrenamiento tiene 10 observaciones, con clases 1,1,1,2,2,2,3,3,3,3. Para cualquier punto del conjunto de prueba,
<span class="math inline">\(k=10\)</span> los vecinos más cercanos incluirán TODOS los puntos del conjunto de entrenamiento y, por lo tanto, cada punto del conjunto de prueba se clasificará en la clase 3. Este clasificador tiene una varianza baja (cero), pero probablemente un sesgo alto.</p>
<p>Si seleccionamos <span class="math inline">\(k\)</span> lo mas pequeño posible, estaríamos en el caso <span class="math inline">\(k=1\)</span>. En este caso, cada punto del conjunto de prueba se coloca en la misma clase que su vecino más cercano en el conjunto de entrenamiento. Esto puede conducir a un clasificador de alta varianza y muy irregular, pero el sesgo tenderá a ser pequeño.</p>
<p>Un segundo tema que es relativamente fácil de abordar se refiere a las escalas en las que se miden los valores de <span class="math inline">\(x\)</span>. Si por ejemplo una variable <span class="math inline">\(x\)</span> tienen un rango de 2 a 4, mientras que otra tiene un rango de 2000 a 4000, la distancia estará dominada por la segunda variable. La solución que se suele utilizar es normalizar todas las variables (cambiar su escala para que su media sea 0 y su desviación estándar sea 1).</p>
<p>Existen muchas liberías para llevar a cabo KNN. Nosotros usaremos la libería <code>class</code> para ilustrar el ejemplo de cáncer de mama visto anteriormente y para el que ya hemos normalizado nuestros predictores.</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="#cb552-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb552-2"><a href="#cb552-2" aria-hidden="true" tabindex="-1"></a><span class="co"># para asegurarnos que usamos knn de class</span></span>
<span id="cb552-3"><a href="#cb552-3" aria-hidden="true" tabindex="-1"></a>fit.knn <span class="ot">&lt;-</span> class<span class="sc">::</span><span class="fu">knn</span>(<span class="at">train=</span><span class="fu">select</span>(breast_train_prep, <span class="sc">!</span>diagnosis),</span>
<span id="cb552-4"><a href="#cb552-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">test=</span><span class="fu">select</span>(breast_test_prep, <span class="sc">!</span>diagnosis),</span>
<span id="cb552-5"><a href="#cb552-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cl=</span>breast_train_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb552-6"><a href="#cb552-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">k=</span><span class="dv">10</span>, <span class="at">prob=</span><span class="cn">TRUE</span>)</span>
<span id="cb552-7"><a href="#cb552-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(fit.knn)</span></code></pre></div>
<pre><code>[1] M M M M M M
Levels: B M</code></pre>
<p>La probabilidad que cada individuo de la muestra test pertenezca al grupo asignado la podemos obtener con</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="#cb554-1" aria-hidden="true" tabindex="-1"></a>prob <span class="ot">&lt;-</span> <span class="fu">attr</span>(fit.knn, <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb554-2"><a href="#cb554-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(prob)</span></code></pre></div>
<pre><code>[1] 1.0 1.0 1.0 0.6 0.7 1.0</code></pre>
<p>A continuación podemos crear un gráfico. Esto es algo complejo, ya que queremos representar los datos de la muestra test coloreados por la clase a la que fueron asignados por el clasificador kNN (como fondo de la imagen) con los datos de entrenamiento (usando un símbolo diferente) y el límite de decisión. Este gráfico sólo lo podemos hacer para dos variables predictoras. Por ejemplo <code>symmetry_worst</code> y <code>texture_se</code>.</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="#cb556-1" aria-hidden="true" tabindex="-1"></a>plot.df <span class="ot">&lt;-</span> breast_test_prep <span class="sc">%&gt;%</span></span>
<span id="cb556-2"><a href="#cb556-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(symmetry_worst, texture_se ) <span class="sc">%&gt;%</span></span>
<span id="cb556-3"><a href="#cb556-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predicted =</span> <span class="fu">as.factor</span>(fit.knn))</span>
<span id="cb556-4"><a href="#cb556-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Usamos un &#39;convex hull&#39; para determinar los puntos que determinan los límites</span></span>
<span id="cb556-5"><a href="#cb556-5" aria-hidden="true" tabindex="-1"></a><span class="co"># de cada cluster</span></span>
<span id="cb556-6"><a href="#cb556-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb556-7"><a href="#cb556-7" aria-hidden="true" tabindex="-1"></a>plot.df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> plot.df<span class="sc">$</span>symmetry_worst, </span>
<span id="cb556-8"><a href="#cb556-8" aria-hidden="true" tabindex="-1"></a>                      <span class="at">y =</span> plot.df<span class="sc">$</span>texture_se, </span>
<span id="cb556-9"><a href="#cb556-9" aria-hidden="true" tabindex="-1"></a>                      <span class="at">predicted =</span> plot.df<span class="sc">$</span>predicted)</span>
<span id="cb556-10"><a href="#cb556-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb556-11"><a href="#cb556-11" aria-hidden="true" tabindex="-1"></a>find_hull <span class="ot">&lt;-</span> <span class="cf">function</span>(df) df[<span class="fu">chull</span>(df<span class="sc">$</span>x, df<span class="sc">$</span>y), ]</span>
<span id="cb556-12"><a href="#cb556-12" aria-hidden="true" tabindex="-1"></a>boundary <span class="ot">&lt;-</span> plyr<span class="sc">::</span><span class="fu">ddply</span>(plot.df1, <span class="at">.variables =</span> <span class="st">&quot;predicted&quot;</span>, <span class="at">.fun =</span> find_hull)</span>
<span id="cb556-13"><a href="#cb556-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb556-14"><a href="#cb556-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot.df1, <span class="fu">aes</span>(x, y, <span class="at">color =</span> predicted, <span class="at">fill =</span> predicted)) <span class="sc">+</span> </span>
<span id="cb556-15"><a href="#cb556-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb556-16"><a href="#cb556-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_polygon</span>(<span class="at">data =</span> boundary, <span class="fu">aes</span>(x,y), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb556-17"><a href="#cb556-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;symmetry_worst&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;texture_se&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-221-1.png" width="672" /></p>
<p>Podemos ver la matriz de confusión</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="#cb557-1" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">predict=</span>fit.knn, <span class="at">Actual=</span>breast_test_prep<span class="sc">$</span>diagnosis)</span>
<span id="cb557-2"><a href="#cb557-2" aria-hidden="true" tabindex="-1"></a>tt</span></code></pre></div>
<pre><code>       Actual
predict   B   M
      B 105   9
      M   2  54</code></pre>
<p>y la precisión es</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(tt)<span class="sc">/</span><span class="fu">sum</span>(tt))</span></code></pre></div>
<pre><code>[1] 0.9352941</code></pre>
<p>Podemos repetir los mismos cálculos para <span class="math inline">\(k=15\)</span></p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="#cb561-1" aria-hidden="true" tabindex="-1"></a>fit.knn2 <span class="ot">&lt;-</span> class<span class="sc">::</span><span class="fu">knn</span>(<span class="at">train=</span><span class="fu">select</span>(breast_train_prep, <span class="sc">!</span>diagnosis),</span>
<span id="cb561-2"><a href="#cb561-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">test=</span><span class="fu">select</span>(breast_test_prep, <span class="sc">!</span>diagnosis),</span>
<span id="cb561-3"><a href="#cb561-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cl=</span>breast_train_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb561-4"><a href="#cb561-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">k=</span><span class="dv">10</span>)</span>
<span id="cb561-5"><a href="#cb561-5" aria-hidden="true" tabindex="-1"></a>fit.knn </span></code></pre></div>
<pre><code>  [1] M M M M M M B B M M M B B M B B M B B M B M M B M B B B B B B M B B M M B B B B B B B B M M B B M
 [50] B B M B B M B M M B B M M B M B B M B B M B M M M M B B B M B B B M B B B B B B B B B B M M B M M
 [99] M B B B B M B B B B B B B M B B B B B B B B B B M B B B B M B M M B B B M B M B B B B B B B M M B
[148] B B M B B B B B M B B B B B B B B B B M M M B
attr(,&quot;prob&quot;)
  [1] 1.0 1.0 1.0 0.6 0.7 1.0 0.5 1.0 1.0 0.9 0.6 1.0 1.0 1.0 1.0 1.0 0.9 1.0 0.6 1.0 1.0 1.0 0.8 0.8
 [25] 0.5 1.0 1.0 0.6 1.0 1.0 0.9 0.9 0.6 1.0 0.8 0.8 0.8 1.0 1.0 1.0 1.0 1.0 0.6 1.0 1.0 1.0 0.9 1.0
 [49] 1.0 0.7 1.0 1.0 1.0 1.0 0.8 1.0 0.9 0.9 1.0 0.6 0.7 1.0 0.7 1.0 0.5 1.0 1.0 1.0 0.8 1.0 0.7 1.0
 [73] 1.0 1.0 1.0 1.0 1.0 0.9 0.5 1.0 1.0 0.9 0.5 1.0 0.6 1.0 1.0 1.0 1.0 0.9 1.0 1.0 0.7 0.7 0.7 1.0
 [97] 0.9 1.0 1.0 0.9 0.9 1.0 1.0 1.0 1.0 1.0 1.0 0.8 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9 1.0 0.7
[121] 1.0 1.0 1.0 0.8 1.0 0.8 1.0 0.6 1.0 1.0 0.9 0.8 0.7 0.9 1.0 1.0 0.5 0.9 1.0 0.8 1.0 0.9 1.0 0.6
[145] 0.9 1.0 0.9 0.9 1.0 0.9 1.0 0.9 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.7 1.0 1.0 1.0 0.7 0.8 0.9 1.0 1.0
[169] 1.0 1.0
Levels: B M</code></pre>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="#cb563-1" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">predict=</span>fit.knn2, <span class="at">Actual=</span>breast_test_prep<span class="sc">$</span>diagnosis)</span>
<span id="cb563-2"><a href="#cb563-2" aria-hidden="true" tabindex="-1"></a>tt</span></code></pre></div>
<pre><code>       Actual
predict   B   M
      B 106   9
      M   1  54</code></pre>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="#cb565-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(tt)<span class="sc">/</span><span class="fu">sum</span>(tt))</span></code></pre></div>
<pre><code>[1] 0.9411765</code></pre>
<p>La precisión es peor. Entonces, parece que la precisión (entre otras medidas) nos puede ayudar a determinar cómo escoger <span class="math inline">\(k\)</span>.</p>
<p>Este parámetro se conoce como <strong>hiper-parámetro</strong> del modelo de predicción, y aquí es donde los métodos de validación cruzada son muy útiles.</p>
<p>Podemos usar la librería <code>caret</code> para realizar estos cálculos:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="#cb567-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="do">## LOCCV</span></span>
<span id="cb567-2"><a href="#cb567-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&quot;loocv&quot;</span>)</span>
<span id="cb567-3"><a href="#cb567-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb567-4"><a href="#cb567-4" aria-hidden="true" tabindex="-1"></a>fit.knn3 <span class="ot">&lt;-</span> <span class="fu">train</span>(diagnosis <span class="sc">~</span> ., </span>
<span id="cb567-5"><a href="#cb567-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>breast_train_prep,</span>
<span id="cb567-6"><a href="#cb567-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method=</span><span class="st">&quot;knn&quot;</span>,</span>
<span id="cb567-7"><a href="#cb567-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> fitControl, </span>
<span id="cb567-8"><a href="#cb567-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneLength=</span><span class="dv">10</span>)</span>
<span id="cb567-9"><a href="#cb567-9" aria-hidden="true" tabindex="-1"></a>      <span class="co"># no necesario pero se podría poner</span></span>
<span id="cb567-10"><a href="#cb567-10" aria-hidden="true" tabindex="-1"></a>      <span class="co"># preProcess = c(&quot;center, &quot;scale&quot;)</span></span>
<span id="cb567-11"><a href="#cb567-11" aria-hidden="true" tabindex="-1"></a>fit.knn3</span></code></pre></div>
<pre><code>k-Nearest Neighbors 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Leave-One-Out Cross-Validation 
Summary of sample sizes: 398, 398, 398, 398, 398, 398, ... 
Resampling results across tuning parameters:

  k   Accuracy   Kappa
   5  0.9423559  0    
   7  0.9448622  0    
   9  0.9523810  0    
  11  0.9448622  0    
  13  0.9423559  0    
  15  0.9373434  0    
  17  0.9373434  0    
  19  0.9373434  0    
  21  0.9373434  0    
  23  0.9373434  0    

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 9.</code></pre>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit.knn3)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-226-1.png" width="672" /></p>
<p>Podemos obtener otras medidas de capacidad predictiva de la siguiente manera:</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="#cb570-1" aria-hidden="true" tabindex="-1"></a>knnPredict <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.knn3, <span class="at">newdata=</span>breast_train_prep) </span>
<span id="cb570-2"><a href="#cb570-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(knnPredict, breast_train_prep<span class="sc">$</span>diagnosis)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   B   M
         B 246  13
         M   4 136
                                         
               Accuracy : 0.9574         
                 95% CI : (0.9327, 0.975)
    No Information Rate : 0.6266         
    P-Value [Acc &gt; NIR] : &lt; 2e-16        
                                         
                  Kappa : 0.9078         
                                         
 Mcnemar&#39;s Test P-Value : 0.05235        
                                         
            Sensitivity : 0.9840         
            Specificity : 0.9128         
         Pos Pred Value : 0.9498         
         Neg Pred Value : 0.9714         
             Prevalence : 0.6266         
         Detection Rate : 0.6165         
   Detection Prevalence : 0.6491         
      Balanced Accuracy : 0.9484         
                                         
       &#39;Positive&#39; Class : B              
                                         </code></pre>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-KNN):</td>
</tr>
<tr class="even">
<td align="left">Implementa una función (idealmente podrímo usar el padigma MapReduce) que nos devuelva la precisión del método KNN usando LOOCV para un rango de <span class="math inline">\(k\)</span> que le de el usuario y que devuelva cuál es el <span class="math inline">\(k\)</span> óptimo. Úsa esta función para reproducir los resultados del ejemplo anterior (los de la función <code>train()</code>).</td>
</tr>
</tbody>
</table>
<!--chapter:end:08-knn.Rmd-->
</div>
<div id="análisis-discriminante-lineal-lda" class="section level1 hasAnchor" number="11">
<h1 class="hasAnchor"><span class="header-section-number">11</span> Análisis discriminante lineal (LDA)<a href="#análisis-discriminante-lineal-lda" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>El análisis discriminante lineal (LDA por sus siglas en inglés) es una clasificación de aprendizaje automático supervisado (binario o multimonial) y un método de reducción de dimensiones. LDA encuentra combinaciones lineales de variables que mejor “discriminan” las clases de la variable respuesta.</p>
<p><strong>Un enfoque (Welch)</strong> de LDA supone que las variables predictoras son variables aleatorias continuas normalmente distribuidas y con la misma varianza. Para que se cumpla esta condición, normalmente deberemos escalar los datos</p>
<p>Para una variable respuesta de <span class="math inline">\(k\)</span> niveles, LDA produce <span class="math inline">\(k-1\)</span> (reglas) discriminantes utilizando el teorema de Bayes.</p>
<p><span class="math display">\[Pr[Y = C_l | X] = \frac{P[Y = C_l] P[X | Y = C_l]}{\sum_{l=1}^C Pr[Y = C_l] Pr[X | Y = C_l]}\]</span></p>
<p>donde <span class="math inline">\(Y\)</span> es la variable respuesta, <span class="math inline">\(X\)</span> son los predictores y <span class="math inline">\(C_l\)</span> es la clase <span class="math inline">\(l\)</span>-ésima. Entonces, la probablidad de que <span class="math inline">\(Y\)</span> sea igual al nivel <span class="math inline">\(C_l\)</span> dados los predictores <span class="math inline">\(X\)</span> es igual a la probabilidad a <em>priori</em> de <span class="math inline">\(Y\)</span> multiplicado por la probabilidad de observar <span class="math inline">\(X\)</span> si <span class="math inline">\(Y=C_l\)</span> dividido por la suma de todas las probabilidades de <span class="math inline">\(X\)</span> data las priors. El valor predicho para cualquier <span class="math inline">\(X\)</span> es simplemente <span class="math inline">\(C_l\)</span> que tenga la probabilidad másxima.</p>
<p>Una forma de calcular las probabilidades es asumir que <span class="math inline">\(X\)</span> tiene una distribución normal multivariante con medias <span class="math inline">\(\mu_l\)</span> y varianza común <span class="math inline">\(\Sigma\)</span>. Entonces la función de discriminación lineal para el grupo <span class="math inline">\(l\)</span> es</p>
<p><span class="math display">\[X&#39;\Sigma^{-1}\mu_l - 0.5 \mu_l^{&#39;}\Sigma^{-1}\mu_l + \log(Pr[Y = C_l])\]</span></p>
<p>La media teórica y la matriz de covarianza se estiman mediante la media muestral
<span class="math inline">\(\mu=\bar{x}_l\)</span> y la covarianza <span class="math inline">\(\Sigma=S\)</span>, y los predictores <span class="math inline">\(X\)</span> se reemplazan con los predictores de muestra que denotamos <span class="math inline">\(u\)</span>.</p>
<p><strong>Otro enfoque (Fisher)</strong> para LDA es encontrar una combinación lineal de predictores que maximice la matriz de covarianza entre grupos, <span class="math inline">\(B\)</span>, relativo a la matriz de covarianza dentro del grupo (intra-grupo) <span class="math inline">\(W\)</span>.</p>
<p><span class="math display">\[\frac{b&#39;Bb}{b&#39;Wb}\]</span></p>
<p>La solución a este problema de optimización es el vector propio correspondiente al valor propio más grande de <span class="math inline">\(W^{-1}B\)</span>. Este vector es un discriminante lineal (e.g. una variable). Resolver para la configuración para dos grupos la función discriminante <span class="math inline">\(S^{-1}(\bar{x}_1 - \bar{x}_2)\)</span> donde <span class="math inline">\(S^{-1}\)</span> es la inversa de la matriz de covarianza de los datos y <span class="math inline">\(\bar{x}_1\)</span> y <span class="math inline">\(\bar{x}_2\)</span> son las medias de cada predictor en los grupos de respuesta 1 y 2. En la práctica, una nueva muestra, <span class="math inline">\(u\)</span> se proyecta sobre la función discriminante como <span class="math inline">\(uS^{-1}(\bar{x}_1 - \bar{x}_2)\)</span>, que devuelve una puntuación discriminante. Luego, una nueva muestra se clasifica en el grupo 1 si la muestra está más cerca de la media del grupo 1 que de la media del grupo 2 en la proyección:</p>
<p><span class="math display">\[\left| b&#39;(u - \bar{x}_1) \right| - \left| b&#39;(u - \bar{x}_2) \right| &lt; 0\]</span>
En general, el modelo requiere <span class="math inline">\(CP + P(P + 1)/2\)</span> parámetros con <span class="math inline">\(P\)</span> predictores y <span class="math inline">\(C\)</span> clases. El tener que estimar parámetros extra en los LDA es debido a que el modelo maneja explícitamente las correlaciones entre predictores. Esto debería <strong>proporcionar alguna ventaja a LDA sobre la regresión logística cuando hay correlaciones importantes</strong>, aunque ambos modelos no serán útiles cuando la multicolinealidad se vuelva extrema.</p>
<p><strong>Take home message:</strong></p>
<ul>
<li><p>La formulación de Fisher es intuitiva, fácil de resolver matemáticamente y, a diferencia del enfoque de Welch, no implica suposiciones sobre las distribuciones subyacentes de los datos.</p></li>
<li><p>En la práctica, es mejor centrar y escalar los predictores y eliminar los predictores de varianza cercana a cero. Si la matriz aún no es invertible, deberíamos usar Penalized Least Squares o Regularización (se verán en otros cursos).</p></li>
</ul>
<p>Veamos cómo hacer este análisis para los datos de cáncer de mama vistos en el capítulo anterior. Podemos llevar a cabo los análisis con muchas librerías, aquí usarems <code>MASS</code>. Tal y como es recomendado, usaremos los datos centrados y escalados (e.g normalizados) y eliminados las variables con varianza cercana a 0 que habíamos obtenido con la librería <code>recipes</code>. Usaremos el enfoque de Fisher que es el que más se usa en la actualida y que está implementado en la función <code>lda</code>.</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="#cb572-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb572-2"><a href="#cb572-2" aria-hidden="true" tabindex="-1"></a>fit.lda <span class="ot">&lt;-</span> <span class="fu">lda</span>(diagnosis <span class="sc">~</span> .,</span>
<span id="cb572-3"><a href="#cb572-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span> breast_train_prep)</span>
<span id="cb572-4"><a href="#cb572-4" aria-hidden="true" tabindex="-1"></a>fit.lda</span></code></pre></div>
<pre><code>Call:
lda(diagnosis ~ ., data = breast_train_prep)

Prior probabilities of groups:
        B         M 
0.6265664 0.3734336 

Group means:
  texture_mean  area_mean smoothness_mean compactness_mean symmetry_mean fractal_dimension_mean
B   -0.3345955 -0.5518490       -0.268585       -0.4766017    -0.2791966           -0.004083286
M    0.5614018  0.9259212        0.450646        0.7996673     0.4684507            0.006851150
   texture_se    area_se smoothness_se compactness_se concavity_se `concave points_se` symmetry_se
B  0.01149947 -0.4401372    0.03661085     -0.2657811   -0.2982358          -0.3482647 -0.01040297
M -0.01929442  0.7384853   -0.06142761      0.4459414    0.5003956           0.5843367  0.01745464
  fractal_dimension_se smoothness_worst compactness_worst `concave points_worst` symmetry_worst
B           -0.1039087       -0.3274326         -0.470998             -0.6204192     -0.3412650
M            0.1743434        0.5493836          0.790265              1.0409719      0.5725924
  fractal_dimension_worst
B              -0.2666749
M               0.4474411

Coefficients of linear discriminants:
                                LD1
texture_mean             0.30931136
area_mean                0.68624260
smoothness_mean          0.13601919
compactness_mean        -0.09120911
symmetry_mean           -0.01090323
fractal_dimension_mean  -0.54404616
texture_se               0.03822818
area_se                  0.14461685
smoothness_se            0.33368817
compactness_se          -0.38173259
concavity_se             0.15241639
`concave points_se`      0.22229600
symmetry_se             -0.04340207
fractal_dimension_se    -0.24056708
smoothness_worst        -0.11356764
compactness_worst        0.06356340
`concave points_worst`   0.75475718
symmetry_worst           0.35329884
fractal_dimension_worst  0.83711669</code></pre>
<p>Podemos observar cuánto vale la media para cada variable en cada uno de los grupos, y esto nos puede ayudar a saber qué variables son más importantes. Los coeficientes de los discriminantes lineales también nos pueden ayudar con la interpretación.</p>
<p>Podemos representar el valor de cada grupo para el primer discriminante lineal (sólo hay 1 ya que tenemos 2 grupos).</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="#cb574-1" aria-hidden="true" tabindex="-1"></a>prd <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.lda, breast_train_prep )</span>
<span id="cb574-2"><a href="#cb574-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ldahist</span>(<span class="at">data =</span> prd<span class="sc">$</span>x[,<span class="dv">1</span>], <span class="at">g =</span> breast_train_prep<span class="sc">$</span>diagnosis)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-229-1.png" width="672" /></p>
<p>Vemos que los grupos quedan bien separados según el primer discrimiante lineal.</p>
<p>Si tuviéramos 3 grupos también podríamos representar la misma clasificación para el primer y el segundo discriminate lineal. Para ello usaríamos la librería <code>ggord</code> que está en GitHub. Usaremos los datos iris para ilustrar este caso:</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="co"># devtools::install_github(&quot;fawda123/ggord&quot;)</span></span>
<span id="cb575-2"><a href="#cb575-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggord)</span>
<span id="cb575-3"><a href="#cb575-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb575-4"><a href="#cb575-4" aria-hidden="true" tabindex="-1"></a>lnr <span class="ot">&lt;-</span> <span class="fu">lda</span>(Species<span class="sc">~</span>., iris)</span>
<span id="cb575-5"><a href="#cb575-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggord</span>(lnr, iris<span class="sc">$</span>Species, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span> ))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-230-1.png" width="672" /></p>
<p>Podemos evaluar de forma manual cómo predice nuestro modelo en la muestra test para nuestro ejemplo de cáncer de mama usando la matriz de confusión:</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="#cb576-1" aria-hidden="true" tabindex="-1"></a>p.train <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.lda, breast_test_prep)<span class="sc">$</span>class</span>
<span id="cb576-2"><a href="#cb576-2" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">predict=</span>p.train, <span class="at">Actual=</span>breast_test_prep<span class="sc">$</span>diagnosis)</span>
<span id="cb576-3"><a href="#cb576-3" aria-hidden="true" tabindex="-1"></a>tt</span></code></pre></div>
<pre><code>       Actual
predict   B   M
      B 104   7
      M   3  56</code></pre>
<p>Cuya precisión podemos calcular como:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(tt)<span class="sc">/</span><span class="fu">sum</span>(tt))</span></code></pre></div>
<pre><code>[1] 0.9411765</code></pre>
<p>También podemos evauar la capacidar de nuestro modelo usando, por ejemplo, 10-fold CV con la librería <code>caret</code>. En este caso bastaría con</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="#cb580-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="do">## 10-fold CV</span></span>
<span id="cb580-2"><a href="#cb580-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb580-3"><a href="#cb580-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb580-4"><a href="#cb580-4" aria-hidden="true" tabindex="-1"></a>                           <span class="do">## repeated five times</span></span>
<span id="cb580-5"><a href="#cb580-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">repeats =</span> <span class="dv">5</span>)</span>
<span id="cb580-6"><a href="#cb580-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb580-7"><a href="#cb580-7" aria-hidden="true" tabindex="-1"></a><span class="fu">train</span>(diagnosis <span class="sc">~</span> ., </span>
<span id="cb580-8"><a href="#cb580-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">data=</span>breast_train_prep,</span>
<span id="cb580-9"><a href="#cb580-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">method=</span><span class="st">&quot;lda&quot;</span>,</span>
<span id="cb580-10"><a href="#cb580-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">trControl =</span> fitControl)</span></code></pre></div>
<pre><code>Linear Discriminant Analysis 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 359, 359, 359, 359, 359, 359, ... 
Resampling results:

  Accuracy   Kappa    
  0.9593974  0.9106868</code></pre>
<p>Vemos que la precisión estimada en la muestra test es bastante parecida a la predicha mediante 10-fold CV.</p>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-LDA):</td>
</tr>
<tr class="even">
<td align="left">Implementa una función (idealmente podrímo usar el padigma MapReduce) que nos devuelva la precisión del método LDA usando K-fold CV. Úsa esta función para reproducir los resultados del ejemplo anterior.</td>
</tr>
</tbody>
</table>
<div id="concurso-predicción-de-actividad-física-con-sensores" class="section level2 hasAnchor" number="11.1">
<h2 class="hasAnchor"><span class="header-section-number">11.1</span> Concurso predicción de actividad física con sensores<a href="#concurso-predicción-de-actividad-física-con-sensores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El uso de dispositivos portátiles comerciales se está convirtiendo en una herramienta extremadamente útil para medir la actividad física a nivel poblacional. Se han recopilado muchos datos para determinar si estos dispositivos pueden predecir con precisión el estar acostado, sentado y diferentes niveles de intensidad de la actividad física mediante estudios controlados en laboratorios. Tenéis a disposición una base de datos de entrenamiento donde se han recolectado información para 4384 momentos de tiempo en los que los participantes estaban andando en una cinta de correr a distintas intesidades (a su ritmo, 3, 5, y 7 METS) y otros momentos en los que estaban acostados o sentado. Se utilizó calorimetría indirecta para medir el gasto energético. La variable resultado del estudio fua la clase de actividad realizada (variable <code>activity</code>) que tiene estas categorías: Pace walk, Running 3 METs, Running 5 METs, Running 7 METs, Lying y Sitting. Se usaron dos tipos de dispositivos (apple watch y fitbit) para medir distintas variables. Las variables son (a partir de “weight” están medidas con el dispositivo):</p>
<pre><code> + **id:** Identificador del individuo y momento 
 + **age:** edad
 + **gender:** sexo del individuo
 + **height:** altura del individuo
 + **weight:** peso de individuo
 + **steps:** número de pasos durante la actividad
 + **hear_rate:** pulso durante la actividad
 + **calories:** calorías consumidas en la actividad
 + **distance:** distancia recorrida en la actividad
 + **entropy_heart:** entropía del pulso (la entropía mide la incertidumbre de una fuente de información)
 + **entropy_setps:** entropía del número de pasos en la actividad 
 + **resting_heart:** pulso en reposo
 + **corr_heart_steps:** correlación entre el pulso y los pasos de la actividad
 + **norm_heart:** pulso centrado
 + **intensity_karvonen:** intensidad de la actividad según el índice de Karnoven
 + **sd_norm_heart:** pulso estandarizado
 + **steps_times_distance:** pasos por tiempo y distancia
 + **device:** dispositivo        </code></pre>
<p><strong>TAREA:</strong> Debéis crear un modelo predictivo que use todas las variables que hay en el objeto <code>train</code> (obviamente except la variable <code>id</code>) que contiene información para 4384 observaciones, usando la estrategia que creáis oportuna y usando como modelo de aprendijaze o bien KNN o LDA. Podéis hacer todas las cosas que queráis con los datos: estratificarlos, analizarlos todos juntos, usar cualquier método de valización cruzada para validar el modelo, crear nuevas variables, elminar datos, … ya que el objetivo es que apliquéis vuestro modelo a los datos <code>test</code> que contiene la misma información para 1880 observaciones excepto el tipo de actividad que se estaba realizando y que es lo que debéis predecir.</p>
<p><strong>ENTREGA:</strong> Debeis subir un fichero <code>NIU.txt</code> (NIU es vuestro identificador de la UAB) a la tarea que hay en Moodle llamada <strong>P-Concurso_Predicción</strong> con vuestras predicciones para la muestra <code>test</code>. Este fichero debe ser un fichero de texto delimitado por tabulaciones con dos columnas que se llamen “id” y “activity”. Obviamente la columna “id” corresponde a la variable <code>id</code> de la base de datos <code>test</code> y la otra columna debe contener vuestra predicción que debe ser un valor entre: Pace walk, Running 3 METs, Running 5 METs, Running 7 METs, Lying o Sitting. Este fichero se puede crear a partir de un objeto de R que tenga un data.frame con esas dos variables y usando la función <code>write.table()</code> y el argumento `sep=“. También debéis subir el archivo de R (con comentarios) o un R Markdown explicando la estrategia llevada a cabo en la tarea de Moodle llamada <strong>P-Concurso_Estrategia</strong>.</p>
<p><strong>EVALUACIÓN</strong>: Yo evaluaré la capacidad predictiva de vuestro modelo ya que tengo el valor real para esa predicción que habéis hecho y a la cuál no tenéis acceso. La nota con la que os evaluaré esta práctica estará en función de vuestra capacidad de predicción y que básicamente será una nota que estableceré según el ranking obtenido por cada uno de vosotros.</p>
<p><strong>ACCESO A DATOS:</strong> Los datos están en un fichero llamado <code>actividad_fisica.Rdata</code> que contiene los objectos <code>train</code> y <code>test</code> a los que he hecho referencia y que están en la carpeta datos del Moodle de la asignatura.</p>
<p><strong>MUY IMPORTANTE:</strong> Aquel alumno que me entrege un fichero que no siga el formato indicado, tendrá un 4 en esta práctica como nota máxima.</p>
<!--chapter:end:09-lda.Rmd-->
</div>
</div>
<div id="máquinas-de-soporte-vectorial" class="section level1 hasAnchor" number="12">
<h1 class="hasAnchor"><span class="header-section-number">12</span> Máquinas de soporte vectorial<a href="#máquinas-de-soporte-vectorial" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Las máquinas de soporte vectorial (SVM por sus siglas en inglés) se fundamentan en el <em>Maximal Margin Classifier</em>, que está basado en el concepto de hiperplano. SVM es un modelo de clasificación que mapea las observaciones como puntos en el espacio para que las categorías se dividan por dichos hiperplanos. Luego, las nuevas observaciones se pueden mapear en el espacio para la predicción. El algoritmo SVM encuentra el hiperplano de separación óptimo utilizando un mapeo no lineal a una dimensión suficientemente alta. El hiperplano se define por las observaciones que se encuentran dentro de un margen optimizado por un hiperparámetro a los que se les asigna un coste (error). Estas observaciones se denominan vectores de soporte.</p>
<div id="clasificador-de-margen-máximo" class="section level2 hasAnchor" number="12.1">
<h2 class="hasAnchor"><span class="header-section-number">12.1</span> Clasificador de margen máximo<a href="#clasificador-de-margen-máximo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El clasificador de margen máximo es el hiperplano óptimo definido en el caso (no muy habitual) en el que dos clases son linealmente separables. Dada una matriz <span class="math inline">\(X\)</span> con dimensión <span class="math inline">\(n \times p\)</span> y una variable respuesta binaria definida como <span class="math inline">\(y \in [-1, 1]\)</span> es posible definir un hiperplano <span class="math inline">\(h(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 \dots + \beta_pX_p = x_i^T \beta + \beta_0 = 0\)</span> tal que todas las observaciones de cada clase caen en un lado opuesto de dicho hiperplano. Este <em>hiperplano de separación</em> tiene la propiedad de que si <span class="math inline">\(\beta\)</span> está restringido al vector unidad, <span class="math inline">\(||\beta|| = \sum\beta^2 = 1\)</span>, entonces el producto del hiperplano y la variable respuesta son distancias positivas perpendiculares al hiperplano, y la menor de ellas se denomina hiperplano marginal, <span class="math inline">\(M\)</span></p>
<p><span class="math display">\[y_i (x_i^{&#39;} \beta + \beta_0) \ge M.\]</span></p>
<p>El clasificador de margen máximo es el hiperplano cuyo margen es máximo <span class="math inline">\(\max \{M\}\)</span> sujeto a <span class="math inline">\(||\beta|| = 1\)</span>. Estos hiperplano separadores raras veces existen. De hecho, incluso si existe un hiperplano separador, su margen resultante es probablemente indeseablemente estrecho. Aquí vemos un ejemplo de clasificador de margen máximo</p>
<div class="figure">
<img src="figures/svm_mmc.png" alt="" />
<p class="caption">Clasificador de margen máximo</p>
</div>
<p>Los datos tienen dos clases que son separables de forma lineal, <span class="math inline">\(y \in [-1, 1]\)</span>, que se pueden explicar según dos variables <span class="math inline">\(X1\)</span> y <span class="math inline">\(X2\)</span></p>
<div class="figure">
<img src="figures/svm_ex.png" alt="" />
<p class="caption">Ejemplo clasificador</p>
</div>
</div>
<div id="clasificador-de-soporte-vectorial" class="section level2 hasAnchor" number="12.2">
<h2 class="hasAnchor"><span class="header-section-number">12.2</span> Clasificador de soporte vectorial<a href="#clasificador-de-soporte-vectorial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El clasificador de margen máximo se puede generalizar a casos no separables utilizando el llamado margen blando. La generalización se denomina clasificador de vectores de soporte. El margen blando permite alguna clasificación errónea en aras de una mayor solidez de las observaciones individuales (es lo que se usa en la práctica). Aquí tenemos la diferencia entre ambos tipos de márgenes que es bastante intuitiva</p>
<div class="figure">
<img src="figures/svm_hard_soft.png" alt="" />
<p class="caption">Margen duro y blando</p>
</div>
<p>El clasificador de soporte vectorial optimiza</p>
<p><span class="math display">\[y_i (x_i^{&#39;} \beta + \beta_0) \ge M(1 - \xi_i)\]</span></p>
<p>donde <span class="math inline">\(\xi_i\)</span> son variables de holgura positivas cuya suma está limitada por algún parámetro de ajuste constante <span class="math inline">\(\sum{\xi_i} \le \Xi\)</span>. Los valores de la variable de holgura indican dónde se encuentra la observación: si <span class="math inline">\(\xi_i = 0\)</span> la observacione se encuentran en el lado correcto del margen; si <span class="math inline">\(\xi_i &gt; 0\)</span> la observación se encuentra en el lado equivocado del margen; si <span class="math inline">\(\xi_i &gt; 1\)</span> la observación se encuentra en el lado equivocado del hiperplano. <span class="math inline">\(\Xi\)</span> establece la tolerancia para la violación del margen. Si <span class="math inline">\(\Xi = 0\)</span> entonces todas las observaciones deben residir en el lado correcto del margen, como en el clasificador de margen máximo. <span class="math inline">\(\Xi\)</span> también controla la relación sesgo-varianza. Si <span class="math inline">\(\Xi\)</span> aumenta, el margen se ensancha y permite más violaciones, aumentando el sesgo y disminuyendo la varianza.</p>
<p>El clasificador de vectores de soporte generalmente se define eliminando la restricción <span class="math inline">\(||\beta|| = 1\)</span>, y definiendo <span class="math inline">\(M = 1 / ||\beta||\)</span>. El problema de optimización se convierte en</p>
<p><span class="math display">\[\min ||\beta|| \hspace{2mm} s.t. \hspace{2mm}  
  \begin{cases}
   y_i(x_i^T\beta + \beta_0) \ge 1 - \xi_i, \hspace{2mm} \forall i &amp;  \\
   \xi_i \ge 0, \hspace{2mm} \sum \xi_i \le \Xi.      
  \end{cases}\]</span></p>
<p>Esta es una ecuación cuadrática con restricciones de desigualdad lineal, por lo que es un problema de optimización convexa que se puede resolver usando multiplicadores de Lagrange. Vuelva a expresar el problema de optimización como</p>
<p><span class="math display">\[\min_{\beta_0, \beta} \frac{1}{2}||\beta||^2 = C\sum_{i = 1}^N \xi_i \\
s.t. \xi_i \ge 0, \hspace{2mm} y_i(x_i^T\beta + \beta_0) \ge 1 - \xi_i, \hspace{2mm} \forall i\]</span></p>
<p>donde el parámetro “coste”, <span class="math inline">\(C\)</span> reemplaza la constante y penaliza los residuos grandes. Este problema de optimización es equivalente a otro problema de optimización, con la fórmula típica de <em>pérdida + penalización</em>:</p>
<p><span class="math display">\[\min_{\beta_0, \beta} \sum_{i=1}^N{[1 - y_if(x_i)]_+} + \frac{\lambda}{2} ||\beta||^2\]</span></p>
<p>donde <span class="math inline">\(\lambda = 1 / C\)</span> y <span class="math inline">\([1 - y_if(x_i)]_+\)</span> es una función de pérdida de “bisagra” con <span class="math inline">\(f(x_i) = sign[Pr(Y = +1|x) - 1 / 2].\)</span></p>
<p>Las estimaciones de los parámetros se pueden escribir como funciones de un conjunto de parámetros desconocidos <span class="math inline">\((\alpha_i)\)</span> y los puntos de datos. La solución al problema de optimización requiere solo los productos internos de las observaciones, representados como <span class="math inline">\(\langle x_i, x_j \rangle\)</span>,</p>
<p><span class="math display">\[f(x) = \beta_0 + \sum_{i = 1}^n {\alpha_i \langle x, x_i \rangle}\]</span></p>
<p>La solución tiene la interesante propiedad de que solo las observaciones sobre o dentro del margen afectan al hiperplano. Estas observaciones se conocen como vectores de soporte. A medida que aumenta la constante, aumenta el número de observaciones infractoras y, por lo tanto, aumenta el número de vectores de apoyo. Esta propiedad hace que el algoritmo sea robusto para las observaciones extremas lejos del hiperplano.</p>
<p>Los estimadores de los parámetros <span class="math inline">\(\alpha_i\)</span> son distintos de cero solo para los vectores de soporte en la solución, es decir, si una observación de entrenamiento no es un vector de soporte, entonces su <span class="math inline">\(\alpha_i\)</span> es 0.</p>
<p>El único defecto del algoritmo es que presupone un límite de decisión lineal.</p>
</div>
<div id="máquinas-de-soporte-vectorial-1" class="section level2 hasAnchor" number="12.3">
<h2 class="hasAnchor"><span class="header-section-number">12.3</span> Máquinas de soporte vectorial<a href="#máquinas-de-soporte-vectorial-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para solventar este problema, se puede ampliar el espacio de características del clasificador de vectores de soporte a relaciones no lineales. Las máquinas de vectores de soporte hacen esto de una manera específica, utilizando <a href="https://jllopisperez.com/2012/12/13/estimacion-no-parametrica-de-funciones-de-densidad-metodo-kernel/">kernels</a>. El kernel es una generalización del producto interno con forma <span class="math inline">\(K(x_i, x_i^{&#39;})\)</span>. Entonces, el kernel lineal es simplemente</p>
<p><span class="math display">\[K(x_i, x_i^{&#39;}) = \langle x, x_i \rangle\]</span></p>
<p>y la solución es</p>
<p><span class="math display">\[f(x) = \beta_0 + \sum_{i = 1}^n {\alpha_i K(x_i, x_i^{&#39;})}.\]</span></p>
<p><span class="math inline">\(K\)</span> puede tomar otra forma, por ejemplo un polinomio</p>
<p><span class="math display">\[K(x, x&#39;) = (\gamma \langle x, x&#39; \rangle + c_0)^d\]</span>
Cuando se emplea <span class="math inline">\(\gamma=1\)</span>, <span class="math inline">\(d=1\)</span> y <span class="math inline">\(c=0\)</span>, el resultado es el mismo que el de un kernel lineal. Si <span class="math inline">\(d&gt;1\)</span>, se generan límites de decisión no lineales, aumentando la no linealidad a medida que aumenta <span class="math inline">\(d\)</span>. No suele ser recomendable emplear valores de <span class="math inline">\(d\)</span> mayores 5 por problemas de overfitting.</p>
<div class="figure">
<img src="figures/svm_kernel_poly.png" alt="" />
<p class="caption">SVM con kernel polinímico de grado 3</p>
</div>
<p>o una forma radial</p>
<p><span class="math display">\[K(x, x&#39;) = \exp\{-\gamma ||x - x&#39;||^2\}.\]</span>
<img src="figures/svm_kernel_rad.png" alt="SVM con kernel radial" /></p>
</div>
<div id="svm-con-e1071" class="section level2 hasAnchor" number="12.4">
<h2 class="hasAnchor"><span class="header-section-number">12.4</span> SVM con <code>e1071</code><a href="#svm-con-e1071" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Veamos un ejemplo donde reproduciremos todos los pasos que nos ayudarán a entender cómo funciona este método. Supongamos que tenemos un conjunto de datos con una variable respuesta <span class="math inline">\(y \in [-1, 1]\)</span> que pretendemos describir según dos variables <span class="math inline">\(X1\)</span> y <span class="math inline">\(X2\)</span> (o que queremos predecir con dos variables).</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb583-2"><a href="#cb583-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb583-3"><a href="#cb583-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span> (<span class="dv">20</span><span class="sc">*</span><span class="dv">2</span>), <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb583-4"><a href="#cb583-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">10</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>))</span>
<span id="cb583-5"><a href="#cb583-5" aria-hidden="true" tabindex="-1"></a>x[y<span class="sc">==</span><span class="dv">1</span>, ] <span class="ot">&lt;-</span> x[y<span class="sc">==</span><span class="dv">1</span>, ] <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb583-6"><a href="#cb583-6" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb583-7"><a href="#cb583-7" aria-hidden="true" tabindex="-1"></a>train_data<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(y)</span></code></pre></div>
<p>El siguiente gráfico nos ilustra si las dos clases son linealmente separables</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="#cb584-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(train_data, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> X2, <span class="at">color =</span> y)) <span class="sc">+</span></span>
<span id="cb584-2"><a href="#cb584-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb584-3"><a href="#cb584-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Respuesta binaria con dos clases&quot;</span>) <span class="sc">+</span></span>
<span id="cb584-4"><a href="#cb584-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-234-1.png" width="672" /></p>
<p>La respuesta es no, no se pueden separar linealmente. Ahora estimaremos una máquina de soporte vectorial. Para ello utilizaremos la librería <code>e1071</code> que implementa el algoritmo SVM mediante <code>svm(..., kernel="linear")</code>. Podemos cambiar el kernel a `c(“polynomial”, “radial”) y el coste a 10. Por ejemplo,</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb585-2"><a href="#cb585-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">svm</span>(</span>
<span id="cb585-3"><a href="#cb585-3" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> ., </span>
<span id="cb585-4"><a href="#cb585-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb585-5"><a href="#cb585-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb585-6"><a href="#cb585-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;C-classification&quot;</span>,  <span class="co"># (default) for classification</span></span>
<span id="cb585-7"><a href="#cb585-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="dv">10</span>,  <span class="co"># default is 1</span></span>
<span id="cb585-8"><a href="#cb585-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale =</span> <span class="cn">FALSE</span>  <span class="co"># do not standardize features</span></span>
<span id="cb585-9"><a href="#cb585-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb585-10"><a href="#cb585-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb585-11"><a href="#cb585-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m, train_data)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-235-1.png" width="672" /></p>
<p>Los vectores de soporte se grafican como “x’s”. En nuestro caso hay 7</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="#cb586-1" aria-hidden="true" tabindex="-1"></a>m<span class="sc">$</span>index</span></code></pre></div>
<pre><code>[1]  1  2  5  7 14 16 17</code></pre>
<p>La función <code>summary()</code> muestra información adicional, incluida la distribución de los vectores de soporte en las clases (4 en la -1 y 3 en la 1).</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="#cb588-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m)</span></code></pre></div>
<pre><code>
Call:
svm(formula = y ~ ., data = train_data, kernel = &quot;linear&quot;, type = &quot;C-classification&quot;, 
    cost = 10, scale = FALSE)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  10 

Number of Support Vectors:  7

 ( 4 3 )


Number of Classes:  2 

Levels: 
 -1 1</code></pre>
<p>Los siete vectores de soporte se componen de cuatro en una clase, tres en la otra. ¿Qué pasa si reducimos el costo de las violaciones de márgenes? Esto aumentará el sesgo y reducirá la varianza.</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="#cb590-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">svm</span>(</span>
<span id="cb590-2"><a href="#cb590-2" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> ., </span>
<span id="cb590-3"><a href="#cb590-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb590-4"><a href="#cb590-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb590-5"><a href="#cb590-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;C-classification&quot;</span>,  </span>
<span id="cb590-6"><a href="#cb590-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fl">0.1</span>,</span>
<span id="cb590-7"><a href="#cb590-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale =</span> <span class="cn">FALSE</span></span>
<span id="cb590-8"><a href="#cb590-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb590-9"><a href="#cb590-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m, train_data)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-238-1.png" width="672" /></p>
<p>Ahora hay muchos más vectores de soporte. (En caso de que esperara ver la formulación del límite de decisión lineal, o al menos una representación gráfica de los márgenes, siga esperando. El modelo está generalizado más allá de dos características, por lo que evidentemente no se preocupa demasiado por admitir demostraciones de dos características saneadas. )</p>
<p>¿Qué nivel de coste produce el mejor rendimiento predictivo ? Recordemos que para contestar a esta pregunta, utilizando los mismos datos, podemos utilizar validación cruzada. SVM tiene por defecto implementado 10-fold CV. Probaremo siete valores candidatos para el coste (argumento <code>cost</code>). NOTA: Para SVM el coste es el hiperparámetro que debemos estimar.</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="#cb591-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb591-2"><a href="#cb591-2" aria-hidden="true" tabindex="-1"></a>m_tune <span class="ot">&lt;-</span> <span class="fu">tune</span>(</span>
<span id="cb591-3"><a href="#cb591-3" aria-hidden="true" tabindex="-1"></a>  svm,</span>
<span id="cb591-4"><a href="#cb591-4" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb591-5"><a href="#cb591-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb591-6"><a href="#cb591-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span><span class="st">&quot;linear&quot;</span>,</span>
<span id="cb591-7"><a href="#cb591-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>))</span>
<span id="cb591-8"><a href="#cb591-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb591-9"><a href="#cb591-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_tune)</span></code></pre></div>
<pre><code>
Parameter tuning of &#39;svm&#39;:

- sampling method: 10-fold cross validation 

- best parameters:
 cost
  0.1

- best performance: 0.05 

- Detailed performance results:
   cost error dispersion
1 1e-03  0.55  0.4377975
2 1e-02  0.55  0.4377975
3 1e-01  0.05  0.1581139
4 1e+00  0.15  0.2415229
5 5e+00  0.15  0.2415229
6 1e+01  0.15  0.2415229
7 1e+02  0.15  0.2415229</code></pre>
<p>El error más bajo de valización cruzada es de 0.05 para <code>cost=0.1</code>. La función <code>tune()</code> guarda el valor del mejor mejor “tuning parameter”</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="#cb593-1" aria-hidden="true" tabindex="-1"></a>m_best <span class="ot">&lt;-</span> m_tune<span class="sc">$</span>best.model</span>
<span id="cb593-2"><a href="#cb593-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_best)</span></code></pre></div>
<pre><code>
Call:
best.tune(METHOD = svm, train.x = y ~ ., data = train_data, ranges = list(cost = c(0.001, 
    0.01, 0.1, 1, 5, 10, 100)), kernel = &quot;linear&quot;)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  0.1 

Number of Support Vectors:  16

 ( 8 8 )


Number of Classes:  2 

Levels: 
 -1 1</code></pre>
<p>Ahora tenemos 16 vectores de soporte, 8 en cada clase. Esto supone un margen bastante amplio.</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_best, train_data)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-241-1.png" width="672" /></p>
<p>Estimemos ahora un modelo SVM usando otro kernel. En ese caso necesitaremos otros hiperparámetros. Por ejmplo, para el modelo poinomial, necesitaremos estimar el mejor grado del polinomio.</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="#cb596-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb596-2"><a href="#cb596-2" aria-hidden="true" tabindex="-1"></a>m3_tune <span class="ot">&lt;-</span> <span class="fu">tune</span>(</span>
<span id="cb596-3"><a href="#cb596-3" aria-hidden="true" tabindex="-1"></a>  svm,</span>
<span id="cb596-4"><a href="#cb596-4" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb596-5"><a href="#cb596-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb596-6"><a href="#cb596-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">kernel =</span><span class="st">&quot;polynomial&quot;</span>,</span>
<span id="cb596-7"><a href="#cb596-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ranges =</span> <span class="fu">list</span>(</span>
<span id="cb596-8"><a href="#cb596-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>),</span>
<span id="cb596-9"><a href="#cb596-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">degree =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb596-10"><a href="#cb596-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb596-11"><a href="#cb596-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb596-12"><a href="#cb596-12" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3_tune)</span></code></pre></div>
<pre><code>
Parameter tuning of &#39;svm&#39;:

- sampling method: 10-fold cross validation 

- best parameters:
 cost degree
    1      1

- best performance: 0.1 

- Detailed performance results:
    cost degree error dispersion
1  1e-03      1  0.60  0.3944053
2  1e-02      1  0.60  0.3944053
3  1e-01      1  0.30  0.2581989
4  1e+00      1  0.10  0.2108185
5  5e+00      1  0.10  0.2108185
6  1e+01      1  0.10  0.2108185
7  1e+02      1  0.10  0.2108185
8  1e-03      2  0.70  0.3496029
9  1e-02      2  0.70  0.3496029
10 1e-01      2  0.70  0.3496029
11 1e+00      2  0.50  0.3333333
12 5e+00      2  0.50  0.3333333
13 1e+01      2  0.50  0.3333333
14 1e+02      2  0.50  0.3333333
15 1e-03      3  0.60  0.3944053
16 1e-02      3  0.60  0.3944053
17 1e-01      3  0.45  0.3689324
18 1e+00      3  0.40  0.3944053
19 5e+00      3  0.50  0.3333333
20 1e+01      3  0.35  0.4116363
21 1e+02      3  0.35  0.3374743</code></pre>
<p>El error más bajo de valización cruzada es de 0.1 para <code>cost=1</code> y grado de polinomio 1.</p>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="#cb598-1" aria-hidden="true" tabindex="-1"></a>m3_best <span class="ot">&lt;-</span> m3_tune<span class="sc">$</span>best.model</span>
<span id="cb598-2"><a href="#cb598-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3_best)</span></code></pre></div>
<pre><code>
Call:
best.tune(METHOD = svm, train.x = y ~ ., data = train_data, ranges = list(cost = c(0.001, 
    0.01, 0.1, 1, 5, 10, 100), degree = c(1, 2, 3)), kernel = &quot;polynomial&quot;)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  polynomial 
       cost:  1 
     degree:  1 
     coef.0:  0 

Number of Support Vectors:  12

 ( 6 6 )


Number of Classes:  2 

Levels: 
 -1 1</code></pre>
<p>Ahora tenemos 12 vectores de soporte, 6 en cada clase. Esto supone un margen bastante amplio.</p>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="#cb600-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m3_best, train_data)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-244-1.png" width="672" /></p>
<p>Para un kernel radial, tenemos que incluir el valor de <code>gamma</code>.</p>
</div>
<div id="svm-con-caret" class="section level2 hasAnchor" number="12.5">
<h2 class="hasAnchor"><span class="header-section-number">12.5</span> SVM con <code>caret</code><a href="#svm-con-caret" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El modelo también se puede ajustar usando la librería <code>caret</code>. Usaremos LOOCV ya que el conjunto de datos es muy pequeño. Normalizaremos las variables para que su escala sea comparable. Esta librería requiere que la variable respuesta sea factor y le pondremos etiquetas para saber cuál es cada clase. Usaremos SVM polinomial como kernel (<code>svmPoly</code>) .</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="#cb601-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb601-2"><a href="#cb601-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kernlab)</span>
<span id="cb601-3"><a href="#cb601-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb601-4"><a href="#cb601-4" aria-hidden="true" tabindex="-1"></a>train_data_3 <span class="ot">&lt;-</span> train_data <span class="sc">%&gt;%</span></span>
<span id="cb601-5"><a href="#cb601-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">factor</span>(y, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)))</span>
<span id="cb601-6"><a href="#cb601-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb601-7"><a href="#cb601-7" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb601-8"><a href="#cb601-8" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb601-9"><a href="#cb601-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data_3,</span>
<span id="cb601-10"><a href="#cb601-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;svmPoly&quot;</span>,</span>
<span id="cb601-11"><a href="#cb601-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb601-12"><a href="#cb601-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(</span>
<span id="cb601-13"><a href="#cb601-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb601-14"><a href="#cb601-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb601-15"><a href="#cb601-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">summaryFunction =</span> twoClassSummary,  <span class="co"># Usaremos AUC para seleccionar el mejor modelo</span></span>
<span id="cb601-16"><a href="#cb601-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">classProbs=</span><span class="cn">TRUE</span></span>
<span id="cb601-17"><a href="#cb601-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb601-18"><a href="#cb601-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb601-19"><a href="#cb601-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb601-20"><a href="#cb601-20" aria-hidden="true" tabindex="-1"></a>m4<span class="sc">$</span>bestTune</span></code></pre></div>
<pre><code>  degree scale    C
7      1   0.1 0.25</code></pre>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="#cb603-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m4)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-246-1.png" width="672" /></p>
<p>Ahora podríamos comprobar qué modelo predice mejor en los datos test (que también generamos aleatoriamente:</p>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="#cb604-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb604-2"><a href="#cb604-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span> (<span class="dv">20</span><span class="sc">*</span><span class="dv">2</span>), <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb604-3"><a href="#cb604-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">10</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>))</span>
<span id="cb604-4"><a href="#cb604-4" aria-hidden="true" tabindex="-1"></a>x[y<span class="sc">==</span><span class="dv">1</span>, ] <span class="ot">&lt;-</span> x[y<span class="sc">==</span><span class="dv">1</span>, ] <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb604-5"><a href="#cb604-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb604-6"><a href="#cb604-6" aria-hidden="true" tabindex="-1"></a>test_data<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(y)</span>
<span id="cb604-7"><a href="#cb604-7" aria-hidden="true" tabindex="-1"></a>test_data<span class="sc">$</span>yFac <span class="ot">&lt;-</span> <span class="fu">factor</span>(test_data<span class="sc">$</span>y, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="#cb605-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">predict</span>(m_best, test_data), test_data<span class="sc">$</span>y)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction -1  1
        -1 10  7
        1   0  3
                                          
               Accuracy : 0.65            
                 95% CI : (0.4078, 0.8461)
    No Information Rate : 0.5             
    P-Value [Acc &gt; NIR] : 0.13159         
                                          
                  Kappa : 0.3             
                                          
 Mcnemar&#39;s Test P-Value : 0.02334         
                                          
            Sensitivity : 1.0000          
            Specificity : 0.3000          
         Pos Pred Value : 0.5882          
         Neg Pred Value : 1.0000          
             Prevalence : 0.5000          
         Detection Rate : 0.5000          
   Detection Prevalence : 0.8500          
      Balanced Accuracy : 0.6500          
                                          
       &#39;Positive&#39; Class : -1              
                                          </code></pre>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="#cb607-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">predict</span>(m3_best, test_data), test_data<span class="sc">$</span>y)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction -1  1
        -1 10  6
        1   0  4
                                          
               Accuracy : 0.7             
                 95% CI : (0.4572, 0.8811)
    No Information Rate : 0.5             
    P-Value [Acc &gt; NIR] : 0.05766         
                                          
                  Kappa : 0.4             
                                          
 Mcnemar&#39;s Test P-Value : 0.04123         
                                          
            Sensitivity : 1.000           
            Specificity : 0.400           
         Pos Pred Value : 0.625           
         Neg Pred Value : 1.000           
             Prevalence : 0.500           
         Detection Rate : 0.500           
   Detection Prevalence : 0.800           
      Balanced Accuracy : 0.700           
                                          
       &#39;Positive&#39; Class : -1              
                                          </code></pre>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="#cb609-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">predict</span>(m4, test_data), test_data<span class="sc">$</span>yFac)</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  A  B
         A 10  8
         B  0  2
                                          
               Accuracy : 0.6             
                 95% CI : (0.3605, 0.8088)
    No Information Rate : 0.5             
    P-Value [Acc &gt; NIR] : 0.25172         
                                          
                  Kappa : 0.2             
                                          
 Mcnemar&#39;s Test P-Value : 0.01333         
                                          
            Sensitivity : 1.0000          
            Specificity : 0.2000          
         Pos Pred Value : 0.5556          
         Neg Pred Value : 1.0000          
             Prevalence : 0.5000          
         Detection Rate : 0.5000          
   Detection Prevalence : 0.9000          
      Balanced Accuracy : 0.6000          
                                          
       &#39;Positive&#39; Class : A               
                                          </code></pre>
<!--chapter:end:10-svm.Rmd-->
</div>
</div>
<div id="respuesta-no-balanceada" class="section level1 hasAnchor" number="13">
<h1 class="hasAnchor"><span class="header-section-number">13</span> Respuesta no balanceada<a href="#respuesta-no-balanceada" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Cuando nos enfrentamos a problemas de clasificación en datos reales, puede ser un desafío tratar con un caso en el que una clase supera con creces a la otra (también conocidas como clases desequilibradas). En terminos prácticos podríamos, por ejemplo, predecir todos los inviduos como la categoría más frecuente y mejoraríamos la precisión que, como vimos en capítulos anteriores, por azar es del 50%.</p>
<p>Estas son algunas de las técnicas más populares para tratar con el desequilibrio de clases, pero existen más. Proporcionamremos una descripción general rápida.</p>
<ul>
<li><p><em>Asignar pesos a cada clase</em>: imponemos un coste mayor cuando se cometen errores en la clase minoritaria</p></li>
<li><p><em>Muestreo descendente (under-sampling)</em>: eliminar observaciones al azar en la clase mayoritaria</p></li>
<li><p><em>Muestreo ascendente (oversampling)</em>: replicar aleatoriamente observaciones en la clase minoritaria</p></li>
<li><p>Además del muestreo descendente y ascendente, existen métodos híbridos que combinan el muestreo descendente con la generación de datos adicionales. Dos de los más populares son <a href="https://journal.r-project.org/archive/2014/RJ-2014-008/RJ-2014-008.pdf">ROSE</a> y <a href="https://www.jair.org/index.php/jair/article/view/10302">SMOTE</a>. El primer método necesita tener instalada la librería <code>ROSE</code> y el segundo la librería <code>DMwR</code>.</p></li>
</ul>
<div class="figure">
<img src="figures/ImbalancedClasses.jpg" alt="" />
<p class="caption">Clases desbalanceadas</p>
</div>
<p>Si queréis podéis encontrar una descripción más detallada en esta publicación de blog de <a href="https://www.svds.com/learning-imbalanced-classes/">Silicon Valley Data Science</a>.</p>
<p>Estos métodos también funcionan para los problemas multi-clase. En <a href="https://link.springer.com/article/10.1007/s13748-016-0094-0">este artículo</a> tenéis más información general sobre el tema.</p>
<p>Debemos tener en cuenta que, en realidad, no deberíamos simplemente realizar un muestreo descendente o ascendente en nuestros datos de entrenamiento y luego ejecutar el modelo. Debemos tener en cuenta la validación cruzada y realizar un muestreo descendente o ascendente en cada sub-muestra de forma independiente para obtener una estimación real del rendimiento del modelo.</p>
<p>También es importante señalar que estas técnicas de ponderación y muestreo tienen mayor impacto en métricas de evaluación del modelo como la precisión, porque mueven artificialmente el umbral para estar más cerca de lo que podría considerarse como la ubicación “óptima” en una curva ROC. Otras métricas como el AUC o la tasa de falsos o verdaderos positivos no se ven tan afectadas.</p>
<p>Ilustremos cómo llevar a cabo estas técnicas con nuestro ejemplo de cáncer de mama. Usaremos los datos que ya están preprocesados según se hizo en la Sección @ref(caret) y que se encuentran en los objetos <code>breast_train_prep</code> y <code>breast_test_prep</code>. Efectivamente, los datos para este problema están desbalanceados respecto a la variable que queremos predecir</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="#cb611-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(breast_test_prep<span class="sc">$</span>diagnosis)</span></code></pre></div>
<pre><code>
  B   M 
107  63 </code></pre>
<p>Afortunadamente, la librería <code>caret</code> hace que sea muy fácil incorporar técnicas de muestreo descendente y ascendente incluyendo validación cruzada. Simplemente basta con utilizar el argumento <code>sampling</code> en nuestro <code>trainControl()</code> y escoger el método “down” o “up” según nos convenga. El resto del proceso de creación de modelo permanece igual que los pasos llevados con cualquier otro método que hemos visto, por ejemlo KNN.</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="#cb613-1" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb613-2"><a href="#cb613-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">number =</span> <span class="dv">10</span>, </span>
<span id="cb613-3"><a href="#cb613-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">repeats =</span> <span class="dv">5</span>, </span>
<span id="cb613-4"><a href="#cb613-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">verboseIter =</span> <span class="cn">FALSE</span>,</span>
<span id="cb613-5"><a href="#cb613-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">sampling =</span> <span class="st">&quot;down&quot;</span>)</span>
<span id="cb613-6"><a href="#cb613-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb613-7"><a href="#cb613-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb613-8"><a href="#cb613-8" aria-hidden="true" tabindex="-1"></a>model_knn_under <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(diagnosis <span class="sc">~</span> .,</span>
<span id="cb613-9"><a href="#cb613-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> breast_train_prep,</span>
<span id="cb613-10"><a href="#cb613-10" aria-hidden="true" tabindex="-1"></a>                         <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb613-11"><a href="#cb613-11" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trControl =</span> ctrl)</span>
<span id="cb613-12"><a href="#cb613-12" aria-hidden="true" tabindex="-1"></a>model_knn_under</span></code></pre></div>
<pre><code>k-Nearest Neighbors 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 359, 359, 359, 359, 359, 359, ... 
Addtional sampling using down-sampling

Resampling results across tuning parameters:

  k  Accuracy   Kappa    
  5  0.9443462  0.8815450
  7  0.9483718  0.8893875
  9  0.9493718  0.8920609

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 9.</code></pre>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb615-1"><a href="#cb615-1" aria-hidden="true" tabindex="-1"></a>cm_under <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(breast_test_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb615-2"><a href="#cb615-2" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">predict</span>(model_knn_under, </span>
<span id="cb615-3"><a href="#cb615-3" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">newdata =</span> breast_test_prep))</span>
<span id="cb615-4"><a href="#cb615-4" aria-hidden="true" tabindex="-1"></a>cm_under</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   B   M
         B 102   5
         M   6  57
                                          
               Accuracy : 0.9353          
                 95% CI : (0.8872, 0.9673)
    No Information Rate : 0.6353          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.8608          
                                          
 Mcnemar&#39;s Test P-Value : 1               
                                          
            Sensitivity : 0.9444          
            Specificity : 0.9194          
         Pos Pred Value : 0.9533          
         Neg Pred Value : 0.9048          
             Prevalence : 0.6353          
         Detection Rate : 0.6000          
   Detection Prevalence : 0.6294          
      Balanced Accuracy : 0.9319          
                                          
       &#39;Positive&#39; Class : B               
                                          </code></pre>
<p>Podemos comparar esta capacidad predictiva con la que tiene el modelo obiviando el problema del desbalanceo y que se estimaría así:</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="#cb617-1" aria-hidden="true" tabindex="-1"></a>crtl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb617-2"><a href="#cb617-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">number =</span> <span class="dv">10</span>,  </span>
<span id="cb617-3"><a href="#cb617-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">repeats =</span> <span class="dv">10</span>,</span>
<span id="cb617-4"><a href="#cb617-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">verboseIter =</span> <span class="cn">FALSE</span>)</span>
<span id="cb617-5"><a href="#cb617-5" aria-hidden="true" tabindex="-1"></a>model_knn <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(diagnosis <span class="sc">~</span> .,</span>
<span id="cb617-6"><a href="#cb617-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">data =</span> breast_train_prep,</span>
<span id="cb617-7"><a href="#cb617-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb617-8"><a href="#cb617-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">trControl =</span> ctrl)</span></code></pre></div>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="#cb618-1" aria-hidden="true" tabindex="-1"></a>cm_original <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(breast_test_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb618-2"><a href="#cb618-2" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">predict</span>(model_knn, </span>
<span id="cb618-3"><a href="#cb618-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">newdata =</span> breast_test_prep))</span>
<span id="cb618-4"><a href="#cb618-4" aria-hidden="true" tabindex="-1"></a>cm_original</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   B   M
         B 101   6
         M   5  58
                                          
               Accuracy : 0.9353          
                 95% CI : (0.8872, 0.9673)
    No Information Rate : 0.6235          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.8617          
                                          
 Mcnemar&#39;s Test P-Value : 1               
                                          
            Sensitivity : 0.9528          
            Specificity : 0.9062          
         Pos Pred Value : 0.9439          
         Neg Pred Value : 0.9206          
             Prevalence : 0.6235          
         Detection Rate : 0.5941          
   Detection Prevalence : 0.6294          
      Balanced Accuracy : 0.9295          
                                          
       &#39;Positive&#39; Class : B               
                                          </code></pre>
<p>Estimemos ahora el modelo con un muestreo ascendente y usando, por ejemplo SMOTE (ROSE sea haría igual usando <code>sampling="rose"</code>)</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="#cb620-1" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb620-2"><a href="#cb620-2" aria-hidden="true" tabindex="-1"></a><span class="co"># OVER</span></span>
<span id="cb620-3"><a href="#cb620-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb620-4"><a href="#cb620-4" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb620-5"><a href="#cb620-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">number =</span> <span class="dv">10</span>, </span>
<span id="cb620-6"><a href="#cb620-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">repeats =</span> <span class="dv">5</span>, </span>
<span id="cb620-7"><a href="#cb620-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">verboseIter =</span> <span class="cn">FALSE</span>,</span>
<span id="cb620-8"><a href="#cb620-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">sampling =</span> <span class="st">&quot;up&quot;</span>)</span>
<span id="cb620-9"><a href="#cb620-9" aria-hidden="true" tabindex="-1"></a>model_knn_over <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(diagnosis <span class="sc">~</span> .,</span>
<span id="cb620-10"><a href="#cb620-10" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> breast_train_prep,</span>
<span id="cb620-11"><a href="#cb620-11" aria-hidden="true" tabindex="-1"></a>                         <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb620-12"><a href="#cb620-12" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trControl =</span> ctrl)</span>
<span id="cb620-13"><a href="#cb620-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb620-14"><a href="#cb620-14" aria-hidden="true" tabindex="-1"></a>cm_over <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(breast_test_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb620-15"><a href="#cb620-15" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">predict</span>(model_knn_over, </span>
<span id="cb620-16"><a href="#cb620-16" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">newdata =</span> breast_test_prep))</span>
<span id="cb620-17"><a href="#cb620-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb620-18"><a href="#cb620-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb620-19"><a href="#cb620-19" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb620-20"><a href="#cb620-20" aria-hidden="true" tabindex="-1"></a><span class="co"># SMOTE</span></span>
<span id="cb620-21"><a href="#cb620-21" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb620-22"><a href="#cb620-22" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb620-23"><a href="#cb620-23" aria-hidden="true" tabindex="-1"></a>                     <span class="at">number =</span> <span class="dv">10</span>, </span>
<span id="cb620-24"><a href="#cb620-24" aria-hidden="true" tabindex="-1"></a>                     <span class="at">repeats =</span> <span class="dv">5</span>, </span>
<span id="cb620-25"><a href="#cb620-25" aria-hidden="true" tabindex="-1"></a>                     <span class="at">verboseIter =</span> <span class="cn">FALSE</span>,</span>
<span id="cb620-26"><a href="#cb620-26" aria-hidden="true" tabindex="-1"></a>                     <span class="at">sampling =</span> <span class="st">&quot;smote&quot;</span>)</span>
<span id="cb620-27"><a href="#cb620-27" aria-hidden="true" tabindex="-1"></a>model_knn_smote <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(diagnosis <span class="sc">~</span> .,</span>
<span id="cb620-28"><a href="#cb620-28" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> breast_train_prep,</span>
<span id="cb620-29"><a href="#cb620-29" aria-hidden="true" tabindex="-1"></a>                         <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb620-30"><a href="#cb620-30" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trControl =</span> ctrl)</span>
<span id="cb620-31"><a href="#cb620-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb620-32"><a href="#cb620-32" aria-hidden="true" tabindex="-1"></a>cm_smote <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(breast_test_prep<span class="sc">$</span>diagnosis,</span>
<span id="cb620-33"><a href="#cb620-33" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">predict</span>(model_knn_smote, </span>
<span id="cb620-34"><a href="#cb620-34" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">newdata =</span> breast_test_prep))</span></code></pre></div>
<p>Y podemos comparar las predicciones con la función <code>resamples</code> (para introducir variabilidad)</p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="#cb621-1" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">original =</span> model_knn,</span>
<span id="cb621-2"><a href="#cb621-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">under =</span> model_knn_under,</span>
<span id="cb621-3"><a href="#cb621-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">over =</span> model_knn_over,</span>
<span id="cb621-4"><a href="#cb621-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">smote =</span> model_knn_smote)</span>
<span id="cb621-5"><a href="#cb621-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb621-6"><a href="#cb621-6" aria-hidden="true" tabindex="-1"></a>resampling <span class="ot">&lt;-</span> <span class="fu">resamples</span>(models)</span>
<span id="cb621-7"><a href="#cb621-7" aria-hidden="true" tabindex="-1"></a><span class="fu">bwplot</span>(resampling)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-255-1.png" width="672" /></p>
<p>O compararlas con otras métricas</p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="#cb622-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb622-2"><a href="#cb622-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb622-3"><a href="#cb622-3" aria-hidden="true" tabindex="-1"></a>select_measures <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Sensitivity&quot;</span>, <span class="st">&quot;Specificity&quot;</span>, <span class="st">&quot;Precision&quot;</span>,</span>
<span id="cb622-4"><a href="#cb622-4" aria-hidden="true" tabindex="-1"></a>                     <span class="st">&quot;Recall&quot;</span>, <span class="st">&quot;F1&quot;</span>)</span>
<span id="cb622-5"><a href="#cb622-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb622-6"><a href="#cb622-6" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb622-7"><a href="#cb622-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (name <span class="cf">in</span> <span class="fu">names</span>(models)) {</span>
<span id="cb622-8"><a href="#cb622-8" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">get</span>(<span class="fu">paste0</span>(<span class="st">&quot;cm_&quot;</span>, name))</span>
<span id="cb622-9"><a href="#cb622-9" aria-hidden="true" tabindex="-1"></a>  comparison.i <span class="ot">&lt;-</span> model<span class="sc">$</span>byClass[select_measures]</span>
<span id="cb622-10"><a href="#cb622-10" aria-hidden="true" tabindex="-1"></a>  comparison <span class="ot">&lt;-</span> <span class="fu">rbind</span>(comparison, comparison.i) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>()</span>
<span id="cb622-11"><a href="#cb622-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb622-12"><a href="#cb622-12" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">&lt;-</span> comparison <span class="sc">%&gt;%</span> </span>
<span id="cb622-13"><a href="#cb622-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_column</span>(<span class="at">model=</span><span class="fu">names</span>(models), <span class="at">.before=</span><span class="cn">TRUE</span>)</span>
<span id="cb622-14"><a href="#cb622-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb622-15"><a href="#cb622-15" aria-hidden="true" tabindex="-1"></a>comparison</span></code></pre></div>
<pre><code># A tibble: 4 × 6
  model    Sensitivity Specificity Precision Recall    F1
  &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
1 original       0.953       0.906     0.944  0.953 0.948
2 under          0.944       0.919     0.953  0.944 0.949
3 over           0.935       0.903     0.944  0.935 0.940
4 smote          0.944       0.919     0.953  0.944 0.949</code></pre>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="#cb624-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb624-2"><a href="#cb624-2" aria-hidden="true" tabindex="-1"></a>comparison <span class="sc">%&gt;%</span></span>
<span id="cb624-3"><a href="#cb624-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(x, y, Sensitivity<span class="sc">:</span>F1) <span class="sc">%&gt;%</span></span>
<span id="cb624-4"><a href="#cb624-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">color =</span> model)) <span class="sc">+</span></span>
<span id="cb624-5"><a href="#cb624-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-256-1.png" width="672" /></p>
<!--chapter:end:11-nobalanceados.Rmd-->
</div>
<div id="árboles-de-decisión" class="section level1 hasAnchor" number="14">
<h1 class="hasAnchor"><span class="header-section-number">14</span> Árboles de decisión<a href="#árboles-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Los árboles de decisión, también conocidos como modelos de árbol de clasificación y regresión (CART), son métodos basados en árboles para el aprendizaje automático supervisado. Los árboles de clasificación y de regresión simples son fáciles de usar e interpretar, pero no son competitivos con los mejores métodos de aprendizaje automático. Sin embargo, forman la base para el conjunto de modelos de ensamblaje como “bagged trees”, “random forest” y “boosted trees”, que aunque son menos interpretables, son muy precisos.</p>
<p>Los modelos CART se puede definir en dos tipos de problemas</p>
<ul>
<li><p><strong>Árboles de clasificación:</strong> la variable resultado es categórica y el métodos se utiliza para identificar la “clase” dentro de la cual es más probable que caiga nuestra variable resultado. Un ejemplo de un problema de tipo clasificación sería determinar quién se suscribirá o no a una plataforma digital; o quién se graduará o no de la escuela secundaria; o si una persona tiene cáncer o no.</p></li>
<li><p><strong>Árboles de regressión:</strong> la variable resultado es continua y el métodos se utiliza para predecir su valor. Un ejemplo de un problema de tipo regresión sería predecir los precios de venta de una casa residencial o el nivel de colesterol de una persona.</p></li>
</ul>
<p>Los modelos CART segmentan el espacio predictor en <span class="math inline">\(K\)</span> nodos terminales no superpuestos (hojas). Cada nodo se describe mediante un conjunto de reglas que se pueden utilizar para predecir nuevas respuestas. El valor predicho <span class="math inline">\(\hat{y}\)</span> para cada nodo es la moda (clasificación) o la media (regresión).</p>
<p>Los modelos CART definen los nodos a través de un proceso <em>top-down greedy</em> llamado división binaria recursiva (<em>recursive binary splitting</em>). El proceso es de arriba hacia abajo porque comienza en la parte superior del árbol con todas las observaciones en una sola región y divide sucesivamente el espacio de predicción. Es <em>greedy</em> porque en cada paso de división, la mejor división se realiza en ese paso en particular sin tener en cuenta las divisiones posteriores. La siguiente figura muestra la idea general de esta metodología:</p>
<div class="figure">
<img src="figures/cart.png" style="width:70.0%" alt="" />
<p class="caption">Diagrama árboles de decisión</p>
</div>
<p>Como vemos en el ejemplo una de las <strong>ventajas</strong> de los modelos CART es que consideran interacciones. En este curso no vamos a ver la <strong>regresión lógica</strong> pero es una metodología muy interesante que extiende CART cuando las variables predictoras son binarias y las interacciones que buscamos son del tipo AND y OR. Esta metodología se ha empleado con éxito para analizar <a href="https://academic.oup.com/biostatistics/article/9/1/187/254635">datos genéticos</a> donde el interés radica en saber cuál es el riesgo de desarrolar una enfermeda si te tiene por ejemplo: “una mutación en un punto A del genoma (SNP) y otra mutación en el punto B ó si se tiene una mutación en el punto C pero no se tiene en el punto D.</p>
<p>También son interesantes porque permiten valores faltantes sin la necesidad de hacer imputaciones previas.</p>
<p>La mejor división es la variable predictora y el punto de corte que minimiza una función de costo. La función de costo más común para los árboles de regresión es la suma de los residuos al cuadrado,</p>
<p><span class="math display">\[RSS = \sum_{k=1}^K\sum_{i \in A_k}{\left(y_i - \hat{y}_{A_k} \right)^2}.\]</span>
Para árboles de clasificación, es el índice de Gini,</p>
<p><span class="math display">\[G = \sum_{c=1}^C{\hat{p}_{kc}(1 - \hat{p}_{kc})},\]</span></p>
<p>y la entropía (aka información estadística)</p>
<p><span class="math display">\[D = - \sum_{c=1}^C{\hat{p}_{kc} \log \hat{p}_{kc}}\]</span></p>
<p>dónde <span class="math inline">\(\hat{p}_{kc}\)</span> es la proporción de observaciones de entrenamiento en el nodo <span class="math inline">\(k\)</span> que son de clase <span class="math inline">\(c\)</span>. Un nodo completamente puro en un árbol binario tendría <span class="math inline">\(\hat{p} \in \{ 0, 1 \}\)</span> y <span class="math inline">\(G=D=0\)</span>. Un nodo completamente impuro en un árbol binario tendría <span class="math inline">\(\hat{p}=0.5\)</span> y <span class="math inline">\(G=0.5^2 \cdot 2 = 0.25\)</span> y <span class="math inline">\(D = -(0.5 \log(0.5)) \cdot 2 = 0.69\)</span>.</p>
<p>CART repite el proceso de división para cada nodo hijo hasta que se satisface un criterio de detención, generalmente cuando ningún tamaño de nodo supera un máximo predefinido o la división no mejora el modelo de manera significativa. CART también puede imponer un número mínimo de observaciones en cada nodo.</p>
<p>Es probable que el árbol resultante esté sobre-entrenado (<em>over-fitting</em>) y, por lo tanto, no se generalice bien para los datos de prueba. Para evitar este problema CART <strong>poda el árbol</strong>, minimizando el error de predicción de validación cruzada. En este caso, el hiperparámetro que debermos seleccionar en este modelo es la profundidad del arbol (e.g. número de nodos).</p>
<p>En lugar de realizar una validación cruzada de todos los subárboles posibles para encontrar el que tenga el mínimo de error, CART utiliza la poda de complejidad de costos (<em>cost-complexity pruning</em>). Costo-complejidad es la compensación entre error (costo) y tamaño del árbol (complejidad) donde la compensación se cuantifica con el parámetro costo-complejidad <span class="math inline">\(c_p\)</span>. El costo-complejidad del árbol, <span class="math inline">\(R_{c_p}(T)\)</span>, es la suma de su riesgo (error) más un factor de “complejidad de costos” <span class="math inline">\(c_p\)</span> multiplicado pro el tamaño del arbol <span class="math inline">\(|T|\)</span>.</p>
<p><span class="math display">\[R_{c_p}(T) = R(T) + c_p|T|\]</span></p>
<p><span class="math inline">\(c_p\)</span> puede tomar cualquier valor de <span class="math inline">\([0..\infty]\)</span>, pero resulta que hay un árbol óptimo para rangos de <span class="math inline">\(c_p\)</span>, por lo que solo hay un conjunto finito de valores interesantes para <span class="math inline">\(c_p\)</span> (ver <a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">Therneau y Atkinson 2019</a>. CART utiliza validación cruzada para determinar qué <span class="math inline">\(c_p\)</span> es óptimo.</p>
<div id="árboles-de-clasificación" class="section level2 hasAnchor" number="14.1">
<h2 class="hasAnchor"><span class="header-section-number">14.1</span> Árboles de clasificación<a href="#árboles-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Veamos cómo crear árboles de clasificación usando el conjunto de datos <code>ISLR::OJ</code> que se usaron para predecir qué marca de zumo de naranja, Citrus Hill (CH) o Minute Maid = (MM) toman los clientes (variable `Purchase) a partir de 17 variables predictoras.</p>
<p>Vamos a introducir la librería <code>skimr</code> que es interesante para hacer descriptivas. Con ella podremos saber, por ejemplo, cuántos tipos de variables tenemos o ver qué distribuciones tienen las variables continuas</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="#cb625-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb625-2"><a href="#cb625-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb625-3"><a href="#cb625-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)  <span class="co"># classification and regression trees </span></span>
<span id="cb625-4"><a href="#cb625-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)  <span class="co"># better formatted plots than the ones in rpart</span></span>
<span id="cb625-5"><a href="#cb625-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb625-6"><a href="#cb625-6" aria-hidden="true" tabindex="-1"></a>oj_dat <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>OJ</span>
<span id="cb625-7"><a href="#cb625-7" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(oj_dat)</span></code></pre></div>
<table>
<caption>(#tab:unnamed-chunk-257)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">oj_dat</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">1070</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">18</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table style="width:100%;">
<colgroup>
<col width="19%" />
<col width="13%" />
<col width="19%" />
<col width="10%" />
<col width="12%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Purchase</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">CH: 653, MM: 417</td>
</tr>
<tr class="even">
<td align="left">Store7</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">No: 714, Yes: 356</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="10%" />
<col width="15%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">WeekofPurchase</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">254.38</td>
<td align="right">15.56</td>
<td align="right">227.00</td>
<td align="right">240.00</td>
<td align="right">257.00</td>
<td align="right">268.00</td>
<td align="right">278.00</td>
<td align="left">▆▅▅▇▇</td>
</tr>
<tr class="even">
<td align="left">StoreID</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.96</td>
<td align="right">2.31</td>
<td align="right">1.00</td>
<td align="right">2.00</td>
<td align="right">3.00</td>
<td align="right">7.00</td>
<td align="right">7.00</td>
<td align="left">▇▅▃▁▇</td>
</tr>
<tr class="odd">
<td align="left">PriceCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.87</td>
<td align="right">0.10</td>
<td align="right">1.69</td>
<td align="right">1.79</td>
<td align="right">1.86</td>
<td align="right">1.99</td>
<td align="right">2.09</td>
<td align="left">▅▂▇▆▁</td>
</tr>
<tr class="even">
<td align="left">PriceMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.09</td>
<td align="right">0.13</td>
<td align="right">1.69</td>
<td align="right">1.99</td>
<td align="right">2.09</td>
<td align="right">2.18</td>
<td align="right">2.29</td>
<td align="left">▂▁▃▇▆</td>
</tr>
<tr class="odd">
<td align="left">DiscCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.05</td>
<td align="right">0.12</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.50</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">DiscMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.12</td>
<td align="right">0.21</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.23</td>
<td align="right">0.80</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">SpecialCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.15</td>
<td align="right">0.35</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="even">
<td align="left">SpecialMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.16</td>
<td align="right">0.37</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="odd">
<td align="left">LoyalCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.57</td>
<td align="right">0.31</td>
<td align="right">0.00</td>
<td align="right">0.33</td>
<td align="right">0.60</td>
<td align="right">0.85</td>
<td align="right">1.00</td>
<td align="left">▅▃▆▆▇</td>
</tr>
<tr class="even">
<td align="left">SalePriceMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.96</td>
<td align="right">0.25</td>
<td align="right">1.19</td>
<td align="right">1.69</td>
<td align="right">2.09</td>
<td align="right">2.13</td>
<td align="right">2.29</td>
<td align="left">▁▂▂▂▇</td>
</tr>
<tr class="odd">
<td align="left">SalePriceCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.82</td>
<td align="right">0.14</td>
<td align="right">1.39</td>
<td align="right">1.75</td>
<td align="right">1.86</td>
<td align="right">1.89</td>
<td align="right">2.09</td>
<td align="left">▂▁▇▇▅</td>
</tr>
<tr class="even">
<td align="left">PriceDiff</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.15</td>
<td align="right">0.27</td>
<td align="right">-0.67</td>
<td align="right">0.00</td>
<td align="right">0.23</td>
<td align="right">0.32</td>
<td align="right">0.64</td>
<td align="left">▁▂▃▇▂</td>
</tr>
<tr class="odd">
<td align="left">PctDiscMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.06</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.11</td>
<td align="right">0.40</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="even">
<td align="left">PctDiscCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.03</td>
<td align="right">0.06</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.25</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">ListPriceDiff</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.22</td>
<td align="right">0.11</td>
<td align="right">0.00</td>
<td align="right">0.14</td>
<td align="right">0.24</td>
<td align="right">0.30</td>
<td align="right">0.44</td>
<td align="left">▂▃▆▇▁</td>
</tr>
<tr class="even">
<td align="left">STORE</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.63</td>
<td align="right">1.43</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">2.00</td>
<td align="right">3.00</td>
<td align="right">4.00</td>
<td align="left">▇▃▅▅▃</td>
</tr>
</tbody>
</table>
<p>Dividiremos nuestra base de datos <code>oj_dat</code> (n = 1070) en <code>oj_train</code> (80%, n = 857) para estimar varios modelos, y <code>oj_test</code> (20%, n = 213) para comparar su rendimiento con datos nuevos.</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="#cb626-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb626-2"><a href="#cb626-2" aria-hidden="true" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> oj_dat<span class="sc">$</span>Purchase, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb626-3"><a href="#cb626-3" aria-hidden="true" tabindex="-1"></a>oj_train <span class="ot">&lt;-</span> oj_dat[partition, ]</span>
<span id="cb626-4"><a href="#cb626-4" aria-hidden="true" tabindex="-1"></a>oj_test <span class="ot">&lt;-</span> oj_dat[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>La función <code>rpart::rpart()</code> construye un árbol completo, minimizando el índice de Gini <span class="math inline">\(G\)</span> por defecto (<code>parms = list (split = "gini")</code>), hasta que se cumpla el criterio de parada. El criterio de parada predeterminado es:</p>
<ul>
<li>solo intenta una división si el nodo actual tiene al menos <code>minsplit = 20</code> observaciones, y</li>
<li>solo acepta una división si
<ul>
<li>los nodos resultantes tienen al menos <code>minbucket = round (minsplit / 3)</code> observaciones, y</li>
<li>el ajuste general resultante mejora en <code>cp = 0.01</code> (es decir, <span class="math inline">\(\Delta G &lt;= 0.01\)</span>).</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="#cb627-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usar method = &quot;class&quot; para clasificación y method = &quot;anova&quot; para regresión</span></span>
<span id="cb627-2"><a href="#cb627-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb627-3"><a href="#cb627-3" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(<span class="at">formula =</span> Purchase <span class="sc">~</span> ., <span class="at">data =</span> oj_train, </span>
<span id="cb627-4"><a href="#cb627-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">method =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb627-5"><a href="#cb627-5" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 857 334 CH (0.61026838 0.38973162)  
   2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
     4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
     5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
      10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894) *
      11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
   3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
     6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
      12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972) *
      13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000) *
     7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322) *</code></pre>
<p>La salida comienza con el nodo raíz. La clase predicha en la raíz es <code>CH</code> y esta predicción produce 334 errores en las 857 observaciones para una tasa de éxito (precisión) del 61% y una tasa de error del 39%. Los nodos secundarios del nodo “x” están etiquetados como 2x) y 2x + 1), por lo que los nodos secundarios de 1) son 2) y 3), y los nodos secundarios de 2) son 4) y 5). Los nodos terminales están etiquetados con un asterisco (*).</p>
<p>Sorprendentemente, solo 3 de las 17 variables se utilizaron en el árbol completo: LoyalCH (lealtad de marca del cliente para CH), PriceDiff (precio relativo de MM sobre CH) y SalePriceMM (precio absoluto de MM). La primera división está en LoyalCH = 0.48285. Aquí hay un diagrama del árbol completo (sin podar).</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="#cb629-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart_full, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-260-1.png" width="672" /></p>
<p>Las cajas muestran la clasificación del nodo (según la moda), la proporción de observaciones que no son <code>CH</code> y la proporción de observaciones incluidas en el nodo.</p>
<p><code>rpart ()</code> no solo hizo crecer el árbol completo, sino que identificó el conjunto de parámetros de complejidad de costos y midió el rendimiento del modelo de cada árbol correspondiente mediante validación cruzada. <code>printcp ()</code> muestra los posibles valores de <span class="math inline">\(c_p\)</span>. La siguiente tabla se puede utilizar esta tabla para decidir cómo podar el árbol.</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="#cb630-1" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(oj_mdl_cart_full)</span></code></pre></div>
<pre><code>
Classification tree:
rpart(formula = Purchase ~ ., data = oj_train, method = &quot;class&quot;)

Variables actually used in tree construction:
[1] LoyalCH     PriceDiff   SalePriceMM

Root node error: 334/857 = 0.38973

n= 857 

        CP nsplit rel error  xerror     xstd
1 0.479042      0   1.00000 1.00000 0.042745
2 0.032934      1   0.52096 0.54192 0.035775
3 0.013473      3   0.45509 0.47006 0.033905
4 0.010000      5   0.42814 0.46407 0.033736</code></pre>
<p>Hay 4 valores de <span class="math inline">\(c_p\)</span> en este modelo. El modelo con el parámetro de complejidad más pequeño permite la mayoría de las divisiones (<code>nsplit</code>). El parámetro de mayor complejidad corresponde a un árbol con solo un nodo raíz. <code>rel error</code> es la tasa de error relativa al nodo raíz. El error absoluto del nodo raíz es 0.38973162 (la proporción de MM), por lo que su <code>rel error</code> es 0.38973162 / 0.38973162 = 1.0. Eso significa que el error absoluto del árbol completo (en CP = 0.01) es 0.42814 * 0.38973162 = 0.1669. Podemos verificarlo calculando la tasa de error de los valores predichos:</p>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="#cb632-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart_full, <span class="at">newdata =</span> oj_train, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb632-2"><a href="#cb632-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(oj_train<span class="sc">$</span>Purchase <span class="sc">!=</span> pred)</span></code></pre></div>
<pre><code>[1] 0.1668611</code></pre>
<p>Para acaber de explicar toda la salida de la table CP, <code>xerror</code> es la tasa de error relativa con validación cruzada y <code>xstd</code> es su error estándar. Si se desea el error más bajo posible, deberíamos podar el árbol con el error de CV relativo más pequeño, <span class="math inline">\(c_p=0.01\)</span>. Si deseamos equilibrar el poder predictivo con la simplicidad, podaremos al árbol más pequeño dentro de 1 SE del que tiene el error relativo más pequeño. La tabla CP no es muy útil para encontrar ese árbol, así que añadiremos una columna para encontrarlo.</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="#cb634-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full<span class="sc">$</span>cptable <span class="sc">%&gt;%</span></span>
<span id="cb634-2"><a href="#cb634-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb634-3"><a href="#cb634-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(</span>
<span id="cb634-4"><a href="#cb634-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">min_idx =</span> <span class="fu">which.min</span>(oj_mdl_cart_full<span class="sc">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]),</span>
<span id="cb634-5"><a href="#cb634-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">rownum =</span> <span class="fu">row_number</span>(),</span>
<span id="cb634-6"><a href="#cb634-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">xerror_cap =</span> oj_mdl_cart_full<span class="sc">$</span>cptable[min_idx, <span class="st">&quot;xerror&quot;</span>] <span class="sc">+</span> </span>
<span id="cb634-7"><a href="#cb634-7" aria-hidden="true" tabindex="-1"></a>                   oj_mdl_cart_full<span class="sc">$</span>cptable[min_idx, <span class="st">&quot;xstd&quot;</span>],</span>
<span id="cb634-8"><a href="#cb634-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">eval =</span> <span class="fu">case_when</span>(rownum <span class="sc">==</span> min_idx <span class="sc">~</span> <span class="st">&quot;min xerror&quot;</span>,</span>
<span id="cb634-9"><a href="#cb634-9" aria-hidden="true" tabindex="-1"></a>                       xerror <span class="sc">&lt;</span> xerror_cap <span class="sc">~</span> <span class="st">&quot;under cap&quot;</span>,</span>
<span id="cb634-10"><a href="#cb634-10" aria-hidden="true" tabindex="-1"></a>                       <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb634-11"><a href="#cb634-11" aria-hidden="true" tabindex="-1"></a>   ) <span class="sc">%&gt;%</span></span>
<span id="cb634-12"><a href="#cb634-12" aria-hidden="true" tabindex="-1"></a>   dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>rownum, <span class="sc">-</span>min_idx) </span></code></pre></div>
<pre><code>          CP nsplit rel.error    xerror       xstd xerror_cap       eval
1 0.47904192      0 1.0000000 1.0000000 0.04274518  0.4978082           
2 0.03293413      1 0.5209581 0.5419162 0.03577468  0.4978082           
3 0.01347305      3 0.4550898 0.4700599 0.03390486  0.4978082  under cap
4 0.01000000      5 0.4281437 0.4640719 0.03373631  0.4978082 min xerror</code></pre>
<p>El árbol más simple que usa la regla 1-SE es <span class="math inline">\(c_p = 0.01347305\)</span> (error CV = 0.18). Afortunadamente, <code>plotcp ()</code> nos da una representación gráfica de la relación entre <code>xerror</code> y <code>cp</code>.</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="#cb636-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(oj_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-264-1.png" width="672" /></p>
<p>La línea discontinua se establece en el mínimo <code>xerror + xstd</code>. El eje superior muestra el número de divisiones en el árbol. NOTA: No estoy seguro de por qué los valores de CP no son los mismos que en la tabla (están cerca, pero no son los mismos). La figura sugiere que debería podar a 5 o 3 divisiones. Vemos que esta curva nunca llega al mínimo, sigue disminuyendo en 5 divisiones. El valor del parámetro de ajuste predeterminado <code>cp = 0.01</code> puede ser demasiado grande, así que lo cambiaremos a <code>cp = 0.001</code> y empezaremos de nuevo.</p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="#cb637-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb637-2"><a href="#cb637-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb637-3"><a href="#cb637-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">formula =</span> Purchase <span class="sc">~</span> .,</span>
<span id="cb637-4"><a href="#cb637-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train,</span>
<span id="cb637-5"><a href="#cb637-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;class&quot;</span>,</span>
<span id="cb637-6"><a href="#cb637-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> <span class="fl">0.001</span></span>
<span id="cb637-7"><a href="#cb637-7" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb637-8"><a href="#cb637-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(oj_mdl_cart_full)</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

  1) root 857 334 CH (0.61026838 0.38973162)  
    2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
      4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
      5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
       10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894)  
         20) ListPriceDiff&gt;=0.255 115  11 CH (0.90434783 0.09565217) *
         21) ListPriceDiff&lt; 0.255 111  39 CH (0.64864865 0.35135135)  
           42) PriceMM&gt;=2.155 19   2 CH (0.89473684 0.10526316) *
           43) PriceMM&lt; 2.155 92  37 CH (0.59782609 0.40217391)  
             86) DiscCH&gt;=0.115 7   0 CH (1.00000000 0.00000000) *
             87) DiscCH&lt; 0.115 85  37 CH (0.56470588 0.43529412)  
              174) ListPriceDiff&gt;=0.215 45  15 CH (0.66666667 0.33333333) *
              175) ListPriceDiff&lt; 0.215 40  18 MM (0.45000000 0.55000000)  
                350) LoyalCH&gt;=0.527571 28  13 CH (0.53571429 0.46428571)  
                  700) WeekofPurchase&lt; 266.5 21   8 CH (0.61904762 0.38095238) *
                  701) WeekofPurchase&gt;=266.5 7   2 MM (0.28571429 0.71428571) *
                351) LoyalCH&lt; 0.527571 12   3 MM (0.25000000 0.75000000) *
       11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
    3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
      6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
       12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972)  
         24) LoyalCH&lt; 0.303104 7   0 CH (1.00000000 0.00000000) *
         25) LoyalCH&gt;=0.303104 64  31 CH (0.51562500 0.48437500)  
           50) WeekofPurchase&gt;=246.5 52  22 CH (0.57692308 0.42307692)  
            100) PriceCH&lt; 1.94 35  11 CH (0.68571429 0.31428571)  
              200) StoreID&lt; 1.5 9   1 CH (0.88888889 0.11111111) *
              201) StoreID&gt;=1.5 26  10 CH (0.61538462 0.38461538)  
                402) LoyalCH&lt; 0.410969 17   4 CH (0.76470588 0.23529412) *
                403) LoyalCH&gt;=0.410969 9   3 MM (0.33333333 0.66666667) *
            101) PriceCH&gt;=1.94 17   6 MM (0.35294118 0.64705882) *
           51) WeekofPurchase&lt; 246.5 12   3 MM (0.25000000 0.75000000) *
       13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000)  
         26) SpecialCH&gt;=0.5 14   6 CH (0.57142857 0.42857143) *
         27) SpecialCH&lt; 0.5 61  10 MM (0.16393443 0.83606557) *
      7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322)  
       14) LoyalCH&gt;=0.035047 117  21 MM (0.17948718 0.82051282)  
         28) WeekofPurchase&lt; 273.5 104  21 MM (0.20192308 0.79807692)  
           56) PriceCH&gt;=1.875 20   9 MM (0.45000000 0.55000000)  
            112) WeekofPurchase&gt;=252.5 12   5 CH (0.58333333 0.41666667) *
            113) WeekofPurchase&lt; 252.5 8   2 MM (0.25000000 0.75000000) *
           57) PriceCH&lt; 1.875 84  12 MM (0.14285714 0.85714286) *
         29) WeekofPurchase&gt;=273.5 13   0 MM (0.00000000 1.00000000) *
       15) LoyalCH&lt; 0.035047 57   1 MM (0.01754386 0.98245614) *</code></pre>
<p>Este es un árbol mucho más grande. ¿Encontramo un valor <code>cp</code> que produce un mínimo?</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="#cb639-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(oj_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-266-1.png" width="672" /></p>
<p>Sí, el mínimo está en CP = 0.011 con 5 divisiones. El mínimo + 1 SE está en CP = 0.021 con 3 divisiones. Podaremos entonces el árbol en 3.</p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="#cb640-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart <span class="ot">&lt;-</span> <span class="fu">prune</span>(</span>
<span id="cb640-2"><a href="#cb640-2" aria-hidden="true" tabindex="-1"></a>   oj_mdl_cart_full,</span>
<span id="cb640-3"><a href="#cb640-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> oj_mdl_cart_full<span class="sc">$</span>cptable[oj_mdl_cart_full<span class="sc">$</span>cptable[, <span class="dv">2</span>] <span class="sc">==</span> <span class="dv">3</span>, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb640-4"><a href="#cb640-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb640-5"><a href="#cb640-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-267-1.png" width="672" /></p>
<p>El indicador de compra más “importante” parece ser <code>LoyalCH</code>. De la <a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">vignette de rpart</a> (página 12) tenemos que:</p>
<pre><code>An overall measure of variable importance is the sum of the goodness of split measures for each split for which it was the primary variable, plus goodness (adjusted agreement) for all splits in which it was a surrogate.</code></pre>
<p>“Surrogate” (variable subrogada[^La FDA define una variable subrogada como “una medida de laboratorio o signo físico que se usa en ensayos terapéuticos como sustituto de una variable clínicamente significativa que es una medida directa sobre lo que siente un paciente, sus funciones o su supervivencia y que se espera que prediga el efecto de la terapia]) se refieren a características alternativas para que un nodo maneje los datos faltantes. Para cada división, CART evalúa una variedad de divisiones alternativas”sustitutas” para usar cuando el valor de la característica para la división principal es NA. Las divisiones sustitutas son divisiones que producen resultados similares a la división original.</p>
<p>La importancia de una variable es la suma de la mejora en la medida general de Gini (o RMSE) producida por los nodos en los que aparece. En el siguiente gráfico podemos ver la importancia de cada variable para este modelo.</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="#cb642-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart<span class="sc">$</span>variable.importance <span class="sc">%&gt;%</span> </span>
<span id="cb642-2"><a href="#cb642-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb642-3"><a href="#cb642-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;Feature&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb642-4"><a href="#cb642-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rename</span>(<span class="at">Overall =</span> <span class="st">&#39;.&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb642-5"><a href="#cb642-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">fct_reorder</span>(Feature, Overall), <span class="at">y =</span> Overall)) <span class="sc">+</span></span>
<span id="cb642-6"><a href="#cb642-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> Overall), <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>, <span class="at">size =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb642-7"><a href="#cb642-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb642-8"><a href="#cb642-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb642-9"><a href="#cb642-9" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Importancia mediante clasificación simple&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-268-1.png" width="672" /></p>
<p><code>LoyalCH</code> es, con mucho, la variable más importante, como se esperaba de su posición en la parte superior del árbol así como en el siguiente nivel abajo.</p>
<p>Podemos ver cómo aparecen los variables subrogadas en el modelo con la función <code>summary()</code>.</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(oj_mdl_cart)</span></code></pre></div>
<pre><code>Call:
rpart(formula = Purchase ~ ., data = oj_train, method = &quot;class&quot;, 
    cp = 0.001)
  n= 857 

          CP nsplit rel error    xerror       xstd
1 0.47904192      0 1.0000000 1.0000000 0.04274518
2 0.03293413      1 0.5209581 0.5419162 0.03577468
3 0.01347305      3 0.4550898 0.4700599 0.03390486

Variable importance
       LoyalCH      PriceDiff    SalePriceMM        StoreID WeekofPurchase         DiscMM 
            67              9              5              4              4              3 
       PriceMM      PctDiscMM        PriceCH 
             3              3              1 

Node number 1: 857 observations,    complexity param=0.4790419
  predicted class=CH  expected loss=0.3897316  P(node) =1
    class counts:   523   334
   probabilities: 0.610 0.390 
  left son=2 (537 obs) right son=3 (320 obs)
  Primary splits:
      LoyalCH       &lt; 0.48285   to the right, improve=132.56800, (0 missing)
      StoreID       &lt; 3.5       to the right, improve= 40.12097, (0 missing)
      PriceDiff     &lt; 0.015     to the right, improve= 24.26552, (0 missing)
      ListPriceDiff &lt; 0.255     to the right, improve= 22.79117, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve= 20.16447, (0 missing)
  Surrogate splits:
      StoreID        &lt; 3.5       to the right, agree=0.646, adj=0.053, (0 split)
      PriceMM        &lt; 1.89      to the right, agree=0.638, adj=0.031, (0 split)
      WeekofPurchase &lt; 229.5     to the right, agree=0.632, adj=0.016, (0 split)
      DiscMM         &lt; 0.77      to the left,  agree=0.629, adj=0.006, (0 split)
      SalePriceMM    &lt; 1.385     to the right, agree=0.629, adj=0.006, (0 split)

Node number 2: 537 observations,    complexity param=0.03293413
  predicted class=CH  expected loss=0.1750466  P(node) =0.6266044
    class counts:   443    94
   probabilities: 0.825 0.175 
  left son=4 (271 obs) right son=5 (266 obs)
  Primary splits:
      LoyalCH       &lt; 0.7648795 to the right, improve=17.669310, (0 missing)
      PriceDiff     &lt; 0.015     to the right, improve=15.475200, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve=13.951730, (0 missing)
      ListPriceDiff &lt; 0.255     to the right, improve=11.407560, (0 missing)
      DiscMM        &lt; 0.15      to the left,  improve= 7.795122, (0 missing)
  Surrogate splits:
      WeekofPurchase &lt; 257.5     to the right, agree=0.594, adj=0.180, (0 split)
      PriceCH        &lt; 1.775     to the right, agree=0.590, adj=0.173, (0 split)
      StoreID        &lt; 3.5       to the right, agree=0.587, adj=0.165, (0 split)
      PriceMM        &lt; 2.04      to the right, agree=0.587, adj=0.165, (0 split)
      SalePriceMM    &lt; 2.04      to the right, agree=0.587, adj=0.165, (0 split)

Node number 3: 320 observations
  predicted class=MM  expected loss=0.25  P(node) =0.3733956
    class counts:    80   240
   probabilities: 0.250 0.750 

Node number 4: 271 observations
  predicted class=CH  expected loss=0.04797048  P(node) =0.3162194
    class counts:   258    13
   probabilities: 0.952 0.048 

Node number 5: 266 observations,    complexity param=0.03293413
  predicted class=CH  expected loss=0.3045113  P(node) =0.3103851
    class counts:   185    81
   probabilities: 0.695 0.305 
  left son=10 (226 obs) right son=11 (40 obs)
  Primary splits:
      PriceDiff     &lt; -0.165    to the right, improve=20.84307, (0 missing)
      ListPriceDiff &lt; 0.235     to the right, improve=20.82404, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve=16.80587, (0 missing)
      DiscMM        &lt; 0.15      to the left,  improve=10.05120, (0 missing)
      PctDiscMM     &lt; 0.0729725 to the left,  improve=10.05120, (0 missing)
  Surrogate splits:
      SalePriceMM    &lt; 1.585     to the right, agree=0.906, adj=0.375, (0 split)
      DiscMM         &lt; 0.57      to the left,  agree=0.895, adj=0.300, (0 split)
      PctDiscMM      &lt; 0.264375  to the left,  agree=0.895, adj=0.300, (0 split)
      WeekofPurchase &lt; 274.5     to the left,  agree=0.872, adj=0.150, (0 split)
      SalePriceCH    &lt; 2.075     to the left,  agree=0.857, adj=0.050, (0 split)

Node number 10: 226 observations
  predicted class=CH  expected loss=0.2212389  P(node) =0.2637106
    class counts:   176    50
   probabilities: 0.779 0.221 

Node number 11: 40 observations
  predicted class=MM  expected loss=0.225  P(node) =0.04667445
    class counts:     9    31
   probabilities: 0.225 0.775 </code></pre>
<p>Una vez tenemos un modelo (o varios) los podemos evaluar en la muestra test con las medidas estándard</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="#cb645-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>) </span>
<span id="cb645-2"><a href="#cb645-2" aria-hidden="true" tabindex="-1"></a>oj_cm_cart <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred,  oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb645-3"><a href="#cb645-3" aria-hidden="true" tabindex="-1"></a>oj_cm_cart</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 113  13
        MM  17  70
                                          
               Accuracy : 0.8592          
                 95% CI : (0.8051, 0.9029)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 1.265e-15       
                                          
                  Kappa : 0.7064          
                                          
 Mcnemar&#39;s Test P-Value : 0.5839          
                                          
            Sensitivity : 0.8692          
            Specificity : 0.8434          
         Pos Pred Value : 0.8968          
         Neg Pred Value : 0.8046          
             Prevalence : 0.6103          
         Detection Rate : 0.5305          
   Detection Prevalence : 0.5915          
      Balanced Accuracy : 0.8563          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>También podemos representar gráficamente la tabla de confusión</p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb647-1"><a href="#cb647-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_test<span class="sc">$</span>Purchase, pred, </span>
<span id="cb647-2"><a href="#cb647-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Clasificación: Predicho vs. Observado&quot;</span>,</span>
<span id="cb647-3"><a href="#cb647-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Observado&quot;</span>,</span>
<span id="cb647-4"><a href="#cb647-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Predicho&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-271-1.png" width="672" /></p>
</div>
<div id="área-bajo-la-curva-roc" class="section level2 hasAnchor" number="14.2">
<h2 class="hasAnchor"><span class="header-section-number">14.2</span> Área bajo la curva ROC<a href="#área-bajo-la-curva-roc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>También podemos calcular el área bajo la curva ROC. La curva ROC (características operativas del receptor) es otra medida de precisión. Corresponde a un gráfico de la tasa de verdaderos positivos (TPR, sensibilidad) versus la tasa de falsos positivos (FPR, 1 - especificidad) para un conjunto de umbrales. De forma predeterminada, el umbral para predecir la clasificación predeterminada es 0.50, pero podría ser cualquier umbral. La función <code>precrec::evalmod ()</code> calcula los valores de la matriz de confusión del modelo usando el conjunto de datos test. El AUC en el conjunto de datos test es 0.8848 y podemos calcularlo con varias funciones: <code>pROC::plot.roc ()</code>, <code>plotROC::geom_roc ()</code>, <code>yardstick::roc_curve ()</code> y <code>plotROC</code> para usar <code>ggplot()</code> [geometría <code>geom_roc ()</code>].</p>
<p>Nosotros usaremos <code>pROC</code>. Para ello necesitamos tener las predicciones como probabilidades para la categoría de referencia. <strong>NOTA:</strong> El AUC es, pues, una medida útil para casos donde el predictor es binario.</p>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="#cb648-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb648-2"><a href="#cb648-2" aria-hidden="true" tabindex="-1"></a>pred2 <span class="ot">&lt;-</span>  <span class="fu">predict</span>(oj_mdl_cart, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb648-3"><a href="#cb648-3" aria-hidden="true" tabindex="-1"></a>roc.car <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb648-4"><a href="#cb648-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb648-5"><a href="#cb648-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-272-1.png" width="672" /></p>
<div id="entrenamiento-con-caret" class="section level3 hasAnchor" number="14.2.1">
<h3 class="hasAnchor"><span class="header-section-number">14.2.1</span> Entrenamiento con <code>caret</code><a href="#entrenamiento-con-caret" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También podemos ajustar el modelo con la función <code>caret::train ()</code>. Recordemo que hay dos formas de ajustar los hiperparámetros cuando usamos <code>train ()</code>:</p>
<ul>
<li>establecer el número de valores de parámetros de ajuste a considerar utilizando <code>tuneLength</code>, o</li>
<li>establecer ciertos valores para cada parámetro utilizando <code>tuneGrid</code>.</li>
</ul>
<p><strong>ESTRATEGIA:</strong> Construiremos el modelo usando una validación cruzada de 10 veces para optimizar el hiperparámetro CP. Si no tenemos idea de cuál es el parámetro de ajuste óptimo, empezaremos con <code>tuneLength</code> para aproximarnos al valor óptimo y luego ajustaremos el valor con <code>tuneGrid</code>. Crearemos un objeto de control de entrenamiento que puedo reutilizar en otras compilaciones de modelos.</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="#cb649-1" aria-hidden="true" tabindex="-1"></a>oj_trControl <span class="ot">=</span> <span class="fu">trainControl</span> (<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb649-2"><a href="#cb649-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb649-3"><a href="#cb649-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span>,  <span class="co"># guardaremos preds para el valor óptimo del parámetro a tunear</span></span>
<span id="cb649-4"><a href="#cb649-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">classProbs =</span> <span class="cn">TRUE</span>,  <span class="co"># probs para las clases además de preds</span></span>
<span id="cb649-5"><a href="#cb649-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">summaryFunction =</span> twoClassSummary</span>
<span id="cb649-6"><a href="#cb649-6" aria-hidden="true" tabindex="-1"></a>   )</span></code></pre></div>
<p>Ahora estimamos el modelo con</p>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="#cb650-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb650-2"><a href="#cb650-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb650-3"><a href="#cb650-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb650-4"><a href="#cb650-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb650-5"><a href="#cb650-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb650-6"><a href="#cb650-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb650-7"><a href="#cb650-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb650-8"><a href="#cb650-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl</span>
<span id="cb650-9"><a href="#cb650-9" aria-hidden="true" tabindex="-1"></a>   )</span></code></pre></div>
<p><code>caret</code> construye un árbol completo usando los parámetros predeterminados de <code>rpart</code> que son: índice de división de Gini, al menos 20 observaciones en un nodo para considerar dividirlo, y al menos 6 observaciones en cada nodo. Luego, <code>caret</code> calcula la precisión para cada valor candidato del hiperparámetro (CP). Estos son los resultados:</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="#cb651-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2</span></code></pre></div>
<pre><code>CART 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  cp           ROC        Sens       Spec     
  0.005988024  0.8539885  0.8605225  0.7274510
  0.008982036  0.8502309  0.8568578  0.7334225
  0.013473054  0.8459290  0.8473149  0.7397504
  0.032934132  0.7776483  0.8509071  0.6796791
  0.479041916  0.5878764  0.9201379  0.2556150

ROC was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.005988024.</code></pre>
<p>El segundo CP (0.008982036) produce la mayor precisión. Podemos profundizar en el mejor valor de CP usando un <em>tuning grid</em>.</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="#cb653-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb653-2"><a href="#cb653-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb653-3"><a href="#cb653-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb653-4"><a href="#cb653-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb653-5"><a href="#cb653-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb653-6"><a href="#cb653-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.001</span>, <span class="at">to =</span> <span class="fl">0.010</span>, <span class="at">length =</span> <span class="dv">11</span>)),  </span>
<span id="cb653-7"><a href="#cb653-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb653-8"><a href="#cb653-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl</span>
<span id="cb653-9"><a href="#cb653-9" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb653-10"><a href="#cb653-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(oj_mdl_cart2)</span></code></pre></div>
<pre><code>CART 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  cp      ROC        Sens       Spec     
  0.0010  0.8513056  0.8529390  0.7182709
  0.0019  0.8528471  0.8529753  0.7213012
  0.0028  0.8524435  0.8510522  0.7302139
  0.0037  0.8533529  0.8510522  0.7421569
  0.0046  0.8540042  0.8491292  0.7333333
  0.0055  0.8543820  0.8567126  0.7334225
  0.0064  0.8539885  0.8605225  0.7274510
  0.0073  0.8521076  0.8625181  0.7335116
  0.0082  0.8521076  0.8625181  0.7335116
  0.0091  0.8502309  0.8568578  0.7334225
  0.0100  0.8507262  0.8510885  0.7424242

ROC was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.0055.</code></pre>
<p>El mejor modelo se consigue con CP = 0.0082. A continuación podemos ver las precisiones de validación cruzada para los valores de CP candidatos.</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="#cb655-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_mdl_cart2)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-277-1.png" width="672" /></p>
<p>Estos son los resultados para el modelo final:</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="#cb656-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

  1) root 857 334 CH (0.61026838 0.38973162)  
    2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
      4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
      5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
       10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894) *
       11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
    3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
      6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
       12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972)  
         24) LoyalCH&lt; 0.303104 7   0 CH (1.00000000 0.00000000) *
         25) LoyalCH&gt;=0.303104 64  31 CH (0.51562500 0.48437500)  
           50) WeekofPurchase&gt;=246.5 52  22 CH (0.57692308 0.42307692)  
            100) PriceCH&lt; 1.94 35  11 CH (0.68571429 0.31428571) *
            101) PriceCH&gt;=1.94 17   6 MM (0.35294118 0.64705882) *
           51) WeekofPurchase&lt; 246.5 12   3 MM (0.25000000 0.75000000) *
       13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000)  
         26) SpecialCH&gt;=0.5 14   6 CH (0.57142857 0.42857143) *
         27) SpecialCH&lt; 0.5 61  10 MM (0.16393443 0.83606557) *
      7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322) *</code></pre>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb658-1"><a href="#cb658-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart2<span class="sc">$</span>finalModel)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-279-1.png" width="672" /></p>
<p>Veamos el rendimiento en la muestra test:</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="#cb659-1" aria-hidden="true" tabindex="-1"></a>pred3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart2, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>) </span>
<span id="cb659-2"><a href="#cb659-2" aria-hidden="true" tabindex="-1"></a>oj_cm_cart2 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred3,  oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb659-3"><a href="#cb659-3" aria-hidden="true" tabindex="-1"></a>oj_cm_cart2</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 117  18
        MM  13  65
                                          
               Accuracy : 0.8545          
                 95% CI : (0.7998, 0.8989)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 4.83e-15        
                                          
                  Kappa : 0.6907          
                                          
 Mcnemar&#39;s Test P-Value : 0.4725          
                                          
            Sensitivity : 0.9000          
            Specificity : 0.7831          
         Pos Pred Value : 0.8667          
         Neg Pred Value : 0.8333          
             Prevalence : 0.6103          
         Detection Rate : 0.5493          
   Detection Prevalence : 0.6338          
      Balanced Accuracy : 0.8416          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>La precisión es 0.8545, un poco peor que la 0.8592 del método directo. El AUC es 0.916 que es mejor que el obtenido con el método directo.</p>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="#cb661-1" aria-hidden="true" tabindex="-1"></a>pred4 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart2, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>] </span>
<span id="cb661-2"><a href="#cb661-2" aria-hidden="true" tabindex="-1"></a>roc.car2 <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred4, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb661-3"><a href="#cb661-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb661-4"><a href="#cb661-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-281-1.png" width="672" /></p>
<p>Podemos comparar ambas curvas ROC mediante el <a href="https://www.jstor.org/stable/pdf/2531595.pdf?seq=1">test de DeLong</a></p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="#cb662-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc.test</span>(roc.car, roc.car2)</span></code></pre></div>
<pre><code>
    DeLong&#39;s test for two correlated ROC curves

data:  roc.car and roc.car2
Z = -2.4259, p-value = 0.01527
alternative hypothesis: true difference in AUC is not equal to 0
95 percent confidence interval:
 -0.056801412 -0.006034547
sample estimates:
AUC of roc1 AUC of roc2 
  0.8848471   0.9162651 </code></pre>
<p>Finalmente, podemos crear fácilmente la gráfica de importancia de variables con la función <code>varImp ()</code>. La lealtad a la marca es lo más importante, seguida de la diferencia de precio.</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="#cb664-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(oj_mdl_cart2), <span class="at">main=</span><span class="st">&quot;Importancia de variables con CART (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-283-1.png" width="672" /></p>
<p>Parece que con la estrategia de <code>caret</code> hemos conseguido un mejor modelo predictivo gracias, sobre todo, a la posibilidad de buscar el mejor hiperparámetro haciend <em>fine tuning</em>.</p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="#cb665-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb665-2"><a href="#cb665-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree&quot;</span>, </span>
<span id="cb665-3"><a href="#cb665-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_cart<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb665-4"><a href="#cb665-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.car<span class="sc">$</span>auc),</span>
<span id="cb665-5"><a href="#cb665-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree (caret)&quot;</span>, </span>
<span id="cb665-6"><a href="#cb665-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_cart2<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb665-7"><a href="#cb665-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.car2<span class="sc">$</span>auc)) <span class="sc">%&gt;%</span> </span>
<span id="cb665-8"><a href="#cb665-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb665-9"><a href="#cb665-9" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="árboles-de-regresión" class="section level2 hasAnchor" number="14.3">
<h2 class="hasAnchor"><span class="header-section-number">14.3</span> Árboles de regresión<a href="#árboles-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un árbol de regresión simple se construye de manera similar a un árbol de clasificación simple y, al igual que el árbol de clasificación, rara vez se usan por sí solo (sobre todo en problemas complejos o de big data). De nuevo, basaremos el aprendizaje de esta metodología partiendo de un ejemplo real. Usaremos el conjunto de datos <code>ISLR::Carseats</code> que pretende predecir las ventas de sillitas de niños para coches (variable <code>Sales</code>) en 400 tiendas usando 10 variables que contienen información de las características de las sillas.</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="#cb666-1" aria-hidden="true" tabindex="-1"></a>cs_dat <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>Carseats</span>
<span id="cb666-2"><a href="#cb666-2" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(cs_dat)</span></code></pre></div>
<table>
<caption>(#tab:unnamed-chunk-285)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">cs_dat</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">400</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="10%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ShelveLoc</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">Med: 219, Bad: 96, Goo: 85</td>
</tr>
<tr class="even">
<td align="left">Urban</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 282, No: 118</td>
</tr>
<tr class="odd">
<td align="left">US</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 258, No: 142</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="15%" />
<col width="7%" />
<col width="7%" />
<col width="3%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sales</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.50</td>
<td align="right">2.82</td>
<td align="right">0</td>
<td align="right">5.39</td>
<td align="right">7.49</td>
<td align="right">9.32</td>
<td align="right">16.27</td>
<td align="left">▁▆▇▃▁</td>
</tr>
<tr class="even">
<td align="left">CompPrice</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">124.97</td>
<td align="right">15.33</td>
<td align="right">77</td>
<td align="right">115.00</td>
<td align="right">125.00</td>
<td align="right">135.00</td>
<td align="right">175.00</td>
<td align="left">▁▅▇▃▁</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">68.66</td>
<td align="right">27.99</td>
<td align="right">21</td>
<td align="right">42.75</td>
<td align="right">69.00</td>
<td align="right">91.00</td>
<td align="right">120.00</td>
<td align="left">▇▆▇▆▅</td>
</tr>
<tr class="even">
<td align="left">Advertising</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.64</td>
<td align="right">6.65</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">5.00</td>
<td align="right">12.00</td>
<td align="right">29.00</td>
<td align="left">▇▃▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">Population</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">264.84</td>
<td align="right">147.38</td>
<td align="right">10</td>
<td align="right">139.00</td>
<td align="right">272.00</td>
<td align="right">398.50</td>
<td align="right">509.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Price</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">115.80</td>
<td align="right">23.68</td>
<td align="right">24</td>
<td align="right">100.00</td>
<td align="right">117.00</td>
<td align="right">131.00</td>
<td align="right">191.00</td>
<td align="left">▁▂▇▆▁</td>
</tr>
<tr class="odd">
<td align="left">Age</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">53.32</td>
<td align="right">16.20</td>
<td align="right">25</td>
<td align="right">39.75</td>
<td align="right">54.50</td>
<td align="right">66.00</td>
<td align="right">80.00</td>
<td align="left">▇▆▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Education</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">13.90</td>
<td align="right">2.62</td>
<td align="right">10</td>
<td align="right">12.00</td>
<td align="right">14.00</td>
<td align="right">16.00</td>
<td align="right">18.00</td>
<td align="left">▇▇▃▇▇</td>
</tr>
</tbody>
</table>
<p>De nuevo, partiremos nuestro conjunto de datos <code>cs_dat</code> (n = 400) en <code>cs_train</code> (80%, n = 321) y <code>cs_test</code> (20%, n = 79).</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="#cb667-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb667-2"><a href="#cb667-2" aria-hidden="true" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> cs_dat<span class="sc">$</span>Sales, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb667-3"><a href="#cb667-3" aria-hidden="true" tabindex="-1"></a>cs_train <span class="ot">&lt;-</span> cs_dat[partition, ]</span>
<span id="cb667-4"><a href="#cb667-4" aria-hidden="true" tabindex="-1"></a>cs_test <span class="ot">&lt;-</span> cs_dat[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>El primer paso es construir un árbol completo y luego realizar una validación cruzada para ayudar a seleccionar la complejidad de costo óptima (cp). La única diferencia ahora es que usaremos <code>method = "anova"</code> en la función <code>rpart ()</code> para poder estimar un árbol de regresión.</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="#cb668-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb668-2"><a href="#cb668-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales <span class="sc">~</span> ., cs_train, <span class="at">method =</span> <span class="st">&quot;anova&quot;</span>)</span>
<span id="cb668-3"><a href="#cb668-3" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full</span></code></pre></div>
<pre><code>n= 321 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 321 2567.76800  7.535950  
   2) ShelveLoc=Bad,Medium 251 1474.14100  6.770359  
     4) Price&gt;=105.5 168  719.70630  5.987024  
       8) ShelveLoc=Bad 50  165.70160  4.693600  
        16) Population&lt; 201.5 20   48.35505  3.646500 *
        17) Population&gt;=201.5 30   80.79922  5.391667 *
       9) ShelveLoc=Medium 118  434.91370  6.535085  
        18) Advertising&lt; 11.5 88  290.05490  6.113068  
          36) CompPrice&lt; 142 69  193.86340  5.769420  
            72) Price&gt;=132.5 16   50.75440  4.455000 *
            73) Price&lt; 132.5 53  107.12060  6.166226 *
          37) CompPrice&gt;=142 19   58.45118  7.361053 *
        19) Advertising&gt;=11.5 30   83.21323  7.773000 *
     5) Price&lt; 105.5 83  442.68920  8.355904  
      10) Age&gt;=63.5 32  153.42300  6.922500  
        20) Price&gt;=85 25   66.89398  6.160800  
          40) ShelveLoc=Bad 9   18.39396  4.772222 *
          41) ShelveLoc=Medium 16   21.38544  6.941875 *
        21) Price&lt; 85 7   20.22194  9.642857 *
      11) Age&lt; 63.5 51  182.26350  9.255294  
        22) Income&lt; 57.5 12   28.03042  7.707500 *
        23) Income&gt;=57.5 39  116.63950  9.731538  
          46) Age&gt;=50.5 14   21.32597  8.451429 *
          47) Age&lt; 50.5 25   59.52474 10.448400 *
   3) ShelveLoc=Good 70  418.98290 10.281140  
     6) Price&gt;=107.5 49  242.58730  9.441633  
      12) Advertising&lt; 13.5 41  162.47820  8.926098  
        24) Age&gt;=61 17   53.37051  7.757647 *
        25) Age&lt; 61 24   69.45776  9.753750 *
      13) Advertising&gt;=13.5 8   13.36599 12.083750 *
     7) Price&lt; 107.5 21   61.28200 12.240000 *</code></pre>
<p>Las ventas pronosticadas en la raíz son las ventas medias para el conjunto de datos de entrenamiento, 7.5 (los valores corresponden a miles de dolares). La primera división está en <code>ShelveLoc = [Bad, Medium]</code> vs <code>Good</code> (calidad). Aquí está el diagrama de árbol sin podar.</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="#cb670-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart_full, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-288-1.png" width="672" /></p>
<p>Cada caja muestra el valor predicho del nodo (media) y la proporción de observaciones que están en el nodo (o nodos secundarios).</p>
<p><code>rpart ()</code> estima el árbol completo y utiliza validación cruzada para probar el rendimiento de los posibles hiperparámetros de complejidad. Como antes, <code>printcp ()</code> muestra los valores de cp candidatos que pueden verse en esta tabla. Estos datos pueden ser utilizados para decidir cómo podar el árbol.</p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="#cb671-1" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(cs_mdl_cart_full)</span></code></pre></div>
<pre><code>
Regression tree:
rpart(formula = Sales ~ ., data = cs_train, method = &quot;anova&quot;)

Variables actually used in tree construction:
[1] Advertising Age         CompPrice   Income      Population  Price       ShelveLoc  

Root node error: 2567.8/321 = 7.9993

n= 321 

         CP nsplit rel error  xerror     xstd
1  0.262736      0   1.00000 1.00635 0.076664
2  0.121407      1   0.73726 0.74888 0.058981
3  0.046379      2   0.61586 0.65278 0.050839
4  0.044830      3   0.56948 0.67245 0.051638
5  0.041671      4   0.52465 0.66230 0.051065
6  0.025993      5   0.48298 0.62345 0.049368
7  0.025823      6   0.45698 0.61980 0.048026
8  0.024007      7   0.43116 0.62058 0.048213
9  0.015441      8   0.40715 0.58061 0.041738
10 0.014698      9   0.39171 0.56413 0.041368
11 0.014641     10   0.37701 0.56277 0.041271
12 0.014233     11   0.36237 0.56081 0.041097
13 0.014015     12   0.34814 0.55647 0.038308
14 0.013938     13   0.33413 0.55647 0.038308
15 0.010560     14   0.32019 0.57110 0.038872
16 0.010000     15   0.30963 0.56676 0.038090</code></pre>
<p>Hay 16 posibles valores de cp en este modelo. El modelo con el parámetro de complejidad más pequeño permite la mayoría de las divisiones (nsplit). El parámetro de mayor complejidad corresponde a un árbol con solo un nodo raíz. <code>rel error</code> es el SSE relativo al nodo raíz. El SSE del nodo raíz es 2567.76800, por lo que su error rel es 2567.76800 / 2567.76800 = 1.0. Eso significa que el error absoluto del árbol completo (en CP = 0.01) es 0.30963 * 2567.76800 = 795.058. Podemos verificar estos resultados calculando el SSE de los valores predichos del modelo:</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="#cb673-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">pred =</span> <span class="fu">predict</span>(cs_mdl_cart_full, <span class="at">newdata =</span> cs_train)) <span class="sc">%&gt;%</span></span>
<span id="cb673-2"><a href="#cb673-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">obs =</span> cs_train<span class="sc">$</span>Sales,</span>
<span id="cb673-3"><a href="#cb673-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">sq_err =</span> (obs <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb673-4"><a href="#cb673-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarise</span>(<span class="at">sse =</span> <span class="fu">sum</span>(sq_err))</span></code></pre></div>
<pre><code>       sse
1 795.0525</code></pre>
<p>La tabla también muestra, <code>xerror</code> que corresponde al SSE con validación cruzada y <code>xstd</code> a su error estándar. Si deseamos el error más bajo posible, podaremos el árbol con el SSE relativo más pequeño (<code>xerror</code>). Si deseamos equilibrar el poder predictivo con la simplicidad, podaremos al árbol más pequeño que esté dentro de 1 SE para el SSE relativo más pequeño. Al igual que en la sección anterior, la tabla CP no es muy útil para encontrar ese árbol, por lo que debemos añadir una columna para visualizar dicha información:</p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="#cb675-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full<span class="sc">$</span>cptable <span class="sc">%&gt;%</span></span>
<span id="cb675-2"><a href="#cb675-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb675-3"><a href="#cb675-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">min_xerror_idx =</span> <span class="fu">which.min</span>(cs_mdl_cart_full<span class="sc">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]),</span>
<span id="cb675-4"><a href="#cb675-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">rownum =</span> <span class="fu">row_number</span>(),</span>
<span id="cb675-5"><a href="#cb675-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">xerror_cap =</span> cs_mdl_cart_full<span class="sc">$</span>cptable[min_xerror_idx, <span class="st">&quot;xerror&quot;</span>] <span class="sc">+</span> </span>
<span id="cb675-6"><a href="#cb675-6" aria-hidden="true" tabindex="-1"></a>             cs_mdl_cart_full<span class="sc">$</span>cptable[min_xerror_idx, <span class="st">&quot;xstd&quot;</span>],</span>
<span id="cb675-7"><a href="#cb675-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">eval =</span> <span class="fu">case_when</span>(rownum <span class="sc">==</span> min_xerror_idx <span class="sc">~</span> <span class="st">&quot;min xerror&quot;</span>,</span>
<span id="cb675-8"><a href="#cb675-8" aria-hidden="true" tabindex="-1"></a>                           xerror <span class="sc">&lt;</span> xerror_cap <span class="sc">~</span> <span class="st">&quot;under cap&quot;</span>,</span>
<span id="cb675-9"><a href="#cb675-9" aria-hidden="true" tabindex="-1"></a>                           <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb675-10"><a href="#cb675-10" aria-hidden="true" tabindex="-1"></a>   dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>rownum, <span class="sc">-</span>min_xerror_idx) </span></code></pre></div>
<pre><code>           CP nsplit rel.error    xerror       xstd xerror_cap       eval
1  0.26273578      0 1.0000000 1.0063530 0.07666355  0.5947744           
2  0.12140705      1 0.7372642 0.7488767 0.05898146  0.5947744           
3  0.04637919      2 0.6158572 0.6527823 0.05083938  0.5947744           
4  0.04483023      3 0.5694780 0.6724529 0.05163819  0.5947744           
5  0.04167149      4 0.5246478 0.6623028 0.05106530  0.5947744           
6  0.02599265      5 0.4829763 0.6234457 0.04936799  0.5947744           
7  0.02582284      6 0.4569836 0.6198034 0.04802643  0.5947744           
8  0.02400748      7 0.4311608 0.6205756 0.04821332  0.5947744           
9  0.01544139      8 0.4071533 0.5806072 0.04173785  0.5947744  under cap
10 0.01469771      9 0.3917119 0.5641331 0.04136793  0.5947744  under cap
11 0.01464055     10 0.3770142 0.5627713 0.04127139  0.5947744  under cap
12 0.01423309     11 0.3623736 0.5608073 0.04109662  0.5947744  under cap
13 0.01401541     12 0.3481405 0.5564663 0.03830810  0.5947744 min xerror
14 0.01393771     13 0.3341251 0.5564663 0.03830810  0.5947744  under cap
15 0.01055959     14 0.3201874 0.5710951 0.03887227  0.5947744  under cap
16 0.01000000     15 0.3096278 0.5667561 0.03808991  0.5947744  under cap</code></pre>
<p>Bien, entonces el árbol más simple es el que tiene CP = 0.02599265 (5 divisiones). También podemos usar <code>plotcp () para visualizar la relación entre</code>xerror<code>y</code>cp`.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="#cb677-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(cs_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-292-1.png" width="672" /></p>
<p>La línea discontinua se establece en el mínimo <code>xerror + xstd</code>. El eje superior muestra el número de divisiones en el árbol. El error relativo más pequeño está en CP = 0.01 (15 divisiones), pero el CP máximo debajo de la línea discontinua (una desviación estándar por encima del error mínimo) está en CP = 0.02599265 (5 divisiones). Utilizamos entonces la función <code>prune ()</code> para podar el árbol especificando el coste-complejidad asociado a este CP.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="#cb678-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart <span class="ot">&lt;-</span> <span class="fu">prune</span>(</span>
<span id="cb678-2"><a href="#cb678-2" aria-hidden="true" tabindex="-1"></a>   cs_mdl_cart_full,</span>
<span id="cb678-3"><a href="#cb678-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> cs_mdl_cart_full<span class="sc">$</span>cptable[cs_mdl_cart_full<span class="sc">$</span>cptable[, <span class="dv">2</span>] <span class="sc">==</span> <span class="dv">5</span>, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb678-4"><a href="#cb678-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb678-5"><a href="#cb678-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-293-1.png" width="672" /></p>
<p>El indicador más “importante” de ventas es <code>ShelveLoc</code>. Estos son los valores de importancia del modelo:</p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="#cb679-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart<span class="sc">$</span>variable.importance <span class="sc">%&gt;%</span> </span>
<span id="cb679-2"><a href="#cb679-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb679-3"><a href="#cb679-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;Feature&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb679-4"><a href="#cb679-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rename</span>(<span class="at">Overall =</span> <span class="st">&#39;.&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb679-5"><a href="#cb679-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">fct_reorder</span>(Feature, Overall), <span class="at">y =</span> Overall)) <span class="sc">+</span></span>
<span id="cb679-6"><a href="#cb679-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> Overall), <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>, <span class="at">size =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb679-7"><a href="#cb679-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb679-8"><a href="#cb679-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb679-9"><a href="#cb679-9" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Variable Importance with Simple Regression&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-294-1.png" width="672" /></p>
<p>El indicador más importante de ventas es <code>ShelveLoc</code>, luego <code>Price</code>, luego <code>Age</code> (edad media de la población donde está la tienda). Todas estas variables aparecen en el modelo final. <code>CompPrice</code> (precio del competidor) también es relevante.</p>
<p>El último paso es hacer predicciones sobre el conjunto de datos de validación. Cuando la variable respuesta es continua usamos:</p>
<ul>
<li><p>la raíz del error cuadrático medio <span class="math inline">\(RMSE = \sqrt{(1/2) \sum{(actual - pred)^2}})\)</span> y</p></li>
<li><p>el errr absoluto medio <span class="math inline">\(MAE = (1/n) \sum{|actual - pred|}\)</span></p></li>
</ul>
<p>La diferencia entre ambos es que RMSE penaliza más los errores grandes. Para un árbol de regresión, basta con indicar <code>type="vector")  en la función</code>predict ()` (que es el valor por defecto).</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="#cb680-1" aria-hidden="true" tabindex="-1"></a>cs_preds_cart <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs_mdl_cart, cs_test, <span class="at">type =</span> <span class="st">&quot;vector&quot;</span>)</span>
<span id="cb680-2"><a href="#cb680-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb680-3"><a href="#cb680-3" aria-hidden="true" tabindex="-1"></a>cs_rmse_cart <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(</span>
<span id="cb680-4"><a href="#cb680-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">pred =</span> cs_preds_cart,</span>
<span id="cb680-5"><a href="#cb680-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">obs =</span> cs_test<span class="sc">$</span>Sales</span>
<span id="cb680-6"><a href="#cb680-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb680-7"><a href="#cb680-7" aria-hidden="true" tabindex="-1"></a>cs_rmse_cart</span></code></pre></div>
<pre><code>[1] 2.363202</code></pre>
<p>El proceso de poda conduce a un error de predicción promedio de 2.363 en el conjunto de datos de prueba. No está mal considerando que la desviación estándar de la variable <code>Sales</code> es 2.8. Podemos visualizar la relación entre los datos predichos y los observados mediante:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="#cb682-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">Predichos =</span> cs_preds_cart, <span class="at">Observados =</span> cs_test<span class="sc">$</span>Sales) <span class="sc">%&gt;%</span></span>
<span id="cb682-2"><a href="#cb682-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Observados, <span class="at">y =</span> Predichos)) <span class="sc">+</span></span>
<span id="cb682-3"><a href="#cb682-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb682-4"><a href="#cb682-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>() <span class="sc">+</span></span>
<span id="cb682-5"><a href="#cb682-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb682-6"><a href="#cb682-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats CART, predichos vs observados&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-296-1.png" width="672" /></p>
<div id="entrenamiento-con-caret-1" class="section level3 hasAnchor" number="14.3.1">
<h3 class="hasAnchor"><span class="header-section-number">14.3.1</span> Entrenamiento con <code>caret</code><a href="#entrenamiento-con-caret-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También podemos ajustar el modelo con <code>caret::train ()</code> especificando <code>method = "rpart"</code>. Construirmos el modelo usando 10-fold CV para optimizar el hiperparámetro CP.</p>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="#cb683-1" aria-hidden="true" tabindex="-1"></a>cs_trControl <span class="ot">=</span> <span class="fu">trainControl</span>(</span>
<span id="cb683-2"><a href="#cb683-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb683-3"><a href="#cb683-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb683-4"><a href="#cb683-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span> </span>
<span id="cb683-5"><a href="#cb683-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Usaremos la misma estrategia que en el caso de los árboles de clasificación,
dejaremos que el modelo busque el mejor parámetro de ajuste de CP con <code>tuneLength</code> y luego lo ajustaremos con <code>tuneGrid</code>.</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="#cb684-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb684-2"><a href="#cb684-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2 <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb684-3"><a href="#cb684-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb684-4"><a href="#cb684-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb684-5"><a href="#cb684-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb684-6"><a href="#cb684-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb684-7"><a href="#cb684-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb684-8"><a href="#cb684-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb684-9"><a href="#cb684-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="#cb685-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2</span></code></pre></div>
<pre><code>CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results across tuning parameters:

  cp          RMSE      Rsquared   MAE     
  0.04167149  2.209383  0.4065251  1.778797
  0.04483023  2.243618  0.3849728  1.805027
  0.04637919  2.275563  0.3684309  1.808814
  0.12140705  2.400455  0.2942663  1.936927
  0.26273578  2.692867  0.1898998  2.192774

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.04167149.</code></pre>
<p>El primer cp (0.04167149) presenta el RMSE más pequeño. Puedemos hacer una búsqueda más fina para mejorar el valor de cp usando un <em>grid</em>:</p>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="#cb687-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb687-2"><a href="#cb687-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2 <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb687-3"><a href="#cb687-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb687-4"><a href="#cb687-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb687-5"><a href="#cb687-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb687-6"><a href="#cb687-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fl">0.1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)),</span>
<span id="cb687-7"><a href="#cb687-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb687-8"><a href="#cb687-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb687-9"><a href="#cb687-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb687-10"><a href="#cb687-10" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2</span></code></pre></div>
<pre><code>CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results across tuning parameters:

  cp    RMSE      Rsquared   MAE     
  0.00  2.055676  0.5027431  1.695453
  0.01  2.135096  0.4642577  1.745937
  0.02  2.095767  0.4733269  1.699235
  0.03  2.131246  0.4534544  1.690453
  0.04  2.146886  0.4411380  1.712705
  0.05  2.284937  0.3614130  1.837782
  0.06  2.265498  0.3709523  1.808319
  0.07  2.282630  0.3597216  1.836227
  0.08  2.282630  0.3597216  1.836227
  0.09  2.282630  0.3597216  1.836227
  0.10  2.282630  0.3597216  1.836227

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.</code></pre>
<p>En este ejemplo, parece que el árbol con mejor rendimiento es el que no ha sido podado.</p>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="#cb689-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cs_mdl_cart2)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-301-1.png" width="672" /></p>
<p>Este sería el modelo final</p>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="#cb690-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart2<span class="sc">$</span>finalModel)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-302-1.png" width="672" /></p>
<p>y estas las variables más importantes</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="#cb691-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(cs_mdl_cart2), <span class="at">main=</span><span class="st">&quot;Importancia de variables para Regresión&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-303-1.png" width="672" /></p>
<p>Como siempre, debemos evaluar el modelo en nuestra muestra test:</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="#cb692-1" aria-hidden="true" tabindex="-1"></a>cs_preds_cart2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs_mdl_cart2, cs_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb692-2"><a href="#cb692-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">Actual =</span> cs_test<span class="sc">$</span>Sales, <span class="at">Predicted =</span> cs_preds_cart2) <span class="sc">%&gt;%</span></span>
<span id="cb692-3"><a href="#cb692-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Actual, <span class="at">y =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb692-4"><a href="#cb692-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb692-5"><a href="#cb692-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y ~ x&quot;</span>) <span class="sc">+</span></span>
<span id="cb692-6"><a href="#cb692-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb692-7"><a href="#cb692-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats CART, Predicted vs Actual (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-304-1.png" width="672" /></p>
<p>Observamos como el modelo sobreestima en el extremo inferior y subestima en el extremo superior. Podemos calcular el RMSE para estos datos:</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="#cb693-1" aria-hidden="true" tabindex="-1"></a>(cs_rmse_cart2 <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(<span class="at">pred =</span> cs_preds_cart2, <span class="at">obs =</span> cs_test<span class="sc">$</span>Sales))</span></code></pre></div>
<pre><code>[1] 2.298331</code></pre>
<p>Caret mejora las predicciones:</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="#cb695-1" aria-hidden="true" tabindex="-1"></a>cs_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb695-2"><a href="#cb695-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree&quot;</span>, <span class="at">RMSE =</span> cs_rmse_cart),</span>
<span id="cb695-3"><a href="#cb695-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree (caret)&quot;</span>, <span class="at">RMSE =</span> cs_rmse_cart2)</span>
<span id="cb695-4"><a href="#cb695-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(RMSE)</span>
<span id="cb695-5"><a href="#cb695-5" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(cs_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">2.298331</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">2.363202</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bagged-trees" class="section level2 hasAnchor" number="14.4">
<h2 class="hasAnchor"><span class="header-section-number">14.4</span> Bagged trees<a href="#bagged-trees" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los CART tiene una capacidad predictiva moderada, es por ello que se han propuesto unos métodos que combinan varios árboles de decisión para producir un mejor rendimiento predictivo que utilizar un solo árbol de decisión. El principio fundamental detrás de estos modelos es que un grupo de predictores débiles puede conseguir un predictor con mejor capacidad predictiva.</p>
<p>Tenemos dos tipos de estrategias:</p>
<ul>
<li><em>Bagging</em></li>
<li><em>Boosting</em></li>
</ul>
<blockquote>
<p>Bagging (Bootstrap Aggregation) se utiliza cuando nuestro objetivo es reducir la varianza de un árbol de decisión. La idea es crear varios subconjuntos de datos a partir de la muestra de entrenamiento elegida al azar con reemplazamiento. Cada subconjunto de datos se utiliza para entrenar un árbol de decisión. Como resultado, terminamos con un conjunto de diferentes modelos. Se utiliza el promedio de todas las predicciones de diferentes árboles, que es más robusto que considerar un solo árbol de decisión.</p>
</blockquote>
<div class="figure">
<img src="figures/bagged_tree.png" alt="" />
<p class="caption">Bagged trees</p>
</div>
<blockquote>
<p>En el Boosting se aprende de forma secuencial. Ajustamos árboles consecutivos (muestra aleatoria) y en cada paso, el objetivo es mejorar el error del árbol anterior.</p>
</blockquote>
<div class="figure">
<img src="figures/boosting.png" style="width:70.0%" alt="" />
<p class="caption">Boosted trees</p>
</div>
<p>Como hemos dicho anteriormente, el algoritmo <em>bagged</em> construye B árboles decisión usando conjuntos de entrenamiento obtenidos mediante remuestreo y promedia las predicciones resultantes. Estos árboles crecen profundamente y no se podan. Por tanto, cada árbol individual tiene una alta varianza, pero un bajo sesgo. Promediar los B árboles ayuda a reducir la varianza. El valor predicho para una observación es la moda (clasificación) o la media (regresión) de los árboles. B generalmente es igual a ~ 25.</p>
<div class="figure">
<img src="figures/bagged_tree_process.png" alt="" />
<p class="caption">Proceso para Bagged trees</p>
</div>
<p>Para un conjunto de entrenamiento de tamaño <span class="math inline">\(n\)</span>, cada árbol se compone de <span class="math inline">\(\sim (1 - e^{-1})n = .632n\)</span> observaciones únicas <em>in-bag</em> y <span class="math inline">\(.368n\)</span> <em>out-of-bag</em>. Las observaciones que no han sido seleccionadas en el re-muestreo se usan para evaluar la precisión del modelo. La capacidad glogal del método se obtiene promediando la capacidad de cada árbol. Esto tiene una <strong>desventaja obvia</strong> y es que si cada árbol tiene un rendimiento deficiente, el rendimiento promedio de muchos árboles seguirá siendo deficiente. Además, otra desventaja de este método es que no existe un árbol único con un conjunto de reglas para interpretar. En consecuencia, no queda claro qué variables son más importantes que otras y en algunos problemas (sobre todo biomédicos) esto puede ser una limitación importante.</p>
<div id="bagging-árboles-de-clasificación" class="section level3 hasAnchor" number="14.4.1">
<h3 class="hasAnchor"><span class="header-section-number">14.4.1</span> Bagging árboles de clasificación<a href="#bagging-árboles-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Veamos de nuevo con un ejemplo cómo trabajar con estos métodos. Usaremos de nuevo los datos de zumos de naranja <code>OJ</code>. Esta vez usaremos un método <em>bagging</em> especificando <code>method="treebag"</code>. Caret no tiene hiperparámetros para este modelo, por lo que no es necesario usar <code>tuneLegth</code> ni <code>tuneGrid</code>. El tamaño de conjunto predeterminado es <code>nbagg = 25</code> (a veces se puede tunear, pero en este caso lo dejaremos fijo).</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="#cb696-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb696-2"><a href="#cb696-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_bag <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb696-3"><a href="#cb696-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb696-4"><a href="#cb696-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb696-5"><a href="#cb696-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb696-6"><a href="#cb696-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl,</span>
<span id="cb696-7"><a href="#cb696-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span></span>
<span id="cb696-8"><a href="#cb696-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb696-9"><a href="#cb696-9" aria-hidden="true" tabindex="-1"></a>oj_mdl_bag<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>
Bagging classification trees with 25 bootstrap replications </code></pre>
<p>Veamos el rendimiento en el conjunto de datos test.</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="#cb698-1" aria-hidden="true" tabindex="-1"></a>pred_bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_bag, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb698-2"><a href="#cb698-2" aria-hidden="true" tabindex="-1"></a>oj_cm_bag <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_bag, oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb698-3"><a href="#cb698-3" aria-hidden="true" tabindex="-1"></a>oj_cm_bag</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 113  16
        MM  17  67
                                          
               Accuracy : 0.8451          
                 95% CI : (0.7894, 0.8909)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 6.311e-14       
                                          
                  Kappa : 0.675           
                                          
 Mcnemar&#39;s Test P-Value : 1               
                                          
            Sensitivity : 0.8692          
            Specificity : 0.8072          
         Pos Pred Value : 0.8760          
         Neg Pred Value : 0.7976          
             Prevalence : 0.6103          
         Detection Rate : 0.5305          
   Detection Prevalence : 0.6056          
      Balanced Accuracy : 0.8382          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>La precisión es 0.8451, sorprendentemente peor que el 0.85915 del modelo de árbol único, pero esa es una diferencia que corresponde a tres predicciones en un conjunto de 213. Esta sería la curva ROC.</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="#cb700-1" aria-hidden="true" tabindex="-1"></a>pred_bag2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_bag, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb700-2"><a href="#cb700-2" aria-hidden="true" tabindex="-1"></a>roc.bag <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred_bag2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb700-3"><a href="#cb700-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb700-4"><a href="#cb700-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-309-1.png" width="672" /></p>
<p>Veamos cuáles son las variables más importantes</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="#cb701-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(oj_mdl_bag), <span class="at">main=</span><span class="st">&quot;Importancia de variables con Bagging&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-310-1.png" width="672" /></p>
<p>Esta es la comparación entre métodos</p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="#cb702-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(oj_scoreboard,</span>
<span id="cb702-2"><a href="#cb702-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Bagging&quot;</span>, </span>
<span id="cb702-3"><a href="#cb702-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_bag<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb702-4"><a href="#cb702-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.bag<span class="sc">$</span>auc)</span>
<span id="cb702-5"><a href="#cb702-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb702-6"><a href="#cb702-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Bagging</td>
<td align="right">0.8450704</td>
<td align="right">0.9099166</td>
</tr>
<tr class="odd">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
</div>
<div id="bagging-árboles-de-regresión" class="section level3 hasAnchor" number="14.4.2">
<h3 class="hasAnchor"><span class="header-section-number">14.4.2</span> Bagging árboles de regresión<a href="#bagging-árboles-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Usemos <em>bagging</em> para predecir las ventas en los datos <code>Carseats</code>:</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="#cb703-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb703-2"><a href="#cb703-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_bag <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb703-3"><a href="#cb703-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb703-4"><a href="#cb703-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb703-5"><a href="#cb703-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb703-6"><a href="#cb703-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb703-7"><a href="#cb703-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb703-8"><a href="#cb703-8" aria-hidden="true" tabindex="-1"></a>cs_mdl_bag</span></code></pre></div>
<pre><code>Bagged CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results:

  RMSE      Rsquared  MAE     
  1.681889  0.675239  1.343427</code></pre>
<p>Veamos el rendimiento en el conjunto de datos test. El RMSE es 1.9185, pero el modelo predice en exceso en el extremo inferior de ventas y tampoco predice bien en el extremo superior (como un árbol simple).</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="#cb705-1" aria-hidden="true" tabindex="-1"></a>cs_preds_bag <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb705-2"><a href="#cb705-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">Predicted =</span> <span class="fu">predict</span>(cs_mdl_bag, <span class="at">newdata =</span> cs_test),</span>
<span id="cb705-3"><a href="#cb705-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">Actual =</span> cs_test<span class="sc">$</span>Sales</span>
<span id="cb705-4"><a href="#cb705-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb705-5"><a href="#cb705-5" aria-hidden="true" tabindex="-1"></a>(cs_rmse_bag <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(<span class="at">pred =</span> cs_preds_bag<span class="sc">$</span>Predicted, <span class="at">obs =</span> cs_preds_bag<span class="sc">$</span>Actual))</span></code></pre></div>
<pre><code>[1] 1.918473</code></pre>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="#cb707-1" aria-hidden="true" tabindex="-1"></a>cs_preds_bag <span class="sc">%&gt;%</span></span>
<span id="cb707-2"><a href="#cb707-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Actual, <span class="at">y =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb707-3"><a href="#cb707-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb707-4"><a href="#cb707-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y ~ x&quot;</span>) <span class="sc">+</span></span>
<span id="cb707-5"><a href="#cb707-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb707-6"><a href="#cb707-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats Bagging, Predicted vs Actual (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-314-1.png" width="672" /></p>
<p>La importancia de las variables son:</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="#cb708-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(cs_mdl_bag), <span class="at">main=</span><span class="st">&quot;Importancia de variables con Bagging&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-315-1.png" width="672" /></p>
<p>Y la comparación quedaría</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="#cb709-1" aria-hidden="true" tabindex="-1"></a>cs_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(cs_scoreboard,</span>
<span id="cb709-2"><a href="#cb709-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Bagging&quot;</span>, <span class="at">RMSE =</span> cs_rmse_bag)</span>
<span id="cb709-3"><a href="#cb709-3" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(RMSE)</span>
<span id="cb709-4"><a href="#cb709-4" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(cs_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Bagging</td>
<td align="right">1.918473</td>
</tr>
<tr class="even">
<td align="left">Single Tree (caret)</td>
<td align="right">2.298331</td>
</tr>
<tr class="odd">
<td align="left">Single Tree</td>
<td align="right">2.363202</td>
</tr>
</tbody>
</table>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-Bagged):</td>
</tr>
<tr class="even">
<td align="left">Implementa una función que implemente el método “bagged tree”. Aplícalo a los datos “Carseats” y compara tus resultados con los que se obtienen usando caret.</td>
</tr>
</tbody>
</table>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P-Bagged Breast cancer):</td>
</tr>
<tr class="even">
<td align="left">Utiliza los datos de cáncer de mama que hemos trabajado en clase “breast_train_prep” y “breast_test_prep” (que puedes encontrar en el fichero “breast.Rdata” del Moodle) para crear un modelo predictivo usando CART y Bagged Trees. Compara los resultados con los obtenidos mediant KNN y LDA reportados en el bookdown del curso.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="random-forest" class="section level2 hasAnchor" number="14.5">
<h2 class="hasAnchor"><span class="header-section-number">14.5</span> Random Forest<a href="#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los <em>Random Forest</em> (bosques aleatorios) también son un conjunto de árboles de decisión (<em>ensambladores</em>) que mejoran los <em>bagged trees</em> mediante la creación de un bosque no correlacionados de árboles que, de nuevo, mejora la capacidad predictiva de un único árbol. Al igual que en el <em>bagged</em> (<em>embolsado</em>), el algoritmo construye varios árboles de decisión sobre muestras de entrenamiento bootstrap. Sin embargo, al construir estos árboles de decisión, cada vez que se considera una división en un árbol, se elige una muestra aleatoria de predictores (hiperparámetro <em>m</em> o <em>mtry</em>) como candidatos de división del conjunto completo de predictores <span class="math inline">\(p\)</span>. En cada división se toma una nueva muestra de predictores. Típicamente <span class="math inline">\(m \approx \sqrt{p}\)</span>. En consecuencia, los árboles <em>bagged</em> son un caso especial de los <em>random forest</em> cuando <span class="math inline">\(m = p\)</span>.</p>
<p>Cada árbol del modelo <em>random forest</em> se construye de la siguiente forma:</p>
<ul>
<li><p>Si denotamos por <span class="math inline">\(N\)</span> el número de casos en el conjunto de entrenamiento, seleccionaremos una muestra de esos <span class="math inline">\(N\)</span> casos se forma aleatoria CON REEMPLAZAMIENTO. Esta muestra será el conjunto de entrenamiento para construir el árbol i-ésimo.</p></li>
<li><p>Si denotamos por <span class="math inline">\(M\)</span> el número total de varibles predictoras, seleccionaremos un número <span class="math inline">\(m &lt; M\)</span> de variables y crearemos un árbol completo con esas variables. El valor <span class="math inline">\(m\)</span> se mantiene constante durante la generación de todo el bosque.</p></li>
<li><p>Cada árbol crece hasta su máxima extensión posible y NO hay proceso de poda.</p></li>
<li><p>La predicción para nuevos individuos se hace a partir de la información obtenida de las predicciones de los <span class="math inline">\(B\)</span> árboles (mayoría de votos para clasificación, promedio para regresión). La siguiente figura ilustra este proceso</p></li>
</ul>
<div class="figure">
<img src="figures/random_forest.png" alt="" />
<p class="caption">Random Forest</p>
</div>
<p>Podemos estimar un <em>random forest</em> con <code>cart</code> indicando el argumento <code>method = "rf"</code>. El hiperparámetro <code>mtry</code> (<span class="math inline">\(m\)</span>) puede tomar cualquier valor de 1 a 17 (el número de predictores) y se espera que el valor óptimo esté cerca de <span class="math inline">\(\sqrt{17} \approx 4\)</span>. En cuanto al número de árboles (segundo hiperparámetro), hay estudios que demuestran que el rendimiento empeora cuando tenemos muchos árboles, sin embargo esto no está muy claro y por lo general se recomienda entrenar modelos con muchos árboles. Por defecto <code>method = "rf"</code> tiene 500 (argumento <code>num.trees</code>).</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="#cb710-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb710-2"><a href="#cb710-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb710-3"><a href="#cb710-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb710-4"><a href="#cb710-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb710-5"><a href="#cb710-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb710-6"><a href="#cb710-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb710-7"><a href="#cb710-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">3</span><span class="sc">:</span><span class="dv">10</span>),</span>
<span id="cb710-8"><a href="#cb710-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl,</span>
<span id="cb710-9"><a href="#cb710-9" aria-hidden="true" tabindex="-1"></a>   <span class="at">num.trees =</span> <span class="dv">500</span></span>
<span id="cb710-10"><a href="#cb710-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb710-11"><a href="#cb710-11" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf</span></code></pre></div>
<pre><code>Random Forest 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  mtry  ROC        Sens       Spec     
   3    0.8655672  0.8565312  0.7185383
   4    0.8685845  0.8641872  0.7122995
   5    0.8682630  0.8470247  0.7183601
   6    0.8672458  0.8412917  0.7124777
   7    0.8695796  0.8412917  0.7183601
   8    0.8668721  0.8393687  0.7213012
   9    0.8652269  0.8432148  0.7153298
  10    0.8671443  0.8413280  0.7152406

ROC was used to select the optimal model using the largest value.
The final value used for the model was mtry = 7.</code></pre>
<p>El valor de ROC más alto se da en <span class="math inline">\(m = 7\)</span> que es más alto de lo que esperábamos, pero fijémosnos que es un valor de ROC muy similar al que se obtiene con <span class="math inline">\(m=4\)</span>, por lo que por el principio de parsimonia podríamos usar dicho valor</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="#cb712-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_mdl_rf)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-318-1.png" width="672" /></p>
<p>También podemos visualizar los resultados con:</p>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="#cb713-1" aria-hidden="true" tabindex="-1"></a>plot_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(model) {</span>
<span id="cb713-2"><a href="#cb713-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb713-3"><a href="#cb713-3" aria-hidden="true" tabindex="-1"></a>    u <span class="ot">&lt;-</span> model<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb713-4"><a href="#cb713-4" aria-hidden="true" tabindex="-1"></a>        dplyr<span class="sc">::</span><span class="fu">select</span>(mtry, ROC, Sens, Spec) <span class="sc">%&gt;%</span></span>
<span id="cb713-5"><a href="#cb713-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">gather</span>(a, b, <span class="sc">-</span>mtry)</span>
<span id="cb713-6"><a href="#cb713-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb713-7"><a href="#cb713-7" aria-hidden="true" tabindex="-1"></a>    u <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(mtry, b)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb713-8"><a href="#cb713-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">facet_wrap</span>(<span class="sc">~</span> a, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span> </span>
<span id="cb713-9"><a href="#cb713-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Número de predictores&quot;</span>, <span class="at">y =</span> <span class="cn">NULL</span>, </span>
<span id="cb713-10"><a href="#cb713-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">title =</span> <span class="st">&quot;Relación entre el número de predictores y el comportamiento del modelo&quot;</span>)</span>
<span id="cb713-11"><a href="#cb713-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb713-12"><a href="#cb713-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb713-13"><a href="#cb713-13" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf <span class="sc">%&gt;%</span> <span class="fu">plot_rf</span>()</span></code></pre></div>
<p><img src="fig/unnamed-chunk-319-1.png" width="672" /></p>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-Plot RF):</td>
</tr>
<tr class="even">
<td align="left">Si en el modelo <code>train</code> usamos <code>metric = "prSummary"</code> también podemos visualizar otras métricas para evaluar el comportamiento del modelo. En particular el AUC que puede ser interesante desde un punto de vista práctico. Crea una función que visualice dichas métricas y aplícalo a los datos <code>oj_train</code> (que obviamente tendrás que re-entrenar con esa nueva métrica).</td>
</tr>
</tbody>
</table>
<p>Podemos usar este modelo para hacer predicciones sobre la muestra test</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="#cb714-1" aria-hidden="true" tabindex="-1"></a>pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_rf, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb714-2"><a href="#cb714-2" aria-hidden="true" tabindex="-1"></a>oj_cm_rf <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_rf, oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb714-3"><a href="#cb714-3" aria-hidden="true" tabindex="-1"></a>oj_cm_rf</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 112  16
        MM  18  67
                                          
               Accuracy : 0.8404          
                 95% CI : (0.7841, 0.8869)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 2.164e-13       
                                          
                  Kappa : 0.6659          
                                          
 Mcnemar&#39;s Test P-Value : 0.8638          
                                          
            Sensitivity : 0.8615          
            Specificity : 0.8072          
         Pos Pred Value : 0.8750          
         Neg Pred Value : 0.7882          
             Prevalence : 0.6103          
         Detection Rate : 0.5258          
   Detection Prevalence : 0.6009          
      Balanced Accuracy : 0.8344          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>Y el área bajo la curva ROC sería:</p>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb716-1"><a href="#cb716-1" aria-hidden="true" tabindex="-1"></a>pred_rf2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_rf, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb716-2"><a href="#cb716-2" aria-hidden="true" tabindex="-1"></a>roc.rf <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred_bag2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb716-3"><a href="#cb716-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb716-4"><a href="#cb716-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-321-1.png" width="672" /></p>
<p>que compara con los modelos anteriores de esta forma:</p>
<p>Y la comparación quedaría</p>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="#cb717-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(oj_scoreboard,</span>
<span id="cb717-2"><a href="#cb717-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Random Forest&quot;</span>, </span>
<span id="cb717-3"><a href="#cb717-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_rf<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb717-4"><a href="#cb717-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.rf<span class="sc">$</span>auc)</span>
<span id="cb717-5"><a href="#cb717-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb717-6"><a href="#cb717-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Bagging</td>
<td align="right">0.8450704</td>
<td align="right">0.9099166</td>
</tr>
<tr class="odd">
<td align="left">Random Forest</td>
<td align="right">0.8403756</td>
<td align="right">0.9099166</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
<p>Recordemos que la importancia de las variables se puede ver con la función <code>varImp</code> al igual que cualquier otro modelo basado en àrboles de decisión.</p>
<p><strong>NOTA:</strong> El ejemplo para Random Forest con árboles de regresión es igual que lo que vimos en la sección anterior.</p>
<p><strong>NOTA2:</strong> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7508310/">En este artículo</a> se hace un “benchmarking” muy interesante para saber qué método y libería de R usar en función de las características de nuestro conjunto de datos.</p>
<p>Speiser JL et al. (2012). <strong>A Comparison of Random Forest Variable Selection Methods for Classification Prediction Modeling</strong></p>
<blockquote>
<p>Random forest classification is a popular machine learning method for developing prediction models in many research settings. Often in prediction modeling, a goal is to reduce the number of variables needed to obtain a prediction in order to reduce the burden of data collection and improve efficiency. Several variable selection methods exist for the setting of random forest classification; however, there is a paucity of literature to guide users as to which method may be preferable for different types of datasets. Using 311 classification datasets freely available online, we evaluate the prediction error rates, number of variables, computation times and area under the receiver operating curve for many random forest variable selection methods. We compare random forest variable selection methods for different types of datasets (datasets with binary outcomes, datasets with many predictors, and datasets with imbalanced outcomes) and for different types of methods (standard random forest versus conditional random forest methods and test based versus performance based methods). Based on our study, the best variable selection methods for most datasets are Jiang’s method and the method implemented in the VSURF R package. For datasets with many predictors, the methods implemented in the R packages varSelRF and Boruta are preferable due to computational efficiency. A significant contribution of this study is the ability to assess different variable selection techniques in the setting of random forest classification in order to identify preferable methods based on applications in expert and intelligent systems.</p>
</blockquote>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P-RF Breast cancer):</td>
</tr>
<tr class="even">
<td align="left">Utiliza los datos de cáncer de mama que hemos trabajado en clase “breast_train_prep” y “breast_test_prep” (que puedes encontrar en el fichero “breast.Rdata” del Moodle) para crear un modelo predictivo usando Random Forest. Compara los resultados con los obtenidos mediante KNN y LDA reportados en el bookdown del curso (y di si mejora los que obtuviste con CART y Bagged Trees).</td>
</tr>
</tbody>
</table>
</div>
<div id="random-forest-pn" class="section level2 hasAnchor" number="14.6">
<h2 class="hasAnchor"><span class="header-section-number">14.6</span> Random Forest p&gt;&gt;n<a href="#random-forest-pn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Problema</strong>: Aplicar Random Forest para conjunto de datos con muchas variables (caso p&gt;&gt;n)</p>
<ul>
<li><strong>Posible estrategia</strong>:</li>
</ul>
<ol style="list-style-type: decimal">
<li>Creamos K subconjuntos de variable</li>
<li>Llevamos a cabo una selección de las variables más importantes y nos quedamos con una parte de ellas. Por ejemplo, las M más informativas</li>
<li>Combinamos las K*M variables y repetimos los pasos 1 y 2</li>
<li>Acabamos con M variables seleccionadas</li>
<li>Aplicamos Random Forest</li>
</ol>
<p>Este enfoque podría causar la pérdida de algunas variables importantes, pero generalmente seleccionará las variables más informativas.</p>
<p>Selección de K y M
<a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">Breiman (2001)</a> recomienda <span class="math inline">\(m=p/3\)</span> en clasificación y <span class="math inline">\(m=\sqrt{p}\)</span> en regresión (mtry). ¿Puede servir esto de ayuda?</p>
<ul>
<li><p><a href="https://cran.r-project.org/web/packages/RRF/RRF.pdf">Reguralized Random Forest</a></p></li>
<li><p><a href="thttps://www.sciencedirect.com/science/article/abs/pii/S0031320313002422">Guided Regularized Random Forest</a></p></li>
<li><p><strong>Otra opción</strong>: Librería <a href="https://www.jstatsoft.org/article/view/v077i01">ranger</a></p></li>
</ul>
<!--chapter:end:12-cart.Rmd-->
</div>
</div>
<div id="boosting" class="section level1 hasAnchor" number="15">
<h1 class="hasAnchor"><span class="header-section-number">15</span> Boosting<a href="#boosting" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Esta sección describe un método alternativo llamado <strong>boosting</strong>, que es similar al método <strong>bagging</strong>, excepto que los árboles se crean (a veces se dice que <em>crecen</em> o se <em>cultivan</em>) secuencialmente. Cada árbol sucesivo se crea utilizando información de árboles creados previamente, con el objetivo de minimizar el error de los modelos anteriores (<a href="https://link.springer.com/book/10.1007/978-1-4614-7138-7">James et al., 2014</a>).</p>
<p>Por ejemplo, dado un modelo de árbol de regresión actual, el procedimiento es el siguiente:</p>
<ol style="list-style-type: decimal">
<li>Ajustamos un árbol de decisión utilizando los errores residuales del modelo como variable de resultado.</li>
<li>Agregamos este nuevo árbol de decisión, ajustado por un parámetro de “contracción” (shrinkage) <code>lambda</code>, en la función ajustada para actualizar los residuales. <code>lambda</code> es un pequeño valor positivo, normalmente comprendido entre 0.01 y 0.001 y tiene como objetivo controlar el sobreajuste.</li>
</ol>
<p>.
Este enfoque da como resultado una mejora lenta y sucesiva del modelo ajustado, lo que resulta en un modelo de muy alto rendimiento. El <strong>boosting</strong> tiene diferentes parámetros de ajuste:</p>
<ul>
<li>El número de árboles M</li>
<li>El parámetro de “contracción” <code>lambda</code></li>
<li>El número de divisiones en cada árbol (pruning).</li>
</ul>
<p>Existen diferentes variantes de <strong>boosting</strong> como el <strong>Adaboost</strong> (clasificación binaria), <strong>Gradient Boosting</strong> y <strong>Stochastic Gradient Boosting</strong>. Este último, implementado en la liberería de R <code>xgboost</code>, es el método más usado comunmente, que implica hacer un remuestreo de observaciones y variables en cada iteración. Es la téncnica que ha demostrado tener un mejor rendimiento.</p>
<p>La idea del <em>boosting</em>, extraída de <a href="https://explained.ai/gradient-boosting/L2-loss.html">aquí</a>, podría verse como un golfista que inicialmente golpea una pelota de golf hacia el hoyo que se encuentra en la posición <span class="math inline">\(y\)</span>, pero que solo llega hasta <span class="math inline">\(f_0\)</span>. Luego, el golfista golpea la pelota repetidamente de forma más suave, moviéndola hacia el hoyo poco a poco y después de reevaluar la dirección y la distancia al hoyo en cada golpeo. El siguiente diagrama ilustra 5 golpes que llegan al hoyo, <span class="math inline">\(y\)</span>, incluidos dos golpes que sobrepasan el hoyo. (Clipart de golfista de <a href="http://etc.usf.edu/clipart/" class="uri">http://etc.usf.edu/clipart/</a>)</p>
<div class="figure">
<img src="figures/golf.png" alt="" />
<p class="caption">Ejemplo del golfista para el boosting</p>
</div>
<p>De forma matemática podríamos decir que una <em>máquina de aumento de gradiente</em> (GBM) es un algoritmo de modelado aditivo que construye gradualmente un modelo compuesto agregando iterativamente <span class="math inline">\(M\)</span> submodelos débiles basados en el rendimiento compuesto de las iteraciones anteriores:</p>
<p><span class="math display">\[F_M(x) = \sum_m^M f_m(x).\]</span></p>
<p>Como hemos dicho anteriromente, la idea es ajustar un modelo de predicción débil (no demasiada buena capacidad predictiva), luego reemplazar los valores de respuesta con los residuos de ese modelo y ajustar otro modelo. Agregar el modelo de predicción residual al modelo de predicción de respuesta original produce un modelo más preciso. GBM repite este proceso una y otra vez, ejecutando nuevos modelos para predecir los residuos de los modelos compuestos anteriores y agregando los resultados para producir nuevos modelos más complejos. Con cada iteración, el modelo se vuelve cada vez más fuerte (mejor predictor). Los árboles sucesivos suelen ponderarse para reducir la velocidad de aprendizaje. La “contracción” reduce la influencia de cada árbol de forma individual y deja margen para que los árboles futuros mejoren el modelo.</p>
<p><span class="math display">\[F_M(x) = f_0 + \eta\sum_{m = 1}^M f_m(x).\]</span></p>
<p>Cuanto menor sea la tasa de aprendizaje, <span class="math inline">\(\eta\)</span>, mayor será el número de árboles necesario, <span class="math inline">\(M\)</span>. <span class="math inline">\(\eta\)</span> y <span class="math inline">\(M\)</span> son hiperparámetros. También podríamos usar otras restricciones a los árboles que se usarían como hiperparámetros adicionales como la profundidad del árbol, el número de nodos, las observaciones mínimas por división y la mejora mínima de la pérdida.</p>
<p>El nombre “gradient boosting” se refiere al uso de una metodología <em>boosting</em> con “gradiente”. Cada iteración de entrenamiento crea un modelo predictor débil y usa los residuos para calcular un gradiente que no es más que la derivada parcial de una función de pérdida. El GBM “desciende el gradiente” para ajustar los parámetros del modelo y reducir el error en la siguiente iteración de entrenamiento.</p>
<p>En el caso de problemas de clasificación, la función de pérdida es el <a href="https://www.kaggle.com/dansbecker/what-is-log-loss">log-loss</a>; para problemas de regresión, la función de pérdida es el error cuadrático medio. GBM continúa hasta que alcanza el número máximo de árboles o un nivel de error aceptable.</p>
<p>Veamos cómo funciona esta metodología con el ejemplo del golfista. La expresión anterior, se puede poner de forma recurrente como</p>
<p><span class="math display">\[
\begin{align*}
&amp; F_0(x) = f_0(x) \\
&amp; F_m(x) = F_{m-1}(x) + \Delta_m(x)
\end{align*}
\]</span></p>
<p>Después del golpe inicial, el golfista determina el “golpe óptimo” calculando la diferencia entre <span class="math inline">\(y\)</span> y la primera aproximación, <span class="math inline">\(y-f_0(x)\)</span>. Esta diferencia generalmente se llama vector residual o residual, pero es útil para aumentar el gradiente pensar en esto como el vector que apunta desde la predicción actual, a la verdadera <span class="math inline">\(y\)</span>. Usar el vector residual para nuestro siguiente golpe, significa entrenar <span class="math inline">\(\Delta_m(x)\)</span> en el valor <span class="math inline">\(y - F_{m-1}(x)\)</span> en el modelo anterior (que es más débil). Al igual que con cualquier modelo de aprendizaje automático, nuestros modelos no tendrán un <em>recall</em> y <em>precision</em> perfectas, por lo que debemos esperar dar una predicción con variabilidad (ruido) en lugar obtener exactamente <span class="math inline">\(y - F_{m-1}(x)\)</span>.</p>
<p>Asumamos como ejemplo que el hoyo está a <span class="math inline">\(y=100\)</span> metros y que <span class="math inline">\(f_0(x)=70\)</span>. En la siguiente tabla podríamos ver una secuencia del algorirmo GBM en función de la imprecisión de los golpes $_{m}(x) del golfista:</p>
<div class="figure">
<img src="figures/example_gbm.png" alt="" />
<p class="caption">Ejemplo numérico GBM</p>
</div>
<p>La implementación de GBM también admitiría una tasa de aprendizaje, <span class="math inline">\(\eta\)</span> que acelera o ralentiza la aproximación a <span class="math inline">\(y\)</span>, lo que ayuda a reducir la probabilidad de sobreajuste.</p>
<div id="cómo-funciona-el-boosting" class="section level2 hasAnchor" number="15.1">
<h2 class="hasAnchor"><span class="header-section-number">15.1</span> Cómo funciona el <em>boosting</em><a href="#cómo-funciona-el-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En resumen la idea principal del <em>boosting</em> es agregar nuevos modelos al conjunto de modelos de forma secuencial. En esencia, el <em>boosting</em> trata de controlar la relación sesgo-varianza comenzando con un modelo débil (por ejemplo, un árbol de decisión con solo unas pocas divisiones) y secuencialmente aumenta su rendimiento al continuar construyendo nuevos árboles, donde cada nuevo árbol en la secuencia intenta arreglar aquellas predicciones dónde el anterior árbol cometió los mayores errores (es decir, cada nuevo árbol en la secuencia se enfocará en las filas de entrenamiento donde el árbol anterior tuvo los mayores errores de predicción). La siguiente figura representa un esquema de esta metodología</p>
<div class="figure">
<img src="figures/boosted-trees-process.png" alt="" />
<p class="caption">Aproximación secuencial de ensamblaje</p>
</div>
</div>
<div id="adaboost" class="section level2 hasAnchor" number="15.2">
<h2 class="hasAnchor"><span class="header-section-number">15.2</span> AdaBoost<a href="#adaboost" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El algoritmo AdaBoost (<a href="https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf">Adaptative Boosting</a>) supuso un avance muy importante en el campo del aprendizaje estadístico, ya que hizo posible aplicar la estrategia de boosting a multitud de problemas. Para el funcionamiento de AdaBoost (problema de clasificación binaria) es necesario establecer:</p>
<ul>
<li><p>Un “predictor débil” (weak learner o base learner), que sea capaz de predecir la variable respuesta con un porcentaje de acierto ligeramente superior a lo esperado por azar. En el caso de los árboles de regresión, este weak learner suele ser un árbol con apenas unos pocos nodos, pero también se puede usar regresión logística.</p></li>
<li><p>Codificar las dos clases de la variable respuesta como +1 y -1.</p></li>
<li><p>Dar un peso inicial e igual para todas las observaciones que forman el conjunto de datos de entrenamiento.</p></li>
</ul>
<p>Una vez que estos tres puntos se han establecido, se inicia un proceso iterativo. En la primera iteración, se ajusta el “predictor base” usando los datos de entrenamiento y los pesos iniciales (todos iguales). Con el “predictor base” ajustado y guardado, se predicen las observaciones de entrenamiento y se identifican aquellas bien y mal clasificadas. Con esta información:</p>
<ul>
<li><p>Se actualizan los pesos de las observaciones, disminuyendo el de las que están bien clasificadas y aumentando el de las mal clasificadas.</p></li>
<li><p>Se asigna un peso total al “predictor base”, proporcional al total de aciertos. Cuantos más aciertos consiga el “predictor base”, mayor será su influencia en el conjunto del predictores ensamblados.</p></li>
</ul>
<p>En la siguiente iteración, se llama de nuevo al “predictor base” y se vuelve a ajustar, esta vez, empleando los pesos actualizados en la iteración anterior. El nuevo “predictor base” se guarda, obteniendo así un nuevo modelo para el ensemblado de predictores débiles. Este proceso se repite <span class="math inline">\(M\)</span> veces, generando un total de <span class="math inline">\(M\)</span> “predictores base”. Para clasificar nuevas observaciones, se obtiene la predicción de cada uno de los “predictores base” que forman el ensemblado y se agregan sus resultados, ponderando el peso de cada uno acorde al peso que se le ha asignado en el ajuste. El objetivo detrás de esta estrategia es que cada nuevo “predictor base” se centra en predecir correctamente las observaciones que los anteriores no han sido capaces.</p>
<p>El pseudocódigo de este algoritmo sería:</p>
<ul>
<li><span class="math inline">\(N\)</span>: número de observaciones en la muestra de entrenamiento</li>
<li><span class="math inline">\(M\)</span>: número de iteraciones (número total de “predictores base”)</li>
<li><span class="math inline">\(G_m\)</span>: “predictor base” en la iteración <span class="math inline">\(m\)</span></li>
<li><span class="math inline">\(w_i\)</span>: peso de la observación <span class="math inline">\(i\)</span>-ésima</li>
<li><span class="math inline">\(\alpha_m\)</span>: peso del “predictor base” <span class="math inline">\(m\)</span>-ésimo</li>
</ul>
<ol style="list-style-type: decimal">
<li>Inicializamos los peso de las observaciones como:</li>
</ol>
<p><span class="math display">\[w_i=\frac{1}{N}, \ \ i=1,2, \cdots, N\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Para <span class="math inline">\(m=1:M\)</span>:</p>
<ul>
<li>Ajustar el “predictor base” <span class="math inline">\(G_m\)</span> usiant las observaciones de entrenamiento y los pesos <span class="math inline">\(w_i\)</span>.</li>
<li>Calcular el error del “predictor base” como:
<span class="math display">\[err_m = \frac{\sum^N_{i=1} w_iI(y_i \neq G_m(x_i))}{\sum^N_{i=1}w_i}\]</span>.</li>
<li>Calcular el peso asignado al “predictor base” <span class="math inline">\(G_m\)</span> como:
<span class="math display">\[\alpha_m = log(\frac{1-err_m}{err_m})\]</span></li>
<li>Actualizar los pesos de las observaciones:
<span class="math display">\[w_i = w_i exp[\alpha_m I(y_i \neq G_m(x_i))], \ \ \ i = 1, 2,..., N\]</span>.</li>
</ul></li>
<li><p>Predecimos las nuevas observaciones mediante el predictor ensamblado que es la agregación de todos los “predictores base” ponderándolos por su peso:
<span class="math display">\[G(x) = sign[\sum^M_{m=1} \alpha_mG_m(x)]\]</span>.</p></li>
</ol>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-AdaBoost):</td>
</tr>
<tr class="even">
<td align="left">Implementa una función para el algoritmo AdaBoost que tenga como “predictor base” la regresión logística. Úsala con el ejemplo de cáncer de mama (breast_train_prep &amp; breast_test_prep) y compara los resultados con los obtenidos mediante LDA que están en este bookdown.</td>
</tr>
</tbody>
</table>
</div>
<div id="gbm-básico" class="section level2 hasAnchor" number="15.3">
<h2 class="hasAnchor"><span class="header-section-number">15.3</span> GBM básico<a href="#gbm-básico" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En 1999, Friedman relacionó AdaBoost con conceptos estadísticos importantes (por ejemplo, funciones de pérdida y modelado aditivo), lo que le permitió generalizar el <em>boosting</em> a problemas de regresión y funciones de pérdida múltiple (<a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">J. H. Friedman 2001 (modified)</a>). Esto llevó al modelo típico de GBM que usamos hoy en día y en el que se basan la mayoría de las implementaciones modernas.</p>
<div id="boostingHiperparam" class="section level3 hasAnchor" number="15.3.1">
<h3 class="hasAnchor"><span class="header-section-number">15.3.1</span> Hiperparámetros<a href="#boostingHiperparam" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un modelo de GBM simple contiene dos categorías de hiperparámetros: hiperparámetros <em>boosting</em> y los hiperparámetros específicos del árbol. Los dos principales tipos de hiperparámetros de <em>boosting</em> incluyen:</p>
<ul>
<li><p><strong>Número de árboles</strong>: el número total de árboles en la secuencia o ensamblaje. El promedio de árboles creados de forma independiente en <em>bagged trees</em> y <em>random forest</em> hace que sea muy difícil sobreajustar con demasiados árboles. Sin embargo, los GBM funcionan de manera diferente ya que cada árbol se crea en secuencia para corregir los errores del árbol anterior. Además, dependiendo de los valores de los otros hiperparámetros, los GBM a menudo requieren muchos árboles (no es raro tener muchos miles de árboles) pero como pueden sobreajustarse fácilmente debemos encontrar el número óptimo de árboles que minimicen la función de pérdida de interés mediante validación cruzada.</p></li>
<li><p><strong>Tasa de aprendizaje</strong>: determina la contribución de cada árbol en el resultado final y controla la rapidez con que el algoritmo avanza por el descenso del gradiente (predictores) (ver la siguiente figura). Los valores oscilan entre 0 y 1 con valores típicos entre 0.001 y 0.3. Los valores más pequeños hacen que el modelo sea robusto a las características específicas de cada árbol individual, lo que le permite generalizar bien. Los valores más pequeños también facilitan la detención antes del sobreajuste; sin embargo, aumentan el riesgo de no alcanzar el óptimo con un número fijo de árboles y son más exigentes desde el punto de vista informático. Este hiperparámetro también se denomina contracción. Generalmente, cuanto menor sea este valor, más preciso puede ser el modelo, pero también requerirá más árboles en el ensamblaje.</p></li>
</ul>
<div class="figure">
<img src="figures/learning-rate.png" alt="" />
<p class="caption">Si la tasa de aprendizaje es muy pequeña, necesitaremos muchas iteraciones para encontrar el mínimo. Una tasa muy grande, nos puede hacer pasar el mínimo</p>
</div>
<p>Los dos hiperparámetros del árbol de aprendizaje en un modelo de GBM simple incluyen:</p>
<ul>
<li><p><strong>Profundidad del árbol</strong>: controla la profundidad de los árboles individuales. Los valores típicos oscilan entre una profundidad de 3 a 8, pero no es raro ver una profundidad de árbol de 1 (<a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">J. Friedman, Hastie y Tibshirani 2001</a>). Los árboles de menor profundidad son computacionalmente eficientes (pero requieren más árboles); sin embargo, los árboles de mayor profundidad permiten que el algoritmo capture interacciones complejas pero también aumentan el riesgo de sobreajuste. Debemos tener en cuenta que valores grandes de <span class="math inline">\(n\)</span> o <span class="math inline">\(p\)</span> en el conjunto de entrenamiento son más tolerantes con árboles profundos.</p></li>
<li><p><strong>Número mínimo de observaciones en nodos terminales</strong>: Además, controla la complejidad de cada árbol. Dado que tendemos a utilizar árboles más cortos, esto rara vez tiene un gran impacto en el rendimiento. Los valores típicos oscilan entre 5 y 15, donde los valores más altos ayudan a evitar que un modelo aprenda relaciones que pueden ser muy específicas para la muestra particular seleccionada para un árbol (sobreajuste) pero los valores más pequeños pueden ayudar con las clases objetivo desequilibradas en los problemas de clasificación.</p></li>
</ul>
</div>
<div id="implementación" class="section level3 hasAnchor" number="15.3.2">
<h3 class="hasAnchor"><span class="header-section-number">15.3.2</span> Implementación<a href="#implementación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hay muchas librería que implementan GBM y variantes de GBM. Podemos encontrar una lista bastante completa en la Vista de tareas de aprendizaje automático de CRAN: <a href="https://cran.r-project.org/web/views/MachineLearning.html" class="uri">https://cran.r-project.org/web/views/MachineLearning.html</a>. Sin embargo, la implementación de R original más popular del algoritmo GBM de Friedman (<a href="https://www.jstor.org/stable/2699986?seq=1">J. H. Friedman 2001</a>; <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167947301000652">Friedman 2002</a>) es el paquete <code>gbm</code>.</p>
<p><code>gbm</code> tiene dos funciones de entrenamiento: <code>gbm::gbm()</code> y <code>gbm::gbm.fit()</code>. La principal diferencia es que <code>gbm::gbm()</code> usa la interfaz de fórmulas para especificar su modelo, mientras que <code>gbm::gbm.fit()</code> requiere las matrices <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> separadas; <code>gbm::gbm.fit()</code> es más eficiente y su uso es recomendado para usuarios avanzados.</p>
<p>La configuración predeterminada en <code>gbm</code> incluye una tasa de aprendizaje (constricción) de 0.001. Esta es una tasa de aprendizaje muy pequeña y normalmente requiere una gran cantidad de árboles para minimizar suficientemente la función de pérdida. Sin embargo, <code>gbm</code> usa un número predeterminado de árboles de 100, que rara vez es suficiente. En consecuencia, comenzamos con una tasa de aprendizaje de 0.1 y aumentamos la cantidad de árboles para entrenar. La profundidad predeterminada de cada árbol (profundidad de interacción) es 1, lo que significa que estamos agrupando un montón de elementos de decisión (es decir, no podemos capturar ningún efecto de interacción).</p>
<p>Para el conjunto de datos de sillitas de coches, aumentamos la profundidad del árbol a 3 y usamos el valor predeterminado para el número mínimo de observaciones requeridas en los nodos terminales de los árboles (n.minobsinnode). Por último, establecemos <code>cv.folds = 10</code> para realizar un CV de 10 veces.</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="#cb718-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb718-2"><a href="#cb718-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb718-3"><a href="#cb718-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb718-4"><a href="#cb718-4" aria-hidden="true" tabindex="-1"></a>md1_gbm <span class="ot">&lt;-</span> <span class="fu">gbm</span>(</span>
<span id="cb718-5"><a href="#cb718-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> Sales <span class="sc">~</span> .,</span>
<span id="cb718-6"><a href="#cb718-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> cs_train,</span>
<span id="cb718-7"><a href="#cb718-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,  <span class="co"># SSE loss function</span></span>
<span id="cb718-8"><a href="#cb718-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.trees =</span> <span class="dv">500</span>,</span>
<span id="cb718-9"><a href="#cb718-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinkage =</span> <span class="fl">0.1</span>,</span>
<span id="cb718-10"><a href="#cb718-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">interaction.depth =</span> <span class="dv">3</span>,</span>
<span id="cb718-11"><a href="#cb718-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.minobsinnode =</span> <span class="dv">10</span>,</span>
<span id="cb718-12"><a href="#cb718-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">cv.folds =</span> <span class="dv">10</span></span>
<span id="cb718-13"><a href="#cb718-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb718-14"><a href="#cb718-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb718-15"><a href="#cb718-15" aria-hidden="true" tabindex="-1"></a><span class="co"># find index for number trees with minimum CV error</span></span>
<span id="cb718-16"><a href="#cb718-16" aria-hidden="true" tabindex="-1"></a>best <span class="ot">&lt;-</span> <span class="fu">which.min</span>(md1_gbm<span class="sc">$</span>cv.error)</span>
<span id="cb718-17"><a href="#cb718-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb718-18"><a href="#cb718-18" aria-hidden="true" tabindex="-1"></a><span class="co"># get MSE and compute RMSE</span></span>
<span id="cb718-19"><a href="#cb718-19" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(md1_gbm<span class="sc">$</span>cv.error[best])</span></code></pre></div>
<pre><code>[1] 1.281917</code></pre>
<p>Nuestros resultados muestra un SSE obtenido mediante validación cruzada de 1.28 que se alcanza con 120 árboles.</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="#cb720-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot error curve</span></span>
<span id="cb720-2"><a href="#cb720-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gbm.perf</span>(md1_gbm, <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-324-1.png" width="672" /></p>
<pre><code>[1] 120</code></pre>
<p>También podemos hacer lo mismo con <code>caret</code></p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="#cb722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb722-2"><a href="#cb722-2" aria-hidden="true" tabindex="-1"></a>garbage <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(</span>
<span id="cb722-3"><a href="#cb722-3" aria-hidden="true" tabindex="-1"></a>cs_mdl_gbm <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb722-4"><a href="#cb722-4" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb722-5"><a href="#cb722-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb722-6"><a href="#cb722-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;gbm&quot;</span>,</span>
<span id="cb722-7"><a href="#cb722-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb722-8"><a href="#cb722-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb722-9"><a href="#cb722-9" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb722-10"><a href="#cb722-10" aria-hidden="true" tabindex="-1"></a>cs_mdl_gbm</span></code></pre></div>
<pre><code>Stochastic Gradient Boosting 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results across tuning parameters:

  interaction.depth  n.trees  RMSE      Rsquared   MAE      
  1                   50      1.842468  0.6718370  1.4969754
  1                  100      1.516967  0.7823612  1.2407807
  1                  150      1.309295  0.8277888  1.0639501
  1                  200      1.216079  0.8429002  0.9866820
  1                  250      1.161540  0.8488463  0.9384418
  2                   50      1.527454  0.7801995  1.2207991
  2                  100      1.240990  0.8381156  1.0063802
  2                  150      1.187603  0.8415216  0.9616681
  2                  200      1.174303  0.8425011  0.9527720
  2                  250      1.172116  0.8403490  0.9500902
  3                   50      1.390969  0.8071393  1.1316570
  3                  100      1.227525  0.8321632  0.9888203
  3                  150      1.201264  0.8345775  0.9694065
  3                  200      1.214462  0.8282833  0.9761625
  3                  250      1.232145  0.8221405  0.9882254
  4                   50      1.341893  0.8128778  1.0949502
  4                  100      1.252282  0.8230712  0.9907410
  4                  150      1.243045  0.8229433  0.9860813
  4                  200      1.258093  0.8162033  0.9947218
  4                  250      1.271058  0.8114156  1.0144873
  5                   50      1.318251  0.8128033  1.0552929
  5                  100      1.250053  0.8226441  0.9958713
  5                  150      1.248402  0.8214824  0.9888330
  5                  200      1.263445  0.8158033  1.0106345
  5                  250      1.273024  0.8124672  1.0213099

Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
Tuning parameter &#39;n.minobsinnode&#39;
 was held constant at a value of 10
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were n.trees = 250, interaction.depth = 1, shrinkage = 0.1
 and n.minobsinnode = 10.</code></pre>
<p>Que no es tan fino y se obtienen diferentes resultados</p>
</div>
<div id="estrategia-general-de-tuning" class="section level3 hasAnchor" number="15.3.3">
<h3 class="hasAnchor"><span class="header-section-number">15.3.3</span> Estrategia general de <em>tuning</em><a href="#estrategia-general-de-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A diferencia de los bosques aleatorios, los GBM pueden tener una alta variabilidad en la precisión dependiendo de la configuración de sus hiperparámetros (<a href="https://www.jmlr.org/papers/volume20/18-444/18-444.pdf">Probst, Bischl y Boulesteix 2019</a>). Por lo tanto, el ajuste puede requerir mucha más estrategia que un modelo de bosque aleatorio. A menudo, un buen enfoque es:</p>
<ol style="list-style-type: decimal">
<li>Elegir una tasa de aprendizaje relativamente alta. Generalmente, el valor predeterminado de 0.1 funciona, pero valores entre 0.05 y 0.2 debería funcionar en una amplia gama de problemas.</li>
<li>Determinar el número óptimo de árboles para esta tasa de aprendizaje.</li>
<li>Corregir los hiperparámetros del árbol y ajuste la tasa de aprendizaje y evaluar la velocidad frente al rendimiento.</li>
<li>Ajustar los parámetros específicos del árbol para determinar la tasa de aprendizaje.</li>
<li>Una vez que se han encontrado los parámetros específicos del árbol, reducir la tasa de aprendizaje para evaluar cualquier mejora en la precisión.</li>
<li>Utilizar la configuración de hiperparámetros finales y aumente los procedimientos de CV para obtener estimaciones más sólidas. A menudo, los pasos anteriores se realizan con un procedimiento de validación simple o un CV de 5 veces debido a restricciones computacionales. Si utilizó k-fold CV en los pasos 1 a 5, este paso no es necesario.</li>
</ol>
<p>Ya hemos hecho los pasos (1) - (2) en el ejemplo anterior con nuestro primer modelo de GBM. A continuación, haremos (3) y evaluaremos el rendimiento de varios valores de tasa de aprendizaje entre 0.005 y 0.3. Nuestros resultados indican que una tasa de aprendizaje de 0.05 minimiza suficientemente nuestra función de pérdida y requiere 260 árboles.</p>
<p>Todos nuestros modelos tardan un poco más de 3 segundos en entrenarse, por lo que no vemos ningún impacto significativo en el tiempo de entrenamiento según la tasa de aprendizaje.</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="#cb724-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create grid search</span></span>
<span id="cb724-2"><a href="#cb724-2" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb724-3"><a href="#cb724-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">learning_rate =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.01</span>, <span class="fl">0.005</span>),</span>
<span id="cb724-4"><a href="#cb724-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">RMSE =</span> <span class="cn">NA</span>,</span>
<span id="cb724-5"><a href="#cb724-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="cn">NA</span>,</span>
<span id="cb724-6"><a href="#cb724-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Time =</span> <span class="cn">NA</span></span>
<span id="cb724-7"><a href="#cb724-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb724-8"><a href="#cb724-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb724-9"><a href="#cb724-9" aria-hidden="true" tabindex="-1"></a><span class="co"># execute grid search</span></span>
<span id="cb724-10"><a href="#cb724-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(hyper_grid))) {</span>
<span id="cb724-11"><a href="#cb724-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb724-12"><a href="#cb724-12" aria-hidden="true" tabindex="-1"></a><span class="co"># fit gbm</span></span>
<span id="cb724-13"><a href="#cb724-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb724-14"><a href="#cb724-14" aria-hidden="true" tabindex="-1"></a>  train_time <span class="ot">&lt;-</span> <span class="fu">system.time</span>({</span>
<span id="cb724-15"><a href="#cb724-15" aria-hidden="true" tabindex="-1"></a>    m <span class="ot">&lt;-</span> <span class="fu">gbm</span>(</span>
<span id="cb724-16"><a href="#cb724-16" aria-hidden="true" tabindex="-1"></a>      Sales <span class="sc">~</span> ., </span>
<span id="cb724-17"><a href="#cb724-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> cs_train, </span>
<span id="cb724-18"><a href="#cb724-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb724-19"><a href="#cb724-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">n.trees =</span> <span class="dv">500</span>, </span>
<span id="cb724-20"><a href="#cb724-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">shrinkage =</span> hyper_grid<span class="sc">$</span>learning_rate[i], </span>
<span id="cb724-21"><a href="#cb724-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">interaction.depth =</span> <span class="dv">3</span>, </span>
<span id="cb724-22"><a href="#cb724-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">n.minobsinnode =</span> <span class="dv">10</span>,</span>
<span id="cb724-23"><a href="#cb724-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">cv.folds =</span> <span class="dv">10</span> </span>
<span id="cb724-24"><a href="#cb724-24" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb724-25"><a href="#cb724-25" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb724-26"><a href="#cb724-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb724-27"><a href="#cb724-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add SSE, trees, and training time to results</span></span>
<span id="cb724-28"><a href="#cb724-28" aria-hidden="true" tabindex="-1"></a>  hyper_grid<span class="sc">$</span>RMSE[i]  <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">min</span>(m<span class="sc">$</span>cv.error))</span>
<span id="cb724-29"><a href="#cb724-29" aria-hidden="true" tabindex="-1"></a>  hyper_grid<span class="sc">$</span>trees[i] <span class="ot">&lt;-</span> <span class="fu">which.min</span>(m<span class="sc">$</span>cv.error)</span>
<span id="cb724-30"><a href="#cb724-30" aria-hidden="true" tabindex="-1"></a>  hyper_grid<span class="sc">$</span>Time[i]  <span class="ot">&lt;-</span> train_time[[<span class="st">&quot;elapsed&quot;</span>]]</span>
<span id="cb724-31"><a href="#cb724-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb724-32"><a href="#cb724-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb724-33"><a href="#cb724-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb724-34"><a href="#cb724-34" aria-hidden="true" tabindex="-1"></a><span class="co"># results</span></span>
<span id="cb724-35"><a href="#cb724-35" aria-hidden="true" tabindex="-1"></a><span class="fu">arrange</span>(hyper_grid, RMSE)</span></code></pre></div>
<pre><code>  learning_rate     RMSE trees Time
1         0.050 1.217178   260 5.81
2         0.100 1.229606    97 5.68
3         0.300 1.324525    49 5.98
4         0.010 1.380635   500 6.38
5         0.005 1.717680   500 6.09</code></pre>
<p>A continuación, estableceremos nuestra tasa de aprendizaje en el nivel óptimo (0.05) y el número de árboles a 260 para ajustar los hiperparámetros específicos del árbol (<code>interaction.depth</code> y <code>n.minobsinnode</code>). El ajuste de los parámetros específicos del árbol nos proporciona una reducción adicional del RMSE si consideramos <code>n.minobsinnode=5</code> (afinamos más en casos raros).</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="#cb726-1" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb726-2"><a href="#cb726-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.trees =</span> <span class="dv">250</span>,</span>
<span id="cb726-3"><a href="#cb726-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinkage =</span> <span class="fl">0.05</span>,</span>
<span id="cb726-4"><a href="#cb726-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">interaction.depth =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>),</span>
<span id="cb726-5"><a href="#cb726-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.minobsinnode =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>)</span>
<span id="cb726-6"><a href="#cb726-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb726-7"><a href="#cb726-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-8"><a href="#cb726-8" aria-hidden="true" tabindex="-1"></a><span class="co"># create model fit function</span></span>
<span id="cb726-9"><a href="#cb726-9" aria-hidden="true" tabindex="-1"></a>model_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n.trees, shrinkage, interaction.depth, n.minobsinnode) {</span>
<span id="cb726-10"><a href="#cb726-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb726-11"><a href="#cb726-11" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">gbm</span>(</span>
<span id="cb726-12"><a href="#cb726-12" aria-hidden="true" tabindex="-1"></a>    Sales <span class="sc">~</span> ., </span>
<span id="cb726-13"><a href="#cb726-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> cs_train, </span>
<span id="cb726-14"><a href="#cb726-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb726-15"><a href="#cb726-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">n.trees =</span> n.trees,</span>
<span id="cb726-16"><a href="#cb726-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">shrinkage =</span> shrinkage,</span>
<span id="cb726-17"><a href="#cb726-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">interaction.depth =</span> interaction.depth,</span>
<span id="cb726-18"><a href="#cb726-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">n.minobsinnode =</span> n.minobsinnode,</span>
<span id="cb726-19"><a href="#cb726-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">cv.folds =</span> <span class="dv">10</span></span>
<span id="cb726-20"><a href="#cb726-20" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb726-21"><a href="#cb726-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute RMSE</span></span>
<span id="cb726-22"><a href="#cb726-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">min</span>(m<span class="sc">$</span>cv.error))</span>
<span id="cb726-23"><a href="#cb726-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb726-24"><a href="#cb726-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-25"><a href="#cb726-25" aria-hidden="true" tabindex="-1"></a><span class="co"># perform search grid with functional programming</span></span>
<span id="cb726-26"><a href="#cb726-26" aria-hidden="true" tabindex="-1"></a>hyper_grid<span class="sc">$</span>rmse <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">pmap_dbl</span>(</span>
<span id="cb726-27"><a href="#cb726-27" aria-hidden="true" tabindex="-1"></a>  hyper_grid,</span>
<span id="cb726-28"><a href="#cb726-28" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span> <span class="fu">model_fit</span>(</span>
<span id="cb726-29"><a href="#cb726-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">n.trees =</span> ..<span class="dv">1</span>,</span>
<span id="cb726-30"><a href="#cb726-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">shrinkage =</span> ..<span class="dv">2</span>,</span>
<span id="cb726-31"><a href="#cb726-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">interaction.depth =</span> ..<span class="dv">3</span>,</span>
<span id="cb726-32"><a href="#cb726-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">n.minobsinnode =</span> ..<span class="dv">4</span></span>
<span id="cb726-33"><a href="#cb726-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb726-34"><a href="#cb726-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb726-35"><a href="#cb726-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-36"><a href="#cb726-36" aria-hidden="true" tabindex="-1"></a><span class="co"># results</span></span>
<span id="cb726-37"><a href="#cb726-37" aria-hidden="true" tabindex="-1"></a><span class="fu">arrange</span>(hyper_grid, rmse)</span></code></pre></div>
<pre><code>  n.trees shrinkage interaction.depth n.minobsinnode     rmse
1     250      0.05                 3              5 1.161167
2     250      0.05                 5              5 1.208882
3     250      0.05                 3             10 1.218783
4     250      0.05                 5             10 1.238141
5     250      0.05                 7              5 1.242564
6     250      0.05                 7             10 1.256821
7     250      0.05                 3             15 1.260654
8     250      0.05                 5             15 1.293758
9     250      0.05                 7             15 1.310991</code></pre>
<p>También podemos ver cómo hacer esto con <code>caret</code> en este <a href="https://topepo.github.io/caret/model-training-and-tuning.html#customizing-the-tuning-process">link</a>.</p>
</div>
</div>
<div id="gbms-estocásticos" class="section level2 hasAnchor" number="15.4">
<h2 class="hasAnchor"><span class="header-section-number">15.4</span> GBMs estocásticos<a href="#gbms-estocásticos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una idea importante propuesda por Breiman (<a href="https://link.springer.com/content/pdf/10.1007/BF00058655.pdf">Breiman (1996a)</a>; <a href="https://link.springer.com/article/10.1023/A:1010933404324">Breiman (2001)</a>) al desarrollar sus algoritmos de <em>bagged</em> y <em>random forest</em> fue que entrenar el algoritmo en una submuestra aleatoria del conjunto de datos de entrenamiento ofreció una reducción adicional en la correlación de árboles y, por lo tanto, una mejora en precisión de predicción. <a href="https://dl.acm.org/doi/10.1016/S0167-9473(01)00065-2">Friedman (2002)</a> utilizó esta misma lógica y actualizó el algoritmo de <em>boosting</em> usando esta idea. Este procedimiento se conoce como <strong>aumento de gradiente estocástico</strong> y, como se ilustra en la siguiente Figura, ayuda a reducir las posibilidades de quedarse atascado en mínimos locales, mesetas y otros terrenos irregulares de la función de pérdida para que podamos encontrar un óptimo casi global.</p>
<div class="figure">
<img src="figures/stochastic-gradient-descent.png" alt="" />
<p class="caption">Si la tasa de aprendizaje es muy pequeña, necesitaremos muchas iteraciones para encontrar el mínimo. Una tasa muy grande, nos puede hacer pasar el mínimo</p>
</div>
<div id="hiperparámetros-estocásticos" class="section level3 hasAnchor" number="15.4.1">
<h3 class="hasAnchor"><span class="header-section-number">15.4.1</span> Hiperparámetros estocásticos<a href="#hiperparámetros-estocásticos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hay algunas variantes de aumento de gradiente estocástico que se pueden utilizar, todas las cuales tienen hiperparámetros adicionales:</p>
<ul>
<li><strong>Muestrear fila antes de crear cada árbol</strong> (disponible en <strong>gbm</strong>, <strong>h2o</strong> y <strong>xgboost</strong>). - <strong>Muestrear columnas antes de crear cada árbol</strong> (<code>h2o</code> y <code>xgboost</code>)</li>
<li><strong>Muestrear columnas antes de considerar cada división en cada árbol</strong> (<code>h2o</code> y <code>xgboost</code>)</li>
</ul>
<p>En general, el muestreo “agresivo” de filas, como la selección de solo el 50% o menos de los datos de entrenamiento, ha demostrado ser beneficioso y los valores típicos oscilan entre 0.5 y 0.8. El muestreo de columnas y el impacto en el rendimiento depende en gran medida de la naturaleza de los datos y de si existe una fuerte multicolinealidad o muchas características ruidosas. Similar a la selección de <code>mtry</code> en el <em>random forest</em>, si hay menos predictores relevantes (más datos ruidosos), los valores más altos de submuestreo de columnas tienden a funcionar mejor porque hace que sea más probable seleccionar aquellas características con la señal más fuerte. Cuando hay muchos predictores relevantes, los valores más bajos de submuestreo de columnas tienden a funcionar bien.</p>
<p>Veamos cómo hacer este proceso con <code>h20</code> (no ejecutado, muy costoso computacionalmente)</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="#cb728-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(h2o)</span>
<span id="cb728-2"><a href="#cb728-2" aria-hidden="true" tabindex="-1"></a><span class="co"># refined hyperparameter grid</span></span>
<span id="cb728-3"><a href="#cb728-3" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb728-4"><a href="#cb728-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_rate =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>),              <span class="co"># row subsampling</span></span>
<span id="cb728-5"><a href="#cb728-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">col_sample_rate =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>),          <span class="co"># col subsampling for each split</span></span>
<span id="cb728-6"><a href="#cb728-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">col_sample_rate_per_tree =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>)  <span class="co"># col subsampling for each tree</span></span>
<span id="cb728-7"><a href="#cb728-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb728-8"><a href="#cb728-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-9"><a href="#cb728-9" aria-hidden="true" tabindex="-1"></a><span class="co"># random grid search strategy</span></span>
<span id="cb728-10"><a href="#cb728-10" aria-hidden="true" tabindex="-1"></a>search_criteria <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb728-11"><a href="#cb728-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">strategy =</span> <span class="st">&quot;RandomDiscrete&quot;</span>,</span>
<span id="cb728-12"><a href="#cb728-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">stopping_metric =</span> <span class="st">&quot;mse&quot;</span>,</span>
<span id="cb728-13"><a href="#cb728-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">stopping_tolerance =</span> <span class="fl">0.001</span>,   </span>
<span id="cb728-14"><a href="#cb728-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">stopping_rounds =</span> <span class="dv">10</span>,         </span>
<span id="cb728-15"><a href="#cb728-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_runtime_secs =</span> <span class="dv">60</span><span class="sc">*</span><span class="dv">60</span>      </span>
<span id="cb728-16"><a href="#cb728-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb728-17"><a href="#cb728-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-18"><a href="#cb728-18" aria-hidden="true" tabindex="-1"></a><span class="co"># active connection to h2o (required)</span></span>
<span id="cb728-19"><a href="#cb728-19" aria-hidden="true" tabindex="-1"></a><span class="fu">h2o.init</span>(<span class="at">max_mem_size =</span> <span class="st">&quot;10g&quot;</span>)</span>
<span id="cb728-20"><a href="#cb728-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-21"><a href="#cb728-21" aria-hidden="true" tabindex="-1"></a><span class="co"># define variables</span></span>
<span id="cb728-22"><a href="#cb728-22" aria-hidden="true" tabindex="-1"></a>train_h2o <span class="ot">&lt;-</span> <span class="fu">as.h2o</span>(cs_train)</span>
<span id="cb728-23"><a href="#cb728-23" aria-hidden="true" tabindex="-1"></a>response <span class="ot">&lt;-</span> <span class="st">&quot;Sales&quot;</span></span>
<span id="cb728-24"><a href="#cb728-24" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">colnames</span>(cs_train), response)</span>
<span id="cb728-25"><a href="#cb728-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-26"><a href="#cb728-26" aria-hidden="true" tabindex="-1"></a><span class="co"># perform grid search </span></span>
<span id="cb728-27"><a href="#cb728-27" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">h2o.grid</span>(</span>
<span id="cb728-28"><a href="#cb728-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">algorithm =</span> <span class="st">&quot;gbm&quot;</span>,</span>
<span id="cb728-29"><a href="#cb728-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid_id =</span> <span class="st">&quot;gbm_grid&quot;</span>,</span>
<span id="cb728-30"><a href="#cb728-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> predictors, </span>
<span id="cb728-31"><a href="#cb728-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> response,</span>
<span id="cb728-32"><a href="#cb728-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">training_frame =</span> train_h2o,</span>
<span id="cb728-33"><a href="#cb728-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">hyper_params =</span> hyper_grid,</span>
<span id="cb728-34"><a href="#cb728-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">ntrees =</span> <span class="dv">500</span>,</span>
<span id="cb728-35"><a href="#cb728-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb728-36"><a href="#cb728-36" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">7</span>,</span>
<span id="cb728-37"><a href="#cb728-37" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_rows =</span> <span class="dv">5</span>,</span>
<span id="cb728-38"><a href="#cb728-38" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfolds =</span> <span class="dv">10</span>,</span>
<span id="cb728-39"><a href="#cb728-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">stopping_rounds =</span> <span class="dv">10</span>,</span>
<span id="cb728-40"><a href="#cb728-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">stopping_tolerance =</span> <span class="dv">0</span>,</span>
<span id="cb728-41"><a href="#cb728-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">search_criteria =</span> search_criteria,</span>
<span id="cb728-42"><a href="#cb728-42" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb728-43"><a href="#cb728-43" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb728-44"><a href="#cb728-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-45"><a href="#cb728-45" aria-hidden="true" tabindex="-1"></a><span class="co"># collect the results and sort by our model performance metric of choice</span></span>
<span id="cb728-46"><a href="#cb728-46" aria-hidden="true" tabindex="-1"></a>grid_perf <span class="ot">&lt;-</span> <span class="fu">h2o.getGrid</span>(</span>
<span id="cb728-47"><a href="#cb728-47" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid_id =</span> <span class="st">&quot;gbm_grid&quot;</span>, </span>
<span id="cb728-48"><a href="#cb728-48" aria-hidden="true" tabindex="-1"></a>  <span class="at">sort_by =</span> <span class="st">&quot;mse&quot;</span>, </span>
<span id="cb728-49"><a href="#cb728-49" aria-hidden="true" tabindex="-1"></a>  <span class="at">decreasing =</span> <span class="cn">FALSE</span></span>
<span id="cb728-50"><a href="#cb728-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb728-51"><a href="#cb728-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-52"><a href="#cb728-52" aria-hidden="true" tabindex="-1"></a>grid_perf</span></code></pre></div>
</div>
</div>
<div id="xgboost" class="section level2 hasAnchor" number="15.5">
<h2 class="hasAnchor"><span class="header-section-number">15.5</span> XGBoost<a href="#xgboost" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Extreme gradient boosting (XGBoost) es una librería optimizada de GBM distribuido (paralelo) que está diseñada para ser eficiente, flexible y portátil en varios idiomas ([Chen y Guestrin 2016] (<a href="https://doi.org/10.1145/2939672.2939785" class="uri">https://doi.org/10.1145/2939672.2939785</a>.)). Aunque XGBoost proporciona las mismas opciones de hiperparámetros basados en el <em>boosting</em> y los métodos que usan árboles ilustrados en las secciones anteriores, también proporciona algunas ventajas sobre el <em>boosting</em> tradicional, como:</p>
<ul>
<li><strong>Regularización</strong>: XGBoost ofrece hiperparámetros de regularización adicionales, que discutiremos a continuación, que añaden protección adicional contra el sobreajuste.</li>
<li><strong>Detención anticipada</strong>: similar a <code>h2o</code>, <code>XGBoost</code> implementa la detención anticipada para que podamos detener la evaluación del modelo cuando los árboles adicionales no ofrecen ninguna mejora.</li>
<li><strong>Procesamiento en paralelo</strong>: dado que el aumento de gradiente es de naturaleza secuencial, es extremadamente difícil de paralelizar. XGBoost ha implementado procedimientos para admitir la compatibilidad de GPU y Spark, lo que le permite ajustar el aumento de gradiente utilizando potentes ordenadores/sistemas de procesamiento distribuido.</li>
<li><strong>Funciones de pérdida</strong>: XGBoost permite a los usuarios definir y optimizar modelos de aumento de gradiente utilizando criterios de evaluación y objetivos personalizados.</li>
<li><strong>Continuar con el modelo existente</strong>: un usuario puede entrenar un modelo XGBoost, guardar los resultados y luego regresar a ese modelo y continuar construyendo sobre los resultados. Ya sea porque se desee revisar los resultados intermedios o haya creado configuraciones de hiperparámetros adicionales para evaluar. XGBoost permite continuar entrenando un modelo sin comenzar desde cero.</li>
<li><strong>Permite tener diferentes “predictores base”</strong> : la mayoría de las implementaciones de GBM se crean con árboles de decisión, pero XGBoost también permite el uso de modelos lineales generalizados.</li>
<li><strong>Múltiples lenguajes</strong>: XGBoost ofrece implementaciones en R, Python, Julia, Scala, Java y C ++.</li>
</ul>
<p>Además de estar implementado en distintos lenguajes, XGboost se puede llevar a cabo de varias formas dentro de R. La implementación principal de R es el paquete <code>xgboost</code>; sin embargo, también se puede usar <code>caret</code> (basta usar <code>method="xgbTree"</code>). Podríamos usar este código:</p>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="#cb729-1" aria-hidden="true" tabindex="-1"></a>tune_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb729-2"><a href="#cb729-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb729-3"><a href="#cb729-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">eta =</span> <span class="fl">0.05</span>,</span>
<span id="cb729-4"><a href="#cb729-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">gamma =</span> <span class="fl">0.01</span>,</span>
<span id="cb729-5"><a href="#cb729-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">colsample_bytree =</span> <span class="fl">0.75</span>,</span>
<span id="cb729-6"><a href="#cb729-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">min_child_weight =</span> <span class="dv">0</span>,</span>
<span id="cb729-7"><a href="#cb729-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">subsample =</span> <span class="fl">0.5</span>)</span>
<span id="cb729-8"><a href="#cb729-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb729-9"><a href="#cb729-9" aria-hidden="true" tabindex="-1"></a>rf_fit <span class="ot">&lt;-</span> <span class="fu">train</span>(Sales <span class="sc">~</span>., </span>
<span id="cb729-10"><a href="#cb729-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> cs_train, </span>
<span id="cb729-11"><a href="#cb729-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">&quot;xgbTree&quot;</span>,</span>
<span id="cb729-12"><a href="#cb729-12" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl=</span>cs_trControl,</span>
<span id="cb729-13"><a href="#cb729-13" aria-hidden="true" tabindex="-1"></a>                <span class="at">tuneGrid =</span> tune_grid,</span>
<span id="cb729-14"><a href="#cb729-14" aria-hidden="true" tabindex="-1"></a>                <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb729-15"><a href="#cb729-15" aria-hidden="true" tabindex="-1"></a>rf_fit</span></code></pre></div>
<pre><code>eXtreme Gradient Boosting 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  1.344485  0.7888624  1.059424

Tuning parameter &#39;nrounds&#39; was held constant at a value of 200
Tuning parameter &#39;max_depth&#39; was
 was held constant at a value of 0.75
Tuning parameter &#39;min_child_weight&#39; was held constant at a
 value of 0
Tuning parameter &#39;subsample&#39; was held constant at a value of 0.5</code></pre>
<p>El paquete <code>h2o</code> también ofrece una implementación de XGBoost. Mostraremos cómo usar <code>xgboost</code>.</p>
<p>Como se mencionó anteriormente, <code>xgboost</code> permite los hiperparámetros tradicionales para <em>boosting</em> y árboles de decisión que discutimos hemos descrito en la Sección @ref{boostingHiperparam} . Sin embargo, <code>xgboost</code> también proporciona hiperparámetros adicionales que pueden ayudar a reducir las posibilidades de sobreajuste, lo que genera menos variabilidad de predicción y, por lo tanto, una mayor precisión.</p>
<div id="reguralización" class="section level3 hasAnchor" number="15.5.1">
<h3 class="hasAnchor"><span class="header-section-number">15.5.1</span> Reguralización<a href="#reguralización" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>xgboost</code> proporciona múltiples parámetros de regularización para ayudar a reducir la complejidad del modelo y evitar el sobreajuste. El primero, <code>gamma</code>, es un hiperparámetro de pseudo-regularización conocido como multiplicador lagrangiano y controla la complejidad de un árbol dado. <code>gamma</code> especifica una reducción de pérdida mínima requerida para hacer una partición adicional en un nodo hoja del árbol. Cuando se especifica <code>gamma</code>, <code>xgboost</code> hará crecer el árbol a la profundidad máxima especificada, pero luego lo podará para encontrar y eliminar divisiones que no cumplan con la gamma especificada. <code>gamma</code> tiende a valer la pena explorar a medida que los árboles en el GBM se vuelven más profundos y cuando ve una diferencia significativa del error de CV entre el la muestra “train” y “test”. El valor de gamma oscila entre <span class="math inline">\(0-\infty\)</span> (0 significa que no hay restricciones, mientras que números grandes significan una mayor regularización). Lo que se cuantifica como un valor de <code>gamma</code> grande depende de la función de pérdida, pero generalmente valores entre 1 y 20 serán suficientes si <code>gamma</code> es necesario.</p>
<p>Dos parámetros de regularización más tradicionales incluyen <code>alpha</code> (reguralización <span class="math inline">\(L_1\)</span>) y <code>lambda</code> (reguralización <span class="math inline">\(L_2\)</span>) [NOTA: lo veréis el año que viene en la asignatura de Modelos avanzados, ahora podéis leer <a href="https://www.iartificial.net/regularizacion-lasso-l1-ridge-l2-y-elasticnet/">esto</a>]. Estos parámetros de regularización limitan cómo de grandes pueden llegar a ser los pesos (o la influencia) de las hojas de un árbol.</p>
<p>Los tres hiperparámetros (<code>gamma</code>, <code>alpha</code>, <code>lambda</code>) funcionan para limitar la complejidad del modelo y reducir el sobreajuste. aunque <code>gamma</code> es lo que más se usa en estos modelos, la estrategia de ajuste debe explorar el impacto de los tres. La siguiente figura ilustra cómo la regularización puede hacer que un modelo de sobreajuste sea más conservador en los datos de entrenamiento, lo que, en algunas circunstancias, puede resultar en mejoras en el error de validación.</p>
<div class="figure">
<img src="figures/xgboost-learning-curve.png" alt="" />
<p class="caption">Cuando un modelo GBM se adapta significativamente a los datos de entrenamiento (azul), considerar la regularización (línea de puntos) hace que el modelo sea más conservador en los datos de entrenamiento, lo que puede mejorar el error de validación cruzada en la muestra test (rojo).</p>
</div>
</div>
<div id="estrategia-de-tuning" class="section level3 hasAnchor" number="15.5.2">
<h3 class="hasAnchor"><span class="header-section-number">15.5.2</span> Estrategia de <em>tuning</em><a href="#estrategia-de-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La estrategia de ajuste general para explorar los hiperparámetros de <code>xgboost</code> se basa en las estrategias de ajuste básicas y estocásticas de GBM:</p>
<ol style="list-style-type: decimal">
<li>Aumentar el número de árboles y ajustar la velocidad de aprendizaje con una parada temprana</li>
<li>Ajustar hiperparámetros específicos del árbol</li>
<li>Explorar los atributos estocásticos de GBM</li>
<li>Si se produce un sobreajuste sustancial (por ejemplo, grandes diferencias entre la muestra “train” y el error de CV), explorar los hiperparámetros de regularización</li>
<li>Si encontramos valores de hiperparámetros que son sustancialmente diferentes de la configuración predeterminada, asegurarnos de volver a ajustar la tasa de aprendizaje.</li>
<li>Obtener el modelo “óptimo” final</li>
</ol>
<p>La ejecución de un modelo XGBoost con <code>xgboost</code> requiere una preparación adicional de datos. <code>xgboost</code> requiere una entrada matricial de las variables predictoras y la respuesta. En consecuencia, para proporcionar una entrada matricial de las variables, necesitamos codificar nuestras variables categóricas numéricamente (es decir, hacer <em>dummies</em>). Como ya sabemos, esto se puede hacer fácilmente con la librería <code>recipies</code></p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="#cb731-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span>
<span id="cb731-2"><a href="#cb731-2" aria-hidden="true" tabindex="-1"></a>xgb_prep <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Sales <span class="sc">~</span> ., <span class="at">data =</span> cs_train) <span class="sc">%&gt;%</span></span>
<span id="cb731-3"><a href="#cb731-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_integer</span>(<span class="fu">all_nominal</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb731-4"><a href="#cb731-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>(<span class="at">training =</span> cs_train, <span class="at">retain =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb731-5"><a href="#cb731-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">juice</span>()  <span class="co"># similar to bake</span></span>
<span id="cb731-6"><a href="#cb731-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb731-7"><a href="#cb731-7" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(xgb_prep[<span class="fu">setdiff</span>(<span class="fu">names</span>(xgb_prep), <span class="st">&quot;Sales&quot;</span>)])</span>
<span id="cb731-8"><a href="#cb731-8" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> xgb_prep<span class="sc">$</span>Sales</span></code></pre></div>
<blockquote>
<p><strong>NOTA</strong>: <code>xgboost</code> permite tres tipos diferentes de matrices para los predictores: matriz R ordinaria, matrices esparsas de la lilbrería <code>Matrix</code> u objetos internos <code>xgb.DMatrix</code> de <code>xgboost</code>. Consultar ?Xgboost::xgboost para obtener más detalles.</p>
</blockquote>
<p>A continuación, pasamos por una serie de búsquedas en cuadrículas (<em>grid search</em>) similares a las secciones anteriores y encontramos que los siguientes hiperparámetros del modelo (proporcionados a través del argumento <code>params</code>) funcionan bastante bien. Nuestro RMSE es ligeramente más bajo que los mejores modelos GBM regulares y estocásticos hasta ahora.</p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="#cb732-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb732-2"><a href="#cb732-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb732-3"><a href="#cb732-3" aria-hidden="true" tabindex="-1"></a>mod_xgb <span class="ot">&lt;-</span> <span class="fu">xgb.cv</span>(</span>
<span id="cb732-4"><a href="#cb732-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> X,</span>
<span id="cb732-5"><a href="#cb732-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> Y,</span>
<span id="cb732-6"><a href="#cb732-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrounds =</span> <span class="dv">500</span>,</span>
<span id="cb732-7"><a href="#cb732-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective =</span> <span class="st">&quot;reg:squarederror&quot;</span>,</span>
<span id="cb732-8"><a href="#cb732-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">early_stopping_rounds =</span> <span class="dv">50</span>, </span>
<span id="cb732-9"><a href="#cb732-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfold =</span> <span class="dv">10</span>,</span>
<span id="cb732-10"><a href="#cb732-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">params =</span> <span class="fu">list</span>(</span>
<span id="cb732-11"><a href="#cb732-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">eta =</span> <span class="fl">0.1</span>,</span>
<span id="cb732-12"><a href="#cb732-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb732-13"><a href="#cb732-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">min_child_weight =</span> <span class="dv">0</span>,</span>
<span id="cb732-14"><a href="#cb732-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">subsample =</span> <span class="fl">0.8</span>,</span>
<span id="cb732-15"><a href="#cb732-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">colsample_bytree =</span> <span class="fl">0.75</span>),</span>
<span id="cb732-16"><a href="#cb732-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="dv">0</span></span>
<span id="cb732-17"><a href="#cb732-17" aria-hidden="true" tabindex="-1"></a>)  </span>
<span id="cb732-18"><a href="#cb732-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb732-19"><a href="#cb732-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb732-20"><a href="#cb732-20" aria-hidden="true" tabindex="-1"></a><span class="co"># minimum test CV RMSE</span></span>
<span id="cb732-21"><a href="#cb732-21" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(mod_xgb<span class="sc">$</span>evaluation_log<span class="sc">$</span>test_rmse_mean)</span></code></pre></div>
<pre><code>[1] 1.42869</code></pre>
<p>En este ejemplo no parece que mejoremos el RMSE, pero no suele ser lo habitual.</p>
<p>A continuación, evaluamos si el sobreajuste está limitando el rendimiento de nuestro modelo al realizar una búsqueda en cuadrícula que examina varios parámetros de regularización (<code>gamma</code>, <code>lambda</code> y <code>alfa</code>). Dado el alto coste computacional, no ejecutamos este código, pero puede comprobarse que no mejoramos con la inclusión de hiperparámetros de reguralización.</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="#cb734-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hyperparameter grid</span></span>
<span id="cb734-2"><a href="#cb734-2" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb734-3"><a href="#cb734-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fl">0.01</span>,</span>
<span id="cb734-4"><a href="#cb734-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">3</span>, </span>
<span id="cb734-5"><a href="#cb734-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">3</span>,</span>
<span id="cb734-6"><a href="#cb734-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="fl">0.5</span>, </span>
<span id="cb734-7"><a href="#cb734-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="fl">0.5</span>,</span>
<span id="cb734-8"><a href="#cb734-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">gamma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>),</span>
<span id="cb734-9"><a href="#cb734-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">lambda =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1e-2</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>),</span>
<span id="cb734-10"><a href="#cb734-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1e-2</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>),</span>
<span id="cb734-11"><a href="#cb734-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">rmse =</span> <span class="dv">0</span>,          <span class="co"># a place to dump RMSE results</span></span>
<span id="cb734-12"><a href="#cb734-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">0</span>          <span class="co"># a place to dump required number of trees</span></span>
<span id="cb734-13"><a href="#cb734-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb734-14"><a href="#cb734-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb734-15"><a href="#cb734-15" aria-hidden="true" tabindex="-1"></a><span class="co"># grid search</span></span>
<span id="cb734-16"><a href="#cb734-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(hyper_grid))) {</span>
<span id="cb734-17"><a href="#cb734-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb734-18"><a href="#cb734-18" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">xgb.cv</span>(</span>
<span id="cb734-19"><a href="#cb734-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> X,</span>
<span id="cb734-20"><a href="#cb734-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> Y,</span>
<span id="cb734-21"><a href="#cb734-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">500</span>,</span>
<span id="cb734-22"><a href="#cb734-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">&quot;reg:squarederror&quot;</span>,</span>
<span id="cb734-23"><a href="#cb734-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">early_stopping_rounds =</span> <span class="dv">50</span>, </span>
<span id="cb734-24"><a href="#cb734-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">nfold =</span> <span class="dv">10</span>,</span>
<span id="cb734-25"><a href="#cb734-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="dv">0</span>,</span>
<span id="cb734-26"><a href="#cb734-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">params =</span> <span class="fu">list</span>( </span>
<span id="cb734-27"><a href="#cb734-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">eta =</span> hyper_grid<span class="sc">$</span>eta[i], </span>
<span id="cb734-28"><a href="#cb734-28" aria-hidden="true" tabindex="-1"></a>      <span class="at">max_depth =</span> hyper_grid<span class="sc">$</span>max_depth[i],</span>
<span id="cb734-29"><a href="#cb734-29" aria-hidden="true" tabindex="-1"></a>      <span class="at">min_child_weight =</span> hyper_grid<span class="sc">$</span>min_child_weight[i],</span>
<span id="cb734-30"><a href="#cb734-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">subsample =</span> hyper_grid<span class="sc">$</span>subsample[i],</span>
<span id="cb734-31"><a href="#cb734-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">colsample_bytree =</span> hyper_grid<span class="sc">$</span>colsample_bytree[i],</span>
<span id="cb734-32"><a href="#cb734-32" aria-hidden="true" tabindex="-1"></a>      <span class="at">gamma =</span> hyper_grid<span class="sc">$</span>gamma[i], </span>
<span id="cb734-33"><a href="#cb734-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">lambda =</span> hyper_grid<span class="sc">$</span>lambda[i], </span>
<span id="cb734-34"><a href="#cb734-34" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> hyper_grid<span class="sc">$</span>alpha[i]</span>
<span id="cb734-35"><a href="#cb734-35" aria-hidden="true" tabindex="-1"></a>    ) </span>
<span id="cb734-36"><a href="#cb734-36" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb734-37"><a href="#cb734-37" aria-hidden="true" tabindex="-1"></a>  hyper_grid<span class="sc">$</span>rmse[i] <span class="ot">&lt;-</span> <span class="fu">min</span>(m<span class="sc">$</span>evaluation_log<span class="sc">$</span>test_rmse_mean)</span>
<span id="cb734-38"><a href="#cb734-38" aria-hidden="true" tabindex="-1"></a>  hyper_grid<span class="sc">$</span>trees[i] <span class="ot">&lt;-</span> m<span class="sc">$</span>best_iteration</span>
<span id="cb734-39"><a href="#cb734-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb734-40"><a href="#cb734-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb734-41"><a href="#cb734-41" aria-hidden="true" tabindex="-1"></a><span class="co"># results</span></span>
<span id="cb734-42"><a href="#cb734-42" aria-hidden="true" tabindex="-1"></a>hyper_grid <span class="sc">%&gt;%</span></span>
<span id="cb734-43"><a href="#cb734-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rmse <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb734-44"><a href="#cb734-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(rmse) <span class="sc">%&gt;%</span></span>
<span id="cb734-45"><a href="#cb734-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glimpse</span>()</span></code></pre></div>
<p>Una vez que hayamos encontrado los hiperparámetros óptimos, ajustaremos el modelo final con <code>xgb.train</code> o <code>xgboost</code>. Debemos asegurarnos de utilizar la cantidad óptima de árboles encontrados durante la validación cruzada. En nuestro ejemplo, agregar regularización no proporciona ninguna mejora, por lo que los excluimos en nuestro modelo final.</p>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="#cb735-1" aria-hidden="true" tabindex="-1"></a><span class="co"># optimal parameter list  (not are the real ones)</span></span>
<span id="cb735-2"><a href="#cb735-2" aria-hidden="true" tabindex="-1"></a>params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb735-3"><a href="#cb735-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fl">0.01</span>,</span>
<span id="cb735-4"><a href="#cb735-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">3</span>,</span>
<span id="cb735-5"><a href="#cb735-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">3</span>,</span>
<span id="cb735-6"><a href="#cb735-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="fl">0.5</span>,</span>
<span id="cb735-7"><a href="#cb735-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="fl">0.5</span></span>
<span id="cb735-8"><a href="#cb735-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb735-9"><a href="#cb735-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb735-10"><a href="#cb735-10" aria-hidden="true" tabindex="-1"></a><span class="co"># train final model</span></span>
<span id="cb735-11"><a href="#cb735-11" aria-hidden="true" tabindex="-1"></a>xgb.fit.final <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(</span>
<span id="cb735-12"><a href="#cb735-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">params =</span> params,</span>
<span id="cb735-13"><a href="#cb735-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> X,</span>
<span id="cb735-14"><a href="#cb735-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> Y,</span>
<span id="cb735-15"><a href="#cb735-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrounds =</span> <span class="dv">3944</span>,</span>
<span id="cb735-16"><a href="#cb735-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective =</span> <span class="st">&quot;reg:squarederror&quot;</span>,</span>
<span id="cb735-17"><a href="#cb735-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="dv">0</span></span>
<span id="cb735-18"><a href="#cb735-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb735-19"><a href="#cb735-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb735-20"><a href="#cb735-20" aria-hidden="true" tabindex="-1"></a>xgb.fit.final</span></code></pre></div>
<pre><code>##### xgb.Booster
raw: 4.2 Mb 
call:
  xgb.train(params = params, data = dtrain, nrounds = nrounds, 
    watchlist = watchlist, verbose = verbose, print_every_n = print_every_n, 
    early_stopping_rounds = early_stopping_rounds, maximize = maximize, 
    save_period = save_period, save_name = save_name, xgb_model = xgb_model, 
    callbacks = callbacks, objective = &quot;reg:squarederror&quot;)
params (as set within xgb.train):
  eta = &quot;0.01&quot;, max_depth = &quot;3&quot;, min_child_weight = &quot;3&quot;, subsample = &quot;0.5&quot;, colsample_bytree = &quot;0.5&quot;, objective = &quot;reg:squarederror&quot;, validate_parameters = &quot;TRUE&quot;
xgb.attributes:
  niter
callbacks:
  cb.evaluation.log()
# of features: 10 
niter: 3944
nfeatures : 10 
evaluation_log:
    iter train_rmse
       1  7.5160087
       2  7.4490349
---                
    3943  0.2764120
    3944  0.2763516</code></pre>
<p><strong>NOTA</strong>: Podemos obtener un ránking con la importancia de cada variable</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="#cb737-1" aria-hidden="true" tabindex="-1"></a>vip<span class="sc">::</span><span class="fu">vip</span>(xgb.fit.final) </span></code></pre></div>
<p><img src="fig/unnamed-chunk-334-1.png" width="672" /></p>
</div>
</div>
<div id="otros-algoritmos-gbm" class="section level2 hasAnchor" number="15.6">
<h2 class="hasAnchor"><span class="header-section-number">15.6</span> Otros algoritmos GBM<a href="#otros-algoritmos-gbm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los GBM son uno de los algoritmos más potentes que hay para crear modelos predictivos. Aunque son menos intuitivos y más exigentes computacionalmente que muchos otros algoritmos de aprendizaje automático, es esencial estar familizarizados con ellos.</p>
<p>Aunque discutimos los algoritmos GBM más populares, debemos tener en cuenta que actualmente se están llevando a cabo mejoras mediante la creación de algoritmos alternativos que no veremos en este curso. Por ejemplo, LightGBM (<a href="https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html">Ke et al. 2017</a>) es una librería de que se basa en el crecimiento de árboles por hojas versus el crecimiento tradicional de árboles por niveles. Esto significa que a medida que un árbol crece más profundo, se enfoca en extender una sola rama en lugar de cultivar múltiples ramas. <code>CatBoost</code> (<a href="https://arxiv.org/abs/1810.11363">Dorogush, Ershov y Gulin 2018</a>) es otra librería que se basa en el uso de métodos eficientes para codificar variables categóricas durante el proceso de aumento de gradiente. Ambos librerías están disponibles en R.</p>
<!--chapter:end:13-XGboost.Rmd-->
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>ejemplo obtenido de <a href="http://varianceexplained.org/r/why-I-use-ggplot2/" class="uri">http://varianceexplained.org/r/why-I-use-ggplot2/</a>)<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>De Fox, John (2016). <em>Regresión aplicada y modelos lineales generalizados.</em> Sage: Los Ángeles.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>La gente usa 2 en lugar de 1,96 para un cálculo rápido. De ahí lo de “más menos 2 veces el error estándar”<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>De Gelman y Hill (2007). <em>Análisis de datos mediante regresión y modelos jerárquicos / multinivel</em>. Cambridge: Cambridge UP.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>James et al. 2014<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>GLM significa modelo lineal generalizado. Esta función se ajustará a una variedad de modelos no lineales. Por ejemplo, podríamos especificar una regresión de Poisson con <code>family = poisson</code>.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Para obtener más detalles, se puede consultar este texto [How to interpret odds ratio in logistic regression?] (<a href="Https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/" class="uri">Https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/</a>).<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
