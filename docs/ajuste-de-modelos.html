<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Ajuste de modelos | Aprendizaje Automático 1</title>
  <meta name="description" content="5 Ajuste de modelos | Aprendizaje Automático 1" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Ajuste de modelos | Aprendizaje Automático 1" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Ajuste de modelos | Aprendizaje Automático 1" />
  
  
  

<meta name="author" content="Juan R González" />


<meta name="date" content="2020-10-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regresión-lineal.html"/>
<link rel="next" href="regresión-logística.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Aprendizaje Automático 1</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html"><i class="fa fa-check"></i><b>2</b> Introducción a Tidyverse</a>
<ul>
<li class="chapter" data-level="2.1" data-path="index.html"><a href="index.html#introducción"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#instalación"><i class="fa fa-check"></i><b>2.2</b> Instalación</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#librerías-básicas"><i class="fa fa-check"></i><b>2.3</b> Librerías básicas</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#manejo-de-datos"><i class="fa fa-check"></i><b>2.4</b> Manejo de datos</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#tibbles"><i class="fa fa-check"></i><b>2.4.1</b> Tibbles</a></li>
<li class="chapter" data-level="2.4.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#importar-datos"><i class="fa fa-check"></i><b>2.4.2</b> Importar datos</a></li>
<li class="chapter" data-level="2.4.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#transformación-de-datos"><i class="fa fa-check"></i><b>2.4.3</b> Transformación de datos</a></li>
<li class="chapter" data-level="2.4.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#filtrar-filas"><i class="fa fa-check"></i><b>2.4.4</b> Filtrar filas</a></li>
<li class="chapter" data-level="2.4.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#filtrado-lógico"><i class="fa fa-check"></i><b>2.4.5</b> Filtrado lógico</a></li>
<li class="chapter" data-level="2.4.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ordenar-filas"><i class="fa fa-check"></i><b>2.4.6</b> Ordenar filas</a></li>
<li class="chapter" data-level="2.4.7" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#seleccionar-columnas-e.g.-variables"><i class="fa fa-check"></i><b>2.4.7</b> Seleccionar columnas (e.g. variables)</a></li>
<li class="chapter" data-level="2.4.8" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#añadir-nuevas-variables"><i class="fa fa-check"></i><b>2.4.8</b> Añadir nuevas variables</a></li>
<li class="chapter" data-level="2.4.9" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#grouped-summaries"><i class="fa fa-check"></i><b>2.4.9</b> Grouped summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#uso-del-pipe"><i class="fa fa-check"></i><b>2.5</b> Uso del pipe <code>%&gt;%</code></a></li>
<li class="chapter" data-level="2.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ejercicios-manejo-de-datos"><i class="fa fa-check"></i><b>2.6</b> Ejercicios (manejo de datos)</a></li>
<li class="chapter" data-level="2.7" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#visualización-de-datos"><i class="fa fa-check"></i><b>2.7</b> Visualización de datos</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-categóricos"><i class="fa fa-check"></i><b>2.7.1</b> Distribución de datos categóricos</a></li>
<li class="chapter" data-level="2.7.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-continuos"><i class="fa fa-check"></i><b>2.7.2</b> Distribución de datos continuos</a></li>
<li class="chapter" data-level="2.7.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-continuos-según-una-variable-categórica"><i class="fa fa-check"></i><b>2.7.3</b> Distribución de datos continuos según una variable categórica</a></li>
<li class="chapter" data-level="2.7.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#dos-variables-categóricas"><i class="fa fa-check"></i><b>2.7.4</b> Dos variables categóricas</a></li>
<li class="chapter" data-level="2.7.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#dos-variables-continuas"><i class="fa fa-check"></i><b>2.7.5</b> Dos variables continuas</a></li>
<li class="chapter" data-level="2.7.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#facets"><i class="fa fa-check"></i><b>2.7.6</b> Facets</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ejercicios-visualización-de-datos"><i class="fa fa-check"></i><b>2.8</b> Ejercicios (Visualización de datos)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introducción-al-aprendizaje-automático.html"><a href="introducción-al-aprendizaje-automático.html"><i class="fa fa-check"></i><b>3</b> Introducción al Aprendizaje Automático</a></li>
<li class="chapter" data-level="4" data-path="regresión-lineal.html"><a href="regresión-lineal.html"><i class="fa fa-check"></i><b>4</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#preliminares"><i class="fa fa-check"></i><b>4.1</b> Preliminares</a></li>
<li class="chapter" data-level="4.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#conceptos-básicos"><i class="fa fa-check"></i><b>4.2</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#modelo-lineal-simple"><i class="fa fa-check"></i><b>4.2.1</b> Modelo lineal simple</a></li>
<li class="chapter" data-level="4.2.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#regresión-lineal-multivariante"><i class="fa fa-check"></i><b>4.2.2</b> Regresión lineal multivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#incertidumbre"><i class="fa fa-check"></i><b>4.2.3</b> Incertidumbre</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ajuste-de-un-modelo-lineal"><i class="fa fa-check"></i><b>4.3</b> Ajuste de un modelo lineal</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#residuos"><i class="fa fa-check"></i><b>4.3.1</b> Residuos</a></li>
<li class="chapter" data-level="4.3.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#coeficientes-de-interpretación"><i class="fa fa-check"></i><b>4.3.2</b> Coeficientes de interpretación</a></li>
<li class="chapter" data-level="4.3.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interacciones"><i class="fa fa-check"></i><b>4.3.3</b> Interacciones</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-por-mínimos-cuadrados"><i class="fa fa-check"></i><b>4.4</b> Estimación por mínimos cuadrados</a></li>
<li class="chapter" data-level="4.5" data-path="regresión-lineal.html"><a href="regresión-lineal.html#medidas-adicionales-de-ajuste-del-modelo"><i class="fa fa-check"></i><b>4.5</b> Medidas adicionales de ajuste del modelo</a></li>
<li class="chapter" data-level="4.6" data-path="regresión-lineal.html"><a href="regresión-lineal.html#sesgo-variación-sobreajuste"><i class="fa fa-check"></i><b>4.6</b> Sesgo, variación, sobreajuste</a></li>
<li class="chapter" data-level="4.7" data-path="regresión-lineal.html"><a href="regresión-lineal.html#regresión-como-estimación-de-una-media-condicional"><i class="fa fa-check"></i><b>4.7</b> Regresión como estimación de una media condicional</a></li>
<li class="chapter" data-level="4.8" data-path="regresión-lineal.html"><a href="regresión-lineal.html#la-función-de-regresión"><i class="fa fa-check"></i><b>4.8</b> La función de regresión</a></li>
<li class="chapter" data-level="4.9" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn"><i class="fa fa-check"></i><b>4.9</b> Estimación no paramétrica de la función de regresión: regresión KNN</a></li>
<li class="chapter" data-level="4.10" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-paramétrica-de-la-función-de-regresión-regresión-lineal"><i class="fa fa-check"></i><b>4.10</b> Estimación paramétrica de la función de regresión: regresión lineal</a></li>
<li class="chapter" data-level="4.11" data-path="regresión-lineal.html"><a href="regresión-lineal.html#predicción"><i class="fa fa-check"></i><b>4.11</b> Predicción</a></li>
<li class="chapter" data-level="4.12" data-path="regresión-lineal.html"><a href="regresión-lineal.html#inferencia-en-el-contexto-de-regresión"><i class="fa fa-check"></i><b>4.12</b> Inferencia en el contexto de regresión</a></li>
<li class="chapter" data-level="4.13" data-path="regresión-lineal.html"><a href="regresión-lineal.html#asunciones-de-un-modelo-de-regresión"><i class="fa fa-check"></i><b>4.13</b> Asunciones de un modelo de regresión</a></li>
<li class="chapter" data-level="4.14" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ejemplos-adicionales-de-interpretación-de-modelos"><i class="fa fa-check"></i><b>4.14</b> Ejemplos adicionales de interpretación de modelos</a>
<ul>
<li class="chapter" data-level="4.14.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos"><i class="fa fa-check"></i><b>4.14.1</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos</a></li>
<li class="chapter" data-level="4.14.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos"><i class="fa fa-check"></i><b>4.14.2</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos</a></li>
<li class="chapter" data-level="4.14.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones"><i class="fa fa-check"></i><b>4.14.3</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos, con interacciones</a></li>
<li class="chapter" data-level="4.14.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones"><i class="fa fa-check"></i><b>4.14.4</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos, con interacciones</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="regresión-lineal.html"><a href="regresión-lineal.html#centrado-y-escalado"><i class="fa fa-check"></i><b>4.15</b> Centrado y escalado</a></li>
<li class="chapter" data-level="4.16" data-path="regresión-lineal.html"><a href="regresión-lineal.html#transformación-de-variables"><i class="fa fa-check"></i><b>4.16</b> Transformación de variables</a></li>
<li class="chapter" data-level="4.17" data-path="regresión-lineal.html"><a href="regresión-lineal.html#colinealidad"><i class="fa fa-check"></i><b>4.17</b> Colinealidad</a></li>
<li class="chapter" data-level="4.18" data-path="regresión-lineal.html"><a href="regresión-lineal.html#valores-atípicos"><i class="fa fa-check"></i><b>4.18</b> Valores atípicos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html"><i class="fa fa-check"></i><b>5</b> Ajuste de modelos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#reglas-generales-para-la-selección-de-variables"><i class="fa fa-check"></i><b>5.1</b> Reglas generales para la selección de variables</a></li>
<li class="chapter" data-level="5.2" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#selección-paso-a-paso-stepwise"><i class="fa fa-check"></i><b>5.2</b> Selección paso a paso (stepwise)</a></li>
<li class="chapter" data-level="5.3" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#comparación-de-modelos"><i class="fa fa-check"></i><b>5.3</b> Comparación de modelos</a></li>
<li class="chapter" data-level="5.4" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#métodos-de-selección-automática"><i class="fa fa-check"></i><b>5.4</b> Métodos de selección automática</a></li>
<li class="chapter" data-level="5.5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#validación-cruzada"><i class="fa fa-check"></i><b>5.5</b> Validación cruzada</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#validación-en-un-conjunto-de-datos-externo"><i class="fa fa-check"></i><b>5.5.1</b> Validación en un conjunto de datos externo</a></li>
<li class="chapter" data-level="5.5.2" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>5.5.2</b> Leave-one-out cross validation (LOOCV)</a></li>
<li class="chapter" data-level="5.5.3" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#k-fold-cross-validation-k-fold-cv"><i class="fa fa-check"></i><b>5.5.3</b> K-fold cross validation (K-fold CV)</a></li>
<li class="chapter" data-level="5.5.4" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#uso-de-cv-para-estimar-el-hiper-parámetro"><i class="fa fa-check"></i><b>5.5.4</b> Uso de CV para estimar el hiper-parámetro</a></li>
<li class="chapter" data-level="5.5.5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#uso-de-bootstrap"><i class="fa fa-check"></i><b>5.5.5</b> Uso de bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#imputación-de-datos-faltantes"><i class="fa fa-check"></i><b>5.6</b> Imputación de datos faltantes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>6</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#la-función-logit-inversa"><i class="fa fa-check"></i><b>6.1</b> La función logit inversa</a></li>
<li class="chapter" data-level="6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística"><i class="fa fa-check"></i><b>6.2</b> Ejemplo de regresión logística</a></li>
<li class="chapter" data-level="6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-probabilidades"><i class="fa fa-check"></i><b>6.3</b> Coeficientes de regresión logística como probabilidades</a></li>
<li class="chapter" data-level="6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-razones-de-odds"><i class="fa fa-check"></i><b>6.4</b> Coeficientes de regresión logística como razones de odds</a></li>
<li class="chapter" data-level="6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#bondad-de-ajuste"><i class="fa fa-check"></i><b>6.5</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="6.6" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes"><i class="fa fa-check"></i><b>6.6</b> Ejemplo de regresión logística: modelización de riesgo diabetes</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#modelo-simple"><i class="fa fa-check"></i><b>6.6.1</b> Modelo simple</a></li>
<li class="chapter" data-level="6.6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#agregar-predictores-y-evaluar-el-ajuste"><i class="fa fa-check"></i><b>6.6.2</b> Agregar predictores y evaluar el ajuste</a></li>
<li class="chapter" data-level="6.6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#análisis-de-interacciones"><i class="fa fa-check"></i><b>6.6.3</b> Análisis de interacciones</a></li>
<li class="chapter" data-level="6.6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#gráfico-de-la-interacción"><i class="fa fa-check"></i><b>6.6.4</b> Gráfico de la interacción</a></li>
<li class="chapter" data-level="6.6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#uso-del-modelo-para-predecir-probabilidades"><i class="fa fa-check"></i><b>6.6.5</b> Uso del modelo para predecir probabilidades</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="regresión-logística.html"><a href="regresión-logística.html#creación-de-un-modelo-y-validación"><i class="fa fa-check"></i><b>6.7</b> Creación de un modelo y validación</a></li>
<li class="chapter" data-level="6.8" data-path="regresión-logística.html"><a href="regresión-logística.html#nomogramas"><i class="fa fa-check"></i><b>6.8</b> Nomogramas</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html"><i class="fa fa-check"></i><b>7</b> Dealing with Big Data in R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#nodes-cores-processes-and-threads"><i class="fa fa-check"></i><b>7.1</b> Nodes, cores, processes and threads</a></li>
<li class="chapter" data-level="7.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#paralelización"><i class="fa fa-check"></i><b>7.2</b> Paralelización</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#shared-memory-programming"><i class="fa fa-check"></i><b>7.2.1</b> Shared Memory Programming</a></li>
<li class="chapter" data-level="7.2.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#distributed-memory-programming"><i class="fa fa-check"></i><b>7.2.2</b> Distributed Memory Programming</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#mapreduce"><i class="fa fa-check"></i><b>7.3</b> MapReduce</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#map"><i class="fa fa-check"></i><b>7.3.1</b> Map</a></li>
<li class="chapter" data-level="7.3.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#reduce"><i class="fa fa-check"></i><b>7.3.2</b> Reduce</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#example-linear-regression-for-big-data"><i class="fa fa-check"></i><b>7.4</b> Example: Linear regression for Big Data</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje Automático 1</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ajuste-de-modelos" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Ajuste de modelos</h1>
<p>Este capítulo cubre varios temas adicionales relacionados con el ajuste de modelos, como la selección de variables, la comparación de modelos, la validación cruzada y la imputación de datos faltantes. Los conceptos y métodos discutidos aquí se aplican tanto a la regresión lineal como a la logística.</p>
<p>Qué pretendemos aprender en este capítulo:</p>
<ul>
<li>Saber cuales son las reglas generales para seleccionar variables en un modelo.</li>
<li>Aprender a llevar a cabo esta selección con métodos automáticos (stepwise).</li>
<li>Cómo comparar dos modelos</li>
<li>Cómo determinar si un modelo tiene sobre-ajuste (overfitting)</li>
<li>Dar una pequeña idea a qué hacer cuando tenemos datos faltantes (missing data)</li>
</ul>
<div id="reglas-generales-para-la-selección-de-variables" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Reglas generales para la selección de variables</h2>
<p>¿Cómo sabemos qué variables (independientes) deben incluirse en un modelo? La respuesta sencilla es: a menudo no lo sabemos. Aquí hay algunas reglas generales cuando se piensa en la selección de variables:</p>
<ul>
<li><p><em>Piensa en los datos</em>. ¿Qué variables tiene sentido incluir dada la situación? ¿Alguna literatura publicada ofrece orientación? Si estamos en modo descriptivo, es posible que solo nos interesen determinadas variables y utilicemos las demás como controles. Si estamos en modo predictivo, incluimos todas las variables que, por razones aditivas, podrían ser importantes para predecir el resultado. Sin embargo, esta es una guía muy general, ya que diferentes contextos exigen diferentes enfoques para el ajuste del modelo.</p></li>
<li><p><em>Incluir términos cuadráticos si hay evidencia de gráficos bivariados de una relación no lineal entre predictor y resultado.</em> En general, no incluimos términos polinomiales con grados superiores a 2. Para hacerlo, se corre el riesgo de sobreajuste (término del que hablaremos más tarde).</p></li>
<li><p><em>Buscar posibles interacciones entre variables con los efectos principales más grandes.</em> En general, no incluimos interacciones de orden superior (mayores que 2) a menos que tengamos una razón lógica y podamos explicarla. También hay que tener en cuenta que las interacciones son bastante difíciles de explicar.</p></li>
<li><p><em>Considerar combinar predictores separados en un solo predictor — un “puntaje total” — obtenido al sumarlos o promediarlos.</em></p></li>
<li><p><em>Simplicidad.</em> Los modelos sencillos son casi siempre mejores — son más interpretables y tienden a tener menor variación (<em>principio de parsimonia</em>).</p></li>
</ul>
</div>
<div id="selección-paso-a-paso-stepwise" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Selección paso a paso (stepwise)</h2>
<p>La técnica tradicional en estadística para seleccionar variables es <em>selección paso a paso</em> (o <em>stepwise</em> en inglés).</p>
<p>Con <em>selección hacia adelante</em> comenzamos con un modelo nulo (solo contiene el <em>intercept</em>) y agregamos una variable a la vez. Si la variable agregada mejora el modelo, la mantenemos y agregamos otra. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura:</p>
<div class="figure">
<img src="figures/fwd_stepwise.png" style="width:40.0%" alt="" />
<p class="caption">Selección hacia adelante</p>
</div>
<p>Con <em>selección hacia atrás</em> comenzamos con un modelo completo (todos los términos disponibles) y eliminamos variables en serie (una a una). Si el modelo es mejor después de eliminar una variable, lo dejamos fuera. Continuamos hasta que se hayan probado todas las variables como podemos ver en la siguiente figura:</p>
<div class="figure">
<img src="figures/bwd_stepwise.png" style="width:40.0%" alt="" />
<p class="caption">Selección hacia atrás</p>
</div>
<p><em>Selección hacia adelante seguida de selección hacia atrás (saltos)</em>. Consiste en ir realizando en cada paso una selección hacia adelante o hacia atrás en función del mejor paso que podamos hacer.</p>
<p>Desafortunadamente, estos procedimientos de ajuste manual son defectuosos. Dependen del orden en el que se agregan o excluyen las variables y, a menudo, no seleccionarán el mejor modelo. Además, por ejemplo, supongamos que tenemos una base de datos con <span class="math inline">\(k\)</span> = 13 variables predictoras, lo que significa que hay <span class="math inline">\(2^k\)</span> o 8192 modelos posibles que podríamos ajustar y eso sin tener encuenta la posible introducción de interacciones o términos polinómicos. Este es un espacio extremadamente grande para buscar el mejor modelo, y la búsqueda es computacionalmente costosa y requiere mucho tiempo. Realizar tal búsqueda manualmente sería prácticamente imposible.</p>
</div>
<div id="comparación-de-modelos" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Comparación de modelos</h2>
<p>Ya estamos familiarizados con los términos <span class="math inline">\(R^2\)</span>, RMSE y RSS. Éstos nos servirán como herramientas para comparar modelos. En general, si agregamos una variable y <span class="math inline">\(R ^2\)</span> sube y RMSE / RSS baja, entonces el modelo con la variable adicional siempre es mejor. La cantidad de variación explicada ha aumentado. Sin embargo, como siempre en estadística debemos preguntarnos ¿es este aumento estadísticamente significativo?. Este hecho también introduce un nuevo problema: el sobreajuste. Sabemos que el, <span class="math inline">\(R^2\)</span> ajustado penaliza el ajuste teniendo en cuenta el número de predictores y podría ser una solución. También tenemos otra posibilidad para penalizar la complejidad de los modelos usando métodos de criterio de información como el AIC (Akaike Information Criterion).</p>
<p><span class="math display">\[\mathrm {AIC} = - 2 \ln(L) + 2k\]</span></p>
<p>donde <span class="math inline">\(k\)</span> es el número de parámetros estimados en el modelo, <span class="math inline">\(L\)</span> es el valor maximizado de la función de verosimilitud del modelo y <span class="math inline">\(ln\)</span> es el logaritmo natural. Dado un conjunto de modelos candidatos para los datos, el modelo preferido es el que tiene el valor de AIC más bajo. Al penalizar por <span class="math inline">\(k\)</span> más grandes (garantizados por el término final, <span class="math inline">\(+ 2k\)</span>), AIC intenta protegerse contra el sobreajuste. Es posible, entonces, observar <span class="math inline">\(R^2\)</span> aumentar con la adición de predictores, mientras que AIC baja.</p>
<p>También podemos comparar modelos con una prueba estadística formal utilizando la
prueba de razón de verosimilitud (LRT por sus siglas en inglés):</p>
<p><span class="math display">\[
2 \times [\ln(L_{a}) - \ln(L_{c})]
\]</span>
donde <span class="math inline">\(\ln(L_{c})\)</span> es el logaritmo de la probabilidad del modelo actual (o basal) y <span class="math inline">\(\ln (L_{a})\)</span> es el logaritmo de la probabilidad del modelo alternativo con predictores adicionales. La función <code>lrtest ()</code> en el paquete <code>lmtest</code> implementa el test LRT. La función <code>anova ()</code> en R base también comparará modelos usando una prueba F.</p>
<p>Vamos a ilustrar algunos de ejemplos de comparación de modelos usando los datos de Hitters del paquete ISLR que tiene información sobre bateadores de la Major League de USA entre los años 1986 y 1987. Estamos interesados en crear un modelo para predecir el salario de los bateadores (variable <code>Salary</code>). Partimos de un modelo nulo:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="ajuste-de-modelos.html#cb252-1"></a><span class="kw">library</span>(ISLR)</span>
<span id="cb252-2"><a href="ajuste-de-modelos.html#cb252-2"></a><span class="kw">data</span>(Hitters)</span>
<span id="cb252-3"><a href="ajuste-de-modelos.html#cb252-3"></a><span class="kw">display</span>(null &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> Hitters))</span></code></pre></div>
<pre><code>## lm(formula = Salary ~ 1, data = Hitters)
##             coef.est coef.se
## (Intercept) 535.93    27.82 
## ---
## n = 263, k = 1
## residual sd = 451.12, R-Squared = 0.00</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="ajuste-de-modelos.html#cb254-1"></a><span class="kw">round</span>(<span class="kw">mean</span>(Hitters<span class="op">$</span>Salary, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 535.93</code></pre>
<p>Un modelo nulo consiste solo en una intersección, cuyo coeficiente, como podemos ver, es solo la media de Salario. La pregunta clave es si a medida que hacemos un modelo más complejo esa complejidad está justificada. Es decir, si agregar predictores no solo reduce el sesgo sino que lo hace sin aumentar indebidamente la varianza. Veámos qué ocurre si agreguamos más predictores.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="ajuste-de-modelos.html#cb256-1"></a><span class="kw">library</span>(lmtest)</span>
<span id="cb256-2"><a href="ajuste-de-modelos.html#cb256-2"></a><span class="kw">display</span>(h1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>Hits, <span class="dt">data =</span> Hitters))</span></code></pre></div>
<pre><code>## lm(formula = Salary ~ Hits, data = Hitters)
##             coef.est coef.se
## (Intercept) 63.05    64.98  
## Hits         4.39     0.56  
## ---
## n = 263, k = 2
## residual sd = 406.17, R-Squared = 0.19</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="ajuste-de-modelos.html#cb258-1"></a><span class="kw">lrtest</span>(null, h1)</span></code></pre></div>
<pre><code>## 
## Model 1: Salary ~ 1
## Model 2: Salary ~ Hits
## 
## L.R. Chisq       d.f.          P 
##         NA          1         NA</code></pre>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="ajuste-de-modelos.html#cb260-1"></a><span class="kw">anova</span>(null, h1)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Salary ~ 1
## Model 2: Salary ~ Hits
##   Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    262 53319113                                  
## 2    261 43058621  1  10260491 62.194 8.531e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="ajuste-de-modelos.html#cb262-1"></a><span class="kw">as.matrix</span>(<span class="kw">AIC</span>(null, h1))</span></code></pre></div>
<pre><code>##      df      AIC
## null  2 3964.130
## h1    3 3909.918</code></pre>
<p>La variable Hits es estadísticamente significativ, ya que el IC del 95% no incluye 0 (4,39 <span class="math inline">\(\pm\)</span> 2 x 0,56) (o el p-valor del test de Score es <span class="math inline">\(&lt;0.05\)</span>). Estos tres métodos coinciden en que el modelo con Hits es una mejora con respecto al modelo nulo. En el caso de <code>lrtest ()</code> y <code>anova ()</code>, el p-valor representa los resultados de una prueba estadística (prueba chi-cuadrado y prueba F, respectivamente) para determinar si el segundo modelo más complejo es un mejor ajuste a los datos. ¿Agregar un predictor adicional, AtBat, mejora aún más el modelo?</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="ajuste-de-modelos.html#cb264-1"></a><span class="kw">display</span>(h2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>Hits <span class="op">+</span><span class="st"> </span>AtBat, <span class="dt">data =</span> Hitters))</span></code></pre></div>
<pre><code>## lm(formula = Salary ~ Hits + AtBat, data = Hitters)
##             coef.est coef.se
## (Intercept) 141.27    76.55 
## Hits          8.21     2.08 
## AtBat        -1.22     0.64 
## ---
## n = 263, k = 3
## residual sd = 404.13, R-Squared = 0.20</code></pre>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="ajuste-de-modelos.html#cb266-1"></a><span class="kw">lrtest</span>(h1, h2)</span></code></pre></div>
<pre><code>## 
## Model 1: Salary ~ Hits
## Model 2: Salary ~ Hits + AtBat
## 
## L.R. Chisq       d.f.          P 
##         NA          1         NA</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="ajuste-de-modelos.html#cb268-1"></a><span class="kw">anova</span>(h1, h2)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Salary ~ Hits
## Model 2: Salary ~ Hits + AtBat
##   Res.Df      RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1    261 43058621                              
## 2    260 42463750  1    594871 3.6423 0.05743 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="ajuste-de-modelos.html#cb270-1"></a><span class="kw">as.matrix</span>(<span class="kw">AIC</span>(h1, h2))</span></code></pre></div>
<pre><code>##    df      AIC
## h1  3 3909.918
## h2  4 3908.260</code></pre>
<p>Los resultados son ambiguos. El <span class="math inline">\(R^2\)</span> aumenta, mientras que AIC, el logaritmo de la probabilidad y el RSS disminuyen, pero la disminución en los dos últimos casos no es estadísticamente significativa. (Este resultado es consistente con el hecho de que AtBat no es en sí mismo estadísticamente significativo, ya que el IC del 95% para AtBat incluye 0: -1.22 <span class="math inline">\(\pm\)</span> 2 x .64). ¿Deberíamos dejar AtBat en el modelo? No mejora mucho el ajuste, si es que lo hace, al tiempo que agrega complejidad. Entonces, deberíamos sacarlo. Desafortunadamente, estas opciones a menudo no son claras, razón por la cual el ajuste de modelos a veces parece más un arte que una ciencia.</p>
<p>Para implementar el método de selección, seguiríamos agregando variables y comparando modelos usando <code>lrtest ()</code> o <code>anova ()</code> con el fin de encontrar el mejor ajuste posible. Sin embargo, un problema con este procedimiento es que el orden en el que recorremos los predictores afectará nuestras decisiones de selección porque el impacto de cada predictor en el ajuste del modelo depende de la presencia de los demás. Por ejemplo, supongamos que agregamos AtBat más adelante en el proceso de selección:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="ajuste-de-modelos.html#cb272-1"></a>h3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>Hits <span class="op">+</span><span class="st"> </span>Years <span class="op">+</span><span class="st"> </span>HmRun <span class="op">+</span><span class="st"> </span>RBI <span class="op">+</span><span class="st"> </span>Walks <span class="op">+</span><span class="st"> </span>Assists, <span class="dt">data =</span> Hitters)</span>
<span id="cb272-2"><a href="ajuste-de-modelos.html#cb272-2"></a>h4 &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>Hits <span class="op">+</span><span class="st"> </span>Years <span class="op">+</span><span class="st"> </span>HmRun <span class="op">+</span><span class="st"> </span>RBI <span class="op">+</span><span class="st"> </span>Walks <span class="op">+</span><span class="st"> </span>Assists <span class="op">+</span><span class="st"> </span>AtBat, <span class="dt">data =</span> Hitters)</span>
<span id="cb272-3"><a href="ajuste-de-modelos.html#cb272-3"></a><span class="kw">lrtest</span>(h3, h4)</span></code></pre></div>
<pre><code>## 
## Model 1: Salary ~ Hits + Years + HmRun + RBI + Walks + Assists
## Model 2: Salary ~ Hits + Years + HmRun + RBI + Walks + Assists + AtBat
## 
## L.R. Chisq       d.f.          P 
##         NA          1         NA</code></pre>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="ajuste-de-modelos.html#cb274-1"></a><span class="kw">as.matrix</span>(<span class="kw">AIC</span>(h3, h4))</span></code></pre></div>
<pre><code>##    df      AIC
## h3  8 3849.311
## h4  9 3840.198</code></pre>
<p>Ahora AtBat mejora claramente el ajuste, pero nunca lo hubiéramos descubierto si ya lo hubiéramos descartado. Esto es preocupante. ¿Existe una forma mejor de seleccionar variables? Quizás, veámoslo.</p>
</div>
<div id="métodos-de-selección-automática" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Métodos de selección automática</h2>
<p>Se han desarrollado algoritmos para buscar en el espacio de modelos de manera eficiente el modelo óptimo. Sin embargo, desde el principio conviene tener cuidado con la selección automática de variables. <em>La elección de variables no debe ser un proceso mecánico.</em> Debemos, en cambio, buscar comprender el proceso de generación de datos. De hecho, el mayor beneficio de la selección manual por pasos consiste menos en producir un buen modelo que en la comprensión obtenida al ajustar muchos modelos y ver, mediante prueba y error, qué predictores son más reactivos con el resultado. Especialmente cuando se trata de descripción, los algoritmos de selección automática de variables son solo herramientas para explorar sus datos y pensar en modelos.</p>
<p>La función <code>step ()</code> en R base automatiza la selección de variables paso a paso usando AIC.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="ajuste-de-modelos.html#cb276-1"></a><span class="kw">display</span>(<span class="kw">step</span>(<span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters), <span class="dt">trace =</span> F, <span class="dt">direction =</span> <span class="st">&quot;forward&quot;</span>))</span></code></pre></div>
<pre><code>## lm(formula = Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + 
##     Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + 
##     League + Division + PutOuts + Assists + Errors + NewLeague, 
##     data = Hitters)
##             coef.est coef.se
## (Intercept)  163.10    90.78
## AtBat         -1.98     0.63
## Hits           7.50     2.38
## HmRun          4.33     6.20
## Runs          -2.38     2.98
## RBI           -1.04     2.60
## Walks          6.23     1.83
## Years         -3.49    12.41
## CAtBat        -0.17     0.14
## CHits          0.13     0.67
## CHmRun        -0.17     1.62
## CRuns          1.45     0.75
## CRBI           0.81     0.69
## CWalks        -0.81     0.33
## LeagueN       62.60    79.26
## DivisionW   -116.85    40.37
## PutOuts        0.28     0.08
## Assists        0.37     0.22
## Errors        -3.36     4.39
## NewLeagueN   -24.76    79.00
## ---
## n = 263, k = 20
## residual sd = 315.58, R-Squared = 0.55</code></pre>
<p>La selección hacia adelante se estableció en 19 predictores con un <span class="math inline">\(R^2\)</span> de .55.</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="ajuste-de-modelos.html#cb278-1"></a><span class="kw">display</span>(<span class="kw">step</span>(<span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters), <span class="dt">trace =</span> F, <span class="dt">direction =</span> <span class="st">&quot;backward&quot;</span>))</span></code></pre></div>
<pre><code>## lm(formula = Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + 
##     CRBI + CWalks + Division + PutOuts + Assists, data = Hitters)
##             coef.est coef.se
## (Intercept)  162.54    66.91
## AtBat         -2.17     0.54
## Hits           6.92     1.65
## Walks          5.77     1.58
## CAtBat        -0.13     0.06
## CRuns          1.41     0.39
## CRBI           0.77     0.21
## CWalks        -0.83     0.26
## DivisionW   -112.38    39.21
## PutOuts        0.30     0.07
## Assists        0.28     0.16
## ---
## n = 263, k = 11
## residual sd = 311.81, R-Squared = 0.54</code></pre>
<p>La selección hacia detrás se estableció en 10 predictores con un <span class="math inline">\(R^2\)</span> de .54. Con muchas menos variables, somos capaces de explicar prácticamente la misma variabilidad.</p>
<p>La función <code>regsubsets ()</code> en el paquete <code>leaps</code> realiza una búsqueda exhaustiva del espacio modelo utilizando el algoritmo de saltos (adelante y atrás) para la selección de variables.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="ajuste-de-modelos.html#cb280-1"></a><span class="kw">library</span>(leaps)</span>
<span id="cb280-2"><a href="ajuste-de-modelos.html#cb280-2"></a><span class="kw">plot</span>(<span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters, <span class="dt">method =</span> <span class="st">&quot;exhaustive&quot;</span>, <span class="dt">nbest =</span> <span class="dv">1</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-77-1.png" width="672" /></p>
<p>El gráfico presenta diferentes modelos que pueden ser buenos candidatos organizados según el BIC (<span class="math inline">\(\mathrm{BIC} = {\ln(n) k - 2 \ ln ({L})}\)</span>, donde <span class="math inline">\(L\)</span> es el valor de máxima verosimilitud, <span class="math inline">\(n\)</span> es el número de observaciones, <span class="math inline">\(k\)</span> es el número de parámetros y <span class="math inline">\(ln\)</span> es el logaritmo natural). Como el AIC, el BIC penaliza por la complejidad del modelo. Un BIC más bajo es mejor. El modelo con el BIC más bajo es el bastante simple en la parte superior de la figura: <em>intercept</em>, AtBat, Hits, Walks, CRBI, DivisionW y PutOuts. Si reajustamos un modelo con estos predictores usando <code>lm ()</code> encontramos que tiene un <span class="math inline">\(R^2\)</span> de .51, que tampoco está muy lejos del valor obtenido con un método hacia adelante y con muchísimas menos variables (principio de parsimonia). Notemos que, además, todos los coefecientes de este modelo (a excepción del <em>intercept</em>, pero que es necesario introducir) son estadísticamente significativos según el test de score:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="ajuste-de-modelos.html#cb281-1"></a><span class="kw">summary</span>(<span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>AtBat <span class="op">+</span><span class="st"> </span>Hits <span class="op">+</span><span class="st"> </span>Walks <span class="op">+</span><span class="st"> </span>CRBI <span class="op">+</span><span class="st"> </span>Division <span class="op">+</span><span class="st"> </span>PutOuts, <span class="dt">data =</span> Hitters))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Salary ~ AtBat + Hits + Walks + CRBI + Division + 
##     PutOuts, data = Hitters)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -873.11 -181.72  -25.91  141.77 2040.47 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   91.51180   65.00006   1.408 0.160382    
## AtBat         -1.86859    0.52742  -3.543 0.000470 ***
## Hits           7.60440    1.66254   4.574 7.46e-06 ***
## Walks          3.69765    1.21036   3.055 0.002488 ** 
## CRBI           0.64302    0.06443   9.979  &lt; 2e-16 ***
## DivisionW   -122.95153   39.82029  -3.088 0.002239 ** 
## PutOuts        0.26431    0.07477   3.535 0.000484 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 319.9 on 256 degrees of freedom
##   (59 observations deleted due to missingness)
## Multiple R-squared:  0.5087,	Adjusted R-squared:  0.4972 
## F-statistic: 44.18 on 6 and 256 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre><code>**IMPORTANTE:** ¿Es este modelo realmente mejor? El algoritmo hizo una búsqueda exhaustiva del espacio de modelos y, sin embargo, arrojó un modelo con $R^2$ un poco más bajo. ¿Cómo podría ser mejor? (probablemente lo sea). Si bien el sesgo en este modelo será mayor que en el modelo más grande seleccionado por la función `step ()`, la varianza probablemente sea menor. Recuerde: el sesgo se refiere al rendimiento del modelo dentro de la muestra y la varianza se refiere al rendimiento del modelo fuera de la muestra: cómo se comporta el modelo cuando encuentra nuevos datos. Si el modelo tiene un rendimiento deficiente en datos nuevos, con una gran discrepancia entre el rendimiento dentro y fuera de la muestra, entonces está sobreajustado. AIC, BIC y $R^2$ ajustado penalizan por la complejidad del modelo para evitar el sobreajuste y tenderán a seleccionar modelos con mayor sesgo y menor varianza.</code></pre>
</div>
<div id="validación-cruzada" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Validación cruzada</h2>
<p>La validación cruzada (CV por sus siglas en inglés) es la técnica que usamos para evaluar si un modelo está sobreajustado y para estimar cómo funcionará con nuevos datos.</p>
<p>El sobreajuste es un peligro importante en el análisis predictivo, especialmente cuando se utilizan algoritmos de aprendizaje automático que, sin el ajuste adecuado, puede aprender datos de nuestra muestra casi a la perfección, esencialmente ajustando el ruido (o variabilidad). Cuando se utiliza un modelo de este tipo para predecir nuevos datos, con un ruido (o variabilidad) diferente, el rendimiento del modelo puede ser sorprendentemente malo. Usamos CV para ayudarnos a identificar y evitar tales situaciones. ¿Cómo podemos hacer esto? Muchos algoritmos de aprendizaje automático requieren que el usuario especifique ciertos parámetros (hiper-parámetros). Veremos más adelante que, por ejemplo, necesitaremos especificar un valor para <span class="math inline">\(m\)</span> que corresponde al número de predictores elegidos al azar que se utilizarán en cada división de árbol cuando usemos “random forest” como algoritmo de aprendizaje. Cuanto menor sea <span class="math inline">\(m\)</span>, más simple será el árbol. Podemos usar CV para elegir el valor de <span class="math inline">\(m\)</span> que minimiza la variación y reduce el sobreajuste. La regresión lineal no tiene parámetros que debe especificar el usuario, pero la CV aún nos ayuda a evaluar cuánto podría sobreajustarse un modelo a los datos de muestra.</p>
<p>De manera breve, los algoritmos de cross-validation se pueden resumir como:</p>
<ul>
<li>Reserva una parte pequeña de los datos</li>
<li>Crea (o entrena) el modelo usando el resto de datos</li>
<li>Testa el modelo en los datos reservados.</li>
</ul>
<p>A continuación se describen algunas de las distintas técnicas de validación cruzada que existen.</p>
<div id="validación-en-un-conjunto-de-datos-externo" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Validación en un conjunto de datos externo</h3>
<p>La versión más simple de CV es el llamado método de conjunto de validación, que consta de los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><em>Dividir los datos de la muestra en dos partes: un conjunto de entrenamiento y otro de validacións.</em> Los investigadores usan diferentes proporciones, pero es común seleccionar al azar el 70% de los datos como conjunto de entrenamiento y el 30% como conjunto de prueba o validación. . (Obviamente, debemos tener suficientes datos en la muestra para ajustar un modelo después de dividir los datos). Debido a que CV se basa en un muestreo aleatorio, nuestros resultados variarán a menos que usemos <code>set.seed ()</code>. Demostraremos usando los datos de Hitters, usando solo casos completos (esto es importante, no tener missings - veremos más adelante alguna forma de solucionar este problema).</li>
</ol>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="ajuste-de-modelos.html#cb284-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb284-2"><a href="ajuste-de-modelos.html#cb284-2"></a>Hitters_complete &lt;-<span class="st"> </span>Hitters[<span class="kw">complete.cases</span>(Hitters), ]</span>
<span id="cb284-3"><a href="ajuste-de-modelos.html#cb284-3"></a>rows &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(Hitters_complete), <span class="fl">.7</span> <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(Hitters_complete))</span>
<span id="cb284-4"><a href="ajuste-de-modelos.html#cb284-4"></a>train &lt;-<span class="st"> </span>Hitters_complete[rows, ]</span>
<span id="cb284-5"><a href="ajuste-de-modelos.html#cb284-5"></a>test &lt;-<span class="st"> </span>Hitters_complete[<span class="op">-</span>rows, ]</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><em>Ajustar un modelo en el conjunto de entrenamiento</em> usando un procedimiento de selección de variables apropiado. Crearemos dos modelos para comparar: uno con todas las variables, luego otro con solo las variables elegidas por <code>regsubsets ()</code>.</li>
</ol>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="ajuste-de-modelos.html#cb285-1"></a>full_model &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span>., <span class="dt">data =</span> train)</span>
<span id="cb285-2"><a href="ajuste-de-modelos.html#cb285-2"></a>select_model &lt;-<span class="st"> </span><span class="kw">lm</span>(Salary <span class="op">~</span><span class="st"> </span>AtBat <span class="op">+</span><span class="st"> </span>Hits <span class="op">+</span><span class="st"> </span>Walks <span class="op">+</span><span class="st"> </span>CRBI <span class="op">+</span><span class="st"> </span>Division <span class="op">+</span><span class="st"> </span>PutOuts, <span class="dt">data =</span> train)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><em>Utilizar ese modelo para predecir en el conjunto de prueba.</em> El rendimiento en el conjunto de prueba es la estimación de CV para el rendimiento fuera de la muestra del modelo.</li>
</ol>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="ajuste-de-modelos.html#cb286-1"></a>results &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Model =</span> <span class="kw">c</span>(<span class="st">&quot;Modelo completo muestra entrenamiento&quot;</span>,</span>
<span id="cb286-2"><a href="ajuste-de-modelos.html#cb286-2"></a>                                <span class="st">&quot;Modelo seleccionado muestra entrenamiento&quot;</span>,</span>
<span id="cb286-3"><a href="ajuste-de-modelos.html#cb286-3"></a>                                <span class="st">&quot;Modelo completo muestra validación&quot;</span>,</span>
<span id="cb286-4"><a href="ajuste-de-modelos.html#cb286-4"></a>                                <span class="st">&quot;Modelo seleccionado muestra validación&quot;</span>),</span>
<span id="cb286-5"><a href="ajuste-de-modelos.html#cb286-5"></a>                      <span class="dt">RMSE =</span> <span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">rmse</span>(<span class="kw">fitted</span>(full_model), train<span class="op">$</span>Salary),</span>
<span id="cb286-6"><a href="ajuste-de-modelos.html#cb286-6"></a>                               <span class="kw">rmse</span>(<span class="kw">fitted</span>(select_model), train<span class="op">$</span>Salary),</span>
<span id="cb286-7"><a href="ajuste-de-modelos.html#cb286-7"></a>                               <span class="kw">rmse</span>(<span class="kw">predict</span>(full_model, <span class="dt">newdata =</span> test), test<span class="op">$</span>Salary), </span>
<span id="cb286-8"><a href="ajuste-de-modelos.html#cb286-8"></a>                               <span class="kw">rmse</span>(<span class="kw">predict</span>(select_model, <span class="dt">newdata =</span> test), test<span class="op">$</span>Salary)),<span class="dv">1</span>))</span>
<span id="cb286-9"><a href="ajuste-de-modelos.html#cb286-9"></a>results</span></code></pre></div>
<pre><code>##                                       Model  RMSE
## 1     Modelo completo muestra entrenamiento 297.8
## 2 Modelo seleccionado muestra entrenamiento 326.1
## 3        Modelo completo muestra validación 368.2
## 4    Modelo seleccionado muestra validación 306.4</code></pre>
<p>Podemos ver que el modelo completo está sobreajustado — el RMSE dentro de la muestra es mejor que el RMSE fuera de muestra — mientras que el modelo seleccionado elegido por <code>regsubsets ()</code> usando BIC no está sobreajustado. De hecho, el modelo seleccionado funciona mucho mejor fuera de la muestra que dentro de la muestra, aunque este resultado en particular es probablemente una cuestión de azar, una función de división aleatoria que estamos usando. Sin embargo, en general, estos resultados ilustran el peligro de la complejidad del modelo y por qué tiene sentido elegir predictores utilizando medidas de ajuste del modelo que penalicen la complejidad. Los modelos simples tienden a generalizar mejor. Esta figura muestra estas relaciones:</p>
<div class="figure">
<img src="figures/overfit.png" alt="" />
<p class="caption">Sobreajuste</p>
</div>
</div>
<div id="leave-one-out-cross-validation-loocv" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Leave-one-out cross validation (LOOCV)</h3>
<p>Este método funciona de la siguiente manera:</p>
<ul>
<li>Extrae una observación de los datos y usa el resto para entrenar el modelo</li>
<li>Testa el modelo con la observación que ha sido extraída en el paso anterior y guarda el error asociado a esa predicción</li>
<li>Repite el proceso para todos los puntos</li>
<li>Calcula el error de predicción global usando el promedio de todos los errores estimados en el paso 2.</li>
</ul>
<p>Veremos más adelante cómo hacer estos cálculos con una libería específica. De momento, para que aprendáis cómo funciona esta metodología, debéis realizar el siguiente ejercicio</p>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-LOOCV):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento de LOOCV y estima el valor de LOOCV para el modelo completo y el modelo seleccionado del ejemplo anterior.</td>
</tr>
</tbody>
</table>
</div>
<div id="k-fold-cross-validation-k-fold-cv" class="section level3" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> K-fold cross validation (K-fold CV)</h3>
<p>La diferencia con LOOCV es que este método evalúa el comportamiento del modelo en un conjunto de datos de distingo tamaño (K). El algoritmo es el siguiente:</p>
<ul>
<li>Separa los datos en k-subconjuntos (k-fold) de forma aleatoria</li>
<li>Guarda uno de los subconjuntos de datos y entrena el modelo con el resto de individuos</li>
<li>Testa el modelo con los datos resevados y guarda el error de predicción promedio.</li>
<li>Repite el proceso hasta que los k subconjuntos hayan servido de muestra test.</li>
<li>Calcula el promedio de los k errores que han sido guardados. Este valor es el error de cross-validación y nos sirve para evaluar el comportamiento de nuestro modelo como si lo usáramos en una base de datos externa.</li>
</ul>
<p>La principal ventaja de este método respecto a LOOCV es el coste computacional. Otra ventaja que no es tan obvia, es que este método a menudo da mejores estimaciones del error del modelo que LOOCV<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>Una pregunta típica es cómo se escoje el valor óptimo de K. Valores pequeños de K da estimaciones sesgadas. Por otro lado, valores grandes de K están menos sesgados, pero tienen mucha variabilidad. En la práctica, normalmente se usan valores de k = 5 or k = 10, ya que estos valores se han mostrado de forma empírica como los que tienen tasas de error estimadas no demasiado sesgadas ni con mucha varianza.</p>
<p>Al igual que en el caso anterior veremos unas liberías adecuadas para hacer estos análisis de forma eficiente. De momento realiza el siguiente ejercicio:</p>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-Kfold):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento de K-fold CV y estima el valor de K-fold CV para el modelo completo y el modelo seleccionado del ejemplo anterior. Haz que la función tenga un parámetro que dependa de K, y da los resultados para K=5 y K=10.</td>
</tr>
</tbody>
</table>
</div>
<div id="uso-de-cv-para-estimar-el-hiper-parámetro" class="section level3" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> Uso de CV para estimar el hiper-parámetro</h3>
<p>Si el algoritmo de aprendizaje automático que vamos a utilizar para realizar predicciones tiene un parámetro que controla el comportamiento (por ejemplo grado de polinomio en regresión no lineal, o el número de nodos en árboles de clasificación) éste podría elegirse de forma que minimizara el error de clasificación. Esta selección también puede dar problemas de sobre ajuste ya que podríamos seleccionar de forma que ajustara perféctamente a nuestros datos.</p>
<p>Para evitar el problema, se puede utilizar cualquiera de las técnicas vistas con anterioridad. Aquí tenemos un ejemplo donde se ha usado un modelo de aprendizaje que se basa en introducir términos polinómicos de varaibles para realizar una mejor predicción mediante regresión lineal usando sólo términos lineales.</p>
<div class="figure">
<img src="figures/cv_hyper.png" style="width:60.0%" alt="" />
<p class="caption">Sobreajuste según un hiper-parámetro</p>
</div>
</div>
<div id="uso-de-bootstrap" class="section level3" number="5.5.5">
<h3><span class="header-section-number">5.5.5</span> Uso de bootstrap</h3>
<p>Si en vez de partir nuestra muestra en <span class="math inline">\(K\)</span> submuestras, realizamos una selección aleatoria de muestras con reemplazamiento, nos encontraremos ante una aproximación de tipo <em>bootstrap</em> que es una técnica muy usada en estadística para hacer inferencia cuando la distribución del estadístico es desconocida basada en el remuestreo [<a href="https://biocosas.github.io/R/100_bootstrap.html">aquí</a> tenéis una descripción sencilla de esta metodología].</p>
<div class="figure">
<img src="figures/bootstrap_1.jpg" style="width:60.0%" alt="" />
<p class="caption">Boostrap</p>
</div>
<div class="figure">
<img src="figures/bootstrap_2.png" style="width:60.0%" alt="" />
<p class="caption">Boostrap</p>
</div>
<p>De manera que el procedimiento <em>bootstrap</em> aplicado a regresión sería:</p>
<ul>
<li>Sacar una muestra aleatoria con remplazamiento de tamaño <span class="math inline">\(n\)</span> de nuestros datos (tenemos <span class="math inline">\(n\)</span> observaciones)</li>
<li>Guardar las muestras que no han sido seleccionadas (datos de prueba)</li>
<li>Entrena el modelo con la muestra <em>bootstrap</em></li>
<li>Testa el modelo con los datos de prueba y guarda el error de predicción promedio.</li>
<li>Repite el proceso <span class="math inline">\(B\)</span> veces</li>
<li>Calcula el promedio de los <span class="math inline">\(B\)</span> errores que han sido guardados. Este valor es el error <em>bootstrap</em> y nos sirve para evaluar el comportamiento de nuestro modelo.</li>
</ul>
<table style="width:75%;">
<colgroup>
<col width="75%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>EJERCICIO</strong> (Entrega en Moodle: P2-bootstrap):</td>
</tr>
<tr class="even">
<td align="left">Crea una función R que lleve a cabo el procedimiento <em>boostrap</em> y estima el valor de este método para el modelo completo y el modelo seleccionado del ejemplo anterior. Haz que la función tenga un parámetro que dependa de <span class="math inline">\(B\)</span>, y da los resultados para B=25, B=50 y B=100. Comenta brevemente los resultados</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="imputación-de-datos-faltantes" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Imputación de datos faltantes</h2>
<p>La mayoría de métodos para aprendizaje automático requiren casos completos. Sin embargo, los datos reales a menudo tienen observaciones faltantes. La función <code>lm ()</code>, analiza casos completos sin indicar nada al usuario, pero … ¿Deberíamos eliminar estas filas o imputar las observaciones que faltan? Casi siempre es mejor imputar, aunque, en la práctica puede que no valga la pena imputar algunas observaciones faltantes, ya que eliminarlas no suele cambiar el ajuste en absoluto. La imputación de datos faltantes es un tema extenso y complicado; aquí haremos una breve introducción y discutiremos los principales temas a tener en cuenta.</p>
<p>Tipos de valores perdidos:</p>
<ul>
<li><p><em>Falta completamente al azar (MCAR por sus siglas en inglés)</em>: la probabilidad de que falte una observación es la misma para todos los casos. Eliminar los casos que faltan en esta instancia no causará sesgos, aunque es posible que perdamos información.</p></li>
<li><p><em>Missing at random (MAR pos sus siglas en inglés)</em>: la probabilidad de que falte una observación depende de un mecanismo conocido. Por ejemplo, es menos probable que algunos grupos respondan encuestas. Si conocemos la pertenencia a un grupo, podemos eliminar las observaciones faltantes siempre que incluyamos el grupo como factor en una regresión. Sin embargo, generalmente podemos hacer algo mejor que simplemente eliminar estos casos.</p></li>
<li><p><em>Missing not at random (MNAR por sus siglas en inglés) </em>: la probabilidad de que falte una observación depende de algún mecanismo desconocido — una variable no observada. Tratar los problemas del MNAR es difícil o incluso imposible.</p></li>
</ul>
<p>Nos centraremos en los problemas MAR. Una solución simple es completar o <em>imputar</em> los valores MAR. Hay dos estrategias principales:</p>
<p><strong>Imputación simple</strong> reemplaza los valores perdidos según una estadística univariante o un modelo de regresión multivariable. Existen muchas librerías que implementan diferentes métodos (en este curso veremos algunas). En la imputación con medianas imputamos los datos faltantes usando la mediana de la variable que presenta datos faltantes (La mediana es mejor que la media cuando los datos de la columna están sesgados). Podemos imputar también usando KNN o <em>random forest</em> creando un modelo multivariante de las observaciones faltantes usando otras variables y usar ese modelo para predecir los valores faltantes.</p>
<p>El problema con la imputación simple, teóricamente, es que la variabilidad de la variable imputada es menor de lo que habría sido la variabilidad en la variable real, creando un sesgo hacia 0 en los coeficientes. Por tanto, mientras que la eliminación pierde información, la imputación única puede provocar sesgos. (Sin embargo, no me queda claro cuán grande es este problema en la práctica).</p>
<p>La <strong>imputación múltiple</strong> aborda estos problemas imputando los valores faltantes con un modelo multivariante, pero agregando la variabilidad de nuevo al volver a incluir la variación del error que normalmente veríamos en los datos. El término “múltiple” en la imputación múltiple se refiere a los múltiples conjuntos de datos creados en el proceso de estimación de los coeficientes de regresión. Los pasos son los siguientes:</p>
<ol style="list-style-type: decimal">
<li><p>Crear <span class="math inline">\(m\)</span> conjuntos de datos completos con valores perdidos imputados. Las imputaciones se realizan extrayendo aleatoriamente distribuciones de valores plausibles para cada vector de columna (variables).</p></li>
<li><p>Ajustar un modelo lineal en cada conjunto de datos imputados y almacene <span class="math inline">\(\hat \beta\)</span>s y SE.</p></li>
<li><p>Promediar los <span class="math inline">\(\hat \beta\)</span>s y combinar los SE para producir coeficientes basados en múltiples conjuntos de datos imputados. Específicamente,</p></li>
</ol>
<p><span class="math display">\[\hat \beta_ {j} = \frac {1} {m} \sum_ {i} \hat \beta_ {ij}\]</span>
y</p>
<p><span class="math display">\[s ^ 2_j = \frac {1} {m} \sum_{i} s^2_{ij} + var \hat \beta_ {ij} (1 + 1 / m),\]</span></p>
<p>donde <span class="math inline">\(\hat \beta_{ij}\)</span> y <span class="math inline">\(s_{ij}\)</span> son las estimaciones y los errores estándar del resultado imputado <span class="math inline">\(i^{th}\)</span> para <span class="math inline">\(i=1, ..., m\)</span> y para el parámetro <span class="math inline">\(j^{th}\)</span>.</p>
<p>La imputación múltiple funciona mejor para la descripción que para la predicción, y probablemente sea preferible a la imputación única si sólo queremos estimar coeficientes. Para la predicción (como es el caso del aprendizaje automático), normalmente bastará con utilizar imputación simple.</p>
<p>Demostraremos métodos de imputación utilizando los datos de Carseats del paquete ISLR. Este es un conjunto de datos simulado de ventas de asientos de coche, del cual eliminaremos aleatoriamente el 25% de las observaciones usando la función <code>prodNA ()</code> en el paquete <code>missForest</code> (teniendo cuidado de dejar la variable de resultado, Sales, intacta).</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="ajuste-de-modelos.html#cb288-1"></a><span class="kw">library</span>(missForest)</span>
<span id="cb288-2"><a href="ajuste-de-modelos.html#cb288-2"></a><span class="kw">data</span>(Carseats)</span>
<span id="cb288-3"><a href="ajuste-de-modelos.html#cb288-3"></a><span class="kw">levels</span>(Carseats<span class="op">$</span>ShelveLoc) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Bad&quot;</span>,<span class="st">&quot;Medium&quot;</span>,<span class="st">&quot;Good&quot;</span>) <span class="co"># Reordenamos los niveles de la variable</span></span>
<span id="cb288-4"><a href="ajuste-de-modelos.html#cb288-4"></a></span>
<span id="cb288-5"><a href="ajuste-de-modelos.html#cb288-5"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb288-6"><a href="ajuste-de-modelos.html#cb288-6"></a>carseats_missx &lt;-<span class="st"> </span><span class="kw">prodNA</span>(Carseats[,<span class="op">-</span><span class="dv">1</span>], <span class="dt">noNA=</span>.<span class="dv">25</span>)</span>
<span id="cb288-7"><a href="ajuste-de-modelos.html#cb288-7"></a>carseats_miss &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">Sales=</span>Carseats[, <span class="dv">1</span>], carseats_missx)</span>
<span id="cb288-8"><a href="ajuste-de-modelos.html#cb288-8"></a><span class="kw">glimpse</span>(carseats_miss)</span></code></pre></div>
<pre><code>## Rows: 400
## Columns: 11
## $ Sales       &lt;dbl&gt; 9.50, 11.22, 10.06, 7.40, 4.15, 10.81, 6.63, 11.85, 6.54, 4.69, 9.01, 11.96, 3.98, 10.96, 11.17, 8.7...
## $ CompPrice   &lt;dbl&gt; 138, 111, 113, 117, 141, 124, 115, NA, NA, NA, 121, 117, NA, 115, 107, NA, 118, NA, 110, 129, 125, 1...
## $ Income      &lt;dbl&gt; 73, 48, 35, 100, 64, 113, NA, 81, 110, 113, 78, 94, NA, 28, 117, 95, 32, 74, 110, 76, NA, NA, 46, NA...
## $ Advertising &lt;dbl&gt; 11, 16, NA, 4, 3, 13, NA, 15, 0, 0, 9, 4, 2, NA, 11, 5, NA, 13, 0, 16, 2, 12, 6, 0, 16, 0, 11, 0, NA...
## $ Population  &lt;dbl&gt; 276, 260, 269, NA, 340, 501, 45, 425, 108, 131, 150, 503, NA, 29, 148, 400, 284, 251, 408, 58, 367, ...
## $ Price       &lt;dbl&gt; 120, NA, NA, 97, 128, 72, 108, 120, NA, 124, 100, NA, NA, NA, 118, 144, 110, 131, 68, 121, NA, 109, ...
## $ ShelveLoc   &lt;fct&gt; Bad, NA, Good, NA, Bad, Bad, Good, NA, Good, Good, Bad, Medium, NA, Medium, Medium, Good, Medium, Me...
## $ Age         &lt;dbl&gt; 42, 65, NA, 55, 38, NA, 71, 67, 76, 76, 26, 50, NA, 53, 52, 76, 63, 52, 46, 69, NA, NA, NA, 79, 42, ...
## $ Education   &lt;dbl&gt; NA, 10, 12, NA, 13, 16, 15, 10, 10, 17, 10, 13, NA, NA, NA, 18, 13, 10, 17, 12, 18, NA, NA, NA, 12, ...
## $ Urban       &lt;fct&gt; NA, Yes, Yes, Yes, Yes, NA, NA, Yes, No, NA, NA, Yes, Yes, Yes, Yes, No, Yes, Yes, No, NA, Yes, No, ...
## $ US          &lt;fct&gt; Yes, Yes, Yes, Yes, No, Yes, No, Yes, NA, Yes, Yes, Yes, No, Yes, Yes, No, No, NA, Yes, Yes, NA, Yes...</code></pre>
<p>Ahora faltan muchas observaciones. Cuando ajustamos un modelo de regresión para la variable Sales observamos que <code>lm ()</code> analiza casos completos y se estima un modelo basado en un subconjunto muy pequeño de datos.</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="ajuste-de-modelos.html#cb290-1"></a><span class="kw">display</span>(<span class="kw">lm</span>(Sales <span class="op">~</span><span class="st"> </span>CompPrice <span class="op">+</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Advertising <span class="op">+</span><span class="st"> </span>Population <span class="op">+</span><span class="st"> </span>Price, <span class="dt">data =</span> carseats_miss))</span></code></pre></div>
<pre><code>## lm(formula = Sales ~ CompPrice + Income + Advertising + Population + 
##     Price, data = carseats_miss)
##             coef.est coef.se
## (Intercept)  6.24     1.99  
## CompPrice    0.10     0.02  
## Income       0.01     0.01  
## Advertising  0.13     0.03  
## Population   0.00     0.00  
## Price       -0.11     0.01  
## ---
## n = 93, k = 6
## residual sd = 2.06, R-Squared = 0.59</code></pre>
<p>Sólo tenemos 93 observaciones de las 400 originales! Demostraremos la imputación múltiple usando la función <code>mice ()</code> de la librería <code>mice</code>.</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="ajuste-de-modelos.html#cb292-1"></a><span class="kw">library</span>(mice)</span>
<span id="cb292-2"><a href="ajuste-de-modelos.html#cb292-2"></a><span class="kw">names</span>(Carseats)</span></code></pre></div>
<pre><code>##  [1] &quot;Sales&quot;       &quot;CompPrice&quot;   &quot;Income&quot;      &quot;Advertising&quot; &quot;Population&quot;  &quot;Price&quot;       &quot;ShelveLoc&quot;   &quot;Age&quot;        
##  [9] &quot;Education&quot;   &quot;Urban&quot;       &quot;US&quot;</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="ajuste-de-modelos.html#cb294-1"></a>carseats_imp &lt;-<span class="st"> </span><span class="kw">mice</span>(carseats_miss, <span class="dt">printFlag =</span> F)</span></code></pre></div>
<p>El objeto <code>carseats_imp</code> incluye (entre muchas otras cosas) <span class="math inline">\(m\)</span> conjuntos de datos imputados (la configuración predeterminada es <span class="math inline">\(m\)</span> = 5). Los conjuntos de datos imputados difieren porque las imputaciones se extraen aleatoriamente de distribuciones de valores plausibles. Podemos visualizar la variabilidad de los predictores en estos conjuntos de datos imputados usando la función <code>densityplot ()</code>.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="ajuste-de-modelos.html#cb295-1"></a><span class="kw">library</span>(lattice)</span>
<span id="cb295-2"><a href="ajuste-de-modelos.html#cb295-2"></a><span class="kw">densityplot</span>(carseats_imp)</span></code></pre></div>
<p><img src="fig/unnamed-chunk-85-1.png" width="672" /></p>
<p>Las líneas azules continuas representan la distribución real de los predictores, mientras que las líneas rojas muestran las distribuciones imputadas. El siguiente paso es usar estos conjuntos de datos imputados para promediar los <span class="math inline">\(\beta\)</span>s y los SE utilizando la función <code>pool ()</code> de la librería <code>mice</code>.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="ajuste-de-modelos.html#cb296-1"></a>carseats_model_imp &lt;-<span class="st"> </span><span class="kw">with</span>(<span class="dt">data =</span> carseats_imp, </span>
<span id="cb296-2"><a href="ajuste-de-modelos.html#cb296-2"></a>     <span class="dt">exp =</span> <span class="kw">lm</span>(Sales <span class="op">~</span><span class="st"> </span>CompPrice <span class="op">+</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Advertising <span class="op">+</span><span class="st"> </span>Population <span class="op">+</span><span class="st"> </span>Price))</span>
<span id="cb296-3"><a href="ajuste-de-modelos.html#cb296-3"></a>mi &lt;-<span class="st"> </span><span class="kw">summary</span>(<span class="kw">pool</span>(carseats_model_imp))</span></code></pre></div>
<p>Estos coeficientes son similares a los del modelo anterior ajustado utilizando los datos no imputados, pero deberían estar más cerca de los valores de la población porque, en lugar de simplemente eliminar los casos incompletos, utiliza información de distribución para hacer suposiciones fundamentadas sobre los datos faltantes. La imputación múltiple funciona mejor para fines de descripción — estimar coeficientes para informar en un artículo académico, por ejemplo — pero usarla para predecir nuevos datos es incómodo o imposible, por las siguientes razones:</p>
<ul>
<li>Si los nuevos datos están completos, podemos utilizar las estimaciones de coeficientes derivadas de la imputación múltiple en una ecuación de regresión para la predicción. Pero esto es difícil ya que hay que hacerlo manualmente. Usamos los datos originales de Carseats como ilustración.</li>
</ul>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="ajuste-de-modelos.html#cb297-1"></a>preds &lt;-<span class="st"> </span>mi[<span class="dv">1</span>, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span></span>
<span id="cb297-2"><a href="ajuste-de-modelos.html#cb297-2"></a><span class="st">  </span>mi[<span class="dv">2</span>, <span class="dv">2</span>]<span class="op">*</span>Carseats<span class="op">$</span>CompPrice <span class="op">+</span></span>
<span id="cb297-3"><a href="ajuste-de-modelos.html#cb297-3"></a><span class="st">  </span>mi[<span class="dv">3</span>, <span class="dv">2</span>]<span class="op">*</span>Carseats<span class="op">$</span>Income <span class="op">+</span></span>
<span id="cb297-4"><a href="ajuste-de-modelos.html#cb297-4"></a><span class="st">  </span>mi[<span class="dv">4</span>, <span class="dv">2</span>]<span class="op">*</span>Carseats<span class="op">$</span>Advertising <span class="op">+</span></span>
<span id="cb297-5"><a href="ajuste-de-modelos.html#cb297-5"></a><span class="st">  </span>mi[<span class="dv">5</span>, <span class="dv">2</span>]<span class="op">*</span>Carseats<span class="op">$</span>Population <span class="op">+</span></span>
<span id="cb297-6"><a href="ajuste-de-modelos.html#cb297-6"></a><span class="st">  </span>mi[<span class="dv">6</span>, <span class="dv">2</span>]<span class="op">*</span>Carseats<span class="op">$</span>Price</span>
<span id="cb297-7"><a href="ajuste-de-modelos.html#cb297-7"></a>  </span>
<span id="cb297-8"><a href="ajuste-de-modelos.html#cb297-8"></a>   </span>
<span id="cb297-9"><a href="ajuste-de-modelos.html#cb297-9"></a><span class="kw">head</span>(preds)</span></code></pre></div>
<pre><code>## [1]  8.989509 10.150578  9.645498  8.405464  7.306136 12.735945</code></pre>
<ul>
<li>Si los nuevos datos no están completos, entonces estos coeficientes imputados son inútiles para predecir en filas con observaciones faltantes. Esto, por ejemplo, es el resultado de intentar predecir utilizando los datos con observaciones faltantes.</li>
</ul>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="ajuste-de-modelos.html#cb299-1"></a>preds &lt;-<span class="st"> </span>mi[<span class="dv">1</span>, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span></span>
<span id="cb299-2"><a href="ajuste-de-modelos.html#cb299-2"></a><span class="st">  </span>mi[<span class="dv">2</span>, <span class="dv">2</span>]<span class="op">*</span>carseats_miss<span class="op">$</span>CompPrice <span class="op">+</span></span>
<span id="cb299-3"><a href="ajuste-de-modelos.html#cb299-3"></a><span class="st">  </span>mi[<span class="dv">3</span>, <span class="dv">2</span>]<span class="op">*</span>carseats_miss<span class="op">$</span>Income <span class="op">+</span></span>
<span id="cb299-4"><a href="ajuste-de-modelos.html#cb299-4"></a><span class="st">  </span>mi[<span class="dv">4</span>, <span class="dv">2</span>]<span class="op">*</span>carseats_miss<span class="op">$</span>Advertising <span class="op">+</span></span>
<span id="cb299-5"><a href="ajuste-de-modelos.html#cb299-5"></a><span class="st">  </span>mi[<span class="dv">5</span>, <span class="dv">2</span>]<span class="op">*</span>carseats_miss<span class="op">$</span>Population <span class="op">+</span></span>
<span id="cb299-6"><a href="ajuste-de-modelos.html#cb299-6"></a><span class="st">  </span>mi[<span class="dv">6</span>, <span class="dv">2</span>]<span class="op">*</span>carseats_miss<span class="op">$</span>Price</span>
<span id="cb299-7"><a href="ajuste-de-modelos.html#cb299-7"></a>  </span>
<span id="cb299-8"><a href="ajuste-de-modelos.html#cb299-8"></a>   </span>
<span id="cb299-9"><a href="ajuste-de-modelos.html#cb299-9"></a><span class="kw">head</span>(preds)</span></code></pre></div>
<pre><code>## [1]  8.989509        NA        NA        NA  7.306136 12.735945</code></pre>
<ul>
<li><p>La imputación múltiple, por lo tanto, no resuelve el principal problema al que nos enfrentamos a menudo con los datos faltantes, que es que, aunque hayamos ajustado con éxito un modelo en nuestros datos, el conjunto de validación también puede tener observaciones faltantes, y nuestras predicciones utilizando esos datos puede no poder realizarse.</p></li>
<li><p>Podríamos usar uno de los conjuntos de datos imputados, pero entonces ya no estamos haciendo imputación múltiple sino imputación simple. En ese momento, los métodos disponibles en el paquete <code>mice</code> ya no ofrecen ninguna ventaja especial sobre los de los paquetes <code>caret</code> y <code>missForest</code>. De hecho, podrían ser peores ya que la función <code>mice ()</code> no fue diseñado para producir la mejor imputación individual, sino más bien una gama de imputaciones plausibles.</p></li>
</ul>
<p>Usando <code>caret</code>, podemos hacer una imputación simple usando knnImpute, medianImpute o bagImpute. Estos métodos solo funcionan para variables numéricas, por lo que crearemos una función personalizada para convertir los factores — Shelveloc, Urban y US — en números enteros. (Al usar el conjunto de datos imputados para la regresión, podríamos dejar estas variables como números enteros, siempre que los valores enteros correspondan a los niveles de los factores).</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="ajuste-de-modelos.html#cb301-1"></a>make_df_numeric &lt;-<span class="st"> </span><span class="cf">function</span>(df){</span>
<span id="cb301-2"><a href="ajuste-de-modelos.html#cb301-2"></a>  <span class="kw">data.frame</span>(<span class="kw">sapply</span>(df, <span class="cf">function</span>(x) <span class="kw">as.numeric</span>(x)))</span>
<span id="cb301-3"><a href="ajuste-de-modelos.html#cb301-3"></a>  }</span>
<span id="cb301-4"><a href="ajuste-de-modelos.html#cb301-4"></a>carseats_miss_num &lt;-<span class="st"> </span><span class="kw">make_df_numeric</span>(carseats_miss)</span>
<span id="cb301-5"><a href="ajuste-de-modelos.html#cb301-5"></a>med_imp &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">preProcess</span>(carseats_miss_num, <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;medianImpute&quot;</span>)), carseats_miss_num)</span>
<span id="cb301-6"><a href="ajuste-de-modelos.html#cb301-6"></a>knn_imp &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">preProcess</span>(carseats_miss_num, <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;knnImpute&quot;</span>)), carseats_miss_num)</span>
<span id="cb301-7"><a href="ajuste-de-modelos.html#cb301-7"></a>bag_imp &lt;-<span class="st"> </span><span class="kw">predict</span>(<span class="kw">preProcess</span>(carseats_miss_num, <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;bagImpute&quot;</span>)), carseats_miss_num)</span></code></pre></div>
<p>El paquete <code>missForest</code> ofrece otra solución de imputación única, que es más simple que las funciones de <code>caret</code> porque maneja datos categóricos automáticamente. Si bien <code>missForest</code> funciona bien para conjuntos de datos pequeños y proporciona imputaciones de buena calidad, es muy lento en conjuntos de datos grandes. De hecho, lo mismo ocurrirá con la función <code>bagImpute ()</code> de <code>caret</code>. En tales casos, podría tener sentido usar la función <code>medianImpute ()</code> de <code>caret</code> en su lugar que es muy rápida.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="ajuste-de-modelos.html#cb302-1"></a>mf_imp &lt;-<span class="st"> </span><span class="kw">missForest</span>(carseats_miss, <span class="dt">verbose =</span> F)</span></code></pre></div>
<pre><code>##   missForest iteration 1 in progress...done!
##   missForest iteration 2 in progress...done!
##   missForest iteration 3 in progress...done!
##   missForest iteration 4 in progress...done!
##   missForest iteration 5 in progress...done!</code></pre>
<p>Comparemos los errores asociados con estos diferentes métodos de imputación. Podemos hacer esto porque, habiendo creado las observaciones faltantes en primer lugar, podemos comparar las observaciones imputadas con las observaciones verdaderas calculando la suma de los cuadrados de la diferencia. Para las imputaciones usando <code>mice ()</code> calculamos los errores para cada uno de los 5 conjuntos de datos imputados. Los resultados de <code>knnImpute ()</code> no son comparables porque la función automáticamente centra y escala las variables y los hemos omitido.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="ajuste-de-modelos.html#cb304-1"></a>comparison &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Method =</span> <span class="kw">c</span>(<span class="st">&quot;mice 1&quot;</span>, </span>
<span id="cb304-2"><a href="ajuste-de-modelos.html#cb304-2"></a>                                    <span class="st">&quot;mice 2&quot;</span>, </span>
<span id="cb304-3"><a href="ajuste-de-modelos.html#cb304-3"></a>                                    <span class="st">&quot;mice 3&quot;</span>, </span>
<span id="cb304-4"><a href="ajuste-de-modelos.html#cb304-4"></a>                                    <span class="st">&quot;mice 4&quot;</span>, </span>
<span id="cb304-5"><a href="ajuste-de-modelos.html#cb304-5"></a>                                    <span class="st">&quot;mice 5&quot;</span>, </span>
<span id="cb304-6"><a href="ajuste-de-modelos.html#cb304-6"></a>                                    <span class="st">&quot;medianImpute&quot;</span>, </span>
<span id="cb304-7"><a href="ajuste-de-modelos.html#cb304-7"></a>                                    <span class="st">&quot;bagImpute&quot;</span>, </span>
<span id="cb304-8"><a href="ajuste-de-modelos.html#cb304-8"></a>                                    <span class="st">&quot;missForest&quot;</span>),</span>
<span id="cb304-9"><a href="ajuste-de-modelos.html#cb304-9"></a>                         <span class="dt">RSS =</span> <span class="kw">c</span>(<span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(<span class="kw">complete</span>(carseats_imp, <span class="dv">1</span>)), <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-10"><a href="ajuste-de-modelos.html#cb304-10"></a>                                 <span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(<span class="kw">complete</span>(carseats_imp, <span class="dv">2</span>)), <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-11"><a href="ajuste-de-modelos.html#cb304-11"></a>                                 <span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(<span class="kw">complete</span>(carseats_imp, <span class="dv">3</span>)), <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-12"><a href="ajuste-de-modelos.html#cb304-12"></a>                                 <span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(<span class="kw">complete</span>(carseats_imp, <span class="dv">4</span>)), <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-13"><a href="ajuste-de-modelos.html#cb304-13"></a>                                 <span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(<span class="kw">complete</span>(carseats_imp, <span class="dv">5</span>)), <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-14"><a href="ajuste-de-modelos.html#cb304-14"></a>                                 <span class="kw">rss</span>(med_imp, <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-15"><a href="ajuste-de-modelos.html#cb304-15"></a>                                 <span class="kw">rss</span>(bag_imp, <span class="kw">make_df_numeric</span>(Carseats)),</span>
<span id="cb304-16"><a href="ajuste-de-modelos.html#cb304-16"></a>                                 <span class="kw">rss</span>(<span class="kw">make_df_numeric</span>(mf_imp<span class="op">$</span>ximp), <span class="kw">make_df_numeric</span>(Carseats))))</span>
<span id="cb304-17"><a href="ajuste-de-modelos.html#cb304-17"></a>                         </span>
<span id="cb304-18"><a href="ajuste-de-modelos.html#cb304-18"></a>comparison <span class="op">%&gt;%</span></span>
<span id="cb304-19"><a href="ajuste-de-modelos.html#cb304-19"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">RSS =</span> <span class="kw">round</span>(RSS)) <span class="op">%&gt;%</span></span>
<span id="cb304-20"><a href="ajuste-de-modelos.html#cb304-20"></a><span class="st">  </span><span class="kw">arrange</span>(RSS)</span></code></pre></div>
<pre><code>##         Method     RSS
## 1   missForest 2489418
## 2 medianImpute 2538059
## 3    bagImpute 2714857
## 4       mice 4 3752513
## 5       mice 5 4389532
## 6       mice 2 4399586
## 7       mice 1 4564721
## 8       mice 3 4791521</code></pre>
<p><code>missforest</code> obtiene los mejores resultados, aunque medianImpute compara muy bien. Los resultados de <code>mice</code> no son muy buenos, probablemente por las razones mencionadas anteriormente: está diseñado para una imputación múltiple, no simple.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>James et al. 2014<a href="ajuste-de-modelos.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regresión-lineal.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regresión-logística.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/isglobal-brge/Aprendizaje_Automatico_1/tree/master/docs04-creacion_modelos.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
