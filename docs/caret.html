<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 La librería caret | Aprendizaje Automático 1</title>
  <meta name="description" content="8 La librería caret | Aprendizaje Automático 1" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="8 La librería caret | Aprendizaje Automático 1" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 La librería caret | Aprendizaje Automático 1" />
  
  
  

<meta name="author" content="Juan R González" />


<meta name="date" content="2021-09-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dealing-with-big-data-in-r.html"/>
<link rel="next" href="KNN.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Aprendizaje Automático 1</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html"><i class="fa fa-check"></i><b>2</b> Introducción a Tidyverse</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#introducción-1"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#instalación"><i class="fa fa-check"></i><b>2.2</b> Instalación</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#librerías-básicas"><i class="fa fa-check"></i><b>2.3</b> Librerías básicas</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#manejo-de-datos"><i class="fa fa-check"></i><b>2.4</b> Manejo de datos</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#tibbles"><i class="fa fa-check"></i><b>2.4.1</b> Tibbles</a></li>
<li class="chapter" data-level="2.4.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#importar-datos"><i class="fa fa-check"></i><b>2.4.2</b> Importar datos</a></li>
<li class="chapter" data-level="2.4.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#transformación-de-datos"><i class="fa fa-check"></i><b>2.4.3</b> Transformación de datos</a></li>
<li class="chapter" data-level="2.4.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#filtrar-filas"><i class="fa fa-check"></i><b>2.4.4</b> Filtrar filas</a></li>
<li class="chapter" data-level="2.4.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#filtrado-lógico"><i class="fa fa-check"></i><b>2.4.5</b> Filtrado lógico</a></li>
<li class="chapter" data-level="2.4.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ordenar-filas"><i class="fa fa-check"></i><b>2.4.6</b> Ordenar filas</a></li>
<li class="chapter" data-level="2.4.7" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#seleccionar-columnas-e.g.-variables"><i class="fa fa-check"></i><b>2.4.7</b> Seleccionar columnas (e.g. variables)</a></li>
<li class="chapter" data-level="2.4.8" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#añadir-nuevas-variables"><i class="fa fa-check"></i><b>2.4.8</b> Añadir nuevas variables</a></li>
<li class="chapter" data-level="2.4.9" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#grouped-summaries"><i class="fa fa-check"></i><b>2.4.9</b> Grouped summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#uso-del-pipe"><i class="fa fa-check"></i><b>2.5</b> Uso del pipe <code>%&gt;%</code></a></li>
<li class="chapter" data-level="2.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ejercicios-manejo-de-datos"><i class="fa fa-check"></i><b>2.6</b> Ejercicios (manejo de datos)</a></li>
<li class="chapter" data-level="2.7" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#visualización-de-datos"><i class="fa fa-check"></i><b>2.7</b> Visualización de datos</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-categóricos"><i class="fa fa-check"></i><b>2.7.1</b> Distribución de datos categóricos</a></li>
<li class="chapter" data-level="2.7.2" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-continuos"><i class="fa fa-check"></i><b>2.7.2</b> Distribución de datos continuos</a></li>
<li class="chapter" data-level="2.7.3" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#distribución-de-datos-continuos-según-una-variable-categórica"><i class="fa fa-check"></i><b>2.7.3</b> Distribución de datos continuos según una variable categórica</a></li>
<li class="chapter" data-level="2.7.4" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#dos-variables-categóricas"><i class="fa fa-check"></i><b>2.7.4</b> Dos variables categóricas</a></li>
<li class="chapter" data-level="2.7.5" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#dos-variables-continuas"><i class="fa fa-check"></i><b>2.7.5</b> Dos variables continuas</a></li>
<li class="chapter" data-level="2.7.6" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#facets"><i class="fa fa-check"></i><b>2.7.6</b> Facets</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="introducción-a-tidyverse.html"><a href="introducción-a-tidyverse.html#ejercicios-visualización-de-datos"><i class="fa fa-check"></i><b>2.8</b> Ejercicios (Visualización de datos)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introducción-al-aprendizaje-automático.html"><a href="introducción-al-aprendizaje-automático.html"><i class="fa fa-check"></i><b>3</b> Introducción al Aprendizaje Automático</a></li>
<li class="chapter" data-level="4" data-path="regresión-lineal.html"><a href="regresión-lineal.html"><i class="fa fa-check"></i><b>4</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#preliminares"><i class="fa fa-check"></i><b>4.1</b> Preliminares</a></li>
<li class="chapter" data-level="4.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#conceptos-básicos"><i class="fa fa-check"></i><b>4.2</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#modelo-lineal-simple"><i class="fa fa-check"></i><b>4.2.1</b> Modelo lineal simple</a></li>
<li class="chapter" data-level="4.2.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#regresión-lineal-multivariante"><i class="fa fa-check"></i><b>4.2.2</b> Regresión lineal multivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#incertidumbre"><i class="fa fa-check"></i><b>4.2.3</b> Incertidumbre</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ajuste-de-un-modelo-lineal"><i class="fa fa-check"></i><b>4.3</b> Ajuste de un modelo lineal</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#residuos"><i class="fa fa-check"></i><b>4.3.1</b> Residuos</a></li>
<li class="chapter" data-level="4.3.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-de-coeficientes"><i class="fa fa-check"></i><b>4.3.2</b> Interpretación de coeficientes</a></li>
<li class="chapter" data-level="4.3.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interacciones"><i class="fa fa-check"></i><b>4.3.3</b> Interacciones</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-por-mínimos-cuadrados"><i class="fa fa-check"></i><b>4.4</b> Estimación por mínimos cuadrados</a></li>
<li class="chapter" data-level="4.5" data-path="regresión-lineal.html"><a href="regresión-lineal.html#medidas-adicionales-de-ajuste-del-modelo"><i class="fa fa-check"></i><b>4.5</b> Medidas adicionales de ajuste del modelo</a></li>
<li class="chapter" data-level="4.6" data-path="regresión-lineal.html"><a href="regresión-lineal.html#sesgo-variación-sobreajuste"><i class="fa fa-check"></i><b>4.6</b> Sesgo, variación, sobreajuste</a></li>
<li class="chapter" data-level="4.7" data-path="regresión-lineal.html"><a href="regresión-lineal.html#regresión-como-estimación-de-una-media-condicional"><i class="fa fa-check"></i><b>4.7</b> Regresión como estimación de una media condicional</a></li>
<li class="chapter" data-level="4.8" data-path="regresión-lineal.html"><a href="regresión-lineal.html#la-función-de-regresión"><i class="fa fa-check"></i><b>4.8</b> La función de regresión</a></li>
<li class="chapter" data-level="4.9" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-no-paramétrica-de-la-función-de-regresión-regresión-knn"><i class="fa fa-check"></i><b>4.9</b> Estimación no paramétrica de la función de regresión: regresión KNN</a></li>
<li class="chapter" data-level="4.10" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-paramétrica-de-la-función-de-regresión-regresión-lineal"><i class="fa fa-check"></i><b>4.10</b> Estimación paramétrica de la función de regresión: regresión lineal</a></li>
<li class="chapter" data-level="4.11" data-path="regresión-lineal.html"><a href="regresión-lineal.html#predicción"><i class="fa fa-check"></i><b>4.11</b> Predicción</a></li>
<li class="chapter" data-level="4.12" data-path="regresión-lineal.html"><a href="regresión-lineal.html#inferencia-en-el-contexto-de-regresión"><i class="fa fa-check"></i><b>4.12</b> Inferencia en el contexto de regresión</a></li>
<li class="chapter" data-level="4.13" data-path="regresión-lineal.html"><a href="regresión-lineal.html#asunciones-de-un-modelo-de-regresión"><i class="fa fa-check"></i><b>4.13</b> Asunciones de un modelo de regresión</a></li>
<li class="chapter" data-level="4.14" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ejemplos-adicionales-de-interpretación-de-modelos"><i class="fa fa-check"></i><b>4.14</b> Ejemplos adicionales de interpretación de modelos</a>
<ul>
<li class="chapter" data-level="4.14.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos"><i class="fa fa-check"></i><b>4.14.1</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos</a></li>
<li class="chapter" data-level="4.14.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos"><i class="fa fa-check"></i><b>4.14.2</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos</a></li>
<li class="chapter" data-level="4.14.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-binarios-y-continuos-con-interacciones"><i class="fa fa-check"></i><b>4.14.3</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores binarios y continuos, con interacciones</a></li>
<li class="chapter" data-level="4.14.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#interpretación-del-intercept-y-los-coeficientes-beta-para-un-modelo-con-predictores-continuos-con-interacciones"><i class="fa fa-check"></i><b>4.14.4</b> Interpretación del <em>intercept</em> y los coeficientes <span class="math inline">\(\beta\)</span> para un modelo con predictores continuos, con interacciones</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="regresión-lineal.html"><a href="regresión-lineal.html#centrado-y-escalado"><i class="fa fa-check"></i><b>4.15</b> Centrado y escalado</a></li>
<li class="chapter" data-level="4.16" data-path="regresión-lineal.html"><a href="regresión-lineal.html#transformación-de-variables"><i class="fa fa-check"></i><b>4.16</b> Transformación de variables</a></li>
<li class="chapter" data-level="4.17" data-path="regresión-lineal.html"><a href="regresión-lineal.html#colinealidad"><i class="fa fa-check"></i><b>4.17</b> Colinealidad</a></li>
<li class="chapter" data-level="4.18" data-path="regresión-lineal.html"><a href="regresión-lineal.html#valores-atípicos"><i class="fa fa-check"></i><b>4.18</b> Valores atípicos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html"><i class="fa fa-check"></i><b>5</b> Ajuste de modelos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#reglas-generales-para-la-selección-de-variables"><i class="fa fa-check"></i><b>5.1</b> Reglas generales para la selección de variables</a></li>
<li class="chapter" data-level="5.2" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#selección-paso-a-paso-stepwise"><i class="fa fa-check"></i><b>5.2</b> Selección paso a paso (stepwise)</a></li>
<li class="chapter" data-level="5.3" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#comparación-de-modelos"><i class="fa fa-check"></i><b>5.3</b> Comparación de modelos</a></li>
<li class="chapter" data-level="5.4" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#métodos-de-selección-automática"><i class="fa fa-check"></i><b>5.4</b> Métodos de selección automática</a></li>
<li class="chapter" data-level="5.5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#validación-cruzada"><i class="fa fa-check"></i><b>5.5</b> Validación cruzada</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#validación-en-un-conjunto-de-datos-externo"><i class="fa fa-check"></i><b>5.5.1</b> Validación en un conjunto de datos externo</a></li>
<li class="chapter" data-level="5.5.2" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>5.5.2</b> Leave-one-out cross validation (LOOCV)</a></li>
<li class="chapter" data-level="5.5.3" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#k-fold-cross-validation-k-fold-cv"><i class="fa fa-check"></i><b>5.5.3</b> K-fold cross validation (K-fold CV)</a></li>
<li class="chapter" data-level="5.5.4" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#uso-de-cv-para-estimar-el-hiper-parámetro"><i class="fa fa-check"></i><b>5.5.4</b> Uso de CV para estimar el hiper-parámetro</a></li>
<li class="chapter" data-level="5.5.5" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#uso-de-bootstrap"><i class="fa fa-check"></i><b>5.5.5</b> Uso de bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="ajuste-de-modelos.html"><a href="ajuste-de-modelos.html#imputación-de-datos-faltantes"><i class="fa fa-check"></i><b>5.6</b> Imputación de datos faltantes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>6</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#la-función-logit-inversa"><i class="fa fa-check"></i><b>6.1</b> La función logit inversa</a></li>
<li class="chapter" data-level="6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística"><i class="fa fa-check"></i><b>6.2</b> Ejemplo de regresión logística</a></li>
<li class="chapter" data-level="6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-probabilidades"><i class="fa fa-check"></i><b>6.3</b> Coeficientes de regresión logística como probabilidades</a></li>
<li class="chapter" data-level="6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-razones-de-odds"><i class="fa fa-check"></i><b>6.4</b> Coeficientes de regresión logística como razones de odds</a></li>
<li class="chapter" data-level="6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#bondad-de-ajuste"><i class="fa fa-check"></i><b>6.5</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="6.6" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes"><i class="fa fa-check"></i><b>6.6</b> Ejemplo de regresión logística: modelización de riesgo diabetes</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#modelo-simple"><i class="fa fa-check"></i><b>6.6.1</b> Modelo simple</a></li>
<li class="chapter" data-level="6.6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#agregar-predictores-y-evaluar-el-ajuste"><i class="fa fa-check"></i><b>6.6.2</b> Agregar predictores y evaluar el ajuste</a></li>
<li class="chapter" data-level="6.6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#análisis-de-interacciones"><i class="fa fa-check"></i><b>6.6.3</b> Análisis de interacciones</a></li>
<li class="chapter" data-level="6.6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#gráfico-de-la-interacción"><i class="fa fa-check"></i><b>6.6.4</b> Gráfico de la interacción</a></li>
<li class="chapter" data-level="6.6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#uso-del-modelo-para-predecir-probabilidades"><i class="fa fa-check"></i><b>6.6.5</b> Uso del modelo para predecir probabilidades</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="regresión-logística.html"><a href="regresión-logística.html#creación-de-un-modelo-y-validación"><i class="fa fa-check"></i><b>6.7</b> Creación de un modelo y validación</a></li>
<li class="chapter" data-level="6.8" data-path="regresión-logística.html"><a href="regresión-logística.html#nomogramas"><i class="fa fa-check"></i><b>6.8</b> Nomogramas</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html"><i class="fa fa-check"></i><b>7</b> Dealing with Big Data in R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#nodes-cores-processes-and-threads"><i class="fa fa-check"></i><b>7.1</b> Nodes, cores, processes and threads</a></li>
<li class="chapter" data-level="7.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#paralelización"><i class="fa fa-check"></i><b>7.2</b> Paralelización</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#shared-memory-programming"><i class="fa fa-check"></i><b>7.2.1</b> Shared Memory Programming</a></li>
<li class="chapter" data-level="7.2.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#distributed-memory-programming"><i class="fa fa-check"></i><b>7.2.2</b> Distributed Memory Programming</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#mapreduce"><i class="fa fa-check"></i><b>7.3</b> MapReduce</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#map"><i class="fa fa-check"></i><b>7.3.1</b> Map</a></li>
<li class="chapter" data-level="7.3.2" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#reduce"><i class="fa fa-check"></i><b>7.3.2</b> Reduce</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="dealing-with-big-data-in-r.html"><a href="dealing-with-big-data-in-r.html#example-linear-regression-for-big-data"><i class="fa fa-check"></i><b>7.4</b> Example: Linear regression for Big Data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>8</b> La librería <code>caret</code></a>
<ul>
<li class="chapter" data-level="8.1" data-path="caret.html"><a href="caret.html#pre-procesado"><i class="fa fa-check"></i><b>8.1</b> Pre-procesado</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="caret.html"><a href="caret.html#creación-de-variables"><i class="fa fa-check"></i><b>8.1.1</b> Creación de variables</a></li>
<li class="chapter" data-level="8.1.2" data-path="caret.html"><a href="caret.html#predictores-con-poca-variabilidad"><i class="fa fa-check"></i><b>8.1.2</b> Predictores con poca variabilidad</a></li>
<li class="chapter" data-level="8.1.3" data-path="caret.html"><a href="caret.html#identificación-de-predictores-correlacionados"><i class="fa fa-check"></i><b>8.1.3</b> Identificación de predictores correlacionados</a></li>
<li class="chapter" data-level="8.1.4" data-path="caret.html"><a href="caret.html#centrado-y-escalado-1"><i class="fa fa-check"></i><b>8.1.4</b> Centrado y escalado</a></li>
<li class="chapter" data-level="8.1.5" data-path="caret.html"><a href="caret.html#imputación"><i class="fa fa-check"></i><b>8.1.5</b> Imputación</a></li>
<li class="chapter" data-level="8.1.6" data-path="caret.html"><a href="caret.html#pre-procesado-con-la-librería-recipes"><i class="fa fa-check"></i><b>8.1.6</b> Pre-procesado con la librería <code>recipes</code></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="caret.html"><a href="caret.html#visualización"><i class="fa fa-check"></i><b>8.2</b> Visualización</a></li>
<li class="chapter" data-level="8.3" data-path="caret.html"><a href="caret.html#ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama"><i class="fa fa-check"></i><b>8.3</b> Ejemplo completo: creación de modelo diagnóstico para cáncer de mama</a></li>
<li class="chapter" data-level="8.4" data-path="caret.html"><a href="caret.html#creación-de-un-modelo-predictivo"><i class="fa fa-check"></i><b>8.4</b> Creación de un modelo predictivo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="KNN.html"><a href="KNN.html"><i class="fa fa-check"></i><b>9</b> K vecinos más próximos (KNN)</a></li>
<li class="chapter" data-level="10" data-path="análisis-discriminante-lineal-lda.html"><a href="análisis-discriminante-lineal-lda.html"><i class="fa fa-check"></i><b>10</b> Análisis discriminante lineal (LDA)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="análisis-discriminante-lineal-lda.html"><a href="análisis-discriminante-lineal-lda.html#concurso-predicción-de-actividad-física-con-sensores"><i class="fa fa-check"></i><b>10.1</b> Concurso predicción de actividad física con sensores</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>11</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="11.1" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#clasificador-de-margen-máximo"><i class="fa fa-check"></i><b>11.1</b> Clasificador de margen máximo</a></li>
<li class="chapter" data-level="11.2" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#clasificador-de-soporte-vectorial"><i class="fa fa-check"></i><b>11.2</b> Clasificador de soporte vectorial</a></li>
<li class="chapter" data-level="11.3" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#máquinas-de-soporte-vectorial-1"><i class="fa fa-check"></i><b>11.3</b> Máquinas de soporte vectorial</a></li>
<li class="chapter" data-level="11.4" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#svm-con-e1071"><i class="fa fa-check"></i><b>11.4</b> SVM con <code>e1071</code></a></li>
<li class="chapter" data-level="11.5" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#svm-con-caret"><i class="fa fa-check"></i><b>11.5</b> SVM con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="respuesta-no-balanceada.html"><a href="respuesta-no-balanceada.html"><i class="fa fa-check"></i><b>12</b> Respuesta no balanceada</a></li>
<li class="chapter" data-level="13" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html"><i class="fa fa-check"></i><b>13</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="13.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#árboles-de-clasificación"><i class="fa fa-check"></i><b>13.1</b> Árboles de clasificación</a></li>
<li class="chapter" data-level="13.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#área-bajo-la-curva-roc"><i class="fa fa-check"></i><b>13.2</b> Área bajo la curva ROC</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#entrenamiento-con-caret"><i class="fa fa-check"></i><b>13.2.1</b> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#árboles-de-regresión"><i class="fa fa-check"></i><b>13.3</b> Árboles de regresión</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#entrenamiento-con-caret-1"><i class="fa fa-check"></i><b>13.3.1</b> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagged-trees"><i class="fa fa-check"></i><b>13.4</b> Bagged trees</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-árboles-de-clasificación"><i class="fa fa-check"></i><b>13.4.1</b> Bagging árboles de clasificación</a></li>
<li class="chapter" data-level="13.4.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-árboles-de-regresión"><i class="fa fa-check"></i><b>13.4.2</b> Bagging árboles de regresión</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest"><i class="fa fa-check"></i><b>13.5</b> Random Forest</a></li>
<li class="chapter" data-level="13.6" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest-pn"><i class="fa fa-check"></i><b>13.6</b> Random Forest p&gt;&gt;n</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>14</b> Boosting</a>
<ul>
<li class="chapter" data-level="14.1" data-path="boosting.html"><a href="boosting.html#cómo-funciona-el-boosting"><i class="fa fa-check"></i><b>14.1</b> Cómo funciona el <em>boosting</em></a></li>
<li class="chapter" data-level="14.2" data-path="boosting.html"><a href="boosting.html#adaboost"><i class="fa fa-check"></i><b>14.2</b> AdaBoost</a></li>
<li class="chapter" data-level="14.3" data-path="boosting.html"><a href="boosting.html#gbm-básico"><i class="fa fa-check"></i><b>14.3</b> GBM básico</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="boosting.html"><a href="boosting.html#boostingHiperparam"><i class="fa fa-check"></i><b>14.3.1</b> Hiperparámetros</a></li>
<li class="chapter" data-level="14.3.2" data-path="boosting.html"><a href="boosting.html#implementación"><i class="fa fa-check"></i><b>14.3.2</b> Implementación</a></li>
<li class="chapter" data-level="14.3.3" data-path="boosting.html"><a href="boosting.html#estrategia-general-de-tuning"><i class="fa fa-check"></i><b>14.3.3</b> Estrategia general de <em>tuning</em></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="boosting.html"><a href="boosting.html#gbms-estocásticos"><i class="fa fa-check"></i><b>14.4</b> GBMs estocásticos</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="boosting.html"><a href="boosting.html#hiperparámetros-estocásticos"><i class="fa fa-check"></i><b>14.4.1</b> Hiperparámetros estocásticos</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="boosting.html"><a href="boosting.html#xgboost"><i class="fa fa-check"></i><b>14.5</b> XGBoost</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="boosting.html"><a href="boosting.html#reguralización"><i class="fa fa-check"></i><b>14.5.1</b> Reguralización</a></li>
<li class="chapter" data-level="14.5.2" data-path="boosting.html"><a href="boosting.html#estrategia-de-tuning"><i class="fa fa-check"></i><b>14.5.2</b> Estrategia de <em>tuning</em></a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="boosting.html"><a href="boosting.html#otros-algoritmos-gbm"><i class="fa fa-check"></i><b>14.6</b> Otros algoritmos GBM</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje Automático 1</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="caret" class="section level1" number="8">
<h1><span class="header-section-number">8</span> La librería <code>caret</code></h1>
<p>R es uno de los lenguajes de programación que más se usa en muchas disciplinas como la biomedicina, la economía y por supuesto, la estadísica. Al tratarse de un software libre, innumerables usuarios han podido implementar sus algoritmos, dando lugar a un número muy elevado de librerías donde encontrar prácticamente todas las técnicas de machine learning existentes. Sin embargo, esto tiene un lado negativo, cada paquete tiene una sintaxis, estructura e implementación propia, lo que dificulta su aprendizaje. El paquete <a href="http://topepo.github.io/caret/index.html">caret</a> (Classification And REgression Training ), desarrollado por Max Kuhn, es una interfaz que unifica bajo un único marco cientos de funciones de distintos paquetes, facilitando en gran medida todas las etapas de de preprocesado, entrenamiento, optimización y validación de modelos predictivos.</p>
<blockquote>
<p>El paquete caret ofrece tal cantidad de posibilidades que, difícilmente, pueden ser mostradas con un único ejemplo. En este capítulo describiremos toda las capacidades de esta libería con un un ejemplo utilizando regresión logística con la que ya estamos familiarizados. El resto de métodos de aprendizaje automático que veremos en el curso también se llevarán a cabo con esta librería y algunas específicas de cada método.</p>
</blockquote>
<p>Otros proyectos similares a <code>caret</code> son: <a href="https://mlr3.mlr-org.com/">mlr3</a>, <a href="https://h2o-release.s3.amazonaws.com/h2o/rel-lambert/5/docs-website/index.html#">H20</a> que veremos en este curso y que está orientado a Big Data y <a href="https://www.tidymodels.org/">tidymodels</a> que forma parte del mundo <code>tydiverse</code>.</p>
<p>Hay muchas funciones de modelado diferentes en R. Algunas tienen una sintaxis diferente para el entrenamiento y / o predicción de modelos. El paquete comenzó como una forma de proporcionar una interfaz uniforme para las funciones mismas, así como una forma de estandarizar las tareas comunes (como el ajuste de parámetros y la importancia de las variables).</p>
<p>La instalación de <code>caret</code> puede ser muy pesada ya que tiene muchas dependencias (todos las librerías que implementan los métodos de aprendizaje automático que se quieran usar). Es por ello que se recomienda instalar la versión mínima y luego ir instalando aquellas librerías que se requieran en función del método que se pretenda usar.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="caret.html#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>, </span>
<span id="cb437-2"><a href="caret.html#cb437-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">dependencies =</span> <span class="fu">c</span>(<span class="st">&quot;Depends&quot;</span>, <span class="st">&quot;Suggests&quot;</span>))</span></code></pre></div>
<p>Luego la librería se carga de la forma usual</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="caret.html#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<p>En este capítulo veremos como realizar:</p>
<ul>
<li>Preprocesamiento (con <code>caret</code> y con <code>recipes</code>)</li>
<li>Visualización</li>
<li>División de datos</li>
<li>Selección de variables</li>
<li>Ajuste de modelo mediante remuestreo</li>
<li>Estimación de la importancia de variables</li>
</ul>
<p>Para ilustrar el uso de esta librería con datos reales usaremos la base de datos Titanic que está en la librería con su mismo nombre. Este conjunto de datos contiene información sobre los pasajeros del Titanic, el transatlántico británico que se hundió en abril de 1912 durante su viaje inaugural desde Southampton a Nueva York. Entre la información almacenada se encuentran la edad, género, características socio-económicas de los pasajeros y si sobrevivieron o no al naufragio (variable respuesta). Este ejemplo puede que no sea muy útil desde un punto de vista científico (en las prácticas trabajaremos con otrods que sí son útiles), pero tienen una serie de características que los hacen idóneos para ser utilizados como ejemplo introductorio al machine learning:</p>
<ul>
<li><p>Contiene suficientes observaciones para entrenar modelos que consigan un poder predictivo alto.</p></li>
<li><p>Incluye tanto variables continuas como cualitativas, lo que permite mostrar diferentes análisis exploratorios.</p></li>
<li><p>La variable respuesta es binaria. Aunque la mayoría de los algoritmos de clasificación mostrados en este capítulo se generalizan para múltiples clases, su interpretación suele ser más sencilla cuando solo hay dos.</p></li>
<li><p>Contiene valores faltantes (<strong>missing</strong> data). La forma en que se manejan estos registros (eliminación o imputación) influye en gran medida en el modelo final.</p></li>
<li><p>Necesitan realizar un pre-procesamiento de datos (eliminación y creación de variables).</p></li>
</ul>
<p>Además, se trata de unos datos cuyas variables pueden entenderse de forma sencilla. Es intuitivo comprender el impacto que puede tener la edad, el sexo, la localización del camarote… en la supervivencia de los pasajeros. Este aspecto es muy importante a al hora de crear buenos modelos predictivos, ya que, comprender a fondo el problema que se pretende modelar es lo más importante para lograr buenos resultados.</p>
<p>La librería <code>titanic</code> contiene un conjunto de datos de entrenamiento y otros de test facilitados en la plataforma <a href="https://www.kaggle.com/c/titanic/data">Kaggle</a> que contiene muchos conjuntos de datos para trabajar con problemas de aprendizaje automático. Los datos test sólo sirven para tener otro conjunto de datos en los que evaluar el modelo, pero <em>no tienen la variable resultado</em> por lo que no se pueden usar para crear el modelo predictivo (Kaggle los usa para ver quién proponer el mejor modelo).</p>
<p>Los datos se cargan de forma habitual</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="caret.html#cb439-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb439-2"><a href="caret.html#cb439-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(titanic)</span>
<span id="cb439-3"><a href="caret.html#cb439-3" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> titanic_train</span></code></pre></div>
<div id="pre-procesado" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Pre-procesado</h2>
<div id="creación-de-variables" class="section level3" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Creación de variables</h3>
<p>El primer paso antes de realizar cualquier análisis estadístico, y en particular para entrenar un modelo predictivo, es llevar a cabo una exploración descriptiva de los datos. Este proceso permite entender mejor que información contiene cada variable, así como detectar posibles errores ya que podríamos encontrarnos con los siguientes problemas:</p>
<ul>
<li><p>Que una columna se haya almacenado con el tipo incorrecto: una variable numérica está siendo reconocida como texto.</p></li>
<li><p>Que una variable contenga valores que no tienen sentido: para indicar que no se dispone de la altura de una persona se introduce el valor cero o un espacio en blanco. No existe nadie cuya altura sea cero.</p></li>
<li><p>Que en una variable de tipo numérico se haya introducido una palabra en lugar de un número.</p></li>
</ul>
<p>Según la información disponible en Kaggle, nuestras variables contienen la siguiente información:</p>
<ul>
<li><p>PassengerId: identificador único del pasajero.</p></li>
<li><p>Survived: si el pasajero sobrevivió al naufragio, codificada como 0 (no) y 1 (si). Esta es la variable respuesta que interesa predecir.</p></li>
<li><p>Pclass: clase a la que pertenecía el pasajero: 1, 2 o 3.</p></li>
<li><p>Name: nombre del pasajero.</p></li>
<li><p>Sex: sexo del pasajero.</p></li>
<li><p>Age: edad del pasajero.</p></li>
<li><p>SibSp: número de hermanos, hermanas, hermanastros o hermanastras en el barco.</p></li>
<li><p>Parch: número de padres e hijos en el barco.</p></li>
<li><p>Ticket: identificador del billete.</p></li>
<li><p>Fare: precio pagado por el billete.</p></li>
<li><p>Cabin: identificador del camarote asignado al pasajero.</p></li>
<li><p>Embarked: puerto en el que embarcó el pasajero.</p></li>
</ul>
<p>Por ello, empezaremos comprobando que cada variable se ha almacenado con el tipo de valor que le corresponde, es decir, que las variables numéricas sean números y las cualitativas factor, character o booleanas. Recordemos que en R, cuando la variable es cualitativa, conviene convertirla en variable factor para que las funciones que implementan muchos de los métodos estadísticos que queremos usar puedan analizarlas de forma conveniente (i.e. dummy variables).</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="caret.html#cb440-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(datos)</span></code></pre></div>
<pre><code>Rows: 891
Columns: 12
$ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...
$ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...
$ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, ...
$ Name        &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (F...
$ Sex         &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;ma...
$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14,...
$ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, ...
$ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, ...
$ Ticket      &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;3...
$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625...
$ Cabin       &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;...
$ Embarked    &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S...</code></pre>
<p>Observamos que el único caso en el que el tipo de valor no se corresponde con la naturaleza de la variable es <code>Survived</code>. Aunque esta variable está codificada como 1 si el pasajero sobrevivió y 0 si murió, no conviene almacenarla en formato numérico, ya que esto puede llevar a errores como el de tratar de calcular su media. Para evitar este tipo de problemas, se recodifica la variable para que sus dos posibles niveles sean <code>Si/No</code> y se convierte a factor. Además, esta re-codificación también ayudará a que los resultados y gráficas se puedan leer fácilmente.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="caret.html#cb442-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Survived =</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(Survived <span class="sc">==</span> <span class="dv">1</span>, <span class="st">&quot;Si&quot;</span>, <span class="st">&quot;No&quot;</span>)))</span>
<span id="cb442-2"><a href="caret.html#cb442-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Survived)</span></code></pre></div>
<pre><code>
 No  Si 
549 342 </code></pre>
<p>La variable Pclass es cualitativa ordinal, es decir, toma distintos valores cualitativos ordenados siguiendo una escala establecida, aunque no es necesario que el intervalo entre mediciones sea uniforme. Por ejemplo, se asume que la diferencia entre primera y segunda clase es menor que la diferencia entre primera y tercera, sin embargo, las diferencias entre primera-segunda y segunda-tercera no tiene por qué ser iguales. Es por ello que es preferible guardar esta variable como factor</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="caret.html#cb444-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Pclass =</span> <span class="fu">as.factor</span>(Pclass))</span>
<span id="cb444-2"><a href="caret.html#cb444-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Pclass)</span></code></pre></div>
<pre><code>
  1   2   3 
216 184 491 </code></pre>
<p>Las variables SibSp y Parch son cuantitativas discretas, pueden tomar únicamente determinados valores numéricos. En este caso, al tratarse de número de personas (familiares e hijos), solo pueden ser números enteros. No existe una norma clara sobre como almacenar estas variables. Para este estudio exploratorio, dado que solo toman unos pocos valores, se decide almacenarlas como factor.</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="caret.html#cb446-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">SibSp =</span> <span class="fu">as.factor</span>(SibSp))</span>
<span id="cb446-2"><a href="caret.html#cb446-2" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Parch =</span> <span class="fu">as.factor</span>(Parch))</span></code></pre></div>
<p>Las variables Sex y Embarked también se convierten a tipo factor.</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="caret.html#cb447-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Sex =</span> <span class="fu">as.factor</span>(Sex))</span>
<span id="cb447-2"><a href="caret.html#cb447-2" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">mutate</span>(datos, <span class="at">Embarked =</span> <span class="fu">as.factor</span>(Embarked))</span></code></pre></div>
<p>Las variables Cabin y Embarked contienen "". Esto consideraría a este valor como una categoría, por lo que habría que hacer</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="caret.html#cb448-1" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>Cabin[datos<span class="sc">$</span>Cabin<span class="sc">==</span><span class="st">&quot;&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb448-2"><a href="caret.html#cb448-2" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>Embarked[datos<span class="sc">$</span>Embarked<span class="sc">==</span><span class="st">&quot;&quot;</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span></code></pre></div>
</div>
<div id="predictores-con-poca-variabilidad" class="section level3" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Predictores con poca variabilidad</h3>
<p>En algunas situaciones, el mecanismo de generación de datos puede crear predictores que solo tienen un valor único (es decir, un “predictor de varianza cero”). Para la mayoría de modelos de aprendizaje automático esto puede provocar que el modelo se bloquee o que el ajuste sea inestable.</p>
<p>De manera similar, los predictores categóricos pueden tener alguna categoría que ocurren con frecuencias muy bajas. Por ejemplo, esto ocurre con la variable número de hijos en el barco</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="caret.html#cb449-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>Parch)</span></code></pre></div>
<pre><code>
  0   1   2   3   4   5   6 
678 118  80   5   4   5   1 </code></pre>
<p>La preocupación aquí es que estos predictores pueden convertirse en predictores de varianza cero cuando los datos se dividen en submuestras de validación cruzada / bootstrap o que algunas muestras pueden tener una influencia muy grande en el modelo (valores influyentes). Es posible que estos predictores de “varianza cercana a cero” deban identificarse y eliminarse antes del modelado.</p>
<p>Para identificar estos tipos de predictores, se pueden calcular las siguientes dos métricas:</p>
<ul>
<li><p>la frecuencia del valor más prevalente sobre el segundo valor más frecuente (llamado “índice de frecuencia”), que estaría cerca de uno para los predictores con buen comportamiento y muy grande para datos altamente desequilibrados y</p></li>
<li><p>el “porcentaje de valores únicos” que es el número de valores únicos dividido por el número total de muestras (multiplicado por 100) que se acerca a cero a medida que aumenta la granularidad de los datos.</p></li>
</ul>
<p>Si la relación de frecuencia es mayor que un umbral preestablecido y el porcentaje de valor único es menor que un umbral, podríamos considerar que un predictor tiene una varianza cercana a cero.</p>
<p>No queremos identificar falsamente los datos que tienen baja granularidad pero están distribuidos de manera uniforme, como los datos de una distribución uniforme discreta. El uso de ambos criterios no debería detectar falsamente tales predictores.</p>
<p>Para realizar estos cálculos podemos usar la función <code>nearZeroVar ()</code> (el argumento saveMetrics se puede usar para mostrar los detalles y - por defecto el valor predeterminado es FALSE):</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="caret.html#cb451-1" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="fu">nearZeroVar</span>(datos, <span class="at">saveMetrics=</span> <span class="cn">TRUE</span>)</span>
<span id="cb451-2"><a href="caret.html#cb451-2" aria-hidden="true" tabindex="-1"></a>nzv</span></code></pre></div>
<pre><code>            freqRatio percentUnique zeroVar   nzv
PassengerId  1.000000   100.0000000   FALSE FALSE
Survived     1.605263     0.2244669   FALSE FALSE
Pclass       2.273148     0.3367003   FALSE FALSE
Name         1.000000   100.0000000   FALSE FALSE
Sex          1.837580     0.2244669   FALSE FALSE
Age          1.111111     9.8765432   FALSE FALSE
SibSp        2.909091     0.7856341   FALSE FALSE
Parch        5.745763     0.7856341   FALSE FALSE
Ticket       1.000000    76.4309764   FALSE FALSE
Fare         1.023810    27.8338945   FALSE FALSE
Cabin        1.000000    16.4983165   FALSE FALSE
Embarked     3.833333     0.3367003   FALSE FALSE</code></pre>
<p>La función <code>nearZeroVar</code> devuelve las posiciones con las variables marcadas como problemáticas. Podríamos crear una base de datos sin variables problemáticas de las siguiente forma:</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="caret.html#cb453-1" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="fu">nearZeroVar</span>(datos)</span>
<span id="cb453-2"><a href="caret.html#cb453-2" aria-hidden="true" tabindex="-1"></a>nzv</span></code></pre></div>
<pre><code>integer(0)</code></pre>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="caret.html#cb455-1" aria-hidden="true" tabindex="-1"></a>filteredDatos <span class="ot">&lt;-</span> <span class="fu">select</span>(datos, <span class="sc">-</span><span class="fu">all_of</span>(nzv))</span>
<span id="cb455-2"><a href="caret.html#cb455-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(datos)</span></code></pre></div>
<pre><code>[1] 891  12</code></pre>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="caret.html#cb457-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(filteredDatos)</span></code></pre></div>
<pre><code>[1] 891  12</code></pre>
<p>En este caso no hemos filtrado ninguna porque ninguna ha devuelto TRUE en las columnas <code>zeroVar</code> y <code>nzv</code> del objeto <code>nzv</code> cuando indicamos <code>saveMetrics= TRUE</code>.</p>
</div>
<div id="identificación-de-predictores-correlacionados" class="section level3" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Identificación de predictores correlacionados</h3>
<p>Algunos de los modelos que vamos a estudiar pueden tratar con predictores correlacionados (como pls). Sin embargo, otros modelos pueden beneficiarse al reducir el nivel de correlación entre los predictores.</p>
<p>Dada una matriz de correlación, la función <code>findCorrelation()</code> es útil para marcar los predictores que deben ser eliminados por su alta correlación con otros:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="caret.html#cb459-1" aria-hidden="true" tabindex="-1"></a>descrCor <span class="ot">&lt;-</span>  <span class="fu">cor</span>(filteredDatos)</span>
<span id="cb459-2"><a href="caret.html#cb459-2" aria-hidden="true" tabindex="-1"></a>highCorr <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">abs</span>(descrCor[<span class="fu">upper.tri</span>(descrCor)]) <span class="sc">&gt;</span> .<span class="dv">99</span>)</span></code></pre></div>
<p>Dado que en nuestro caso la mayoría de variables son categóricas, no tiene mucho sentido llevar a cabo este pre-proceso. Además, la función <code>cor()</code> sólo puede aplicarse a datos continuos. Existen otras funciones para calcular las correlaciones entre variables categóricas, que deberían implementarse de forma manual.</p>
</div>
<div id="centrado-y-escalado-1" class="section level3" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Centrado y escalado</h3>
<p>En ocasiones es recomendable centrar y escalar las variables continuas para evitar que aquellas vairables con rangos mayores tengan más importancia. Esto se puede hacer de forma sencilla con la función <code>preProcess</code> de la siguiente manera</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="caret.html#cb460-1" aria-hidden="true" tabindex="-1"></a>datosTransf <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(datos, <span class="at">method=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span>
<span id="cb460-2"><a href="caret.html#cb460-2" aria-hidden="true" tabindex="-1"></a>datosTransf</span></code></pre></div>
<pre><code>Created from 183 samples and 12 variables

Pre-processing:
  - centered (3)
  - ignored (9)
  - scaled (3)</code></pre>
<p>Vemos que este escalado y centrado no se ha aplicado a 7 de las 12 variables ya que no variables categóricas o carácter.</p>
<p>También podemos transformar nuestros datos para garantizar normalidad utilizando transformacines exponenciales (“expoTrans”), Box-Cox (“BoxCox”) o Yeo-Johnson (“YeoJohnson”). Esto se puede hacer de forma sencilla mediante</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="caret.html#cb462-1" aria-hidden="true" tabindex="-1"></a>preProc <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(datos, <span class="at">method=</span><span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>, <span class="st">&quot;YeoJohnson&quot;</span>))</span>
<span id="cb462-2"><a href="caret.html#cb462-2" aria-hidden="true" tabindex="-1"></a>preProc</span></code></pre></div>
<pre><code>Created from 183 samples and 12 variables

Pre-processing:
  - centered (3)
  - ignored (9)
  - scaled (3)
  - Yeo-Johnson transformation (3)

Lambda estimates for Yeo-Johnson transformation:
0.71, 0.76, -0.1</code></pre>
<p>Los valores Lambda corresponden a las diferentes transformaciones usadas para cada unos de las variables según la definición que se puede encontrar <a href="(https://en.wikipedia.org/wiki/Power_transform)">aquí</a>. Este objeto tiene toda la información para centrar, escalar, transformar, e incluso eliminar o no variables.</p>
</div>
<div id="imputación" class="section level3" number="8.1.5">
<h3><span class="header-section-number">8.1.5</span> Imputación</h3>
<p>En el capítulo de modelización ya hablamos de este tema. La librería <code>caret</code> facilita la imputación mediante la función <code>preProcess()</code>. Basta con usar en el argumento <code>method</code> cualquiera de estas approximaciones: “knnImpute,” “bagImpute,” “medianImpute.”</p>
<p><strong>NOTA</strong>: también se podría usar “zv” y “nzv” para eliminar aquellos predictores con poca variabilidad, así que todos los pasos se pueden hacer con la función <code>preProcess()</code> [ver ayuda de la función para más detalles]</p>
</div>
<div id="pre-procesado-con-la-librería-recipes" class="section level3" number="8.1.6">
<h3><span class="header-section-number">8.1.6</span> Pre-procesado con la librería <code>recipes</code></h3>
<p>El preprocesado de datos engloba aquellas transformaciones de los datos hechas con la finalidad de que puedan ser aceptados por el algoritmo de machine learning o que mejoren sus resultados. Todo preprocesado de datos debe aprenderse de las observaciones de entrenamiento y luego aplicarse al conjunto de entrenamiento y al de test. Esto es muy importante para no violar la condición de que ninguna información procedente de las observaciones de test puede participar o influir en el ajuste del modelo. Aunque no es posible crear un único listado, algunos pasos de preprocesado que más suelen aplicarse en la práctica son:</p>
<ul>
<li><p>Imputación de valores ausentes</p></li>
<li><p>Exclusión de variables con varianza próxima a cero</p></li>
<li><p>Reducción de dimensionalidad</p></li>
<li><p>Estandarización de las variables numéricas</p></li>
<li><p>Binarización de las variables cualitativas</p></li>
</ul>
<p>El paquete <code>caret</code> incorpora muchas funciones para preprocesar los datos. Sin embargo, para facilitar todavía más el aprendizaje de las transformaciones, únicamente con las observaciones de entrenamiento, y poder aplicarlas después a cualquier conjunto de datos, el mismo autor ha creado el paquete <code>recipes</code>.</p>
<p>La idea detrás de este paquete es la siguiente:</p>
<ol style="list-style-type: decimal">
<li>Definir cuál es la variable respuesta, los predictores y el set de datos de entrenamiento, <code>recipe()</code>.</li>
<li>Definir todas las transformaciones (escalado, selección, filtrado…) que se desea aplicar, <code>step_()</code>.</li>
<li>Aprender los parámetros necesarios para dichas transformaciones con las observaciones de entrenamiento <code>rep()</code>.</li>
<li>Aplicar las trasformaciones aprendidas a cualquier conjunto de datos <code>bake()</code>.</li>
</ol>
<p>En los siguientes apartados, se almacenan en un objeto recipe todos los pasos de preprocesado y, finalmente, se aplican a los datos.</p>
<div id="imputación-de-valores-ausentes" class="section level4" number="8.1.6.1">
<h4><span class="header-section-number">8.1.6.1</span> Imputación de valores ausentes</h4>
<p>Para ver qué cantidad de datos faltantes hay podemos crear la siguiente figura:</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="caret.html#cb464-1" aria-hidden="true" tabindex="-1"></a>datos_long <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span> <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">&quot;variable&quot;</span>, <span class="at">value =</span> <span class="st">&quot;valor&quot;</span>, <span class="sc">-</span>PassengerId)</span>
<span id="cb464-2"><a href="caret.html#cb464-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb464-3"><a href="caret.html#cb464-3" aria-hidden="true" tabindex="-1"></a>datos_long <span class="sc">%&gt;%</span></span>
<span id="cb464-4"><a href="caret.html#cb464-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(variable) <span class="sc">%&gt;%</span> </span>
<span id="cb464-5"><a href="caret.html#cb464-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">porcentaje_NA =</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">is.na</span>(valor)) <span class="sc">/</span> <span class="fu">length</span>(valor)) <span class="sc">%&gt;%</span></span>
<span id="cb464-6"><a href="caret.html#cb464-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(variable, <span class="fu">desc</span>(porcentaje_NA)), <span class="at">y =</span> porcentaje_NA)) <span class="sc">+</span></span>
<span id="cb464-7"><a href="caret.html#cb464-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb464-8"><a href="caret.html#cb464-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Porcentaje valores ausentes por variable&quot;</span>,</span>
<span id="cb464-9"><a href="caret.html#cb464-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> <span class="st">&quot;Variable&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Porcentaje NAs&quot;</span>) <span class="sc">+</span></span>
<span id="cb464-10"><a href="caret.html#cb464-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="fig/unnamed-chunk-167-1.png" width="672" /></p>
<p>Podemos observar que las variables “Cabin,” “Age” y “Embarked” contienen valores ausentes. La gran mayoría de algoritmos no aceptan observaciones incompletas, por lo que, cuando el set de datos contiene valores ausentes, se puede:</p>
<ul>
<li><p>Eliminar aquellas observaciones que estén incompletas.</p></li>
<li><p>Eliminar aquellas variables que contengan valores ausentes.</p></li>
<li><p>Tratar de estimar los valores ausentes empleando el resto de información disponible (imputación).</p></li>
</ul>
<p>Las primeras dos opciones, aunque sencillas, suponen perder información. La eliminación de observaciones solo puede aplicarse cuando se dispone de muchas y el porcentaje de registros incompletos es muy bajo. En el caso de eliminar variables, el impacto dependerá de cuanta información aporten dichas variables al modelo.</p>
<p>Cuando se emplea imputación, es muy importante tener en cuenta el riesgo que se corre al introducir valores en predictores que tengan mucha influencia en el modelo. Supóngase un estudio médico en el que, cuando uno de los predictores es positivo, el modelo predice casi siempre que el paciente está sano. Para un paciente cuyo valor de este predictor se desconoce, el riesgo de que la imputación sea errónea es muy alto, por lo que es preferible obtener una predicción basada únicamente en la información disponible. Esta es otra muestra de la importancia que tiene que el analista conozca el problema al que se enfrenta y pueda así tomar la mejor decisión.</p>
<p>En el conjunto de datos <code>Titanic</code>, si se eliminan las observaciones incompletas, se pasa de 891 observaciones a 714, por lo que esta no es una opción.</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="caret.html#cb465-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(datos)</span></code></pre></div>
<pre><code>[1] 891</code></pre>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="caret.html#cb467-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(datos[<span class="fu">complete.cases</span>(datos),])</span></code></pre></div>
<pre><code>[1] 183</code></pre>
<p>La variable Cabin está ausente para casi un 80% de las observaciones, con un porcentaje tan alto de valores ausentes, no es conveniente imputarla, se excluye directamente del modelo. Esto deja al modelo con dos variables que requieren de imputación: Age y Embarked.</p>
<p>La imputación es un proceso complejo que debe de realizarse con detenimiento, identificando cuidadosamente qué variables son las adecuadas para cada imputación. La librería <code>recipes</code> permite 4 métodos de imputación distintos:</p>
<ul>
<li><p><code>step_bagimpute()</code>: imputación vía Bagged Trees.</p></li>
<li><p><code>step_knnimpute()</code>: imputación vía K-Nearest Neighbors.</p></li>
<li><p><code>step_meanimpute()</code>: imputación vía media del predictor (predictores continuos).</p></li>
<li><p><code>step_modeimpute()</code>: imputación vía moda del predictor (predictores cualitativos).</p></li>
</ul>
<p>Como ya vimos en su momento, las librerías <code>Hmisc</code>, <code>missForest</code> y <code>MICE</code> también permiten aplicar otros métodos.</p>
<p>Se imputa la variable Embarked con el valor C (más frecuene). Como no existe una función <code>step()</code> que haga sustituciones por valores concretos, se realiza una sustitución de forma externa al <code>recipe</code>.</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="caret.html#cb469-1" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span></span>
<span id="cb469-2"><a href="caret.html#cb469-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Embarked =</span> <span class="fu">replace</span>(Embarked, <span class="fu">is.na</span>(Embarked), <span class="st">&quot;C&quot;</span>))</span></code></pre></div>
<p>La variable Age se imputa con el método bagging empleando todos los otros predictores.</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="caret.html#cb470-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span>
<span id="cb470-2"><a href="caret.html#cb470-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Se crea un objeto recipe() con la variable respuesta y los predictores. </span></span>
<span id="cb470-3"><a href="caret.html#cb470-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Las variables *PassengerId*, *Name*, *Ticket* no parecen aportar información</span></span>
<span id="cb470-4"><a href="caret.html#cb470-4" aria-hidden="true" tabindex="-1"></a><span class="co"># relevante sobre la supervivencia de los pasajeros. Excluyendo todas estas</span></span>
<span id="cb470-5"><a href="caret.html#cb470-5" aria-hidden="true" tabindex="-1"></a><span class="co"># variables, se propone como modelo inicial el formado por los predictores:</span></span>
<span id="cb470-6"><a href="caret.html#cb470-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  Pclass + Sex + SibSp + Parch + Fare + Embarked + Age.</span></span>
<span id="cb470-7"><a href="caret.html#cb470-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb470-8"><a href="caret.html#cb470-8" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(<span class="at">formula =</span> Survived <span class="sc">~</span> Pclass <span class="sc">+</span> Sex <span class="sc">+</span> SibSp <span class="sc">+</span> Parch <span class="sc">+</span></span>
<span id="cb470-9"><a href="caret.html#cb470-9" aria-hidden="true" tabindex="-1"></a>                                  Fare <span class="sc">+</span> Embarked <span class="sc">+</span> Age,</span>
<span id="cb470-10"><a href="caret.html#cb470-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span>  datos)</span>
<span id="cb470-11"><a href="caret.html#cb470-11" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7</code></pre>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="caret.html#cb472-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_bagimpute</span>(Age)</span>
<span id="cb472-2"><a href="caret.html#cb472-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Operations:

Bagged tree imputation for Age</code></pre>
<p>NOTA: este objeto no es la imputación, es la <code>recipe</code> para realizarla. La idea es seguir haciendo pasos de pre-proceso y al final aplicarlos a nuestros datos</p>
</div>
<div id="variables-con-varianza-próxima-a-cero" class="section level4" number="8.1.6.2">
<h4><span class="header-section-number">8.1.6.2</span> Variables con varianza próxima a cero</h4>
<p>No se deben incluir en el modelo predictores que contengan un único valor (cero-varianza) ya que no aportan información. Tampoco es conveniente incluir predictores que tengan una varianza próxima a cero, es decir, predictores que toman solo unos pocos valores, de los cuales, algunos aparecen con muy poca frecuencia. El problema con estos últimos es que pueden convertirse en predictores con varianza cero cuando se dividen las observaciones por validación cruzada o bootstrap.</p>
<p>La función <code>nearZeroVar()</code> del paquete <code>caret</code> y <code>step_nzv()</code> del paquete <code>recipe</code> identifican como predictores potencialmente problemáticos aquellos que tienen un único valor (cero varianza) o que cumplen las dos siguientes condiciones:</p>
<ul>
<li><p>Ratio de frecuencias: ratio entre la frecuencia del valor más común y la frecuencia del segundo valor más común. Este ratio tiende a 1 si las frecuencias están equidistribuidas y a valores grandes cuando la frecuencia del valor mayoritario supera por mucho al resto (el denominador es un número decimal pequeño). Valor por defecto freqCut = 95/5.</p></li>
<li><p>Porcentaje de valores únicos: número de valores únicos dividido entre el total de muestras (multiplicado por 100). Este porcentaje se aproxima a cero cuanto mayor es la variedad de valores. Valor por defecto uniqueCut = 10.</p></li>
</ul>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="caret.html#cb474-1" aria-hidden="true" tabindex="-1"></a>datos <span class="sc">%&gt;%</span> <span class="fu">select</span>(Pclass, Sex, SibSp, Parch, Fare, Embarked, Age) <span class="sc">%&gt;%</span></span>
<span id="cb474-2"><a href="caret.html#cb474-2" aria-hidden="true" tabindex="-1"></a>          <span class="fu">nearZeroVar</span>(<span class="at">saveMetrics =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>         freqRatio percentUnique zeroVar   nzv
Pclass    2.273148     0.3367003   FALSE FALSE
Sex       1.837580     0.2244669   FALSE FALSE
SibSp     2.909091     0.7856341   FALSE FALSE
Parch     5.745763     0.7856341   FALSE FALSE
Fare      1.023810    27.8338945   FALSE FALSE
Embarked  3.788235     0.3367003   FALSE FALSE
Age       1.111111     9.8765432   FALSE FALSE</code></pre>
<p>Entre los predictores incluidos en el modelo, no se detecta ninguno con varianza cero o próxima a cero. Actualizamos nuestro objeto <code>recipe</code></p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="caret.html#cb476-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p>Si bien la eliminación de predictores no informativos podría considerarse un paso propio del proceso de selección de predictores, dado que consiste en un filtrado por varianza, tiene que realizarse antes de estandarizar los datos, ya que después, todos los predictores tienen varianza 1.</p>
</div>
<div id="normalización-de-datos" class="section level4" number="8.1.6.3">
<h4><span class="header-section-number">8.1.6.3</span> Normalización de datos</h4>
<p>Como ya hemos mencionado anteriormente, también podemos transformar nuestros datos para garantizar normalidad utilizando transformaciones Box-Cox (“BoxCox”) o Yeo-Johnson (“YeoJohnson”). Esto se puede hacer de forma sencilla mediante</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="caret.html#cb477-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_BoxCox</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>ó</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="caret.html#cb478-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_YeoJohnson</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>respectivamente.</p>
</div>
<div id="estandarización-y-escalado" class="section level4" number="8.1.6.4">
<h4><span class="header-section-number">8.1.6.4</span> Estandarización y escalado</h4>
<p>Cuando los predictores son numéricos, la escala en la que se miden, así como la magnitud de su varianza pueden influir en gran medida en el modelo. Muchos algoritmos de machine learning (SVM, redes neuronales, lasso…) son sensibles a esto, de forma que, si no se igualan de alguna forma los predictores, aquellos que se midan en una escala mayor o que tengan más varianza, dominarán el modelo aunque no sean los que más relación tienen con la variable respuesta. Existen principalmente 2 estrategias para evitarlo:</p>
<ul>
<li><p><em>Centrado</em>: consiste en restarle a cada valor la media del predictor al que pertenece. Si los datos están almacenados en un dataframe, el centrado se consigue restándole a cada valor la media de la columna en la que se encuentra. Como resultado de esta transformación, todos los predictores pasan a tener una media de cero, es decir, los valores se centran en torno al origen.</p></li>
<li><p><em>Normalización (estandarización)</em>: consiste en transformar los datos de forma que todos los predictores estén aproximadamente en la misma escala (centrado + escalado).</p></li>
</ul>
<p>Con este código se normalizan todas las variables numéricas.</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="caret.html#cb479-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_center</span>(<span class="fu">all_numeric</span>())</span>
<span id="cb479-2"><a href="caret.html#cb479-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p>Nunca se debe estandarizar las variables después de ser binarizadas (ver siguiente sección).</p>
</div>
<div id="binarización-de-variables-cuantitativas" class="section level4" number="8.1.6.5">
<h4><span class="header-section-number">8.1.6.5</span> Binarización de variables cuantitativas</h4>
<p>La binarización consiste en crear nuevas variables dummy con cada uno de los niveles de las variables cualitativas. Por ejemplo, una variable llamada color que contenga los niveles rojo, verde y azul, se convertirá en tres nuevas variables (color_rojo, color_verde, color_azul), todas con el valor 0 excepto la que coincide con la observación, que toma el valor 1.</p>
<p>Por defecto, la función <code>step_dummy(all_nominal())</code> binariza todas las variables almacenadas como tipo factor o character. Además, elimina uno de los niveles para evitar redundancias. Volviendo al ejemplo anterior, no es necesario almacenar las tres variables, ya que, si color_rojo y color_verde toman el valor 0, la variable color_azul toma necesariamente el valor 1. Si color_rojo o color_verde toman el valor 1, entonces color_azul es necesariamente 0.</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="caret.html#cb480-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>(),</span>
<span id="cb480-2"><a href="caret.html#cb480-2" aria-hidden="true" tabindex="-1"></a>                                              <span class="sc">-</span><span class="fu">all_outcomes</span>())</span></code></pre></div>
<p>Finalmente, esto es lo que hemos preparado para pre-procesar nuestros datos:</p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="caret.html#cb481-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Operations:

Bagged tree imputation for Age
Sparse, unbalanced variable filter on all_predictors()
Centering for all_numeric()
Scaling for all_numeric()
Dummy variables from all_nominal(), -all_outcomes()</code></pre>
</div>
<div id="obtención-de-datos-para-entrenar" class="section level4" number="8.1.6.6">
<h4><span class="header-section-number">8.1.6.6</span> Obtención de datos para entrenar</h4>
<p>Una vez que se ha creado el objeto recipe con todas las transformaciones de preprocesado, se aprende con los datos de entrenamiento y se aplican a los dos conjuntos de datos.</p>
<p><strong>IMPORTANTE</strong> Para nosotros el objeto <code>datos</code> es nuestro train, y aplicamos estas <code>recipe</code> a estos datos y luego también tenemos que aplicarlo a los datos train para que las variables con las que hagamos predicciones estén en las mismas escalas, sin valores faltantes, cero-varianza, etc.</p>
<ul>
<li><em>Paso 1</em>: Se entrena el objeto <code>recipe</code></li>
</ul>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="caret.html#cb483-1" aria-hidden="true" tabindex="-1"></a>trained_recipe <span class="ot">&lt;-</span> <span class="fu">prep</span>(objeto_recipe, <span class="at">training =</span> datos)</span>
<span id="cb483-2"><a href="caret.html#cb483-2" aria-hidden="true" tabindex="-1"></a>trained_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Training data contained 891 data points and 177 incomplete rows. 

Operations:

Bagged tree imputation for Age [trained]
Sparse, unbalanced variable filter removed no terms [trained]
Centering for Fare, Age [trained]
Scaling for Fare, Age [trained]
Dummy variables from Pclass, Sex, SibSp, Parch, Embarked [trained]</code></pre>
<ul>
<li><em>Paso 2</em>: Se aplican las transformaciones al conjunto de entrenamiento y de test (en nuestro caso sólo tenemos train)</li>
</ul>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="caret.html#cb485-1" aria-hidden="true" tabindex="-1"></a>datos_train_transf <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> datos)</span>
<span id="cb485-2"><a href="caret.html#cb485-2" aria-hidden="true" tabindex="-1"></a><span class="co"># datos_test_prep  &lt;- bake(trained_recipe, new_data = datos_test)</span></span>
<span id="cb485-3"><a href="caret.html#cb485-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-4"><a href="caret.html#cb485-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(datos_train_transf)</span></code></pre></div>
<pre><code>Rows: 891
Columns: 21
$ Fare       &lt;dbl&gt; -0.50216314, 0.78640362, -0.48857985, 0.42049407, -0.48606...
$ Age        &lt;dbl&gt; -0.57161891, 0.62175764, -0.27327478, 0.39799954, 0.397999...
$ Survived   &lt;fct&gt; No, Si, Si, Si, No, No, No, No, Si, Si, Si, Si, No, No, No...
$ Pclass_X2  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0...
$ Pclass_X3  &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1...
$ Sex_male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0...
$ SibSp_X1   &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0...
$ SibSp_X2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ SibSp_X3   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ SibSp_X4   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0...
$ SibSp_X5   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ SibSp_X8   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ Parch_X1   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0...
$ Parch_X2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ Parch_X3   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ Parch_X4   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ Parch_X5   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0...
$ Parch_X6   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
$ Embarked_C &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1...
$ Embarked_Q &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0...
$ Embarked_S &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0...</code></pre>
</div>
</div>
</div>
<div id="visualización" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Visualización</h2>
<p>Podemos empezar con unos gráficos para las variables continuas de la siguiente forma:</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="caret.html#cb487-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb487-2"><a href="caret.html#cb487-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span>
<span id="cb487-3"><a href="caret.html#cb487-3" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">4</span>)</span>
<span id="cb487-4"><a href="caret.html#cb487-4" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb487-5"><a href="caret.html#cb487-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived, </span>
<span id="cb487-6"><a href="caret.html#cb487-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;pairs&quot;</span>,</span>
<span id="cb487-7"><a href="caret.html#cb487-7" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Add a key at the top</span></span>
<span id="cb487-8"><a href="caret.html#cb487-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-181-1.png" width="672" /></p>
<p>ó</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="caret.html#cb488-1" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">9</span>)</span>
<span id="cb488-2"><a href="caret.html#cb488-2" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb488-3"><a href="caret.html#cb488-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived,</span>
<span id="cb488-4"><a href="caret.html#cb488-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;density&quot;</span>, </span>
<span id="cb488-5"><a href="caret.html#cb488-5" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to xyplot() to </span></span>
<span id="cb488-6"><a href="caret.html#cb488-6" aria-hidden="true" tabindex="-1"></a>            <span class="do">## make it prettier</span></span>
<span id="cb488-7"><a href="caret.html#cb488-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), </span>
<span id="cb488-8"><a href="caret.html#cb488-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>)), </span>
<span id="cb488-9"><a href="caret.html#cb488-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">adjust =</span> <span class="fl">1.5</span>, </span>
<span id="cb488-10"><a href="caret.html#cb488-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">pch =</span> <span class="st">&quot;|&quot;</span>, </span>
<span id="cb488-11"><a href="caret.html#cb488-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), </span>
<span id="cb488-12"><a href="caret.html#cb488-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-182-1.png" width="672" /></p>
<p>ó</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="caret.html#cb489-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(datos_train_transf, <span class="fu">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Fare&quot;</span>)), </span>
<span id="cb489-2"><a href="caret.html#cb489-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> datos_train_transf<span class="sc">$</span>Survived, </span>
<span id="cb489-3"><a href="caret.html#cb489-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;box&quot;</span>, </span>
<span id="cb489-4"><a href="caret.html#cb489-4" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to bwplot() </span></span>
<span id="cb489-5"><a href="caret.html#cb489-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>),</span>
<span id="cb489-6"><a href="caret.html#cb489-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">x =</span> <span class="fu">list</span>(<span class="at">rot =</span> <span class="dv">90</span>)),  </span>
<span id="cb489-7"><a href="caret.html#cb489-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), </span>
<span id="cb489-8"><a href="caret.html#cb489-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-183-1.png" width="672" /></p>
</div>
<div id="ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Ejemplo completo: creación de modelo diagnóstico para cáncer de mama</h2>
<p>Para illustrar el uso de esta librería con datos reales, usaremos una base de datos que contiene datos de un estudio sobre diagnóstico del cáncer de mama por imagen. Mediante una punción con aguja fina se extrae una muestra del tejido sospechoso de la paciente. La muestra se tiñe para resaltar los núcleos de las células y se determinan los límites exactos de los núcleos. Las variables consideradas corresponden a distintos aspectos de la forma del núcleo. El fichero <code>breast.csv</code> accesible en el Moodle contiene 30 variables explicativas medidas en pacientes cuyos tumores fueron diagnosticados posteriormente como benignos o malignos (variable <code>diagnosis</code> considerada como la variable resultado). Hay 569 observaciones, de las que 357 corresponden a tumores benignos y 212 a tumores malignos. La primera variable (<code>id</code>) corresponde al identificador de paciente. Información adicional sobre estos datos se pueden encontrar <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">aquí</a>.</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="caret.html#cb490-1" aria-hidden="true" tabindex="-1"></a>breast <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_delim</span>(<span class="st">&quot;data/breast.csv&quot;</span>, <span class="at">delim=</span><span class="st">&quot;,&quot;</span>)</span></code></pre></div>
<p>Podemos hacer servir <code>caret</code> o <code>recipes</code> para llevar a cabo todos estos pasos. Lo haremos con <code>recipes</code> que controlamos un poco más qué estamos llevando a cabo en cada momento.</p>
<p><strong>Paso 1</strong>: Visualizar la información de la que disponemos y ver si las variables están en el formato que corresponde</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="caret.html#cb491-1" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">glimpse</span>(breast)</span></code></pre></div>
<pre><code>Rows: 569
Columns: 32
$ id                      &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402,...
$ diagnosis               &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, ...
$ radius_mean             &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.45...
$ texture_mean            &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19....
$ perimeter_mean          &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57,...
$ area_mean               &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1,...
$ smoothness_mean         &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, ...
$ compactness_mean        &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, ...
$ concavity_mean          &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, ...
$ `concave points_mean`   &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, ...
$ symmetry_mean           &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.208...
$ fractal_dimension_mean  &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, ...
$ radius_se               &lt;dbl&gt; 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.334...
$ texture_se              &lt;dbl&gt; 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.890...
$ perimeter_se            &lt;dbl&gt; 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.1...
$ area_se                 &lt;dbl&gt; 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53...
$ smoothness_se           &lt;dbl&gt; 0.006399, 0.005225, 0.006150, 0.009110, 0.011...
$ compactness_se          &lt;dbl&gt; 0.049040, 0.013080, 0.040060, 0.074580, 0.024...
$ concavity_se            &lt;dbl&gt; 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, ...
$ `concave points_se`     &lt;dbl&gt; 0.015870, 0.013400, 0.020580, 0.018670, 0.018...
$ symmetry_se             &lt;dbl&gt; 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, ...
$ fractal_dimension_se    &lt;dbl&gt; 0.006193, 0.003532, 0.004571, 0.009208, 0.005...
$ radius_worst            &lt;dbl&gt; 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22....
$ texture_worst           &lt;dbl&gt; 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27....
$ perimeter_worst         &lt;dbl&gt; 184.60, 158.80, 152.50, 98.87, 152.20, 103.40...
$ area_worst              &lt;dbl&gt; 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6,...
$ smoothness_worst        &lt;dbl&gt; 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.179...
$ compactness_worst       &lt;dbl&gt; 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.524...
$ concavity_worst         &lt;dbl&gt; 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, ...
$ `concave points_worst`  &lt;dbl&gt; 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, ...
$ symmetry_worst          &lt;dbl&gt; 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.398...
$ fractal_dimension_worst &lt;dbl&gt; 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, ...</code></pre>
<p>Vemos que todas las variables excepto nuestro resultado (diagnosis: tipo de tumor) son continuas. Como la variable resultado es character, es recomendable pasarla a factor</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="caret.html#cb493-1" aria-hidden="true" tabindex="-1"></a>breast <span class="ot">&lt;-</span> <span class="fu">mutate</span>(breast, <span class="at">diagnosis=</span><span class="fu">as.factor</span>(diagnosis))</span></code></pre></div>
<p><strong>Paso 2:</strong> Puesto que no tenemos datos de entrenamiento y test, lo crearemos nosotros</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="caret.html#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb494-2"><a href="caret.html#cb494-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb494-3"><a href="caret.html#cb494-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb494-4"><a href="caret.html#cb494-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> breast<span class="sc">$</span>diagnosis, <span class="at">p =</span> <span class="fl">0.7</span>, </span>
<span id="cb494-5"><a href="caret.html#cb494-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">list =</span> <span class="cn">FALSE</span>, <span class="at">times =</span> <span class="dv">1</span>)</span>
<span id="cb494-6"><a href="caret.html#cb494-6" aria-hidden="true" tabindex="-1"></a>breast_train <span class="ot">&lt;-</span> breast[train, ]</span>
<span id="cb494-7"><a href="caret.html#cb494-7" aria-hidden="true" tabindex="-1"></a>breast_test  <span class="ot">&lt;-</span> breast[<span class="sc">-</span>train, ]</span></code></pre></div>
<p><strong>Paso 3:</strong> Crear un objeto <code>recipe</code> con la variable respuesta y los predictores</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="caret.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(recipes)</span>
<span id="cb495-2"><a href="caret.html#cb495-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(<span class="at">formula =</span> diagnosis <span class="sc">~</span> . ,</span>
<span id="cb495-3"><a href="caret.html#cb495-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span>  breast_train)</span>
<span id="cb495-4"><a href="caret.html#cb495-4" aria-hidden="true" tabindex="-1"></a><span class="co"># debemos eliminar la variable id que irrelevante para predecir</span></span>
<span id="cb495-5"><a href="caret.html#cb495-5" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_rm</span>(id)</span>
<span id="cb495-6"><a href="caret.html#cb495-6" aria-hidden="true" tabindex="-1"></a>objeto_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor         31

Operations:

Delete terms id</code></pre>
<p><strong>Paso 4:</strong> Veamos si tenemos datos faltantes</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="caret.html#cb497-1" aria-hidden="true" tabindex="-1"></a><span class="fu">any</span>(<span class="fu">is.na</span>(breast))</span></code></pre></div>
<pre><code>[1] FALSE</code></pre>
<p><strong>Paso 5:</strong> Puesto que no hay, podemos pasar al siguiente paso que sería ver si hay que eliminar variablaes con varianza próxima a cero. Empecemos viendo si hay alguna. Puesto que todas son continuas, esto nos facilitará la escritura en R no teniendo que usar la función <code>select ()</code> para seleccionar las varaibles continuas</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="caret.html#cb499-1" aria-hidden="true" tabindex="-1"></a>breast_train <span class="sc">%&gt;%</span> <span class="fu">nearZeroVar</span>(<span class="at">saveMetrics =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>                        freqRatio percentUnique zeroVar   nzv
id                       1.000000   100.0000000   FALSE FALSE
diagnosis                1.677852     0.5012531   FALSE FALSE
radius_mean              1.000000    86.2155388   FALSE FALSE
texture_mean             1.500000    88.9724311   FALSE FALSE
perimeter_mean           1.000000    93.9849624   FALSE FALSE
area_mean                1.000000    95.2380952   FALSE FALSE
smoothness_mean          1.000000    85.7142857   FALSE FALSE
compactness_mean         1.000000    96.4912281   FALSE FALSE
concavity_mean           3.000000    95.7393484   FALSE FALSE
concave points_mean      3.000000    96.7418546   FALSE FALSE
symmetry_mean            1.333333    81.2030075   FALSE FALSE
fractal_dimension_mean   1.500000    92.2305764   FALSE FALSE
radius_se                1.000000    95.4887218   FALSE FALSE
texture_se               1.000000    93.4837093   FALSE FALSE
perimeter_se             2.000000    94.9874687   FALSE FALSE
area_se                  1.500000    95.4887218   FALSE FALSE
smoothness_se            1.000000    97.2431078   FALSE FALSE
compactness_se           1.500000    96.2406015   FALSE FALSE
concavity_se             3.000000    95.2380952   FALSE FALSE
concave points_se        2.000000    91.7293233   FALSE FALSE
symmetry_se              1.000000    90.9774436   FALSE FALSE
fractal_dimension_se     1.000000    97.2431078   FALSE FALSE
radius_worst             1.333333    83.2080201   FALSE FALSE
texture_worst            1.000000    92.2305764   FALSE FALSE
perimeter_worst          1.500000    93.4837093   FALSE FALSE
area_worst               1.000000    96.4912281   FALSE FALSE
smoothness_worst         1.000000    78.9473684   FALSE FALSE
compactness_worst        1.500000    95.7393484   FALSE FALSE
concavity_worst          2.000000    96.7418546   FALSE FALSE
concave points_worst     2.000000    89.9749373   FALSE FALSE
symmetry_worst           1.500000    90.7268170   FALSE FALSE
fractal_dimension_worst  1.000000    96.4912281   FALSE FALSE</code></pre>
<p>Vemos que tampoco hay ninguna variable que tenga que ser eliminada por este motivo. Este paso no sería necesario realizarlo, pero lo dejamos para que sirva como ejemplo para otros casos</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="caret.html#cb501-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_nzv</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p><strong>Paso 6:</strong> El siguiente paso sería eliminar aquellas variables con correlación elevada. El argumento <code>threshold</code> nos permite elegir el grado de correlación que por defecto es 0.9.</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="caret.html#cb502-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_corr</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
<p><strong>Paso 7:</strong> Ahora centraremos y normalizaremos los datos (esto último no tiene porqué sere necesario). Recordamos que también se pueden transformar los datos para garantizar normalidad usando <code>preProcess()</code> con el métodos Box-Cox o Yeo-Johnson de <code>caret()</code>.</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="caret.html#cb503-1" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_center</span>(<span class="fu">all_numeric</span>())</span>
<span id="cb503-2"><a href="caret.html#cb503-2" aria-hidden="true" tabindex="-1"></a>objeto_recipe <span class="ot">&lt;-</span> objeto_recipe <span class="sc">%&gt;%</span> <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>())</span></code></pre></div>
<p><strong>Paso 8</strong>: La binarización de variables no es necesario</p>
<p><strong>Paso 9</strong>: Aprendizaje de las transformaciones de pre-procesado y aplicación a nuestros conjuntos de datos. Empezamos con el entrenamiento</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="caret.html#cb504-1" aria-hidden="true" tabindex="-1"></a>trained_recipe <span class="ot">&lt;-</span> <span class="fu">prep</span>(objeto_recipe, <span class="at">training =</span> breast_train)</span>
<span id="cb504-2"><a href="caret.html#cb504-2" aria-hidden="true" tabindex="-1"></a>trained_recipe</span></code></pre></div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor         31

Training data contained 399 data points and no missing data.

Operations:

Variables removed id [trained]
Sparse, unbalanced variable filter removed no terms [trained]
Correlation filter removed perimeter_mean, perimeter_se, ... [trained]
Centering for texture_mean, area_mean, ... [trained]
Scaling for texture_mean, area_mean, ... [trained]</code></pre>
<p>y continuamos con la aplicación a nuestros datos test y train</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="caret.html#cb506-1" aria-hidden="true" tabindex="-1"></a>breast_train_prep <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> breast_train)</span>
<span id="cb506-2"><a href="caret.html#cb506-2" aria-hidden="true" tabindex="-1"></a>breast_test_prep  <span class="ot">&lt;-</span> <span class="fu">bake</span>(trained_recipe, <span class="at">new_data =</span> breast_test)</span>
<span id="cb506-3"><a href="caret.html#cb506-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb506-4"><a href="caret.html#cb506-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(breast_train_prep)</span></code></pre></div>
<pre><code>Rows: 399
Columns: 20
$ texture_mean            &lt;dbl&gt; 0.4958449, 0.2881680, -1.1536351, -0.8289907,...
$ area_mean               &lt;dbl&gt; 1.57356630, -0.76566930, 1.84274018, -0.50508...
$ smoothness_mean         &lt;dbl&gt; 0.86440333, 3.11247741, 0.22892950, 2.1080187...
$ compactness_mean        &lt;dbl&gt; 1.04870954, 3.38781648, 0.53750149, 1.2392335...
$ symmetry_mean           &lt;dbl&gt; 0.917687339, 2.799401020, -0.008914095, 0.981...
$ fractal_dimension_mean  &lt;dbl&gt; -0.42639724, 4.98925612, -0.59414511, 1.90761...
$ texture_se              &lt;dbl&gt; -0.80849714, -0.08080732, -0.81953767, -0.604...
$ area_se                 &lt;dbl&gt; 1.31855202, -0.28815366, 1.32841354, -0.28911...
$ smoothness_se           &lt;dbl&gt; -0.30223259, 0.65056583, 1.41666726, 0.135539...
$ compactness_se          &lt;dbl&gt; 0.85265446, 2.83595905, -0.03500649, 0.472884...
$ concavity_se            &lt;dbl&gt; 0.30900888, 1.07030125, 1.08153957, 0.2424114...
$ `concave points_se`     &lt;dbl&gt; 1.630026033, 1.284095782, 1.316696538, -0.038...
$ symmetry_se             &lt;dbl&gt; 0.24097383, 4.68326185, -0.35005507, 0.139278...
$ fractal_dimension_se    &lt;dbl&gt; 0.392387187, 2.560158937, 0.646704166, 0.6312...
$ smoothness_worst        &lt;dbl&gt; 0.47944015, 3.24454482, 0.18348094, 1.9465522...
$ compactness_worst       &lt;dbl&gt; 1.05036897, 3.78488958, -0.30822603, 1.671794...
$ `concave points_worst`  &lt;dbl&gt; 1.9634318, 2.1840781, 0.7384643, 0.9149814, 0...
$ symmetry_worst          &lt;dbl&gt; 1.09719973, 5.76429394, -0.82980875, 1.671136...
$ fractal_dimension_worst &lt;dbl&gt; 0.17926376, 4.82187666, -0.40772078, 2.180446...
$ diagnosis               &lt;fct&gt; M, M, M, M, M, M, M, M, M, M, M, M, B, B, M, ...</code></pre>
<p><strong>Paso 10:</strong> Visualización</p>
<p>Hagamos algunos de los gráficos que hemos visto</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="caret.html#cb508-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AppliedPredictiveModeling)</span>
<span id="cb508-2"><a href="caret.html#cb508-2" aria-hidden="true" tabindex="-1"></a><span class="fu">transparentTheme</span>(<span class="at">trans =</span> .<span class="dv">4</span>)</span>
<span id="cb508-3"><a href="caret.html#cb508-3" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> <span class="fu">select</span>(breast_train_prep, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>), </span>
<span id="cb508-4"><a href="caret.html#cb508-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> breast_train_prep<span class="sc">$</span>diagnosis, </span>
<span id="cb508-5"><a href="caret.html#cb508-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;pairs&quot;</span>,</span>
<span id="cb508-6"><a href="caret.html#cb508-6" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Add a key at the top</span></span>
<span id="cb508-7"><a href="caret.html#cb508-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="fig/unnamed-chunk-196-1.png" width="672" /></p>
</div>
<div id="creación-de-un-modelo-predictivo" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Creación de un modelo predictivo</h2>
<p>Una vez que ya hemos preprocesado nuestros datos, podemos pasar a la parte de creación de un modelo. La librería <code>caret</code> tiene varias funciones que intenta reproducir lo que hasta ahora hemos realizado más o menos de forma manual.</p>
<p>La función <code>train</code> se puede usar para:</p>
<ul>
<li>evaluar, mediante remuestreo, el efecto de los parámetros de ajuste del modelo - elegir el modelo “óptimo” a través de estos parámetros</li>
<li>estimar el rendimiento del modelo a partir de un conjunto de entrenamiento</li>
</ul>
<p>Primero, se debe elegir un modelo específico. Actualmente, hay 238 disponibles que pueden consultarse <a href="https://topepo.github.io/caret/available-models.html">aquí</a>. Estos modelos los iremos viendo de forma individual a lo largo del curso y estudiaremos los parámetros que potencialmente pueden optimizarse. También se pueden crear modelos definidos por el usuario.</p>
<div class="figure">
<img src="figures/TrainAlgo.png" alt="" />
<p class="caption">Algoritmo de entrenamiento</p>
</div>
<p>El primer paso para ajustar el modelo (línea 1 en el algoritmo a continuación) es elegir un conjunto de parámetros para evaluar. Por ejemplo, si se ajusta a un modelo de mínimos cuadrados parciales (PLS), se debe especificar el número de componentes PLS a evaluar.</p>
<p>Una vez que se han definido el modelo y los valores de los parámetros de ajuste, también se debe especificar el tipo de remuestreo. Actualmente, tiene implementado LOOCV, K-fold CV y Bootstrap. Después del remuestreo, se obtiene una medida de ajuste para cada remuestra que permite guiar al usuario sobre qué valores de parámetros de ajuste deben elegirse. De forma predeterminada, la función elige automáticamente los parámetros de ajuste asociados con el mejor valor, aunque se pueden utilizar diferentes métricas.</p>
<p>Veamos cómo funcionaría en nuestro caso utilizando la regresión logística (dado que nuestro outcome es binario) como método de aprendizaje para la creación de un modelo predictivo.</p>
<p>Partimos del hecho que ya hemos hecho un pre-procesado de datos tal y como hemos mostrado anteriormente y que nuestros datos de entrenamiento y validación se llaman <code>breast_train_prep</code> y <code>breast_test_prep</code>, respectivamente. Por defecto el método utiliza boostrap para evaluar la capacidad predictiva del modelo. La función <code>trainControl()</code> se puede utilizar para especificar el tipo de remuestreo. Podéis encontrar más información sobre esta función <a href="https://topepo.github.io/caret/model-training-and-tuning.html#control">aquí</a>:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="caret.html#cb509-1" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="do">## 10-fold CV</span></span>
<span id="cb509-2"><a href="caret.html#cb509-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb509-3"><a href="caret.html#cb509-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb509-4"><a href="caret.html#cb509-4" aria-hidden="true" tabindex="-1"></a>                           <span class="do">## repeated ten times</span></span>
<span id="cb509-5"><a href="caret.html#cb509-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">repeats =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>Estamos haciendo una estimación de la capacidad predictiva del modelo con un 10-fold CV (argumento <code>number</code>) y lo repetimos 10 veces para garantizar aleatoriedad.</p>
<p>Despues usamos la función <code>train()</code></p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="caret.html#cb510-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb510-2"><a href="caret.html#cb510-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressMessages</span>(fit <span class="ot">&lt;-</span> <span class="fu">train</span>(diagnosis <span class="sc">~</span> ., <span class="at">data =</span> breast_train_prep, </span>
<span id="cb510-3"><a href="caret.html#cb510-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb510-4"><a href="caret.html#cb510-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">trControl =</span> fitControl))</span>
<span id="cb510-5"><a href="caret.html#cb510-5" aria-hidden="true" tabindex="-1"></a>fit</span></code></pre></div>
<pre><code>Generalized Linear Model 

399 samples
 19 predictor
  2 classes: &#39;B&#39;, &#39;M&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 
Summary of sample sizes: 360, 359, 359, 359, 359, 359, ... 
Resampling results:

  Accuracy   Kappa    
  0.9506731  0.8948839</code></pre>
<table style="width:94%;">
<colgroup>
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>EJERCICIO</strong> (Entrega en Moodle: P-Preproceso cáncer de cervix): Vamos analizar los datos pertenecientes a un estudio multicéntrico internacional caso-control de cáncer de cuello uterino realizado en 7 países: Brasil, Marruecos, Filipinas, Tailandia, Perú, España y Colombia. La base de datos contiene información sobre variables identificativas (<code>status</code> es la variable respuesta 0:Control - 1:Caso), demográficas, de riesgo incluyendo la presencia de infección por Virus del Papiloma Humano de 1489 casos de cáncer de cuello uterino y 1421 controles apareados por grupos de edad.</td>
</tr>
<tr class="even">
<td>&gt; Las variables pueden contener valores en blanco que corresponden a información perdida o que no procede.</td>
</tr>
<tr class="odd">
<td>La información de las variables se puede ver en el siguiente archivo html que se puede visualizar en su totalidad con la barra que hay en la derecha:</td>
</tr>
<tr class="even">
<td><embed src="data/multicentric.htm" style="width:105.0%" /></td>
</tr>
<tr class="odd">
<td>- Realiza todos los pasos de preprocesado necesarios para crear una base de datos de entrenamiento (70%) y otra de test (30%) que usaremos para otros ejercicios futuros correspondientes a los diferentes métodos de aprendizaje automático que veremos en este curso. Recordemos que la variable resultado es una variable binaria (status: 0-Control/1-Caso).</td>
</tr>
</tbody>
</table>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dealing-with-big-data-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="KNN.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/isglobal-brge/Aprendizaje_Automatico_1/tree/master/docs07-caret.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
